[2024-07-28T00:15:36.457+0000] {processor.py:157} INFO - Started process (PID=80341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:15:36.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:15:36.470+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:15:36.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:15:36.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:15:36.547+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:15:36.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:15:36.571+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:15:36.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:15:36.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-28T00:16:07.334+0000] {processor.py:157} INFO - Started process (PID=80366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:16:07.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:16:07.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:07.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:16:07.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:16:07.400+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:07.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:16:07.413+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:07.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:16:07.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-28T00:16:37.892+0000] {processor.py:157} INFO - Started process (PID=80391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:16:37.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:16:37.896+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:37.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:16:37.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:16:37.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:37.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:16:37.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:37.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:16:37.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T00:17:08.334+0000] {processor.py:157} INFO - Started process (PID=80416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:17:08.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:17:08.338+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:08.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:17:08.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:17:08.363+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:08.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:17:08.374+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:08.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:17:08.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T00:17:38.827+0000] {processor.py:157} INFO - Started process (PID=80441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:17:38.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:17:38.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:38.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:17:38.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:17:38.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:38.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:17:38.865+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:38.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:17:38.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T00:34:00.757+0000] {processor.py:157} INFO - Started process (PID=80466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:34:00.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:34:00.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:00.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:34:00.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:34:00.790+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:00.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:34:00.803+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:00.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:34:00.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T00:34:31.254+0000] {processor.py:157} INFO - Started process (PID=80892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:34:31.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:34:31.263+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:31.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:34:31.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:34:31.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:31.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:34:31.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:31.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:34:31.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-28T00:35:01.748+0000] {processor.py:157} INFO - Started process (PID=80917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:35:01.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:35:01.753+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:01.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:35:01.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:35:01.784+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:01.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:35:01.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:01.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:35:01.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T00:35:32.240+0000] {processor.py:157} INFO - Started process (PID=80942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:35:32.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:35:32.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:32.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:35:32.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:35:32.273+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:32.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:35:32.283+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:32.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:35:32.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T00:36:02.698+0000] {processor.py:157} INFO - Started process (PID=80966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:36:02.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:36:02.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:02.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:36:02.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:36:02.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:02.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:36:02.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:02.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:36:02.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T00:36:33.099+0000] {processor.py:157} INFO - Started process (PID=80995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:36:33.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:36:33.102+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:33.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:36:33.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:36:33.137+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:33.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:36:33.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:33.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:36:33.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T00:37:03.583+0000] {processor.py:157} INFO - Started process (PID=81020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:37:03.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:37:03.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:03.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:37:03.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:37:03.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:03.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:37:03.643+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:03.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:37:03.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-28T00:37:33.967+0000] {processor.py:157} INFO - Started process (PID=81045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:37:33.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:37:33.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:33.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:37:33.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:37:33.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:33.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:37:34.009+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:34.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:37:34.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T00:38:04.484+0000] {processor.py:157} INFO - Started process (PID=81070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:38:04.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:38:04.488+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:38:04.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:38:04.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:38:04.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:38:04.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:38:04.535+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:38:04.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:38:04.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T00:54:59.862+0000] {processor.py:157} INFO - Started process (PID=81094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:54:59.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:54:59.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:54:59.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:54:59.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:54:59.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:54:59.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:54:59.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:54:59.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:54:59.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-28T00:55:30.571+0000] {processor.py:157} INFO - Started process (PID=81121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:55:30.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:55:30.573+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:55:30.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:55:30.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:55:30.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:55:30.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:55:30.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:55:30.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:55:30.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T00:56:01.037+0000] {processor.py:157} INFO - Started process (PID=81146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:56:01.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:56:01.041+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:01.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:56:01.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:56:01.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:01.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:56:01.092+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:01.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:56:01.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T00:56:31.581+0000] {processor.py:157} INFO - Started process (PID=81171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:56:31.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:56:31.585+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:31.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:56:31.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:56:31.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:31.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:56:31.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:31.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:56:31.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T00:57:02.029+0000] {processor.py:157} INFO - Started process (PID=81196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:57:02.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T00:57:02.032+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:57:02.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:57:02.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T00:57:02.060+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:57:02.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:57:02.069+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:57:02.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-28T00:57:02.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T01:12:59.342+0000] {processor.py:157} INFO - Started process (PID=81221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:12:59.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:12:59.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:12:59.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:12:59.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:12:59.390+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:12:59.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:12:59.405+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:12:59.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:12:59.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-28T01:13:29.916+0000] {processor.py:157} INFO - Started process (PID=81637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:13:29.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:13:29.927+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:13:29.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:13:29.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:13:29.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:13:29.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:13:30.001+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:13:30.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:13:30.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-28T01:14:00.450+0000] {processor.py:157} INFO - Started process (PID=81662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:14:00.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:14:00.453+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:00.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:14:00.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:14:00.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:00.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:14:00.490+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:00.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:14:00.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T01:14:30.928+0000] {processor.py:157} INFO - Started process (PID=81687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:14:30.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:14:30.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:30.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:14:30.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:14:30.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:30.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:14:30.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:30.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:14:30.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T01:16:32.178+0000] {processor.py:157} INFO - Started process (PID=81712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:16:32.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:16:32.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:16:32.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:16:32.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:16:32.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:16:32.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:16:32.296+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:16:32.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:16:32.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-28T01:17:02.909+0000] {processor.py:157} INFO - Started process (PID=81739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:17:02.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:17:02.915+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:02.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:17:02.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:17:02.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:02.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:17:02.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:02.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:17:02.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T01:17:33.458+0000] {processor.py:157} INFO - Started process (PID=81764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:17:33.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:17:33.468+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:33.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:17:33.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:17:33.488+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:33.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:17:33.498+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:33.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:17:33.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T01:18:03.965+0000] {processor.py:157} INFO - Started process (PID=81789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:18:03.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:18:03.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:03.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:18:03.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:18:03.995+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:03.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:18:04.006+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:04.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:18:04.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T01:18:34.504+0000] {processor.py:157} INFO - Started process (PID=81814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:18:34.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:18:34.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:34.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:18:34.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:18:34.533+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:34.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:18:34.546+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:34.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:18:34.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T01:35:04.880+0000] {processor.py:157} INFO - Started process (PID=81838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:35:04.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:35:04.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:04.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:35:04.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:35:04.924+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:04.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:35:04.937+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:04.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:35:04.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T01:35:35.392+0000] {processor.py:157} INFO - Started process (PID=81866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:35:35.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:35:35.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:35.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:35:35.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:35:35.438+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:35.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:35:35.457+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:35.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:35:35.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T01:36:05.824+0000] {processor.py:157} INFO - Started process (PID=81891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:36:05.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:36:05.828+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:05.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:36:05.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:36:05.864+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:05.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:36:05.876+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:05.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:36:05.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T01:36:36.270+0000] {processor.py:157} INFO - Started process (PID=81916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:36:36.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:36:36.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:36.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:36:36.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:36:36.314+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:36.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:36:36.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:36.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:36:36.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T01:52:37.234+0000] {processor.py:157} INFO - Started process (PID=81941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:52:37.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:52:37.238+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:52:37.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:52:37.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:52:37.264+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:52:37.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:52:37.273+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:52:37.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:52:37.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T01:53:07.729+0000] {processor.py:157} INFO - Started process (PID=81968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:53:07.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:53:07.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:07.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:53:07.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:53:07.771+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:07.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:53:07.783+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:07.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:53:07.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T01:53:38.163+0000] {processor.py:157} INFO - Started process (PID=81993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:53:38.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:53:38.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:38.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:53:38.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:53:38.188+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:38.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:53:38.197+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:38.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:53:38.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-28T01:54:08.597+0000] {processor.py:157} INFO - Started process (PID=82018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:54:08.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:54:08.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:08.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:54:08.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:54:08.636+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:08.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:54:08.647+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:08.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:54:08.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T01:54:38.988+0000] {processor.py:157} INFO - Started process (PID=82043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:54:38.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T01:54:38.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:38.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:54:39.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T01:54:39.013+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:39.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:54:39.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:39.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T01:54:39.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-28T02:08:38.396+0000] {processor.py:157} INFO - Started process (PID=82068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:08:38.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:08:38.401+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:08:38.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:08:38.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:08:38.437+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:08:38.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:08:38.462+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:08:38.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:08:38.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T02:09:08.940+0000] {processor.py:157} INFO - Started process (PID=82095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:09:08.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:09:08.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:08.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:09:08.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:09:09.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:09.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:09:09.031+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:09.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:09:09.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-28T02:09:39.483+0000] {processor.py:157} INFO - Started process (PID=82120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:09:39.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:09:39.486+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:39.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:09:39.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:09:39.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:39.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:09:39.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:39.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:09:39.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T02:10:09.880+0000] {processor.py:157} INFO - Started process (PID=82145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:10:09.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:10:09.883+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:09.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:10:09.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:10:09.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:09.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:10:09.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:09.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:10:09.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T02:10:40.331+0000] {processor.py:157} INFO - Started process (PID=82170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:10:40.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:10:40.335+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:40.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:10:40.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:10:40.363+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:40.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:10:40.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:40.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:10:40.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T02:17:44.286+0000] {processor.py:157} INFO - Started process (PID=82196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:17:44.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:17:44.293+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:17:44.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:17:44.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:17:44.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:17:44.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:17:44.396+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:17:44.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:17:44.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-28T02:18:15.139+0000] {processor.py:157} INFO - Started process (PID=82222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:18:15.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:18:15.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:15.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:18:15.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:18:15.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:15.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:18:15.197+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:15.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:18:15.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T02:18:45.602+0000] {processor.py:157} INFO - Started process (PID=82247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:18:45.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:18:45.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:45.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:18:45.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:18:45.633+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:45.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:18:45.643+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:45.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:18:45.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T02:19:16.042+0000] {processor.py:157} INFO - Started process (PID=82272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:19:16.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:19:16.053+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:16.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:19:16.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:19:16.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:16.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:19:16.087+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:16.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:19:16.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T02:19:46.499+0000] {processor.py:157} INFO - Started process (PID=82297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:19:46.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:19:46.509+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:46.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:19:46.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:19:46.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:46.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:19:46.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:46.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:19:46.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T02:37:22.613+0000] {processor.py:157} INFO - Started process (PID=82321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:37:22.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:37:22.623+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:22.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:37:22.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:37:22.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:22.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:37:22.754+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:22.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:37:22.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-07-28T02:37:53.383+0000] {processor.py:157} INFO - Started process (PID=82348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:37:53.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:37:53.392+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:53.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:37:53.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:37:53.430+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:53.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:37:53.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:53.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:37:53.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-28T02:38:23.853+0000] {processor.py:157} INFO - Started process (PID=82373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:38:23.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:38:23.856+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:23.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:38:23.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:38:23.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:23.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:38:23.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:23.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:38:23.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T02:38:54.284+0000] {processor.py:157} INFO - Started process (PID=82398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:38:54.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:38:54.286+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:54.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:38:54.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:38:54.316+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:54.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:38:54.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:54.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:38:54.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T02:54:35.267+0000] {processor.py:157} INFO - Started process (PID=82424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:54:35.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:54:35.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:54:35.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:54:35.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:54:35.346+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:54:35.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:54:35.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:54:35.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:54:35.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-28T02:55:05.885+0000] {processor.py:157} INFO - Started process (PID=82450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:55:05.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:55:05.890+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:05.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:55:05.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:55:05.952+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:05.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:55:05.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:05.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:55:05.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-28T02:55:36.375+0000] {processor.py:157} INFO - Started process (PID=82475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:55:36.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:55:36.377+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:36.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:55:36.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:55:36.402+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:36.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:55:36.413+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:36.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:55:36.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T02:56:06.819+0000] {processor.py:157} INFO - Started process (PID=82500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:56:06.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:56:06.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:06.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:56:06.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:56:06.850+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:06.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:56:06.860+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:06.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:56:06.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T02:56:37.324+0000] {processor.py:157} INFO - Started process (PID=82525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:56:37.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T02:56:37.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:37.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:56:37.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T02:56:37.358+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:37.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:56:37.368+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:37.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T02:56:37.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T03:08:56.871+0000] {processor.py:157} INFO - Started process (PID=82551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:08:56.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:08:56.877+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:08:56.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:08:56.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:08:56.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:08:56.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:08:56.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:08:56.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:08:56.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-28T03:09:27.498+0000] {processor.py:157} INFO - Started process (PID=82577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:09:27.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:09:27.503+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:27.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:09:27.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:09:27.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:27.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:09:27.554+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:27.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:09:27.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T03:09:58.037+0000] {processor.py:157} INFO - Started process (PID=82602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:09:58.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:09:58.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:58.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:09:58.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:09:58.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:58.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:09:58.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:58.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:09:58.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T03:10:28.552+0000] {processor.py:157} INFO - Started process (PID=82627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:10:28.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:10:28.555+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:10:28.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:10:28.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:10:28.581+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:10:28.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:10:28.593+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:10:28.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:10:28.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T03:18:33.355+0000] {processor.py:157} INFO - Started process (PID=82652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:18:33.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:18:33.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:18:33.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:18:33.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:18:33.431+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:18:33.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:18:33.470+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:18:33.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:18:33.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-28T03:19:03.986+0000] {processor.py:157} INFO - Started process (PID=82677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:19:03.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:19:04.005+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:04.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:19:04.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:19:04.042+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:04.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:19:04.053+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:04.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:19:04.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-28T03:19:34.511+0000] {processor.py:157} INFO - Started process (PID=82702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:19:34.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:19:34.514+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:34.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:19:34.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:19:34.539+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:34.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:19:34.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:34.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:19:34.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T03:20:04.954+0000] {processor.py:157} INFO - Started process (PID=82727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:20:04.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:20:04.957+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:04.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:20:04.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:20:04.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:04.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:20:04.992+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:04.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:20:05.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T03:20:35.419+0000] {processor.py:157} INFO - Started process (PID=82752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:20:35.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:20:35.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:35.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:20:35.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:20:35.447+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:35.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:20:35.457+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:35.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:20:35.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T03:37:19.002+0000] {processor.py:157} INFO - Started process (PID=82776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:37:19.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:37:19.020+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:19.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:37:19.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:37:19.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:19.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:37:19.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:19.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:37:19.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-07-28T03:37:49.646+0000] {processor.py:157} INFO - Started process (PID=82802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:37:49.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:37:49.651+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:49.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:37:49.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:37:49.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:49.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:37:49.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:49.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:37:49.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-28T03:38:20.101+0000] {processor.py:157} INFO - Started process (PID=82827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:38:20.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:38:20.102+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:20.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:38:20.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:38:20.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:20.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:38:20.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:20.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:38:20.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-28T03:38:50.607+0000] {processor.py:157} INFO - Started process (PID=82852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:38:50.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:38:50.611+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:50.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:38:50.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:38:50.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:50.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:38:50.651+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:50.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:38:50.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T03:55:09.451+0000] {processor.py:157} INFO - Started process (PID=82878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:55:09.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:55:09.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:09.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:55:09.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:55:09.544+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:09.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:55:09.565+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:09.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:55:09.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-28T03:55:40.064+0000] {processor.py:157} INFO - Started process (PID=82904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:55:40.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:55:40.069+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:40.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:55:40.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:55:40.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:40.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:55:40.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:40.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:55:40.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T03:56:10.560+0000] {processor.py:157} INFO - Started process (PID=82929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:56:10.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:56:10.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:10.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:56:10.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:56:10.581+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:10.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:56:10.591+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:10.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:56:10.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-28T03:56:41.062+0000] {processor.py:157} INFO - Started process (PID=82954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:56:41.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:56:41.066+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:41.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:56:41.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:56:41.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:41.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:56:41.107+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:41.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:56:41.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T03:57:11.511+0000] {processor.py:157} INFO - Started process (PID=82979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:57:11.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:57:11.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:11.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:57:11.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:57:11.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:11.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:57:11.560+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:11.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:57:11.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T03:57:41.943+0000] {processor.py:157} INFO - Started process (PID=83004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:57:41.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:57:41.945+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:41.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:57:41.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:57:41.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:41.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:57:41.981+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:41.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:57:41.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T03:58:12.454+0000] {processor.py:157} INFO - Started process (PID=83029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:58:12.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:58:12.457+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:12.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:58:12.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:58:12.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:12.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:58:12.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:12.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:58:12.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T03:58:42.926+0000] {processor.py:157} INFO - Started process (PID=83054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:58:42.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:58:42.929+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:42.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:58:42.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:58:42.957+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:42.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:58:42.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:42.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:58:42.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T03:59:13.359+0000] {processor.py:157} INFO - Started process (PID=83079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:59:13.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T03:59:13.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:59:13.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:59:13.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T03:59:13.386+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:59:13.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:59:13.396+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:59:13.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T03:59:13.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T04:14:37.389+0000] {processor.py:157} INFO - Started process (PID=83103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:14:37.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:14:37.401+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:14:37.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:14:37.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:14:37.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:14:37.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:14:37.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:14:37.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:14:37.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-28T04:15:08.006+0000] {processor.py:157} INFO - Started process (PID=83129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:15:08.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:15:08.013+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:08.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:15:08.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:15:08.053+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:08.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:15:08.064+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:08.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:15:08.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T04:15:38.476+0000] {processor.py:157} INFO - Started process (PID=83154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:15:38.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:15:38.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:38.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:15:38.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:15:38.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:38.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:15:38.518+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:38.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:15:38.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T04:16:08.982+0000] {processor.py:157} INFO - Started process (PID=83179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:16:08.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:16:08.985+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:08.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:16:08.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:16:09.013+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:09.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:16:09.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:09.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:16:09.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T04:16:39.393+0000] {processor.py:157} INFO - Started process (PID=83204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:16:39.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:16:39.396+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:39.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:16:39.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:16:39.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:39.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:16:39.433+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:39.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:16:39.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T04:19:33.717+0000] {processor.py:157} INFO - Started process (PID=83229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:19:33.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:19:33.720+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:19:33.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:19:33.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:19:33.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:19:33.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:19:33.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:19:33.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:19:33.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T04:20:04.205+0000] {processor.py:157} INFO - Started process (PID=83254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:20:04.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:20:04.209+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:04.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:20:04.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:20:04.242+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:04.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:20:04.253+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:04.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:20:04.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T04:20:34.632+0000] {processor.py:157} INFO - Started process (PID=83280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:20:34.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:20:34.636+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:34.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:20:34.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:20:34.669+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:34.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:20:34.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:34.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:20:34.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T04:21:05.077+0000] {processor.py:157} INFO - Started process (PID=83305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:21:05.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:21:05.081+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:05.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:21:05.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:21:05.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:05.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:21:05.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:05.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:21:05.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T04:21:35.481+0000] {processor.py:157} INFO - Started process (PID=83330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:21:35.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:21:35.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:35.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:21:35.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:21:35.504+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:35.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:21:35.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:35.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:21:35.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-28T04:37:12.797+0000] {processor.py:157} INFO - Started process (PID=83355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:37:12.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:37:12.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:12.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:37:12.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:37:12.873+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:12.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:37:12.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:12.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:37:12.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-28T04:37:43.340+0000] {processor.py:157} INFO - Started process (PID=83381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:37:43.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:37:43.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:43.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:37:43.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:37:43.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:43.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:37:43.404+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:43.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:37:43.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T04:38:13.866+0000] {processor.py:157} INFO - Started process (PID=83407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:38:13.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:38:13.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:13.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:38:13.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:38:13.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:13.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:38:13.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:13.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:38:13.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T04:38:44.302+0000] {processor.py:157} INFO - Started process (PID=83432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:38:44.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:38:44.305+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:44.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:38:44.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:38:44.338+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:44.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:38:44.349+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:44.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:38:44.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T04:39:14.772+0000] {processor.py:157} INFO - Started process (PID=83457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:39:14.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:39:14.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:14.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:39:14.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:39:14.817+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:14.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:39:14.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:14.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:39:14.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T04:39:45.250+0000] {processor.py:157} INFO - Started process (PID=83482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:39:45.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:39:45.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:45.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:39:45.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:39:45.283+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:45.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:39:45.293+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:45.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:39:45.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T04:40:15.612+0000] {processor.py:157} INFO - Started process (PID=83507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:40:15.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:40:15.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:40:15.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:40:15.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:40:15.644+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:40:15.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:40:15.657+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:40:15.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:40:15.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T04:55:44.019+0000] {processor.py:157} INFO - Started process (PID=83534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:55:44.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:55:44.032+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:55:44.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:55:44.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:55:44.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:55:44.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:55:44.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:55:44.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:55:44.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-28T04:56:14.612+0000] {processor.py:157} INFO - Started process (PID=83559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:56:14.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:56:14.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:14.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:56:14.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:56:14.659+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:14.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:56:14.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:14.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:56:14.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T04:56:45.069+0000] {processor.py:157} INFO - Started process (PID=83584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:56:45.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:56:45.072+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:45.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:56:45.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:56:45.104+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:45.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:56:45.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:45.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:56:45.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T04:57:15.523+0000] {processor.py:157} INFO - Started process (PID=83609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:57:15.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T04:57:15.525+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:57:15.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:57:15.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T04:57:15.544+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:57:15.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:57:15.555+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:57:15.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T04:57:15.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-28T05:03:16.997+0000] {processor.py:157} INFO - Started process (PID=83634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:03:17.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:03:17.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:17.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:03:17.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:03:17.036+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:17.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:03:17.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:17.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:03:17.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T05:03:47.487+0000] {processor.py:157} INFO - Started process (PID=83659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:03:47.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:03:47.491+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:47.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:03:47.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:03:47.526+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:47.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:03:47.538+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:47.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:03:47.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T05:04:17.935+0000] {processor.py:157} INFO - Started process (PID=83684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:04:17.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:04:17.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:17.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:04:17.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:04:17.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:17.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:04:17.985+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:17.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:04:17.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T05:04:48.390+0000] {processor.py:157} INFO - Started process (PID=83709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:04:48.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:04:48.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:48.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:04:48.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:04:48.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:48.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:04:48.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:48.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:04:48.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T05:05:18.809+0000] {processor.py:157} INFO - Started process (PID=83734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:05:18.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:05:18.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:18.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:05:18.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:05:18.834+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:18.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:05:18.843+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:18.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:05:18.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-28T05:05:49.284+0000] {processor.py:157} INFO - Started process (PID=83758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:05:49.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:05:49.288+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:49.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:05:49.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:05:49.316+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:49.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:05:49.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:49.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:05:49.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:06:19.701+0000] {processor.py:157} INFO - Started process (PID=83784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:06:19.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:06:19.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:19.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:06:19.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:06:19.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:19.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:06:19.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:19.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:06:19.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T05:06:50.108+0000] {processor.py:157} INFO - Started process (PID=83809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:06:50.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:06:50.113+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:50.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:06:50.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:06:50.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:50.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:06:50.155+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:50.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:06:50.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:07:20.605+0000] {processor.py:157} INFO - Started process (PID=83834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:07:20.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:07:20.608+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:20.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:07:20.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:07:20.642+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:20.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:07:20.656+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:20.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:07:20.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T05:07:51.055+0000] {processor.py:157} INFO - Started process (PID=83859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:07:51.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:07:51.058+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:51.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:07:51.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:07:51.088+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:51.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:07:51.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:51.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:07:51.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:08:21.483+0000] {processor.py:157} INFO - Started process (PID=83884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:08:21.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:08:21.487+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:21.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:08:21.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:08:21.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:21.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:08:21.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:21.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:08:21.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T05:08:51.877+0000] {processor.py:157} INFO - Started process (PID=83909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:08:51.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:08:51.879+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:51.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:08:51.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:08:51.901+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:51.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:08:51.912+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:51.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:08:51.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-28T05:09:22.298+0000] {processor.py:157} INFO - Started process (PID=83934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:09:22.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:09:22.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:22.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:09:22.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:09:22.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:22.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:09:22.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:22.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:09:22.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T05:09:52.799+0000] {processor.py:157} INFO - Started process (PID=83959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:09:52.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:09:52.802+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:52.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:09:52.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:09:52.842+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:52.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:09:52.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:52.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:09:52.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T05:10:23.271+0000] {processor.py:157} INFO - Started process (PID=83984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:10:23.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:10:23.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:23.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:10:23.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:10:23.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:23.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:10:23.309+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:23.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:10:23.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T05:10:53.679+0000] {processor.py:157} INFO - Started process (PID=84009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:10:53.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:10:53.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:53.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:10:53.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:10:53.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:53.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:10:53.720+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:53.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:10:53.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:11:24.101+0000] {processor.py:157} INFO - Started process (PID=84034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:11:24.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:11:24.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:24.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:11:24.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:11:24.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:24.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:11:24.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:24.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:11:24.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T05:11:54.517+0000] {processor.py:157} INFO - Started process (PID=84059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:11:54.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:11:54.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:54.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:11:54.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:11:54.546+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:54.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:11:54.556+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:54.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:11:54.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:12:24.982+0000] {processor.py:157} INFO - Started process (PID=84084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:12:24.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:12:24.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:24.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:12:24.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:12:25.004+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:25.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:12:25.013+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:25.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:12:25.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-28T05:12:55.415+0000] {processor.py:157} INFO - Started process (PID=84109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:12:55.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:12:55.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:55.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:12:55.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:12:55.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:55.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:12:55.453+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:55.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:12:55.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T05:13:25.932+0000] {processor.py:157} INFO - Started process (PID=84134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:13:25.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:13:25.937+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:25.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:13:25.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:13:25.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:25.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:13:25.979+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:25.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:13:25.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T05:13:56.380+0000] {processor.py:157} INFO - Started process (PID=84159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:13:56.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:13:56.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:56.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:13:56.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:13:56.413+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:56.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:13:56.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:56.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:13:56.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:14:26.874+0000] {processor.py:157} INFO - Started process (PID=84184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:14:26.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:14:26.876+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:26.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:14:26.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:14:26.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:26.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:14:26.918+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:26.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:14:26.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:14:57.311+0000] {processor.py:157} INFO - Started process (PID=84209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:14:57.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:14:57.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:57.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:14:57.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:14:57.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:57.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:14:57.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:57.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:14:57.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T05:15:27.710+0000] {processor.py:157} INFO - Started process (PID=84234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:15:27.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:15:27.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:27.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:15:27.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:15:27.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:27.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:15:27.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:27.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:15:27.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T05:15:58.124+0000] {processor.py:157} INFO - Started process (PID=84259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:15:58.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:15:58.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:58.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:15:58.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:15:58.152+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:58.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:15:58.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:58.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:15:58.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T05:16:28.580+0000] {processor.py:157} INFO - Started process (PID=84284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:16:28.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:16:28.585+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:28.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:16:28.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:16:28.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:28.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:16:28.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:28.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:16:28.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T05:16:59.059+0000] {processor.py:157} INFO - Started process (PID=84309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:16:59.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:16:59.062+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:59.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:16:59.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:16:59.087+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:59.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:16:59.096+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:59.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:16:59.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T05:17:29.433+0000] {processor.py:157} INFO - Started process (PID=84334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:17:29.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:17:29.436+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:29.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:17:29.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:17:29.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:29.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:17:29.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:29.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:17:29.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T05:17:59.844+0000] {processor.py:157} INFO - Started process (PID=84359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:17:59.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:17:59.849+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:59.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:17:59.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:17:59.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:59.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:17:59.896+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:59.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:17:59.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T05:18:30.355+0000] {processor.py:157} INFO - Started process (PID=84384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:18:30.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:18:30.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:18:30.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:18:30.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:18:30.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:18:30.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:18:30.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:18:30.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:18:30.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:19:00.833+0000] {processor.py:157} INFO - Started process (PID=84409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:19:00.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:19:00.837+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:00.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:19:00.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:19:00.866+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:00.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:19:00.875+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:00.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:19:00.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:19:31.312+0000] {processor.py:157} INFO - Started process (PID=84434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:19:31.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:19:31.316+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:31.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:19:31.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:19:31.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:31.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:19:31.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:31.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:19:31.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T05:20:01.683+0000] {processor.py:157} INFO - Started process (PID=84459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:20:01.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:20:01.693+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:01.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:20:01.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:20:01.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:01.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:20:01.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:01.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:20:01.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-28T05:20:32.215+0000] {processor.py:157} INFO - Started process (PID=84484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:20:32.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:20:32.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:32.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:20:32.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:20:32.253+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:32.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:20:32.264+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:32.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:20:32.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T05:21:02.632+0000] {processor.py:157} INFO - Started process (PID=84509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:21:02.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:21:02.635+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:02.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:21:02.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:21:02.667+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:02.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:21:02.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:02.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:21:02.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T05:21:33.097+0000] {processor.py:157} INFO - Started process (PID=84534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:21:33.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:21:33.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:33.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:21:33.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:21:33.129+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:33.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:21:33.138+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:33.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:21:33.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:22:03.560+0000] {processor.py:157} INFO - Started process (PID=84559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:22:03.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:22:03.565+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:03.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:22:03.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:22:03.601+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:03.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:22:03.611+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:03.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:22:03.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T05:22:34.004+0000] {processor.py:157} INFO - Started process (PID=84584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:22:34.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:22:34.009+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:34.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:22:34.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:22:34.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:34.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:22:34.047+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:34.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:22:34.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T05:23:04.411+0000] {processor.py:157} INFO - Started process (PID=84609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:23:04.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:23:04.415+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:04.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:23:04.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:23:04.442+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:04.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:23:04.454+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:04.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:23:04.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:23:34.918+0000] {processor.py:157} INFO - Started process (PID=84634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:23:34.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:23:34.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:34.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:23:34.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:23:34.952+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:34.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:23:34.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:34.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:23:34.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:24:05.395+0000] {processor.py:157} INFO - Started process (PID=84659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:24:05.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:24:05.399+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:05.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:24:05.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:24:05.425+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:05.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:24:05.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:05.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:24:05.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T05:24:35.827+0000] {processor.py:157} INFO - Started process (PID=84684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:24:35.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:24:35.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:35.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:24:35.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:24:35.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:35.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:24:35.870+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:35.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:24:35.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:25:06.222+0000] {processor.py:157} INFO - Started process (PID=84709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:25:06.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:25:06.225+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:06.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:25:06.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:25:06.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:06.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:25:06.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:06.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:25:06.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T05:25:36.723+0000] {processor.py:157} INFO - Started process (PID=84734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:25:36.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:25:36.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:36.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:25:36.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:25:36.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:36.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:25:36.782+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:36.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:25:36.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-28T05:26:07.192+0000] {processor.py:157} INFO - Started process (PID=84759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:26:07.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:26:07.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:07.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:26:07.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:26:07.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:07.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:26:07.236+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:07.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:26:07.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T05:26:37.639+0000] {processor.py:157} INFO - Started process (PID=84784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:26:37.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:26:37.642+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:37.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:26:37.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:26:37.670+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:37.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:26:37.680+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:37.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:26:37.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T05:27:08.070+0000] {processor.py:157} INFO - Started process (PID=84809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:27:08.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:27:08.072+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:08.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:27:08.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:27:08.098+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:08.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:27:08.107+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:08.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:27:08.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T05:27:38.547+0000] {processor.py:157} INFO - Started process (PID=84834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:27:38.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:27:38.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:38.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:27:38.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:27:38.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:38.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:27:38.584+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:38.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:27:38.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T05:28:08.998+0000] {processor.py:157} INFO - Started process (PID=84859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:28:09.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:28:09.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:09.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:28:09.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:28:09.034+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:09.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:28:09.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:09.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:28:09.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T05:28:39.504+0000] {processor.py:157} INFO - Started process (PID=84884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:28:39.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:28:39.507+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:39.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:28:39.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:28:39.539+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:39.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:28:39.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:39.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:28:39.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T05:29:09.961+0000] {processor.py:157} INFO - Started process (PID=84909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:29:09.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:29:09.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:09.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:29:09.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:29:09.993+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:09.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:29:10.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:10.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:29:10.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:29:40.412+0000] {processor.py:157} INFO - Started process (PID=84934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:29:40.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:29:40.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:40.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:29:40.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:29:40.447+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:40.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:29:40.457+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:40.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:29:40.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T05:30:10.879+0000] {processor.py:157} INFO - Started process (PID=84959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:30:10.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:30:10.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:10.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:30:10.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:30:10.910+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:10.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:30:10.922+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:10.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:30:10.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:30:41.340+0000] {processor.py:157} INFO - Started process (PID=84983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:30:41.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:30:41.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:41.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:30:41.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:30:41.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:41.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:30:41.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:41.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:30:41.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T05:31:11.994+0000] {processor.py:157} INFO - Started process (PID=85009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:31:11.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:31:11.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:11.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:31:12.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:31:12.027+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:12.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:31:12.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:12.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:31:12.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:31:42.461+0000] {processor.py:157} INFO - Started process (PID=85034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:31:42.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:31:42.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:42.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:31:42.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:31:42.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:42.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:31:42.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:42.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:31:42.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T05:32:12.936+0000] {processor.py:157} INFO - Started process (PID=85059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:32:12.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:32:12.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:12.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:32:12.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:32:12.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:12.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:32:12.976+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:12.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:32:12.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T05:32:43.349+0000] {processor.py:157} INFO - Started process (PID=85084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:32:43.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:32:43.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:43.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:32:43.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:32:43.378+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:43.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:32:43.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:43.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:32:43.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T05:33:13.800+0000] {processor.py:157} INFO - Started process (PID=85109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:33:13.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:33:13.805+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:13.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:33:13.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:33:13.841+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:13.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:33:13.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:13.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:33:13.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T05:33:44.261+0000] {processor.py:157} INFO - Started process (PID=85134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:33:44.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:33:44.263+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:44.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:33:44.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:33:44.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:44.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:33:44.290+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:44.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:33:44.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-28T05:34:14.681+0000] {processor.py:157} INFO - Started process (PID=85159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:34:14.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:34:14.684+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:14.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:34:14.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:34:14.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:14.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:34:14.721+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:14.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:34:14.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T05:34:45.139+0000] {processor.py:157} INFO - Started process (PID=85184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:34:45.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:34:45.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:45.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:34:45.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:34:45.179+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:45.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:34:45.191+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:45.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:34:45.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T05:35:15.563+0000] {processor.py:157} INFO - Started process (PID=85209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:35:15.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:35:15.566+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:15.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:35:15.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:35:15.600+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:15.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:35:15.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:15.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:35:15.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T05:35:46.005+0000] {processor.py:157} INFO - Started process (PID=85234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:35:46.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:35:46.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:46.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:35:46.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:35:46.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:46.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:35:46.046+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:46.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:35:46.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T05:36:16.416+0000] {processor.py:157} INFO - Started process (PID=85259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:36:16.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:36:16.419+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:16.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:36:16.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:36:16.446+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:16.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:36:16.455+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:16.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:36:16.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T05:36:46.899+0000] {processor.py:157} INFO - Started process (PID=85284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:36:46.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:36:46.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:46.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:36:46.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:36:46.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:46.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:36:46.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:46.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:36:46.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T05:37:17.339+0000] {processor.py:157} INFO - Started process (PID=85309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:37:17.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:37:17.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:17.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:37:17.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:37:17.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:17.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:37:17.380+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:17.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:37:17.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:37:47.748+0000] {processor.py:157} INFO - Started process (PID=85334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:37:47.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:37:47.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:47.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:37:47.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:37:47.780+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:47.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:37:47.790+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:47.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:37:47.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T05:38:18.176+0000] {processor.py:157} INFO - Started process (PID=85359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:38:18.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:38:18.180+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:18.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:38:18.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:38:18.218+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:18.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:38:18.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:18.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:38:18.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T05:38:48.618+0000] {processor.py:157} INFO - Started process (PID=85384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:38:48.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:38:48.621+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:48.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:38:48.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:38:48.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:48.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:38:48.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:48.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:38:48.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T05:39:19.109+0000] {processor.py:157} INFO - Started process (PID=85409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:39:19.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:39:19.122+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:19.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:39:19.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:39:19.177+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:19.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:39:19.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:19.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:39:19.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-28T05:39:49.684+0000] {processor.py:157} INFO - Started process (PID=85434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:39:49.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:39:49.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:49.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:39:49.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:39:49.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:49.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:39:49.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:49.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:39:49.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T05:40:20.166+0000] {processor.py:157} INFO - Started process (PID=85459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:40:20.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:40:20.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:20.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:40:20.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:40:20.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:20.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:40:20.211+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:20.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:40:20.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T05:40:50.599+0000] {processor.py:157} INFO - Started process (PID=85484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:40:50.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:40:50.601+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:50.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:40:50.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:40:50.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:50.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:40:50.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:50.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:40:50.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-28T05:41:21.070+0000] {processor.py:157} INFO - Started process (PID=85509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:41:21.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:41:21.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:21.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:41:21.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:41:21.112+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:21.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:41:21.125+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:21.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:41:21.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T05:41:51.600+0000] {processor.py:157} INFO - Started process (PID=85534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:41:51.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:41:51.610+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:51.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:41:51.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:41:51.656+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:51.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:41:51.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:51.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:41:51.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T05:42:22.081+0000] {processor.py:157} INFO - Started process (PID=85559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:42:22.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:42:22.084+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:22.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:42:22.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:42:22.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:22.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:42:22.119+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:22.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:42:22.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T05:42:52.513+0000] {processor.py:157} INFO - Started process (PID=85584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:42:52.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:42:52.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:52.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:42:52.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:42:52.543+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:52.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:42:52.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:52.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:42:52.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:43:22.941+0000] {processor.py:157} INFO - Started process (PID=85609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:43:22.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:43:22.947+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:22.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:43:22.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:43:22.974+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:22.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:43:22.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:22.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:43:22.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T05:43:53.443+0000] {processor.py:157} INFO - Started process (PID=85634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:43:53.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:43:53.446+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:53.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:43:53.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:43:53.480+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:53.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:43:53.490+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:53.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:43:53.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:44:23.868+0000] {processor.py:157} INFO - Started process (PID=85658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:44:23.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:44:23.870+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:23.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:44:23.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:44:23.894+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:23.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:44:23.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:23.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:44:23.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T05:44:54.310+0000] {processor.py:157} INFO - Started process (PID=85684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:44:54.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:44:54.313+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:54.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:44:54.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:44:54.342+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:54.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:44:54.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:54.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:44:54.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:45:24.731+0000] {processor.py:157} INFO - Started process (PID=85709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:45:24.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:45:24.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:24.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:45:24.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:45:24.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:24.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:45:24.775+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:24.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:45:24.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T05:45:55.227+0000] {processor.py:157} INFO - Started process (PID=85734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:45:55.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:45:55.231+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:55.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:45:55.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:45:55.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:55.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:45:55.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:55.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:45:55.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:46:25.762+0000] {processor.py:157} INFO - Started process (PID=85759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:46:25.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:46:25.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:25.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:46:25.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:46:25.791+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:25.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:46:25.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:25.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:46:25.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:46:56.191+0000] {processor.py:157} INFO - Started process (PID=85784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:46:56.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:46:56.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:56.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:46:56.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:46:56.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:56.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:46:56.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:56.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:46:56.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:47:26.677+0000] {processor.py:157} INFO - Started process (PID=85809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:47:26.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:47:26.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:26.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:47:26.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:47:26.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:26.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:47:26.724+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:26.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:47:26.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T05:47:57.061+0000] {processor.py:157} INFO - Started process (PID=85834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:47:57.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:47:57.064+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:57.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:47:57.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:47:57.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:57.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:47:57.096+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:57.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:47:57.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T05:48:27.506+0000] {processor.py:157} INFO - Started process (PID=85859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:48:27.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:48:27.511+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:27.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:48:27.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:48:27.539+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:27.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:48:27.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:27.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:48:27.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T05:48:57.973+0000] {processor.py:157} INFO - Started process (PID=85884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:48:57.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:48:57.976+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:57.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:48:57.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:48:58.006+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:58.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:48:58.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:58.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:48:58.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T05:49:28.408+0000] {processor.py:157} INFO - Started process (PID=85909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:49:28.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:49:28.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:28.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:49:28.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:49:28.438+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:28.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:49:28.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:28.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:49:28.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:49:58.887+0000] {processor.py:157} INFO - Started process (PID=85934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:49:58.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:49:58.890+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:58.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:49:58.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:49:58.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:58.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:49:58.927+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:58.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:49:58.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T05:50:29.311+0000] {processor.py:157} INFO - Started process (PID=85959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:50:29.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:50:29.316+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:29.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:50:29.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:50:29.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:29.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:50:29.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:29.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:50:29.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T05:50:59.796+0000] {processor.py:157} INFO - Started process (PID=85984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:50:59.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:50:59.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:59.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:50:59.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:50:59.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:59.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:50:59.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:59.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:50:59.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T05:51:30.244+0000] {processor.py:157} INFO - Started process (PID=86009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:51:30.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:51:30.248+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:51:30.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:51:30.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:51:30.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:51:30.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:51:30.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:51:30.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:51:30.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T05:52:00.710+0000] {processor.py:157} INFO - Started process (PID=86034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:52:00.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:52:00.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:00.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:52:00.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:52:00.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:00.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:52:00.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:00.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:52:00.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T05:52:31.167+0000] {processor.py:157} INFO - Started process (PID=86059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:52:31.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:52:31.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:31.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:52:31.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:52:31.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:31.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:52:31.212+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:31.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:52:31.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T05:53:01.540+0000] {processor.py:157} INFO - Started process (PID=86084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:53:01.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:53:01.542+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:01.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:53:01.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:53:01.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:01.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:53:01.579+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:01.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:53:01.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T05:53:31.998+0000] {processor.py:157} INFO - Started process (PID=86109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:53:31.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:53:32.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:32.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:53:32.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:53:32.026+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:32.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:53:32.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:32.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:53:32.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T05:54:02.439+0000] {processor.py:157} INFO - Started process (PID=86134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:54:02.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:54:02.443+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:02.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:54:02.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:54:02.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:02.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:54:02.488+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:02.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:54:02.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T05:54:32.867+0000] {processor.py:157} INFO - Started process (PID=86159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:54:32.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:54:32.872+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:32.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:54:32.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:54:32.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:32.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:54:32.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:32.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:54:32.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T05:55:03.320+0000] {processor.py:157} INFO - Started process (PID=86184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:55:03.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:55:03.323+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:03.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:55:03.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:55:03.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:03.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:55:03.363+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:03.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:55:03.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:55:33.678+0000] {processor.py:157} INFO - Started process (PID=86209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:55:33.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:55:33.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:33.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:55:33.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:55:33.707+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:33.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:55:33.717+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:33.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:55:33.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:56:04.155+0000] {processor.py:157} INFO - Started process (PID=86234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:56:04.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:56:04.159+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:04.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:56:04.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:56:04.188+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:04.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:56:04.199+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:04.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:56:04.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T05:56:34.575+0000] {processor.py:157} INFO - Started process (PID=86259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:56:34.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:56:34.578+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:34.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:56:34.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:56:34.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:34.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:56:34.613+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:34.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:56:34.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T05:57:04.999+0000] {processor.py:157} INFO - Started process (PID=86284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:57:05.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:57:05.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:05.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:57:05.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:57:05.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:05.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:57:05.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:05.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:57:05.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T05:57:35.466+0000] {processor.py:157} INFO - Started process (PID=86309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:57:35.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:57:35.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:35.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:57:35.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:57:35.498+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:35.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:57:35.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:35.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:57:35.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T05:58:05.930+0000] {processor.py:157} INFO - Started process (PID=86334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:58:05.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:58:05.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:05.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:58:05.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:58:05.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:05.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:58:05.976+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:05.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:58:05.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T05:58:36.387+0000] {processor.py:157} INFO - Started process (PID=86359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:58:36.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:58:36.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:36.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:58:36.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:58:36.418+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:36.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:58:36.429+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:36.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:58:36.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:59:06.798+0000] {processor.py:157} INFO - Started process (PID=86384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:59:06.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:59:06.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:06.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:59:06.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:59:06.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:06.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:59:06.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:06.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:59:06.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T05:59:37.267+0000] {processor.py:157} INFO - Started process (PID=86409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:59:37.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T05:59:37.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:37.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:59:37.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T05:59:37.297+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:37.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:59:37.307+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:37.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T05:59:37.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T06:00:07.689+0000] {processor.py:157} INFO - Started process (PID=86434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:00:07.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:00:07.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:07.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:00:07.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:00:07.722+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:07.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:00:07.735+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:07.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:00:07.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T06:00:38.098+0000] {processor.py:157} INFO - Started process (PID=86459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:00:38.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:00:38.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:38.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:00:38.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:00:38.130+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:38.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:00:38.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:38.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:00:38.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T06:01:08.586+0000] {processor.py:157} INFO - Started process (PID=86484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:01:08.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:01:08.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:08.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:01:08.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:01:08.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:08.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:01:08.628+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:08.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:01:08.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T06:01:39.037+0000] {processor.py:157} INFO - Started process (PID=86509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:01:39.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:01:39.041+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:39.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:01:39.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:01:39.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:39.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:01:39.091+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:39.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:01:39.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T06:02:09.536+0000] {processor.py:157} INFO - Started process (PID=86534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:02:09.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:02:09.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:09.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:02:09.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:02:09.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:09.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:02:09.580+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:09.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:02:09.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T06:02:39.923+0000] {processor.py:157} INFO - Started process (PID=86558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:02:39.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:02:39.926+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:39.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:02:39.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:02:39.949+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:39.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:02:39.958+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:39.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:02:39.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T06:03:10.343+0000] {processor.py:157} INFO - Started process (PID=86584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:03:10.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:03:10.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:10.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:03:10.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:03:10.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:10.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:03:10.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:10.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:03:10.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T06:03:40.848+0000] {processor.py:157} INFO - Started process (PID=86609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:03:40.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:03:40.852+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:40.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:03:40.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:03:40.880+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:40.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:03:40.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:40.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:03:40.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T06:04:11.325+0000] {processor.py:157} INFO - Started process (PID=86634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:04:11.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:04:11.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:04:11.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:04:11.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:04:11.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:04:11.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:04:11.365+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:04:11.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:04:11.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T06:19:25.309+0000] {processor.py:157} INFO - Started process (PID=86659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:19:25.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:19:25.312+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:25.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:19:25.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:19:25.366+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:25.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:19:25.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:25.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:19:25.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-28T06:19:55.818+0000] {processor.py:157} INFO - Started process (PID=86686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:19:55.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:19:55.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:55.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:19:55.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:19:55.861+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:55.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:19:55.874+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:55.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:19:55.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T06:20:26.271+0000] {processor.py:157} INFO - Started process (PID=86711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:20:26.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:20:26.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:26.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:20:26.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:20:26.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:26.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:20:26.312+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:26.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:20:26.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T06:20:56.718+0000] {processor.py:157} INFO - Started process (PID=86736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:20:56.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:20:56.719+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:56.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:20:56.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:20:56.741+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:56.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:20:56.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:56.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:20:56.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-28T06:21:27.178+0000] {processor.py:157} INFO - Started process (PID=86761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:21:27.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:21:27.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:21:27.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:21:27.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:21:27.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:21:27.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:21:27.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:21:27.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:21:27.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T06:37:54.080+0000] {processor.py:157} INFO - Started process (PID=86787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:37:54.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:37:54.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:37:54.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:37:54.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:37:54.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:37:54.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:37:54.154+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:37:54.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:37:54.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T06:38:24.561+0000] {processor.py:157} INFO - Started process (PID=86812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:38:24.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:38:24.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:38:24.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:38:24.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:38:24.601+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:38:24.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:38:24.612+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:38:24.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:38:24.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T06:54:14.736+0000] {processor.py:157} INFO - Started process (PID=86837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:54:14.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:54:14.740+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:14.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:54:14.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:54:14.772+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:14.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:54:14.782+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:14.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:54:14.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T06:54:45.212+0000] {processor.py:157} INFO - Started process (PID=86862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:54:45.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T06:54:45.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:45.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:54:45.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T06:54:45.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:45.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:54:45.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:45.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T06:54:45.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T07:11:06.654+0000] {processor.py:157} INFO - Started process (PID=86889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:11:06.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:11:06.657+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:06.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:11:06.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:11:06.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:06.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:11:06.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:06.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:11:06.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-28T07:11:37.170+0000] {processor.py:157} INFO - Started process (PID=86914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:11:37.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:11:37.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:37.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:11:37.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:11:37.212+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:37.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:11:37.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:37.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:11:37.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T07:12:07.674+0000] {processor.py:157} INFO - Started process (PID=86939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:12:07.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:12:07.678+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:07.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:12:07.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:12:07.705+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:07.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:12:07.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:07.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:12:07.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T07:12:38.115+0000] {processor.py:157} INFO - Started process (PID=86963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:12:38.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:12:38.119+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:38.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:12:38.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:12:38.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:38.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:12:38.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:38.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:12:38.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T07:20:41.124+0000] {processor.py:157} INFO - Started process (PID=86991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:20:41.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:20:41.128+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:20:41.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:20:41.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:20:41.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:20:41.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:20:41.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:20:41.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:20:41.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-28T07:21:11.685+0000] {processor.py:157} INFO - Started process (PID=87016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:21:11.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:21:11.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:11.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:21:11.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:21:11.724+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:11.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:21:11.735+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:11.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:21:11.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-28T07:21:42.149+0000] {processor.py:157} INFO - Started process (PID=87041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:21:42.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:21:42.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:42.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:21:42.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:21:42.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:42.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:21:42.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:42.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:21:42.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T07:22:12.622+0000] {processor.py:157} INFO - Started process (PID=87066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:22:12.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:22:12.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:12.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:22:12.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:22:12.649+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:12.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:22:12.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:12.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:22:12.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T07:22:43.092+0000] {processor.py:157} INFO - Started process (PID=87091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:22:43.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:22:43.096+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:43.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:22:43.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:22:43.125+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:43.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:22:43.135+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:43.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:22:43.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T07:38:24.511+0000] {processor.py:157} INFO - Started process (PID=87118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:38:24.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:38:24.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:24.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:38:24.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:38:24.593+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:24.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:38:24.618+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:24.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:38:24.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-28T07:38:55.190+0000] {processor.py:157} INFO - Started process (PID=87143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:38:55.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:38:55.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:55.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:38:55.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:38:55.226+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:55.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:38:55.238+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:55.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:38:55.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T07:39:25.629+0000] {processor.py:157} INFO - Started process (PID=87168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:39:25.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:39:25.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:25.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:39:25.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:39:25.665+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:25.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:39:25.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:25.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:39:25.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T07:39:56.077+0000] {processor.py:157} INFO - Started process (PID=87193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:39:56.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:39:56.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:56.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:39:56.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:39:56.103+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:56.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:39:56.114+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:56.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:39:56.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T07:40:26.691+0000] {processor.py:157} INFO - Started process (PID=87217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:40:26.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:40:26.695+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:40:26.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:40:26.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:40:26.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:40:26.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:40:26.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:40:26.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:40:26.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T07:57:10.268+0000] {processor.py:157} INFO - Started process (PID=87242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:57:10.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:57:10.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:10.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:57:10.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:57:10.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:10.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:57:10.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:10.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:57:10.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T07:57:40.774+0000] {processor.py:157} INFO - Started process (PID=87270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:57:40.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:57:40.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:40.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:57:40.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:57:40.808+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:40.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:57:40.819+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:40.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:57:40.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T07:58:11.203+0000] {processor.py:157} INFO - Started process (PID=87295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:58:11.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:58:11.205+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:11.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:58:11.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:58:11.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:11.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:58:11.247+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:11.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:58:11.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T07:58:41.692+0000] {processor.py:157} INFO - Started process (PID=87320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:58:41.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T07:58:41.695+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:41.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:58:41.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T07:58:41.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:41.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:58:41.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:41.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T07:58:41.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T08:14:57.850+0000] {processor.py:157} INFO - Started process (PID=87345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:14:57.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:14:57.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:14:57.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:14:57.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:14:57.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:14:57.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:14:57.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:14:57.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:14:57.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T08:15:28.343+0000] {processor.py:157} INFO - Started process (PID=87372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:15:28.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:15:28.349+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:28.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:15:28.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:15:28.416+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:28.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:15:28.441+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:28.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:15:28.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-28T08:15:58.860+0000] {processor.py:157} INFO - Started process (PID=87397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:15:58.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:15:58.863+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:58.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:15:58.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:15:58.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:58.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:15:58.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:58.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:15:58.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T08:16:29.287+0000] {processor.py:157} INFO - Started process (PID=87422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:16:29.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:16:29.289+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:29.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:16:29.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:16:29.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:29.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:16:29.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:29.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:16:29.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T08:16:59.800+0000] {processor.py:157} INFO - Started process (PID=87447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:16:59.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:16:59.803+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:59.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:16:59.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:16:59.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:59.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:16:59.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:59.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:16:59.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T08:21:44.741+0000] {processor.py:157} INFO - Started process (PID=87474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:21:44.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:21:44.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:21:44.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:21:44.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:21:44.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:21:44.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:21:44.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:21:44.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:21:44.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-28T08:22:15.335+0000] {processor.py:157} INFO - Started process (PID=87499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:22:15.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:22:15.339+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:22:15.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:22:15.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:22:15.371+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:22:15.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:22:15.382+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:22:15.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:22:15.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T08:40:09.174+0000] {processor.py:157} INFO - Started process (PID=87524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:40:09.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:40:09.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:09.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:40:09.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:40:09.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:09.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:40:09.273+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:09.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:40:09.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-28T08:40:39.806+0000] {processor.py:157} INFO - Started process (PID=87549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:40:39.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:40:39.811+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:39.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:40:39.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:40:39.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:39.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:40:39.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:39.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:40:39.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T08:41:10.253+0000] {processor.py:157} INFO - Started process (PID=87574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:41:10.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:41:10.258+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:10.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:41:10.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:41:10.294+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:10.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:41:10.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:10.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:41:10.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T08:41:40.812+0000] {processor.py:157} INFO - Started process (PID=87599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:41:40.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:41:40.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:40.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:41:40.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:41:40.846+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:40.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:41:40.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:40.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:41:40.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T08:58:24.361+0000] {processor.py:157} INFO - Started process (PID=87623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:58:24.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:58:24.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:24.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:58:24.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:58:24.431+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:24.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:58:24.455+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:24.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:58:24.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T08:58:55.000+0000] {processor.py:157} INFO - Started process (PID=87649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:58:55.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:58:55.012+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:55.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:58:55.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:58:55.039+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:55.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:58:55.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:55.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:58:55.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T08:59:25.390+0000] {processor.py:157} INFO - Started process (PID=87674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:59:25.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:59:25.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:25.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:59:25.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:59:25.429+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:25.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:59:25.442+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:25.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:59:25.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T08:59:55.909+0000] {processor.py:157} INFO - Started process (PID=87699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:59:55.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T08:59:55.912+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:55.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:59:55.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T08:59:55.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:55.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:59:55.952+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:55.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T08:59:55.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T09:16:50.307+0000] {processor.py:157} INFO - Started process (PID=87726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:16:50.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:16:50.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:16:50.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:16:50.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:16:50.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:16:50.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:16:50.385+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:16:50.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:16:50.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-28T09:17:20.965+0000] {processor.py:157} INFO - Started process (PID=87751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:17:20.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:17:20.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:20.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:17:20.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:17:21.005+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:21.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:17:21.017+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:21.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:17:21.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T09:17:51.389+0000] {processor.py:157} INFO - Started process (PID=87776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:17:51.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:17:51.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:51.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:17:51.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:17:51.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:51.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:17:51.428+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:51.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:17:51.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T09:18:21.864+0000] {processor.py:157} INFO - Started process (PID=87801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:18:21.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:18:21.867+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:21.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:18:21.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:18:21.899+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:21.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:18:21.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:21.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:18:21.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T09:18:52.236+0000] {processor.py:157} INFO - Started process (PID=87826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:18:52.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:18:52.242+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:52.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:18:52.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:18:52.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:52.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:18:52.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:52.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:18:52.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T09:22:36.303+0000] {processor.py:157} INFO - Started process (PID=87853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:22:36.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:22:36.307+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:22:36.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:22:36.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:22:36.331+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:22:36.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:22:36.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:22:36.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:22:36.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T09:23:06.681+0000] {processor.py:157} INFO - Started process (PID=87877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:23:06.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:23:06.686+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:23:06.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:23:06.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:23:06.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:23:06.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:23:06.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:23:06.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:23:06.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T09:39:42.463+0000] {processor.py:157} INFO - Started process (PID=87902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:39:42.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:39:42.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:39:42.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:39:42.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:39:42.586+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:39:42.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:39:42.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:39:42.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:39:42.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-07-28T09:40:13.159+0000] {processor.py:157} INFO - Started process (PID=87928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:40:13.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:40:13.166+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:13.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:40:13.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:40:13.202+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:13.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:40:13.213+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:13.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:40:13.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T09:40:43.647+0000] {processor.py:157} INFO - Started process (PID=87953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:40:43.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:40:43.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:43.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:40:43.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:40:43.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:43.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:40:43.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:43.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:40:43.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T09:41:14.138+0000] {processor.py:157} INFO - Started process (PID=87978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:41:14.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:41:14.141+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:41:14.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:41:14.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:41:14.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:41:14.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:41:14.181+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:41:14.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:41:14.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T09:57:06.358+0000] {processor.py:157} INFO - Started process (PID=88003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:57:06.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:57:06.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:06.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:57:06.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:57:06.419+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:06.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:57:06.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:06.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:57:06.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-28T09:57:36.885+0000] {processor.py:157} INFO - Started process (PID=88028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:57:36.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:57:36.889+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:36.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:57:36.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:57:36.916+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:36.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:57:36.926+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:36.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:57:36.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T09:58:07.376+0000] {processor.py:157} INFO - Started process (PID=88053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:58:07.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:58:07.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:07.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:58:07.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:58:07.414+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:07.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:58:07.426+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:07.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:58:07.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T09:58:37.883+0000] {processor.py:157} INFO - Started process (PID=88078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:58:37.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:58:37.887+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:37.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:58:37.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:58:37.919+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:37.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:58:37.930+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:37.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:58:37.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T09:59:08.420+0000] {processor.py:157} INFO - Started process (PID=88103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:59:08.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T09:59:08.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:59:08.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:59:08.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T09:59:08.441+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:59:08.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:59:08.454+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:59:08.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T09:59:08.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-28T10:00:36.840+0000] {processor.py:157} INFO - Started process (PID=88128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:00:36.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:00:36.843+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:00:36.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:00:36.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:00:36.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:00:36.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:00:36.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:00:36.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:00:36.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T10:01:07.926+0000] {processor.py:157} INFO - Started process (PID=88155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:01:07.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:01:07.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:07.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:01:07.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:01:07.997+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:07.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:01:08.012+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:08.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:01:08.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-28T10:01:38.448+0000] {processor.py:157} INFO - Started process (PID=88180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:01:38.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:01:38.455+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:38.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:01:38.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:01:38.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:38.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:01:38.513+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:38.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:01:38.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-28T10:02:08.947+0000] {processor.py:157} INFO - Started process (PID=88205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:02:08.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:02:08.949+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:08.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:02:08.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:02:08.977+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:08.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:02:08.988+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:08.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:02:08.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T10:02:39.466+0000] {processor.py:157} INFO - Started process (PID=88230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:02:39.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:02:39.471+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:39.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:02:39.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:02:39.526+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:39.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:02:39.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:39.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:02:39.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-28T10:03:09.933+0000] {processor.py:157} INFO - Started process (PID=88254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:03:09.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:03:09.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:09.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:03:09.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:03:10.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:10.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:03:10.032+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:10.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:03:10.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-28T10:03:40.410+0000] {processor.py:157} INFO - Started process (PID=88280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:03:40.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:03:40.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:40.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:03:40.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:03:40.439+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:40.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:03:40.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:40.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:03:40.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T10:04:10.821+0000] {processor.py:157} INFO - Started process (PID=88305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:04:10.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:04:10.825+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:10.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:04:10.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:04:10.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:10.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:04:10.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:10.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:04:10.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T10:04:41.293+0000] {processor.py:157} INFO - Started process (PID=88330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:04:41.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:04:41.297+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:41.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:04:41.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:04:41.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:41.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:04:41.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:41.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:04:41.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T10:05:11.793+0000] {processor.py:157} INFO - Started process (PID=88355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:05:11.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:05:11.795+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:11.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:05:11.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:05:11.826+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:11.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:05:11.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:11.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:05:11.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T10:05:42.279+0000] {processor.py:157} INFO - Started process (PID=88380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:05:42.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:05:42.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:42.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:05:42.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:05:42.323+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:42.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:05:42.337+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:42.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:05:42.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T10:06:12.710+0000] {processor.py:157} INFO - Started process (PID=88405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:06:12.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:06:12.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:12.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:06:12.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:06:12.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:12.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:06:12.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:12.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:06:12.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T10:06:43.114+0000] {processor.py:157} INFO - Started process (PID=88430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:06:43.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:06:43.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:43.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:06:43.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:06:43.145+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:43.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:06:43.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:43.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:06:43.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T10:07:13.622+0000] {processor.py:157} INFO - Started process (PID=88455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:07:13.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:07:13.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:13.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:07:13.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:07:13.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:13.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:07:13.688+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:13.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:07:13.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-28T10:07:44.071+0000] {processor.py:157} INFO - Started process (PID=88480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:07:44.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:07:44.080+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:44.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:07:44.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:07:44.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:44.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:07:44.111+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:44.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:07:44.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T10:08:14.526+0000] {processor.py:157} INFO - Started process (PID=88505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:08:14.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:08:14.533+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:14.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:08:14.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:08:14.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:14.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:08:14.561+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:14.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:08:14.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T10:08:44.933+0000] {processor.py:157} INFO - Started process (PID=88530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:08:44.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:08:44.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:44.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:08:44.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:08:44.958+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:44.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:08:44.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:44.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:08:44.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T10:09:15.294+0000] {processor.py:157} INFO - Started process (PID=88555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:09:15.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:09:15.297+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:15.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:09:15.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:09:15.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:15.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:09:15.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:15.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:09:15.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T10:09:45.819+0000] {processor.py:157} INFO - Started process (PID=88579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:09:45.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:09:45.826+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:45.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:09:45.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:09:45.847+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:45.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:09:45.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:45.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:09:45.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T10:10:16.249+0000] {processor.py:157} INFO - Started process (PID=88605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:10:16.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:10:16.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:16.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:10:16.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:10:16.276+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:16.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:10:16.286+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:16.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:10:16.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T10:10:46.726+0000] {processor.py:157} INFO - Started process (PID=88630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:10:46.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:10:46.732+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:46.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:10:46.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:10:46.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:46.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:10:46.780+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:46.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:10:46.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T10:11:17.119+0000] {processor.py:157} INFO - Started process (PID=88655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:11:17.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:11:17.122+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:17.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:11:17.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:11:17.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:17.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:11:17.172+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:17.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:11:17.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T10:11:47.615+0000] {processor.py:157} INFO - Started process (PID=88680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:11:47.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:11:47.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:47.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:11:47.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:11:47.643+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:47.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:11:47.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:47.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:11:47.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T10:12:18.082+0000] {processor.py:157} INFO - Started process (PID=88705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:12:18.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:12:18.090+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:18.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:12:18.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:12:18.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:18.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:12:18.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:18.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:12:18.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T10:12:48.672+0000] {processor.py:157} INFO - Started process (PID=88729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:12:48.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:12:48.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:48.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:12:48.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:12:48.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:48.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:12:48.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:48.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:12:48.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T10:43:42.550+0000] {processor.py:157} INFO - Started process (PID=88755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:43:42.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T10:43:42.556+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:43:42.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:43:42.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T10:43:42.594+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:43:42.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:43:42.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:43:42.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T10:43:42.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T11:02:12.727+0000] {processor.py:157} INFO - Started process (PID=88783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:02:12.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:02:12.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:12.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:02:12.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:02:12.790+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:12.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:02:12.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:12.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:02:12.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T11:02:43.240+0000] {processor.py:157} INFO - Started process (PID=88809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:02:43.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:02:43.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:43.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:02:43.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:02:43.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:43.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:02:43.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:43.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:02:43.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T11:03:13.671+0000] {processor.py:157} INFO - Started process (PID=88834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:03:13.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:03:13.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:13.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:03:13.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:03:13.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:13.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:03:13.720+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:13.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:03:13.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T11:03:44.147+0000] {processor.py:157} INFO - Started process (PID=88859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:03:44.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:03:44.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:44.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:03:44.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:03:44.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:44.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:03:44.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:44.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:03:44.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T11:04:14.571+0000] {processor.py:157} INFO - Started process (PID=88884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:04:14.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:04:14.575+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:14.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:04:14.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:04:14.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:14.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:04:14.615+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:14.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:04:14.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T11:04:45.034+0000] {processor.py:157} INFO - Started process (PID=88909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:04:45.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:04:45.037+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:45.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:04:45.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:04:45.069+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:45.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:04:45.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:45.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:04:45.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T11:05:15.448+0000] {processor.py:157} INFO - Started process (PID=88934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:05:15.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:05:15.452+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:15.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:05:15.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:05:15.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:15.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:05:15.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:15.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:05:15.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T11:05:45.876+0000] {processor.py:157} INFO - Started process (PID=88959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:05:45.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:05:45.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:45.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:05:45.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:05:45.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:45.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:05:45.929+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:45.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:05:45.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T11:06:16.344+0000] {processor.py:157} INFO - Started process (PID=88984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:06:16.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:06:16.349+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:16.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:06:16.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:06:16.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:16.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:06:16.396+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:16.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:06:16.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T11:06:46.735+0000] {processor.py:157} INFO - Started process (PID=89009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:06:46.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:06:46.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:46.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:06:46.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:06:46.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:46.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:06:46.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:46.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:06:46.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T11:07:17.171+0000] {processor.py:157} INFO - Started process (PID=89034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:07:17.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:07:17.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:17.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:07:17.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:07:17.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:17.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:07:17.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:17.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:07:17.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T11:07:47.602+0000] {processor.py:157} INFO - Started process (PID=89059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:07:47.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:07:47.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:47.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:07:47.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:07:47.634+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:47.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:07:47.644+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:47.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:07:47.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T11:08:18.077+0000] {processor.py:157} INFO - Started process (PID=89084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:08:18.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:08:18.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:18.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:08:18.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:08:18.117+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:18.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:08:18.129+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:18.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:08:18.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T11:08:48.481+0000] {processor.py:157} INFO - Started process (PID=89109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:08:48.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:08:48.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:48.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:08:48.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:08:48.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:48.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:08:48.517+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:48.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:08:48.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T11:09:18.854+0000] {processor.py:157} INFO - Started process (PID=89134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:09:18.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:09:18.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:18.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:09:18.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:09:18.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:18.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:09:18.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:18.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:09:18.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T11:09:49.316+0000] {processor.py:157} INFO - Started process (PID=89159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:09:49.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:09:49.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:49.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:09:49.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:09:49.348+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:49.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:09:49.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:49.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:09:49.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T11:10:19.722+0000] {processor.py:157} INFO - Started process (PID=89184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:10:19.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:10:19.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:19.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:10:19.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:10:19.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:19.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:10:19.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:19.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:10:19.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T11:10:50.186+0000] {processor.py:157} INFO - Started process (PID=89209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:10:50.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:10:50.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:50.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:10:50.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:10:50.215+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:50.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:10:50.225+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:50.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:10:50.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T11:11:20.597+0000] {processor.py:157} INFO - Started process (PID=89234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:11:20.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:11:20.599+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:20.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:11:20.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:11:20.626+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:20.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:11:20.635+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:20.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:11:20.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T11:11:50.990+0000] {processor.py:157} INFO - Started process (PID=89259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:11:50.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:11:50.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:50.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:11:51.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:11:51.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:51.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:11:51.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:51.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:11:51.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T11:12:21.494+0000] {processor.py:157} INFO - Started process (PID=89284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:12:21.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:12:21.498+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:21.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:12:21.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:12:21.524+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:21.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:12:21.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:21.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:12:21.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:12:51.900+0000] {processor.py:157} INFO - Started process (PID=89309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:12:51.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:12:51.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:51.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:12:51.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:12:51.928+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:51.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:12:51.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:51.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:12:51.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T11:13:22.357+0000] {processor.py:157} INFO - Started process (PID=89334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:13:22.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:13:22.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:22.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:13:22.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:13:22.390+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:22.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:13:22.399+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:22.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:13:22.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T11:13:52.767+0000] {processor.py:157} INFO - Started process (PID=89359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:13:52.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:13:52.771+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:52.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:13:52.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:13:52.804+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:52.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:13:52.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:52.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:13:52.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T11:14:23.240+0000] {processor.py:157} INFO - Started process (PID=89384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:14:23.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:14:23.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:23.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:14:23.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:14:23.273+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:23.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:14:23.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:23.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:14:23.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T11:14:53.672+0000] {processor.py:157} INFO - Started process (PID=89409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:14:53.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:14:53.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:53.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:14:53.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:14:53.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:53.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:14:53.711+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:53.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:14:53.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:15:24.129+0000] {processor.py:157} INFO - Started process (PID=89434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:15:24.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:15:24.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:24.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:15:24.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:15:24.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:24.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:15:24.177+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:24.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:15:24.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T11:15:54.585+0000] {processor.py:157} INFO - Started process (PID=89459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:15:54.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:15:54.592+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:54.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:15:54.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:15:54.622+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:54.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:15:54.635+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:54.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:15:54.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T11:16:25.027+0000] {processor.py:157} INFO - Started process (PID=89484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:16:25.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:16:25.030+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:25.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:16:25.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:16:25.055+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:25.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:16:25.064+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:25.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:16:25.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T11:16:55.444+0000] {processor.py:157} INFO - Started process (PID=89509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:16:55.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:16:55.451+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:55.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:16:55.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:16:55.484+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:55.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:16:55.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:55.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:16:55.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T11:17:25.898+0000] {processor.py:157} INFO - Started process (PID=89534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:17:25.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:17:25.900+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:25.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:17:25.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:17:25.930+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:25.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:17:25.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:25.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:17:25.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:17:56.334+0000] {processor.py:157} INFO - Started process (PID=89559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:17:56.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:17:56.337+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:56.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:17:56.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:17:56.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:56.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:17:56.377+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:56.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:17:56.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T11:18:26.814+0000] {processor.py:157} INFO - Started process (PID=89584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:18:26.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:18:26.818+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:26.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:18:26.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:18:26.843+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:26.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:18:26.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:26.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:18:26.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T11:18:57.211+0000] {processor.py:157} INFO - Started process (PID=89609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:18:57.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:18:57.215+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:57.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:18:57.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:18:57.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:57.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:18:57.250+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:57.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:18:57.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T11:19:27.699+0000] {processor.py:157} INFO - Started process (PID=89634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:19:27.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:19:27.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:27.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:19:27.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:19:27.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:27.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:19:27.740+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:27.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:19:27.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T11:19:58.102+0000] {processor.py:157} INFO - Started process (PID=89659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:19:58.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:19:58.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:58.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:19:58.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:19:58.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:58.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:19:58.135+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:58.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:19:58.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-28T11:20:28.533+0000] {processor.py:157} INFO - Started process (PID=89684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:20:28.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:20:28.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:28.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:20:28.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:20:28.565+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:28.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:20:28.576+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:28.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:20:28.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T11:20:59.018+0000] {processor.py:157} INFO - Started process (PID=89709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:20:59.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:20:59.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:59.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:20:59.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:20:59.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:59.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:20:59.063+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:59.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:20:59.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T11:21:29.456+0000] {processor.py:157} INFO - Started process (PID=89734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:21:29.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:21:29.460+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:29.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:21:29.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:21:29.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:29.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:21:29.505+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:29.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:21:29.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T11:21:59.911+0000] {processor.py:157} INFO - Started process (PID=89759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:21:59.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:21:59.913+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:59.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:21:59.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:21:59.940+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:59.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:21:59.951+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:59.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:21:59.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T11:22:30.339+0000] {processor.py:157} INFO - Started process (PID=89784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:22:30.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:22:30.344+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:22:30.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:22:30.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:22:30.369+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:22:30.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:22:30.381+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:22:30.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:22:30.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T11:23:00.719+0000] {processor.py:157} INFO - Started process (PID=89809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:23:00.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:23:00.723+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:00.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:23:00.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:23:00.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:00.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:23:00.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:00.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:23:00.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:23:31.139+0000] {processor.py:157} INFO - Started process (PID=89834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:23:31.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:23:31.140+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:31.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:23:31.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:23:31.161+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:31.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:23:31.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:31.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:23:31.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-28T11:24:01.493+0000] {processor.py:157} INFO - Started process (PID=89859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:24:01.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:24:01.497+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:01.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:24:01.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:24:01.523+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:01.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:24:01.533+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:01.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:24:01.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:24:31.939+0000] {processor.py:157} INFO - Started process (PID=89884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:24:31.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:24:31.942+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:31.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:24:31.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:24:31.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:31.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:24:31.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:31.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:24:31.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T11:25:02.284+0000] {processor.py:157} INFO - Started process (PID=89909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:25:02.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:25:02.289+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:02.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:25:02.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:25:02.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:02.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:25:02.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:02.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:25:02.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T11:25:32.774+0000] {processor.py:157} INFO - Started process (PID=89934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:25:32.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:25:32.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:32.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:25:32.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:25:32.811+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:32.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:25:32.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:32.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:25:32.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T11:26:03.242+0000] {processor.py:157} INFO - Started process (PID=89959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:26:03.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:26:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:03.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:26:03.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:26:03.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:03.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:26:03.294+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:03.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:26:03.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T11:26:33.726+0000] {processor.py:157} INFO - Started process (PID=89984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:26:33.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:26:33.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:33.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:26:33.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:26:33.763+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:33.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:26:33.773+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:33.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:26:33.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T11:27:04.132+0000] {processor.py:157} INFO - Started process (PID=90009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:27:04.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:27:04.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:04.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:27:04.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:27:04.162+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:04.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:27:04.172+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:04.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:27:04.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:27:34.533+0000] {processor.py:157} INFO - Started process (PID=90034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:27:34.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:27:34.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:34.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:27:34.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:27:34.565+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:34.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:27:34.576+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:34.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:27:34.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T11:28:05.000+0000] {processor.py:157} INFO - Started process (PID=90059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:28:05.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:28:05.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:05.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:28:05.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:28:05.031+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:05.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:28:05.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:05.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:28:05.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T11:28:35.384+0000] {processor.py:157} INFO - Started process (PID=90084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:28:35.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:28:35.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:35.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:28:35.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:28:35.414+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:35.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:28:35.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:35.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:28:35.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T11:29:05.811+0000] {processor.py:157} INFO - Started process (PID=90109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:29:05.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:29:05.816+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:05.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:29:05.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:29:05.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:05.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:29:05.864+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:05.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:29:05.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T11:29:36.291+0000] {processor.py:157} INFO - Started process (PID=90134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:29:36.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:29:36.294+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:36.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:29:36.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:29:36.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:36.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:29:36.331+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:36.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:29:36.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:30:06.708+0000] {processor.py:157} INFO - Started process (PID=90159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:30:06.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:30:06.711+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:06.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:30:06.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:30:06.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:06.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:30:06.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:06.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:30:06.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T11:30:37.164+0000] {processor.py:157} INFO - Started process (PID=90184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:30:37.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:30:37.168+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:37.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:30:37.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:30:37.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:37.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:30:37.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:37.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:30:37.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-28T11:31:07.548+0000] {processor.py:157} INFO - Started process (PID=90209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:31:07.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:31:07.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:07.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:31:07.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:31:07.594+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:07.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:31:07.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:07.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:31:07.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T11:31:37.964+0000] {processor.py:157} INFO - Started process (PID=90234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:31:37.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:31:37.972+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:37.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:31:37.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:31:38.018+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:38.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:31:38.034+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:38.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:31:38.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-28T11:32:08.501+0000] {processor.py:157} INFO - Started process (PID=90259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:32:08.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:32:08.511+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:08.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:32:08.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:32:08.554+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:08.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:32:08.570+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:08.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:32:08.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-28T11:32:39.202+0000] {processor.py:157} INFO - Started process (PID=90284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:32:39.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:32:39.208+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:39.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:32:39.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:32:39.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:39.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:32:39.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:39.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:32:39.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-28T11:33:09.758+0000] {processor.py:157} INFO - Started process (PID=90309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:33:09.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:33:09.766+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:09.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:33:09.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:33:09.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:09.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:33:09.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:09.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:33:09.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-28T11:33:40.249+0000] {processor.py:157} INFO - Started process (PID=90334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:33:40.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:33:40.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:40.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:33:40.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:33:40.326+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:40.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:33:40.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:40.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:33:40.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T11:34:10.795+0000] {processor.py:157} INFO - Started process (PID=90359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:34:10.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:34:10.802+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:10.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:34:10.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:34:10.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:10.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:34:10.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:10.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:34:10.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-28T11:34:41.361+0000] {processor.py:157} INFO - Started process (PID=90384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:34:41.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:34:41.369+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:41.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:34:41.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:34:41.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:41.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:34:41.425+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:41.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:34:41.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T11:35:11.812+0000] {processor.py:157} INFO - Started process (PID=90409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:35:11.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:35:11.821+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:11.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:35:11.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:35:11.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:11.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:35:11.886+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:11.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:35:11.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-28T11:35:42.358+0000] {processor.py:157} INFO - Started process (PID=90434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:35:42.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:35:42.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:42.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:35:42.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:35:42.390+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:42.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:35:42.400+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:42.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:35:42.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T11:36:12.842+0000] {processor.py:157} INFO - Started process (PID=90459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:36:12.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:36:12.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:12.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:36:12.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:36:12.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:12.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:36:12.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:12.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:36:12.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-28T11:36:43.418+0000] {processor.py:157} INFO - Started process (PID=90484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:36:43.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:36:43.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:43.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:36:43.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:36:43.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:43.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:36:43.492+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:43.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:36:43.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-28T11:37:13.763+0000] {processor.py:157} INFO - Started process (PID=90509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:37:13.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:37:13.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:13.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:37:13.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:37:13.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:13.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:37:13.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:13.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:37:13.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-28T11:37:44.247+0000] {processor.py:157} INFO - Started process (PID=90534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:37:44.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:37:44.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:44.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:37:44.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:37:44.291+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:44.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:37:44.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:44.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:37:44.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T11:38:14.714+0000] {processor.py:157} INFO - Started process (PID=90559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:38:14.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:38:14.719+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:14.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:38:14.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:38:14.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:14.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:38:14.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:14.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:38:14.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T11:38:45.163+0000] {processor.py:157} INFO - Started process (PID=90584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:38:45.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:38:45.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:45.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:38:45.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:38:45.192+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:45.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:38:45.202+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:45.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:38:45.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T11:39:15.704+0000] {processor.py:157} INFO - Started process (PID=90609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:39:15.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:39:15.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:15.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:39:15.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:39:15.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:15.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:39:15.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:15.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:39:15.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T11:39:46.195+0000] {processor.py:157} INFO - Started process (PID=90634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:39:46.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:39:46.202+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:46.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:39:46.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:39:46.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:46.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:39:46.257+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:46.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:39:46.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-28T11:40:16.717+0000] {processor.py:157} INFO - Started process (PID=90659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:40:16.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:40:16.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:16.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:40:16.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:40:16.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:16.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:40:16.830+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:16.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:40:16.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-28T11:40:47.379+0000] {processor.py:157} INFO - Started process (PID=90684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:40:47.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:40:47.389+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:47.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:40:47.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:40:47.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:47.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:40:47.451+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:47.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:40:47.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-28T11:41:18.069+0000] {processor.py:157} INFO - Started process (PID=90709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:41:18.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:41:18.075+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:18.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:41:18.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:41:18.125+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:18.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:41:18.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:18.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:41:18.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-28T11:41:48.607+0000] {processor.py:157} INFO - Started process (PID=90733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:41:48.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:41:48.612+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:48.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:41:48.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:41:48.654+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:48.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:41:48.668+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:48.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:41:48.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-28T11:42:19.031+0000] {processor.py:157} INFO - Started process (PID=90759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:42:19.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:42:19.039+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:19.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:42:19.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:42:19.067+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:19.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:42:19.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:19.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:42:19.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T11:42:49.446+0000] {processor.py:157} INFO - Started process (PID=90784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:42:49.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:42:49.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:49.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:42:49.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:42:49.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:49.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:42:49.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:49.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:42:49.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:43:19.845+0000] {processor.py:157} INFO - Started process (PID=90809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:43:19.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:43:19.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:19.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:43:19.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:43:19.874+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:19.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:43:19.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:19.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:43:19.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T11:43:50.403+0000] {processor.py:157} INFO - Started process (PID=90834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:43:50.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:43:50.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:50.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:43:50.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:43:50.463+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:50.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:43:50.488+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:50.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:43:50.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-28T11:44:20.909+0000] {processor.py:157} INFO - Started process (PID=90859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:44:20.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:44:20.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:20.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:44:20.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:44:20.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:20.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:44:20.974+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:20.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:44:20.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-28T11:44:51.284+0000] {processor.py:157} INFO - Started process (PID=90884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:44:51.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:44:51.288+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:51.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:44:51.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:44:51.314+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:51.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:44:51.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:51.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:44:51.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T11:45:21.715+0000] {processor.py:157} INFO - Started process (PID=90909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:45:21.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:45:21.717+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:21.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:45:21.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:45:21.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:21.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:45:21.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:21.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:45:21.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T11:45:52.100+0000] {processor.py:157} INFO - Started process (PID=90934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:45:52.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:45:52.103+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:52.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:45:52.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:45:52.130+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:52.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:45:52.140+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:52.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:45:52.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T11:46:22.508+0000] {processor.py:157} INFO - Started process (PID=90959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:46:22.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:46:22.513+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:22.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:46:22.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:46:22.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:22.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:46:22.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:22.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:46:22.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-28T11:46:52.963+0000] {processor.py:157} INFO - Started process (PID=90984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:46:52.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:46:52.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:52.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:46:52.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:46:52.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:52.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:46:53.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:53.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:46:53.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T11:47:23.350+0000] {processor.py:157} INFO - Started process (PID=91009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:47:23.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:47:23.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:23.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:47:23.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:47:23.374+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:23.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:47:23.382+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:23.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:47:23.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-28T11:47:53.774+0000] {processor.py:157} INFO - Started process (PID=91034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:47:53.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:47:53.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:53.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:47:53.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:47:53.806+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:53.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:47:53.820+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:53.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:47:53.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T11:48:24.192+0000] {processor.py:157} INFO - Started process (PID=91059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:48:24.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:48:24.198+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:24.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:48:24.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:48:24.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:24.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:48:24.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:24.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:48:24.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T11:48:54.611+0000] {processor.py:157} INFO - Started process (PID=91084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:48:54.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:48:54.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:54.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:48:54.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:48:54.639+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:54.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:48:54.648+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:54.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:48:54.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T11:49:25.051+0000] {processor.py:157} INFO - Started process (PID=91109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:49:25.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:49:25.055+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:25.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:49:25.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:49:25.082+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:25.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:49:25.093+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:25.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:49:25.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T11:49:55.480+0000] {processor.py:157} INFO - Started process (PID=91134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:49:55.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:49:55.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:55.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:49:55.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:49:55.510+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:55.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:49:55.520+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:55.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:49:55.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T11:50:25.913+0000] {processor.py:157} INFO - Started process (PID=91159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:50:25.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:50:25.916+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:25.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:50:25.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:50:25.949+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:25.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:50:25.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:25.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:50:25.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T11:50:56.298+0000] {processor.py:157} INFO - Started process (PID=91184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:50:56.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:50:56.300+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:56.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:50:56.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:50:56.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:56.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:50:56.333+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:56.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:50:56.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T11:51:26.704+0000] {processor.py:157} INFO - Started process (PID=91208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:51:26.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:51:26.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:26.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:51:26.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:51:26.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:26.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:51:26.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:26.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:51:26.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T11:51:57.181+0000] {processor.py:157} INFO - Started process (PID=91234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:51:57.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:51:57.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:57.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:51:57.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:51:57.212+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:57.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:51:57.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:57.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:51:57.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T11:52:27.595+0000] {processor.py:157} INFO - Started process (PID=91259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:52:27.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:52:27.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:27.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:52:27.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:52:27.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:27.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:52:27.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:27.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:52:27.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-28T11:52:57.999+0000] {processor.py:157} INFO - Started process (PID=91284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:52:58.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:52:58.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:58.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:52:58.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:52:58.030+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:58.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:52:58.042+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:58.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:52:58.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T11:53:28.417+0000] {processor.py:157} INFO - Started process (PID=91308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:53:28.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:53:28.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:28.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:53:28.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:53:28.467+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:28.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:53:28.482+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:28.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:53:28.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-28T11:53:58.778+0000] {processor.py:157} INFO - Started process (PID=91334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:53:58.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:53:58.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:58.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:53:58.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:53:58.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:58.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:53:58.824+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:58.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:53:58.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T11:54:29.231+0000] {processor.py:157} INFO - Started process (PID=91359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:54:29.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:54:29.237+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:29.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:54:29.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:54:29.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:29.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:54:29.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:29.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:54:29.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T11:54:59.685+0000] {processor.py:157} INFO - Started process (PID=91384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:54:59.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:54:59.691+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:59.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:54:59.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:54:59.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:59.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:54:59.771+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:59.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:54:59.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-28T11:55:30.204+0000] {processor.py:157} INFO - Started process (PID=91409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:55:30.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:55:30.213+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:55:30.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:55:30.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:55:30.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:55:30.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:55:30.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:55:30.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:55:30.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T11:56:00.751+0000] {processor.py:157} INFO - Started process (PID=91434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:56:00.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:56:00.758+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:00.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:56:00.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:56:00.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:00.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:56:00.852+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:00.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:56:00.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-28T11:56:31.210+0000] {processor.py:157} INFO - Started process (PID=91459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:56:31.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:56:31.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:31.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:56:31.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:56:31.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:31.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:56:31.331+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:31.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:56:31.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-28T11:57:01.643+0000] {processor.py:157} INFO - Started process (PID=91484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:57:01.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:57:01.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:01.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:57:01.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:57:01.719+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:01.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:57:01.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:01.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:57:01.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-28T11:57:32.099+0000] {processor.py:157} INFO - Started process (PID=91509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:57:32.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:57:32.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:32.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:57:32.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:57:32.161+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:32.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:57:32.179+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:32.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:57:32.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-28T11:58:02.453+0000] {processor.py:157} INFO - Started process (PID=91534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:58:02.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:58:02.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:02.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:58:02.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:58:02.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:02.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:58:02.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:02.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:58:02.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-28T11:58:32.801+0000] {processor.py:157} INFO - Started process (PID=91559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:58:32.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:58:32.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:32.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:58:32.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:58:32.843+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:32.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:58:32.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:32.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:58:32.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T11:59:03.279+0000] {processor.py:157} INFO - Started process (PID=91584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:59:03.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:59:03.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:03.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:59:03.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:59:03.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:03.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:59:03.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:03.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:59:03.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-28T11:59:33.668+0000] {processor.py:157} INFO - Started process (PID=91609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:59:33.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T11:59:33.680+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:33.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:59:33.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T11:59:33.775+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:33.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:59:33.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:33.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T11:59:33.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-07-28T12:00:04.101+0000] {processor.py:157} INFO - Started process (PID=91634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:00:04.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:00:04.108+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:04.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:00:04.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:00:04.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:04.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:00:04.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:04.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:00:04.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-28T12:00:34.580+0000] {processor.py:157} INFO - Started process (PID=91658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:00:34.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:00:34.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:34.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:00:34.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:00:34.644+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:34.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:00:34.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:34.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:00:34.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-28T12:01:04.962+0000] {processor.py:157} INFO - Started process (PID=91684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:01:04.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:01:04.977+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:04.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:01:04.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:01:05.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:05.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:01:05.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:05.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:01:05.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-28T12:01:35.384+0000] {processor.py:157} INFO - Started process (PID=91709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:01:35.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:01:35.399+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:35.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:01:35.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:01:35.465+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:35.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:01:35.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:35.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:01:35.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-28T12:02:05.772+0000] {processor.py:157} INFO - Started process (PID=91734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:02:05.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:02:05.792+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:05.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:02:05.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:02:05.930+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:05.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:02:05.946+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:05.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:02:05.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-07-28T12:02:36.239+0000] {processor.py:157} INFO - Started process (PID=91759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:02:36.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:02:36.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:36.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:02:36.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:02:36.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:36.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:02:36.322+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:36.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:02:36.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-28T12:03:06.622+0000] {processor.py:157} INFO - Started process (PID=91784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:03:06.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:03:06.629+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:06.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:03:06.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:03:06.688+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:06.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:03:06.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:06.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:03:06.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-28T12:03:37.131+0000] {processor.py:157} INFO - Started process (PID=91809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:03:37.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:03:37.137+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:37.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:03:37.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:03:37.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:37.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:03:37.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:37.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:03:37.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-28T12:04:07.581+0000] {processor.py:157} INFO - Started process (PID=91832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:04:07.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:04:07.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:07.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:04:07.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:04:07.661+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:07.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:04:07.680+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:07.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:04:07.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-28T12:04:37.994+0000] {processor.py:157} INFO - Started process (PID=91859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:04:37.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:04:38.004+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:38.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:04:38.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:04:38.067+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:38.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:04:38.090+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:38.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:04:38.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-28T12:05:08.402+0000] {processor.py:157} INFO - Started process (PID=91884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:05:08.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:05:08.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:08.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:05:08.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:05:08.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:08.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:05:08.504+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:08.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:05:08.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-28T12:05:38.913+0000] {processor.py:157} INFO - Started process (PID=91909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:05:38.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:05:38.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:38.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:05:38.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:05:38.974+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:38.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:05:38.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:38.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:05:39.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T12:06:09.393+0000] {processor.py:157} INFO - Started process (PID=91933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:06:09.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:06:09.400+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:09.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:06:09.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:06:09.445+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:09.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:06:09.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:09.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:06:09.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T12:06:39.749+0000] {processor.py:157} INFO - Started process (PID=91959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:06:39.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:06:39.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:39.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:06:39.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:06:39.820+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:39.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:06:39.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:39.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:06:39.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-28T12:07:10.277+0000] {processor.py:157} INFO - Started process (PID=91984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:07:10.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:07:10.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:10.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:07:10.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:07:10.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:10.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:07:10.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:10.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:07:10.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-28T12:07:40.770+0000] {processor.py:157} INFO - Started process (PID=92008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:07:40.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:07:40.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:40.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:07:40.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:07:40.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:40.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:07:40.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:40.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:07:40.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-28T12:08:11.137+0000] {processor.py:157} INFO - Started process (PID=92034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:08:11.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:08:11.173+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:11.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:08:11.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:08:11.238+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:11.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:08:11.258+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:11.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:08:11.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-28T12:08:41.556+0000] {processor.py:157} INFO - Started process (PID=92059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:08:41.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:08:41.564+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:41.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:08:41.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:08:41.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:41.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:08:41.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:41.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:08:41.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-28T12:09:11.914+0000] {processor.py:157} INFO - Started process (PID=92084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:09:11.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:09:11.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:11.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:09:11.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:09:11.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:11.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:09:11.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:11.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:09:11.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-28T12:09:42.313+0000] {processor.py:157} INFO - Started process (PID=92109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:09:42.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:09:42.321+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:42.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:09:42.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:09:42.380+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:42.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:09:42.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:42.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:09:42.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-28T12:10:12.805+0000] {processor.py:157} INFO - Started process (PID=92134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:10:12.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:10:12.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:12.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:10:12.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:10:12.860+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:12.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:10:12.883+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:12.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:10:12.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T12:10:43.247+0000] {processor.py:157} INFO - Started process (PID=92159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:10:43.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:10:43.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:43.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:10:43.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:10:43.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:43.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:10:43.316+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:43.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:10:43.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-28T12:11:13.639+0000] {processor.py:157} INFO - Started process (PID=92184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:11:13.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:11:13.649+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:13.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:11:13.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:11:13.693+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:13.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:11:13.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:13.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:11:13.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T12:11:44.021+0000] {processor.py:157} INFO - Started process (PID=92209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:11:44.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:11:44.032+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:44.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:11:44.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:11:44.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:44.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:11:44.113+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:44.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:11:44.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T12:12:14.565+0000] {processor.py:157} INFO - Started process (PID=92234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:12:14.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:12:14.575+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:14.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:12:14.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:12:14.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:14.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:12:14.635+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:14.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:12:14.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T12:12:44.973+0000] {processor.py:157} INFO - Started process (PID=92259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:12:44.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:12:44.977+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:44.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:12:44.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:12:45.022+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:45.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:12:45.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:45.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:12:45.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-28T12:13:15.314+0000] {processor.py:157} INFO - Started process (PID=92284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:13:15.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:13:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:15.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:13:15.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:13:15.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:15.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:13:15.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:15.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:13:15.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T12:13:45.696+0000] {processor.py:157} INFO - Started process (PID=92309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:13:45.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:13:45.702+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:45.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:13:45.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:13:45.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:45.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:13:45.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:45.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:13:45.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-28T12:14:16.099+0000] {processor.py:157} INFO - Started process (PID=92334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:14:16.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:14:16.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:16.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:14:16.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:14:16.152+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:16.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:14:16.168+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:16.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:14:16.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T12:14:46.450+0000] {processor.py:157} INFO - Started process (PID=92359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:14:46.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:14:46.454+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:46.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:14:46.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:14:46.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:46.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:14:46.495+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:46.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:14:46.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T12:15:16.816+0000] {processor.py:157} INFO - Started process (PID=92384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:15:16.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:15:16.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:16.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:15:16.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:15:16.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:16.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:15:16.933+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:16.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:15:16.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-28T12:15:47.388+0000] {processor.py:157} INFO - Started process (PID=92409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:15:47.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:15:47.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:47.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:15:47.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:15:47.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:47.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:15:47.529+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:47.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:15:47.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-07-28T12:16:17.826+0000] {processor.py:157} INFO - Started process (PID=92434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:16:17.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:16:17.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:17.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:16:17.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:16:17.902+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:17.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:16:17.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:17.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:16:17.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-28T12:16:48.190+0000] {processor.py:157} INFO - Started process (PID=92459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:16:48.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:16:48.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:48.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:16:48.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:16:48.243+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:48.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:16:48.257+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:48.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:16:48.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-28T12:17:18.692+0000] {processor.py:157} INFO - Started process (PID=92484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:17:18.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:17:18.698+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:18.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:17:18.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:17:18.745+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:18.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:17:18.759+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:18.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:17:18.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-28T12:17:49.068+0000] {processor.py:157} INFO - Started process (PID=92509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:17:49.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:17:49.081+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:49.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:17:49.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:17:49.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:49.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:17:49.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:49.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:17:49.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-28T12:18:19.444+0000] {processor.py:157} INFO - Started process (PID=92534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:18:19.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:18:19.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:19.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:18:19.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:18:19.516+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:19.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:18:19.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:19.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:18:19.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T12:18:49.828+0000] {processor.py:157} INFO - Started process (PID=92559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:18:49.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:18:49.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:49.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:18:49.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:18:49.926+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:49.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:18:49.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:49.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:18:49.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-28T12:19:20.197+0000] {processor.py:157} INFO - Started process (PID=92584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:19:20.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:19:20.204+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:20.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:19:20.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:19:20.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:20.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:19:20.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:20.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:19:20.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T12:19:50.683+0000] {processor.py:157} INFO - Started process (PID=92609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:19:50.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:19:50.691+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:50.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:19:50.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:19:50.737+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:50.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:19:50.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:50.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:19:50.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-28T12:20:21.118+0000] {processor.py:157} INFO - Started process (PID=92634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:20:21.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:20:21.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:21.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:20:21.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:20:21.191+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:21.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:20:21.209+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:21.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:20:21.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-28T12:20:51.429+0000] {processor.py:157} INFO - Started process (PID=92659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:20:51.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:20:51.431+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:51.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:20:51.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:20:51.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:51.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:20:51.465+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:51.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:20:51.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T12:21:21.828+0000] {processor.py:157} INFO - Started process (PID=92684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:21:21.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:21:21.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:21.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:21:21.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:21:21.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:21.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:21:21.947+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:21.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:21:21.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-28T12:21:52.215+0000] {processor.py:157} INFO - Started process (PID=92709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:21:52.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:21:52.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:52.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:21:52.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:21:52.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:52.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:21:52.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:52.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:21:52.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-28T12:22:22.692+0000] {processor.py:157} INFO - Started process (PID=92734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:22:22.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:22:22.706+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:22.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:22:22.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:22:22.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:22.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:22:22.808+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:22.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:22:22.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-28T12:22:53.114+0000] {processor.py:157} INFO - Started process (PID=92759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:22:53.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:22:53.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:53.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:22:53.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:22:53.204+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:53.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:22:53.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:53.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:22:53.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-28T12:23:23.681+0000] {processor.py:157} INFO - Started process (PID=92784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:23:23.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:23:23.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:23.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:23:23.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:23:23.813+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:23.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:23:23.826+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:23.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:23:23.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-07-28T12:23:54.066+0000] {processor.py:157} INFO - Started process (PID=92809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:23:54.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:23:54.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:54.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:23:54.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:23:54.135+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:54.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:23:54.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:54.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:23:54.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-28T12:24:24.657+0000] {processor.py:157} INFO - Started process (PID=92834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:24:24.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:24:24.665+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:24.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:24:24.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:24:24.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:24.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:24:24.732+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:24.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:24:24.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-28T12:24:55.291+0000] {processor.py:157} INFO - Started process (PID=92859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:24:55.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:24:55.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:55.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:24:55.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:24:55.368+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:55.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:24:55.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:55.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:24:55.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-28T12:25:25.731+0000] {processor.py:157} INFO - Started process (PID=92884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:25:25.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:25:25.736+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:25.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:25:25.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:25:25.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:25.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:25:25.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:25.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:25:25.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T12:25:56.080+0000] {processor.py:157} INFO - Started process (PID=92909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:25:56.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:25:56.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:56.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:25:56.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:25:56.122+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:56.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:25:56.137+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:56.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:25:56.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T12:26:26.540+0000] {processor.py:157} INFO - Started process (PID=92934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:26:26.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:26:26.554+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:26.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:26:26.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:26:26.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:26.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:26:26.639+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:26.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:26:26.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-28T12:26:57.064+0000] {processor.py:157} INFO - Started process (PID=92959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:26:57.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:26:57.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:57.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:26:57.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:26:57.107+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:57.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:26:57.119+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:57.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:26:57.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T12:27:27.554+0000] {processor.py:157} INFO - Started process (PID=92984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:27:27.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:27:27.561+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:27.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:27:27.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:27:27.598+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:27.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:27:27.613+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:27.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:27:27.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-28T12:27:57.995+0000] {processor.py:157} INFO - Started process (PID=93008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:27:57.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:27:58.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:58.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:27:58.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:27:58.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:58.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:27:58.057+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:58.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:27:58.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T12:28:28.477+0000] {processor.py:157} INFO - Started process (PID=93034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:28:28.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:28:28.488+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:28.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:28:28.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:28:28.542+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:28.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:28:28.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:28.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:28:28.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T12:28:58.963+0000] {processor.py:157} INFO - Started process (PID=93059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:28:58.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:28:58.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:58.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:28:58.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:28:59.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:59.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:28:59.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:59.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:28:59.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-28T12:29:29.341+0000] {processor.py:157} INFO - Started process (PID=93084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:29:29.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:29:29.346+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:29.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:29:29.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:29:29.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:29.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:29:29.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:29.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:29:29.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-28T12:29:59.670+0000] {processor.py:157} INFO - Started process (PID=93109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:29:59.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:29:59.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:59.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:29:59.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:29:59.706+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:59.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:29:59.723+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:59.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:29:59.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T12:30:30.101+0000] {processor.py:157} INFO - Started process (PID=93134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:30:30.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:30:30.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:30:30.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:30:30.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:30:30.150+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:30:30.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:30:30.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:30:30.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:30:30.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T12:31:00.510+0000] {processor.py:157} INFO - Started process (PID=93159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:31:00.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:31:00.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:00.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:31:00.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:31:00.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:00.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:31:00.545+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:00.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:31:00.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T12:31:30.936+0000] {processor.py:157} INFO - Started process (PID=93184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:31:30.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:31:30.944+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:30.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:31:30.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:31:30.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:30.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:31:30.994+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:30.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:31:31.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T12:32:01.329+0000] {processor.py:157} INFO - Started process (PID=93209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:32:01.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:32:01.333+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:01.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:32:01.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:32:01.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:01.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:32:01.371+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:01.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:32:01.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T12:32:31.846+0000] {processor.py:157} INFO - Started process (PID=93234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:32:31.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:32:31.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:31.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:32:31.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:32:31.892+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:31.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:32:31.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:31.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:32:31.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T12:33:02.233+0000] {processor.py:157} INFO - Started process (PID=93259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:33:02.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:33:02.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:02.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:33:02.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:33:02.264+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:02.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:33:02.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:02.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:33:02.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T12:33:32.655+0000] {processor.py:157} INFO - Started process (PID=93284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:33:32.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:33:32.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:32.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:33:32.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:33:32.696+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:32.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:33:32.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:32.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:33:32.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T12:34:03.072+0000] {processor.py:157} INFO - Started process (PID=93309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:34:03.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:34:03.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:03.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:34:03.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:34:03.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:03.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:34:03.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:03.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:34:03.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T12:34:33.594+0000] {processor.py:157} INFO - Started process (PID=93334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:34:33.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:34:33.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:33.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:34:33.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:34:33.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:33.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:34:33.728+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:33.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:34:33.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-28T12:35:04.079+0000] {processor.py:157} INFO - Started process (PID=93358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:35:04.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:35:04.086+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:04.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:35:04.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:35:04.146+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:04.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:35:04.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:04.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:35:04.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-28T12:35:34.636+0000] {processor.py:157} INFO - Started process (PID=93384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:35:34.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:35:34.643+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:34.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:35:34.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:35:34.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:34.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:35:34.792+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:34.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:35:34.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-07-28T12:36:04.953+0000] {processor.py:157} INFO - Started process (PID=93409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:36:04.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:36:04.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:04.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:36:04.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:36:05.029+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:05.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:36:05.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:05.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:36:05.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-28T12:36:35.333+0000] {processor.py:157} INFO - Started process (PID=93434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:36:35.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:36:35.344+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:35.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:36:35.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:36:35.375+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:35.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:36:35.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:35.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:36:35.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T12:37:05.812+0000] {processor.py:157} INFO - Started process (PID=93459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:37:05.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:37:05.817+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:05.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:37:05.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:37:05.876+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:05.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:37:05.889+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:05.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:37:05.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-28T12:37:36.181+0000] {processor.py:157} INFO - Started process (PID=93484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:37:36.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:37:36.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:36.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:37:36.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:37:36.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:36.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:37:36.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:36.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:37:36.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-28T12:38:06.665+0000] {processor.py:157} INFO - Started process (PID=93509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:38:06.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:38:06.670+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:06.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:38:06.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:38:06.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:06.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:38:06.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:06.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:38:06.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T12:38:36.986+0000] {processor.py:157} INFO - Started process (PID=93534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:38:36.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:38:36.990+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:36.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:38:37.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:38:37.036+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:37.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:38:37.053+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:37.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:38:37.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-28T12:39:07.382+0000] {processor.py:157} INFO - Started process (PID=93559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:39:07.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:39:07.404+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:07.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:39:07.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:39:07.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:07.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:39:07.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:07.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:39:07.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-28T12:39:37.940+0000] {processor.py:157} INFO - Started process (PID=93582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:39:37.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:39:37.947+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:37.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:39:37.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:39:37.986+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:37.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:39:38.001+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:38.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:39:38.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-28T12:40:08.315+0000] {processor.py:157} INFO - Started process (PID=93609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:40:08.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:40:08.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:08.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:40:08.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:40:08.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:08.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:40:08.385+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:08.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:40:08.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-28T12:40:38.709+0000] {processor.py:157} INFO - Started process (PID=93634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:40:38.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:40:38.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:38.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:40:38.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:40:38.773+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:38.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:40:38.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:38.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:40:38.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-28T12:41:09.184+0000] {processor.py:157} INFO - Started process (PID=93659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:41:09.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:41:09.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:09.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:41:09.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:41:09.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:09.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:41:09.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:09.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:41:09.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-28T12:41:39.765+0000] {processor.py:157} INFO - Started process (PID=93684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:41:39.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:41:39.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:39.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:41:39.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:41:39.874+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:39.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:41:39.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:39.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:41:39.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-28T12:42:10.110+0000] {processor.py:157} INFO - Started process (PID=93708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:42:10.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:42:10.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:10.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:42:10.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:42:10.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:10.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:42:10.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:10.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:42:10.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-28T12:42:40.479+0000] {processor.py:157} INFO - Started process (PID=93734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:42:40.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:42:40.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:40.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:42:40.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:42:40.523+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:40.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:42:40.537+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:40.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:42:40.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T12:43:10.845+0000] {processor.py:157} INFO - Started process (PID=93759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:43:10.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:43:10.854+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:10.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:43:10.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:43:10.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:10.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:43:10.919+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:10.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:43:10.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T12:43:41.323+0000] {processor.py:157} INFO - Started process (PID=93784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:43:41.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:43:41.331+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:41.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:43:41.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:43:41.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:41.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:43:41.392+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:41.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:43:41.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T12:44:11.702+0000] {processor.py:157} INFO - Started process (PID=93809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:44:11.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:44:11.706+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:11.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:44:11.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:44:11.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:11.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:44:11.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:11.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:44:11.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-28T12:44:42.217+0000] {processor.py:157} INFO - Started process (PID=93834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:44:42.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:44:42.224+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:42.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:44:42.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:44:42.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:42.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:44:42.280+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:42.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:44:42.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-28T12:45:12.665+0000] {processor.py:157} INFO - Started process (PID=93859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:45:12.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:45:12.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:12.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:45:12.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:45:12.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:12.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:45:12.745+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:12.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:45:12.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-28T12:45:43.164+0000] {processor.py:157} INFO - Started process (PID=93884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:45:43.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:45:43.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:43.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:45:43.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:45:43.226+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:43.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:45:43.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:43.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:45:43.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-28T12:46:13.503+0000] {processor.py:157} INFO - Started process (PID=93909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:46:13.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:46:13.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:13.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:46:13.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:46:13.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:13.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:46:13.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:13.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:46:13.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T12:46:43.878+0000] {processor.py:157} INFO - Started process (PID=93934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:46:43.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:46:43.887+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:43.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:46:43.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:46:43.978+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:43.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:46:43.990+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:43.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:46:44.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-28T12:47:14.197+0000] {processor.py:157} INFO - Started process (PID=93959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:47:14.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:47:14.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:14.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:47:14.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:47:14.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:14.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:47:14.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:14.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:47:14.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T12:47:44.660+0000] {processor.py:157} INFO - Started process (PID=93984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:47:44.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:47:44.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:44.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:47:44.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:47:44.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:44.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:47:44.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:44.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:47:44.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T12:48:15.040+0000] {processor.py:157} INFO - Started process (PID=94009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:48:15.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:48:15.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:15.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:48:15.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:48:15.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:15.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:48:15.090+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:15.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:48:15.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T12:48:45.434+0000] {processor.py:157} INFO - Started process (PID=94034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:48:45.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:48:45.443+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:45.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:48:45.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:48:45.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:45.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:48:45.524+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:45.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:48:45.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-28T12:49:15.850+0000] {processor.py:157} INFO - Started process (PID=94059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:49:15.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:49:15.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:15.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:49:15.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:49:15.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:15.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:49:15.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:15.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:49:15.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-28T12:49:46.201+0000] {processor.py:157} INFO - Started process (PID=94084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:49:46.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:49:46.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:46.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:49:46.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:49:46.241+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:46.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:49:46.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:46.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:49:46.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T12:50:16.589+0000] {processor.py:157} INFO - Started process (PID=94109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:50:16.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:50:16.591+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:16.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:50:16.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:50:16.612+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:16.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:50:16.623+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:16.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:50:16.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-28T12:50:46.980+0000] {processor.py:157} INFO - Started process (PID=94134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:50:46.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:50:46.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:46.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:50:47.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:50:47.016+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:47.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:50:47.027+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:47.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:50:47.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T12:51:17.282+0000] {processor.py:157} INFO - Started process (PID=94159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:51:17.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:51:17.284+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:17.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:51:17.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:51:17.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:17.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:51:17.326+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:17.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:51:17.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T12:51:47.702+0000] {processor.py:157} INFO - Started process (PID=94184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:51:47.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:51:47.707+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:47.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:51:47.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:51:47.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:47.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:51:47.761+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:47.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:51:47.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T12:52:18.314+0000] {processor.py:157} INFO - Started process (PID=94209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:52:18.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:52:18.332+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:18.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:52:18.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:52:18.384+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:18.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:52:18.399+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:18.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:52:18.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-28T12:52:49.045+0000] {processor.py:157} INFO - Started process (PID=94234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:52:49.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:52:49.058+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:49.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:52:49.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:52:49.107+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:49.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:52:49.121+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:49.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:52:49.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-28T12:53:19.423+0000] {processor.py:157} INFO - Started process (PID=94258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:53:19.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:53:19.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:19.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:53:19.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:53:19.504+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:19.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:53:19.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:19.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:53:19.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-28T12:53:49.826+0000] {processor.py:157} INFO - Started process (PID=94284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:53:49.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:53:49.834+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:49.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:53:49.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:53:49.873+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:49.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:53:49.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:49.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:53:49.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-28T12:54:20.178+0000] {processor.py:157} INFO - Started process (PID=94309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:54:20.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:54:20.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:20.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:54:20.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:54:20.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:20.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:54:20.236+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:20.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:54:20.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T12:54:50.618+0000] {processor.py:157} INFO - Started process (PID=94334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:54:50.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:54:50.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:50.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:54:50.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:54:50.645+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:50.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:54:50.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:50.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:54:50.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T12:55:20.962+0000] {processor.py:157} INFO - Started process (PID=94359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:55:20.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:55:20.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:20.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:55:20.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:55:21.001+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:21.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:55:21.013+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:21.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:55:21.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T12:55:51.392+0000] {processor.py:157} INFO - Started process (PID=94384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:55:51.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:55:51.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:51.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:55:51.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:55:51.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:51.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:55:51.437+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:51.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:55:51.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T12:56:21.785+0000] {processor.py:157} INFO - Started process (PID=94409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:56:21.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:56:21.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:21.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:56:21.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:56:21.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:21.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:56:21.824+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:21.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:56:21.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T12:56:52.221+0000] {processor.py:157} INFO - Started process (PID=94434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:56:52.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:56:52.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:52.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:56:52.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:56:52.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:52.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:56:52.264+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:52.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:56:52.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T12:57:22.615+0000] {processor.py:157} INFO - Started process (PID=94459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:57:22.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:57:22.618+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:22.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:57:22.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:57:22.642+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:22.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:57:22.654+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:22.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:57:22.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T12:57:53.005+0000] {processor.py:157} INFO - Started process (PID=94484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:57:53.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:57:53.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:53.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:57:53.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:57:53.031+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:53.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:57:53.041+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:53.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:57:53.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T12:58:23.378+0000] {processor.py:157} INFO - Started process (PID=94509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:58:23.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:58:23.381+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:23.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:58:23.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:58:23.409+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:23.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:58:23.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:23.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:58:23.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T12:58:53.796+0000] {processor.py:157} INFO - Started process (PID=94534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:58:53.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:58:53.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:53.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:58:53.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:58:53.825+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:53.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:58:53.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:53.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:58:53.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T12:59:24.186+0000] {processor.py:157} INFO - Started process (PID=94559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:59:24.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:59:24.188+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:24.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:59:24.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:59:24.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:24.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:59:24.224+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:24.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:59:24.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T12:59:54.587+0000] {processor.py:157} INFO - Started process (PID=94584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:59:54.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T12:59:54.590+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:54.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:59:54.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T12:59:54.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:54.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:59:54.626+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:54.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T12:59:54.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T13:00:25.015+0000] {processor.py:157} INFO - Started process (PID=94609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:00:25.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:00:25.018+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:25.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:00:25.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:00:25.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:25.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:00:25.059+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:25.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:00:25.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T13:00:55.518+0000] {processor.py:157} INFO - Started process (PID=94634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:00:55.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:00:55.524+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:55.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:00:55.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:00:55.559+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:55.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:00:55.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:55.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:00:55.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T13:01:25.900+0000] {processor.py:157} INFO - Started process (PID=94659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:01:25.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:01:25.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:25.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:01:25.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:01:25.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:25.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:01:25.947+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:25.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:01:25.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T13:01:56.373+0000] {processor.py:157} INFO - Started process (PID=94684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:01:56.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:01:56.377+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:56.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:01:56.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:01:56.402+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:56.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:01:56.412+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:56.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:01:56.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:02:26.798+0000] {processor.py:157} INFO - Started process (PID=94709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:02:26.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:02:26.802+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:26.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:02:26.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:02:26.828+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:26.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:02:26.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:26.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:02:26.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:02:57.228+0000] {processor.py:157} INFO - Started process (PID=94734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:02:57.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:02:57.231+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:57.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:02:57.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:02:57.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:57.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:02:57.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:57.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:02:57.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T13:03:27.665+0000] {processor.py:157} INFO - Started process (PID=94759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:03:27.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:03:27.669+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:27.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:03:27.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:03:27.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:27.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:03:27.711+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:27.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:03:27.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T13:03:58.049+0000] {processor.py:157} INFO - Started process (PID=94784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:03:58.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:03:58.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:58.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:03:58.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:03:58.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:58.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:03:58.092+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:58.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:03:58.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:04:28.494+0000] {processor.py:157} INFO - Started process (PID=94809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:04:28.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:04:28.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:28.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:04:28.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:04:28.526+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:28.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:04:28.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:28.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:04:28.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T13:04:58.879+0000] {processor.py:157} INFO - Started process (PID=94834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:04:58.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:04:58.881+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:58.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:04:58.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:04:58.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:58.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:04:58.914+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:58.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:04:58.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T13:05:29.333+0000] {processor.py:157} INFO - Started process (PID=94859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:05:29.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:05:29.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:29.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:05:29.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:05:29.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:29.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:05:29.375+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:29.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:05:29.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T13:05:59.807+0000] {processor.py:157} INFO - Started process (PID=94884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:05:59.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:05:59.810+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:59.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:05:59.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:05:59.845+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:59.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:05:59.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:59.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:05:59.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T13:06:30.153+0000] {processor.py:157} INFO - Started process (PID=94909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:06:30.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:06:30.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:06:30.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:06:30.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:06:30.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:06:30.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:06:30.193+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:06:30.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:06:30.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:07:00.562+0000] {processor.py:157} INFO - Started process (PID=94934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:07:00.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:07:00.566+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:00.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:07:00.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:07:00.592+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:00.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:07:00.602+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:00.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:07:00.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T13:07:30.970+0000] {processor.py:157} INFO - Started process (PID=94959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:07:30.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:07:30.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:30.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:07:30.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:07:30.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:30.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:07:31.009+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:31.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:07:31.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T13:08:01.373+0000] {processor.py:157} INFO - Started process (PID=94984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:08:01.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:08:01.377+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:01.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:08:01.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:08:01.405+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:01.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:08:01.414+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:01.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:08:01.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T13:08:31.744+0000] {processor.py:157} INFO - Started process (PID=95009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:08:31.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:08:31.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:31.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:08:31.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:08:31.773+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:31.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:08:31.785+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:31.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:08:31.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:09:02.134+0000] {processor.py:157} INFO - Started process (PID=95034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:09:02.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:09:02.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:02.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:09:02.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:09:02.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:02.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:09:02.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:02.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:09:02.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-28T13:09:32.534+0000] {processor.py:157} INFO - Started process (PID=95059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:09:32.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:09:32.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:32.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:09:32.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:09:32.575+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:32.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:09:32.585+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:32.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:09:32.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T13:10:02.958+0000] {processor.py:157} INFO - Started process (PID=95084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:10:02.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:10:02.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:02.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:10:02.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:10:02.990+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:02.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:10:03.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:03.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:10:03.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T13:10:33.361+0000] {processor.py:157} INFO - Started process (PID=95109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:10:33.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:10:33.365+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:33.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:10:33.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:10:33.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:33.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:10:33.403+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:33.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:10:33.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T13:11:03.771+0000] {processor.py:157} INFO - Started process (PID=95134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:11:03.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:11:03.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:03.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:11:03.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:11:03.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:03.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:11:03.811+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:03.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:11:03.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:11:34.111+0000] {processor.py:157} INFO - Started process (PID=95159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:11:34.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:11:34.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:34.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:11:34.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:11:34.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:34.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:11:34.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:34.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:11:34.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T13:12:04.520+0000] {processor.py:157} INFO - Started process (PID=95184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:12:04.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:12:04.524+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:04.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:12:04.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:12:04.553+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:04.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:12:04.566+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:04.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:12:04.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T13:12:34.981+0000] {processor.py:157} INFO - Started process (PID=95209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:12:34.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:12:34.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:34.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:12:34.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:12:35.009+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:35.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:12:35.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:35.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:12:35.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T13:13:05.355+0000] {processor.py:157} INFO - Started process (PID=95234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:13:05.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:13:05.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:05.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:13:05.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:13:05.378+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:05.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:13:05.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:05.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:13:05.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-28T13:13:35.756+0000] {processor.py:157} INFO - Started process (PID=95259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:13:35.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:13:35.759+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:35.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:13:35.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:13:35.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:35.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:13:35.797+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:35.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:13:35.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:14:06.221+0000] {processor.py:157} INFO - Started process (PID=95284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:14:06.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:14:06.226+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:06.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:14:06.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:14:06.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:06.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:14:06.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:06.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:14:06.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T13:14:36.670+0000] {processor.py:157} INFO - Started process (PID=95309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:14:36.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:14:36.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:36.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:14:36.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:14:36.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:36.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:14:36.711+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:36.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:14:36.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:15:07.132+0000] {processor.py:157} INFO - Started process (PID=95334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:15:07.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:15:07.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:07.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:15:07.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:15:07.161+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:07.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:15:07.172+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:07.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:15:07.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:15:37.474+0000] {processor.py:157} INFO - Started process (PID=95359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:15:37.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:15:37.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:37.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:15:37.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:15:37.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:37.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:15:37.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:37.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:15:37.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T13:16:07.932+0000] {processor.py:157} INFO - Started process (PID=95384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:16:07.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:16:07.935+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:07.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:16:07.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:16:07.964+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:07.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:16:07.975+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:07.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:16:07.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T13:16:38.331+0000] {processor.py:157} INFO - Started process (PID=95409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:16:38.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:16:38.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:38.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:16:38.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:16:38.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:38.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:16:38.374+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:38.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:16:38.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:17:08.699+0000] {processor.py:157} INFO - Started process (PID=95434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:17:08.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:17:08.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:08.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:17:08.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:17:08.737+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:08.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:17:08.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:08.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:17:08.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T13:17:39.176+0000] {processor.py:157} INFO - Started process (PID=95459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:17:39.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:17:39.179+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:39.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:17:39.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:17:39.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:39.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:17:39.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:39.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:17:39.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:18:09.531+0000] {processor.py:157} INFO - Started process (PID=95484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:18:09.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:18:09.534+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:09.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:18:09.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:18:09.560+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:09.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:18:09.573+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:09.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:18:09.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:18:39.956+0000] {processor.py:157} INFO - Started process (PID=95509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:18:39.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:18:39.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:39.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:18:39.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:18:39.986+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:39.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:18:39.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:39.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:18:40.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:19:10.353+0000] {processor.py:157} INFO - Started process (PID=95534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:19:10.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:19:10.358+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:10.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:19:10.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:19:10.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:10.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:19:10.407+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:10.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:19:10.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T13:19:40.725+0000] {processor.py:157} INFO - Started process (PID=95559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:19:40.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:19:40.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:40.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:19:40.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:19:40.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:40.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:19:40.782+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:40.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:19:40.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T13:20:11.172+0000] {processor.py:157} INFO - Started process (PID=95584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:20:11.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:20:11.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:11.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:20:11.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:20:11.199+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:11.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:20:11.209+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:11.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:20:11.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T13:20:41.529+0000] {processor.py:157} INFO - Started process (PID=95609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:20:41.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:20:41.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:41.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:20:41.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:20:41.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:41.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:20:41.560+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:41.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:20:41.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-28T13:21:11.953+0000] {processor.py:157} INFO - Started process (PID=95634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:21:11.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:21:11.956+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:11.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:21:11.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:21:11.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:11.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:21:11.992+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:11.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:21:12.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:21:42.381+0000] {processor.py:157} INFO - Started process (PID=95659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:21:42.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:21:42.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:42.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:21:42.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:21:42.407+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:42.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:21:42.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:42.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:21:42.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T13:22:12.722+0000] {processor.py:157} INFO - Started process (PID=95684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:22:12.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:22:12.727+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:12.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:22:12.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:22:12.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:12.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:22:12.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:12.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:22:12.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:22:43.191+0000] {processor.py:157} INFO - Started process (PID=95709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:22:43.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:22:43.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:43.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:22:43.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:22:43.226+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:43.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:22:43.238+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:43.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:22:43.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T13:23:13.649+0000] {processor.py:157} INFO - Started process (PID=95734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:23:13.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:23:13.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:13.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:23:13.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:23:13.685+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:13.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:23:13.695+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:13.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:23:13.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T13:23:44.043+0000] {processor.py:157} INFO - Started process (PID=95759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:23:44.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:23:44.046+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:44.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:23:44.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:23:44.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:44.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:23:44.090+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:44.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:23:44.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T13:24:14.492+0000] {processor.py:157} INFO - Started process (PID=95784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:24:14.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:24:14.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:14.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:24:14.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:24:14.520+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:14.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:24:14.534+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:14.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:24:14.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T13:24:44.874+0000] {processor.py:157} INFO - Started process (PID=95809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:24:44.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:24:44.877+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:44.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:24:44.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:24:44.900+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:44.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:24:44.911+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:44.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:24:44.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T13:25:15.316+0000] {processor.py:157} INFO - Started process (PID=95834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:25:15.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:25:15.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:15.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:25:15.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:25:15.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:15.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:25:15.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:15.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:25:15.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T13:25:45.724+0000] {processor.py:157} INFO - Started process (PID=95859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:25:45.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:25:45.728+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:45.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:25:45.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:25:45.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:45.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:25:45.772+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:45.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:25:45.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T13:26:16.146+0000] {processor.py:157} INFO - Started process (PID=95884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:26:16.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:26:16.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:16.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:26:16.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:26:16.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:16.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:26:16.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:16.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:26:16.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:26:46.560+0000] {processor.py:157} INFO - Started process (PID=95909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:26:46.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:26:46.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:46.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:26:46.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:26:46.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:46.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:26:46.649+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:46.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:26:46.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-28T13:27:16.884+0000] {processor.py:157} INFO - Started process (PID=95934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:27:16.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:27:16.887+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:16.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:27:16.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:27:16.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:16.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:27:16.929+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:16.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:27:16.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T13:27:47.235+0000] {processor.py:157} INFO - Started process (PID=95959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:27:47.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:27:47.238+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:47.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:27:47.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:27:47.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:47.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:27:47.280+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:47.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:27:47.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T13:28:17.661+0000] {processor.py:157} INFO - Started process (PID=95984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:28:17.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:28:17.664+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:17.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:28:17.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:28:17.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:17.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:28:17.702+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:17.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:28:17.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:28:48.055+0000] {processor.py:157} INFO - Started process (PID=96009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:28:48.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:28:48.061+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:48.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:28:48.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:28:48.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:48.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:28:48.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:48.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:28:48.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T13:29:18.510+0000] {processor.py:157} INFO - Started process (PID=96034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:29:18.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:29:18.516+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:18.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:29:18.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:29:18.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:18.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:29:18.561+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:18.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:29:18.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T13:29:48.898+0000] {processor.py:157} INFO - Started process (PID=96059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:29:48.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:29:48.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:48.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:29:48.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:29:48.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:48.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:29:48.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:48.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:29:48.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:30:19.344+0000] {processor.py:157} INFO - Started process (PID=96084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:30:19.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:30:19.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:19.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:30:19.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:30:19.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:19.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:30:19.385+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:19.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:30:19.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:30:49.783+0000] {processor.py:157} INFO - Started process (PID=96109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:30:49.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:30:49.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:49.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:30:49.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:30:49.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:49.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:30:49.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:49.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:30:49.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:31:20.169+0000] {processor.py:157} INFO - Started process (PID=96134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:31:20.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:31:20.172+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:20.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:31:20.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:31:20.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:20.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:31:20.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:20.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:31:20.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:31:50.602+0000] {processor.py:157} INFO - Started process (PID=96159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:31:50.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:31:50.605+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:50.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:31:50.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:31:50.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:50.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:31:50.641+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:50.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:31:50.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T13:32:20.980+0000] {processor.py:157} INFO - Started process (PID=96184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:32:20.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:32:20.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:20.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:32:20.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:32:20.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:20.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:32:21.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:21.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:32:21.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-28T13:32:51.321+0000] {processor.py:157} INFO - Started process (PID=96209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:32:51.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:32:51.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:51.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:32:51.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:32:51.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:51.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:32:51.375+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:51.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:32:51.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T13:33:21.682+0000] {processor.py:157} INFO - Started process (PID=96234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:33:21.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:33:21.685+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:21.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:33:21.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:33:21.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:21.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:33:21.722+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:21.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:33:21.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:33:52.073+0000] {processor.py:157} INFO - Started process (PID=96259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:33:52.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:33:52.075+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:52.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:33:52.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:33:52.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:52.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:33:52.113+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:52.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:33:52.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:34:22.524+0000] {processor.py:157} INFO - Started process (PID=96284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:34:22.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:34:22.527+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:22.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:34:22.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:34:22.556+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:22.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:34:22.566+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:22.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:34:22.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T13:34:52.964+0000] {processor.py:157} INFO - Started process (PID=96309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:34:52.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:34:52.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:52.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:34:52.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:34:52.992+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:52.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:34:53.004+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:53.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:34:53.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:35:23.339+0000] {processor.py:157} INFO - Started process (PID=96334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:35:23.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:35:23.343+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:23.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:35:23.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:35:23.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:23.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:35:23.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:23.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:35:23.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T13:35:53.727+0000] {processor.py:157} INFO - Started process (PID=96359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:35:53.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:35:53.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:53.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:35:53.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:35:53.754+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:53.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:35:53.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:53.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:35:53.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T13:36:24.124+0000] {processor.py:157} INFO - Started process (PID=96384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:36:24.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:36:24.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:24.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:36:24.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:36:24.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:24.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:36:24.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:24.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:36:24.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-28T13:36:54.662+0000] {processor.py:157} INFO - Started process (PID=96409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:36:54.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:36:54.670+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:54.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:36:54.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:36:54.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:54.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:36:54.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:54.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:36:54.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-28T13:37:25.166+0000] {processor.py:157} INFO - Started process (PID=96433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:37:25.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:37:25.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:25.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:37:25.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:37:25.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:25.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:37:25.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:25.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:37:25.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-28T13:37:55.528+0000] {processor.py:157} INFO - Started process (PID=96459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:37:55.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:37:55.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:55.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:37:55.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:37:55.602+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:55.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:37:55.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:55.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:37:55.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-28T13:38:25.957+0000] {processor.py:157} INFO - Started process (PID=96482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:38:25.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:38:25.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:25.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:38:25.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:38:26.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:26.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:38:26.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:26.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:38:26.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-28T13:38:56.419+0000] {processor.py:157} INFO - Started process (PID=96509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:38:56.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:38:56.425+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:56.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:38:56.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:38:56.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:56.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:38:56.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:56.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:38:56.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T13:39:26.960+0000] {processor.py:157} INFO - Started process (PID=96533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:39:26.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:39:26.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:26.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:39:27.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:39:27.042+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:27.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:39:27.057+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:27.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:39:27.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-28T13:39:57.317+0000] {processor.py:157} INFO - Started process (PID=96559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:39:57.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:39:57.321+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:57.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:39:57.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:39:57.366+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:57.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:39:57.382+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:57.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:39:57.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T13:40:27.713+0000] {processor.py:157} INFO - Started process (PID=96584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:40:27.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:40:27.717+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:27.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:40:27.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:40:27.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:27.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:40:27.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:27.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:40:27.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T13:40:58.143+0000] {processor.py:157} INFO - Started process (PID=96609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:40:58.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:40:58.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:58.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:40:58.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:40:58.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:58.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:40:58.188+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:58.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:40:58.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T13:41:28.623+0000] {processor.py:157} INFO - Started process (PID=96634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:41:28.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:41:28.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:28.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:41:28.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:41:28.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:28.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:41:28.732+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:28.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:41:28.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-28T13:41:59.016+0000] {processor.py:157} INFO - Started process (PID=96659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:41:59.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:41:59.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:59.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:41:59.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:41:59.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:59.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:41:59.060+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:59.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:41:59.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T13:42:29.471+0000] {processor.py:157} INFO - Started process (PID=96684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:42:29.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:42:29.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:29.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:42:29.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:42:29.535+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:29.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:42:29.553+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:29.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:42:29.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-28T13:42:59.837+0000] {processor.py:157} INFO - Started process (PID=96709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:42:59.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:42:59.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:59.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:42:59.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:42:59.868+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:59.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:42:59.878+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:59.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:42:59.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:43:30.331+0000] {processor.py:157} INFO - Started process (PID=96733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:43:30.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:43:30.339+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:43:30.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:43:30.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:43:30.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:43:30.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:43:30.445+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:43:30.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:43:30.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-28T13:44:00.759+0000] {processor.py:157} INFO - Started process (PID=96758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:44:00.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:44:00.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:00.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:44:00.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:44:00.804+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:00.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:44:00.819+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:00.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:44:00.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-28T13:44:31.267+0000] {processor.py:157} INFO - Started process (PID=96784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:44:31.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:44:31.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:31.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:44:31.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:44:31.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:31.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:44:31.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:31.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:44:31.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-28T13:45:01.822+0000] {processor.py:157} INFO - Started process (PID=96809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:45:01.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:45:01.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:01.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:45:01.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:45:01.870+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:01.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:45:01.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:01.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:45:01.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T13:45:32.212+0000] {processor.py:157} INFO - Started process (PID=96834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:45:32.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:45:32.215+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:32.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:45:32.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:45:32.242+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:32.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:45:32.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:32.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:45:32.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T13:46:02.641+0000] {processor.py:157} INFO - Started process (PID=96859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:46:02.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:46:02.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:02.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:46:02.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:46:02.695+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:02.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:46:02.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:02.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:46:02.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-28T13:46:33.022+0000] {processor.py:157} INFO - Started process (PID=96884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:46:33.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:46:33.025+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:33.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:46:33.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:46:33.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:33.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:46:33.062+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:33.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:46:33.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:47:03.387+0000] {processor.py:157} INFO - Started process (PID=96909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:47:03.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:47:03.389+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:03.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:47:03.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:47:03.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:03.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:47:03.428+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:03.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:47:03.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T13:47:33.840+0000] {processor.py:157} INFO - Started process (PID=96934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:47:33.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:47:33.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:33.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:47:33.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:47:33.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:33.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:47:33.923+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:33.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:47:33.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-28T13:48:04.305+0000] {processor.py:157} INFO - Started process (PID=96959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:48:04.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:48:04.312+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:04.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:48:04.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:48:04.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:04.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:48:04.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:04.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:48:04.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-28T13:48:34.682+0000] {processor.py:157} INFO - Started process (PID=96984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:48:34.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:48:34.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:34.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:48:34.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:48:34.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:34.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:48:34.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:34.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:48:34.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-28T13:49:05.298+0000] {processor.py:157} INFO - Started process (PID=97009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:49:05.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:49:05.305+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:05.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:49:05.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:49:05.343+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:05.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:49:05.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:05.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:49:05.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-28T13:49:35.740+0000] {processor.py:157} INFO - Started process (PID=97034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:49:35.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:49:35.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:35.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:49:35.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:49:35.792+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:35.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:49:35.806+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:35.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:49:35.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T13:50:06.216+0000] {processor.py:157} INFO - Started process (PID=97059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:50:06.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:50:06.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:06.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:50:06.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:50:06.247+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:06.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:50:06.257+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:06.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:50:06.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T13:50:36.615+0000] {processor.py:157} INFO - Started process (PID=97084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:50:36.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:50:36.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:36.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:50:36.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:50:36.637+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:36.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:50:36.646+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:36.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:50:36.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-28T13:51:07.045+0000] {processor.py:157} INFO - Started process (PID=97109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:51:07.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:51:07.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:07.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:51:07.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:51:07.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:07.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:51:07.089+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:07.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:51:07.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T13:51:37.490+0000] {processor.py:157} INFO - Started process (PID=97134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:51:37.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:51:37.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:37.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:51:37.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:51:37.528+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:37.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:51:37.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:37.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:51:37.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T13:52:07.833+0000] {processor.py:157} INFO - Started process (PID=97159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:52:07.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:52:07.842+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:07.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:52:07.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:52:07.878+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:07.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:52:07.890+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:07.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:52:07.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T13:52:38.203+0000] {processor.py:157} INFO - Started process (PID=97184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:52:38.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:52:38.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:38.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:52:38.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:52:38.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:38.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:52:38.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:38.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:52:38.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T13:53:08.685+0000] {processor.py:157} INFO - Started process (PID=97209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:53:08.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:53:08.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:08.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:53:08.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:53:08.741+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:08.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:53:08.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:08.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:53:08.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-28T13:53:38.904+0000] {processor.py:157} INFO - Started process (PID=97234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:53:38.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:53:38.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:38.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:53:38.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:53:38.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:38.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:53:38.950+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:38.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:53:38.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T13:55:31.580+0000] {processor.py:157} INFO - Started process (PID=97261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:55:31.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:55:31.583+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:55:31.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:55:31.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:55:31.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:55:31.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:55:31.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:55:31.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:55:31.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T13:56:02.014+0000] {processor.py:157} INFO - Started process (PID=97285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:56:02.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:56:02.020+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:56:02.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:56:02.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:56:02.049+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:56:02.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:56:02.060+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:56:02.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:56:02.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T13:57:47.384+0000] {processor.py:157} INFO - Started process (PID=97312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:57:47.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T13:57:47.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:57:47.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:57:47.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T13:57:47.412+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:57:47.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:57:47.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:57:47.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T13:57:47.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T14:14:12.707+0000] {processor.py:157} INFO - Started process (PID=97338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:14:12.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:14:12.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:12.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:14:12.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:14:12.766+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:12.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:14:12.796+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:12.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:14:12.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-28T14:14:43.275+0000] {processor.py:157} INFO - Started process (PID=97363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:14:43.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:14:43.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:43.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:14:43.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:14:43.343+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:43.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:14:43.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:43.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:14:43.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-28T14:15:13.762+0000] {processor.py:157} INFO - Started process (PID=97388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:15:13.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:15:13.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:13.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:15:13.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:15:13.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:13.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:15:13.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:13.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:15:13.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T14:15:44.220+0000] {processor.py:157} INFO - Started process (PID=97413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:15:44.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:15:44.224+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:44.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:15:44.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:15:44.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:44.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:15:44.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:44.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:15:44.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T14:16:14.685+0000] {processor.py:157} INFO - Started process (PID=97438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:16:14.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:16:14.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:14.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:16:14.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:16:14.717+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:14.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:16:14.728+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:14.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:16:14.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T14:16:45.164+0000] {processor.py:157} INFO - Started process (PID=97463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:16:45.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:16:45.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:45.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:16:45.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:16:45.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:45.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:16:45.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:45.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:16:45.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T14:32:56.426+0000] {processor.py:157} INFO - Started process (PID=97488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:32:56.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:32:56.430+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:32:56.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:32:56.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:32:56.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:32:56.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:32:56.494+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:32:56.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:32:56.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-28T14:37:15.239+0000] {processor.py:157} INFO - Started process (PID=97513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:37:15.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:37:15.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:15.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:37:15.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:37:15.307+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:15.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:37:15.346+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:15.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:37:15.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-28T14:37:45.835+0000] {processor.py:157} INFO - Started process (PID=97537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:37:45.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:37:45.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:45.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:37:45.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:37:45.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:45.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:37:45.911+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:45.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:37:45.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-28T14:38:16.362+0000] {processor.py:157} INFO - Started process (PID=97563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:38:16.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:38:16.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:16.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:38:16.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:38:16.393+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:16.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:38:16.406+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:16.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:38:16.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T14:38:46.760+0000] {processor.py:157} INFO - Started process (PID=97588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:38:46.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:38:46.762+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:46.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:38:46.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:38:46.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:46.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:38:46.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:46.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:38:46.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T14:39:17.120+0000] {processor.py:157} INFO - Started process (PID=97613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:39:17.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:39:17.125+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:17.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:39:17.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:39:17.152+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:17.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:39:17.161+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:17.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:39:17.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T14:39:47.603+0000] {processor.py:157} INFO - Started process (PID=97638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:39:47.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:39:47.608+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:47.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:39:47.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:39:47.637+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:47.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:39:47.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:47.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:39:47.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T14:40:17.961+0000] {processor.py:157} INFO - Started process (PID=97663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:40:17.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:40:17.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:17.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:40:17.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:40:17.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:17.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:40:17.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:17.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:40:18.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T14:40:48.407+0000] {processor.py:157} INFO - Started process (PID=97688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:40:48.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:40:48.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:48.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:40:48.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:40:48.447+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:48.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:40:48.460+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:48.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:40:48.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T14:41:18.842+0000] {processor.py:157} INFO - Started process (PID=97713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:41:18.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:41:18.845+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:18.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:41:18.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:41:18.872+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:18.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:41:18.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:18.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:41:18.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T14:41:49.295+0000] {processor.py:157} INFO - Started process (PID=97738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:41:49.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:41:49.298+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:49.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:41:49.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:41:49.325+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:49.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:41:49.335+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:49.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:41:49.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T14:42:19.677+0000] {processor.py:157} INFO - Started process (PID=97763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:42:19.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:42:19.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:19.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:42:19.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:42:19.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:19.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:42:19.721+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:19.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:42:19.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T14:42:50.105+0000] {processor.py:157} INFO - Started process (PID=97788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:42:50.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:42:50.111+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:50.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:42:50.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:42:50.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:50.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:42:50.154+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:50.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:42:50.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T14:43:20.548+0000] {processor.py:157} INFO - Started process (PID=97813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:43:20.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:43:20.553+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:20.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:43:20.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:43:20.582+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:20.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:43:20.593+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:20.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:43:20.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T14:43:51.002+0000] {processor.py:157} INFO - Started process (PID=97838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:43:51.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:43:51.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:51.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:43:51.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:43:51.050+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:51.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:43:51.064+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:51.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:43:51.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-28T14:44:21.485+0000] {processor.py:157} INFO - Started process (PID=97863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:44:21.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:44:21.490+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:21.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:44:21.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:44:21.520+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:21.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:44:21.530+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:21.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:44:21.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T14:44:52.022+0000] {processor.py:157} INFO - Started process (PID=97888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:44:52.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:44:52.027+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:52.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:44:52.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:44:52.064+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:52.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:44:52.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:52.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:44:52.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T14:45:22.504+0000] {processor.py:157} INFO - Started process (PID=97913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:45:22.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:45:22.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:22.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:45:22.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:45:22.538+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:22.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:45:22.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:22.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:45:22.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T14:45:53.012+0000] {processor.py:157} INFO - Started process (PID=97938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:45:53.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:45:53.015+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:53.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:45:53.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:45:53.042+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:53.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:45:53.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:53.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:45:53.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T14:46:23.471+0000] {processor.py:157} INFO - Started process (PID=97963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:46:23.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:46:23.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:23.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:46:23.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:46:23.501+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:23.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:46:23.511+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:23.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:46:23.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T14:46:53.934+0000] {processor.py:157} INFO - Started process (PID=97988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:46:53.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:46:53.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:53.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:46:53.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:46:53.967+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:53.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:46:53.978+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:53.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:46:53.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T14:47:24.298+0000] {processor.py:157} INFO - Started process (PID=98013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:47:24.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:47:24.300+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:24.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:47:24.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:47:24.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:24.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:47:24.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:24.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:47:24.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-28T14:47:54.733+0000] {processor.py:157} INFO - Started process (PID=98038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:47:54.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:47:54.737+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:54.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:47:54.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:47:54.766+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:54.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:47:54.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:54.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:47:54.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T14:48:25.216+0000] {processor.py:157} INFO - Started process (PID=98063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:48:25.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:48:25.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:25.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:48:25.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:48:25.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:25.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:48:25.258+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:25.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:48:25.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T14:48:55.758+0000] {processor.py:157} INFO - Started process (PID=98088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:48:55.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:48:55.763+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:55.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:48:55.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:48:55.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:55.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:48:55.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:55.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:48:55.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T14:49:26.231+0000] {processor.py:157} INFO - Started process (PID=98113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:49:26.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:49:26.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:26.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:49:26.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:49:26.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:26.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:49:26.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:26.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:49:26.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T14:49:56.647+0000] {processor.py:157} INFO - Started process (PID=98138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:49:56.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:49:56.651+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:56.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:49:56.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:49:56.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:56.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:49:56.686+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:56.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:49:56.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T14:50:27.181+0000] {processor.py:157} INFO - Started process (PID=98163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:50:27.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:50:27.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:27.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:50:27.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:50:27.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:27.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:50:27.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:27.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:50:27.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T14:50:57.634+0000] {processor.py:157} INFO - Started process (PID=98188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:50:57.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:50:57.639+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:57.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:50:57.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:50:57.670+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:57.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:50:57.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:57.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:50:57.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T14:51:28.086+0000] {processor.py:157} INFO - Started process (PID=98213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:51:28.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:51:28.093+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:28.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:51:28.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:51:28.120+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:28.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:51:28.130+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:28.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:51:28.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T14:51:58.444+0000] {processor.py:157} INFO - Started process (PID=98238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:51:58.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:51:58.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:58.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:51:58.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:51:58.486+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:58.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:51:58.500+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:58.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:51:58.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T14:52:28.941+0000] {processor.py:157} INFO - Started process (PID=98263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:52:28.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:52:28.944+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:28.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:52:28.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:52:28.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:28.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:52:28.981+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:28.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:52:28.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T14:52:59.430+0000] {processor.py:157} INFO - Started process (PID=98288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:52:59.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:52:59.436+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:59.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:52:59.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:52:59.465+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:59.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:52:59.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:59.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:52:59.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T14:53:29.923+0000] {processor.py:157} INFO - Started process (PID=98313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:53:29.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:53:29.926+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:53:29.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:53:29.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:53:29.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:53:29.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:53:29.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:53:29.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:53:29.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T14:54:00.357+0000] {processor.py:157} INFO - Started process (PID=98338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:54:00.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:54:00.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:00.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:54:00.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:54:00.393+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:00.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:54:00.402+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:00.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:54:00.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T14:54:30.708+0000] {processor.py:157} INFO - Started process (PID=98363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:54:30.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:54:30.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:30.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:54:30.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:54:30.736+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:30.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:54:30.745+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:30.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:54:30.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T14:55:01.180+0000] {processor.py:157} INFO - Started process (PID=98388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:55:01.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:55:01.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:01.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:55:01.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:55:01.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:01.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:55:01.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:01.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:55:01.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T14:55:31.670+0000] {processor.py:157} INFO - Started process (PID=98413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:55:31.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:55:31.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:31.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:55:31.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:55:31.699+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:31.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:55:31.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:31.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:55:31.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T14:56:02.102+0000] {processor.py:157} INFO - Started process (PID=98438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:56:02.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:56:02.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:02.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:56:02.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:56:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:02.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:56:02.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:02.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:56:02.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T14:56:32.548+0000] {processor.py:157} INFO - Started process (PID=98463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:56:32.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:56:32.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:32.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:56:32.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:56:32.579+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:32.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:56:32.592+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:32.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:56:32.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T14:57:02.981+0000] {processor.py:157} INFO - Started process (PID=98488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:57:02.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:57:02.985+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:02.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:57:02.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:57:03.010+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:03.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:57:03.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:03.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:57:03.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T14:57:33.437+0000] {processor.py:157} INFO - Started process (PID=98513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:57:33.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:57:33.441+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:33.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:57:33.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:57:33.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:33.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:57:33.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:33.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:57:33.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T14:58:03.957+0000] {processor.py:157} INFO - Started process (PID=98538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:58:03.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:58:03.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:03.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:58:03.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:58:03.988+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:03.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:58:04.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:04.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:58:04.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T14:58:34.474+0000] {processor.py:157} INFO - Started process (PID=98563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:58:34.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:58:34.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:34.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:58:34.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:58:34.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:34.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:58:34.524+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:34.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:58:34.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T14:59:04.903+0000] {processor.py:157} INFO - Started process (PID=98588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:59:04.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:59:04.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:04.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:59:04.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:59:04.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:04.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:59:04.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:04.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:59:04.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T14:59:35.309+0000] {processor.py:157} INFO - Started process (PID=98613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:59:35.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T14:59:35.313+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:35.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:59:35.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T14:59:35.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:35.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:59:35.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:35.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T14:59:35.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T15:00:05.747+0000] {processor.py:157} INFO - Started process (PID=98638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:00:05.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:00:05.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:05.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:00:05.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:00:05.776+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:05.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:00:05.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:05.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:00:05.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T15:00:36.249+0000] {processor.py:157} INFO - Started process (PID=98663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:00:36.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:00:36.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:36.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:00:36.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:00:36.280+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:36.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:00:36.290+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:36.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:00:36.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T15:01:06.742+0000] {processor.py:157} INFO - Started process (PID=98688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:01:06.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:01:06.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:06.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:01:06.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:01:06.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:06.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:01:06.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:06.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:01:06.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T15:01:37.209+0000] {processor.py:157} INFO - Started process (PID=98713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:01:37.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:01:37.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:37.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:01:37.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:01:37.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:37.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:01:37.250+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:37.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:01:37.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T15:02:07.649+0000] {processor.py:157} INFO - Started process (PID=98738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:02:07.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:02:07.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:07.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:02:07.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:02:07.677+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:07.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:02:07.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:07.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:02:07.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:02:38.113+0000] {processor.py:157} INFO - Started process (PID=98763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:02:38.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:02:38.115+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:38.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:02:38.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:02:38.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:38.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:02:38.152+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:38.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:02:38.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T15:03:08.627+0000] {processor.py:157} INFO - Started process (PID=98788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:03:08.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:03:08.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:08.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:03:08.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:03:08.664+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:08.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:03:08.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:08.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:03:08.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:03:39.108+0000] {processor.py:157} INFO - Started process (PID=98813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:03:39.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:03:39.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:39.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:03:39.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:03:39.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:39.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:03:39.145+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:39.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:03:39.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T15:04:09.540+0000] {processor.py:157} INFO - Started process (PID=98838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:04:09.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:04:09.543+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:09.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:04:09.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:04:09.570+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:09.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:04:09.580+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:09.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:04:09.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T15:04:40.005+0000] {processor.py:157} INFO - Started process (PID=98863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:04:40.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:04:40.012+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:40.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:04:40.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:04:40.046+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:40.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:04:40.057+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:40.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:04:40.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T15:05:10.485+0000] {processor.py:157} INFO - Started process (PID=98888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:05:10.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:05:10.490+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:10.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:05:10.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:05:10.519+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:10.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:05:10.528+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:10.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:05:10.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T15:05:40.924+0000] {processor.py:157} INFO - Started process (PID=98913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:05:40.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:05:40.929+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:40.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:05:40.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:05:40.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:40.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:05:40.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:40.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:05:40.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T15:06:11.338+0000] {processor.py:157} INFO - Started process (PID=98938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:06:11.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:06:11.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:11.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:06:11.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:06:11.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:11.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:06:11.403+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:11.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:06:11.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-28T15:06:41.863+0000] {processor.py:157} INFO - Started process (PID=98963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:06:41.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:06:41.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:41.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:06:41.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:06:41.919+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:41.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:06:41.934+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:41.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:06:41.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-28T15:07:12.349+0000] {processor.py:157} INFO - Started process (PID=98988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:07:12.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:07:12.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:12.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:07:12.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:07:12.381+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:12.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:07:12.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:12.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:07:12.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:07:42.849+0000] {processor.py:157} INFO - Started process (PID=99013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:07:42.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:07:42.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:42.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:07:42.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:07:42.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:42.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:07:42.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:42.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:07:42.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T15:08:13.355+0000] {processor.py:157} INFO - Started process (PID=99038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:08:13.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:08:13.358+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:13.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:08:13.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:08:13.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:13.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:08:13.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:13.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:08:13.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-28T15:08:43.831+0000] {processor.py:157} INFO - Started process (PID=99063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:08:43.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:08:43.833+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:43.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:08:43.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:08:43.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:43.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:08:43.866+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:43.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:08:43.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T15:09:14.251+0000] {processor.py:157} INFO - Started process (PID=99088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:09:14.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:09:14.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:14.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:09:14.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:09:14.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:14.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:09:14.295+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:14.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:09:14.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:09:44.750+0000] {processor.py:157} INFO - Started process (PID=99113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:09:44.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:09:44.754+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:44.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:09:44.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:09:44.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:44.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:09:44.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:44.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:09:44.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T15:10:15.226+0000] {processor.py:157} INFO - Started process (PID=99138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:10:15.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:10:15.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:15.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:10:15.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:10:15.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:15.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:10:15.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:15.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:10:15.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:10:45.658+0000] {processor.py:157} INFO - Started process (PID=99163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:10:45.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:10:45.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:45.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:10:45.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:10:45.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:45.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:10:45.699+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:45.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:10:45.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:11:16.083+0000] {processor.py:157} INFO - Started process (PID=99188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:11:16.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:11:16.088+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:16.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:11:16.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:11:16.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:16.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:11:16.139+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:16.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:11:16.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T15:11:46.500+0000] {processor.py:157} INFO - Started process (PID=99213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:11:46.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:11:46.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:46.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:11:46.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:11:46.528+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:46.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:11:46.537+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:46.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:11:46.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T15:12:16.985+0000] {processor.py:157} INFO - Started process (PID=99238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:12:16.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:12:16.990+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:16.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:12:17.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:12:17.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:17.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:12:17.030+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:17.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:12:17.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:12:47.456+0000] {processor.py:157} INFO - Started process (PID=99263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:12:47.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:12:47.460+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:47.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:12:47.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:12:47.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:47.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:12:47.509+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:47.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:12:47.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T15:13:17.902+0000] {processor.py:157} INFO - Started process (PID=99288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:13:17.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:13:17.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:17.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:13:17.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:13:17.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:17.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:13:17.948+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:17.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:13:17.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:13:48.311+0000] {processor.py:157} INFO - Started process (PID=99313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:13:48.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:13:48.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:48.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:13:48.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:13:48.344+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:48.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:13:48.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:48.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:13:48.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:14:18.791+0000] {processor.py:157} INFO - Started process (PID=99338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:14:18.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:14:18.795+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:18.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:14:18.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:14:18.834+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:18.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:14:18.846+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:18.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:14:18.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T15:14:49.334+0000] {processor.py:157} INFO - Started process (PID=99363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:14:49.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:14:49.337+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:49.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:14:49.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:14:49.365+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:49.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:14:49.375+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:49.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:14:49.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:15:19.689+0000] {processor.py:157} INFO - Started process (PID=99388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:15:19.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:15:19.691+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:19.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:15:19.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:15:19.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:19.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:15:19.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:19.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:15:19.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T15:15:50.163+0000] {processor.py:157} INFO - Started process (PID=99413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:15:50.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:15:50.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:50.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:15:50.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:15:50.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:50.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:15:50.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:50.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:15:50.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T15:16:20.563+0000] {processor.py:157} INFO - Started process (PID=99438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:16:20.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:16:20.568+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:20.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:16:20.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:16:20.602+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:20.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:16:20.615+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:20.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:16:20.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T15:16:51.068+0000] {processor.py:157} INFO - Started process (PID=99463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:16:51.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:16:51.071+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:51.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:16:51.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:16:51.098+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:51.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:16:51.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:51.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:16:51.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T15:17:21.481+0000] {processor.py:157} INFO - Started process (PID=99488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:17:21.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:17:21.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:21.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:17:21.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:17:21.513+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:21.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:17:21.527+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:21.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:17:21.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:17:51.987+0000] {processor.py:157} INFO - Started process (PID=99513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:17:51.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:17:51.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:51.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:17:52.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:17:52.021+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:52.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:17:52.034+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:52.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:17:52.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T15:18:22.430+0000] {processor.py:157} INFO - Started process (PID=99538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:18:22.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:18:22.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:22.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:18:22.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:18:22.460+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:22.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:18:22.471+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:22.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:18:22.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T15:18:52.835+0000] {processor.py:157} INFO - Started process (PID=99563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:18:52.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:18:52.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:52.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:18:52.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:18:52.873+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:52.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:18:52.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:52.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:18:52.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T15:19:23.317+0000] {processor.py:157} INFO - Started process (PID=99588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:19:23.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:19:23.322+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:23.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:19:23.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:19:23.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:23.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:19:23.365+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:23.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:19:23.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T15:19:53.772+0000] {processor.py:157} INFO - Started process (PID=99613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:19:53.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:19:53.775+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:53.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:19:53.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:19:53.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:53.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:19:53.810+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:53.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:19:53.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T15:20:24.263+0000] {processor.py:157} INFO - Started process (PID=99638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:20:24.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:20:24.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:24.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:20:24.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:20:24.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:24.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:20:24.309+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:24.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:20:24.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T15:20:54.765+0000] {processor.py:157} INFO - Started process (PID=99663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:20:54.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:20:54.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:54.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:20:54.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:20:54.803+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:54.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:20:54.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:54.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:20:54.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T15:21:25.245+0000] {processor.py:157} INFO - Started process (PID=99688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:21:25.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:21:25.248+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:25.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:21:25.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:21:25.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:25.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:21:25.284+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:25.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:21:25.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T15:21:55.724+0000] {processor.py:157} INFO - Started process (PID=99713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:21:55.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:21:55.727+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:55.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:21:55.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:21:55.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:55.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:21:55.766+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:55.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:21:55.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:22:26.199+0000] {processor.py:157} INFO - Started process (PID=99738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:22:26.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:22:26.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:26.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:22:26.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:22:26.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:26.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:22:26.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:26.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:22:26.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T15:22:56.711+0000] {processor.py:157} INFO - Started process (PID=99763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:22:56.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:22:56.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:56.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:22:56.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:22:56.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:56.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:22:56.763+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:56.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:22:56.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T15:23:27.156+0000] {processor.py:157} INFO - Started process (PID=99788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:23:27.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:23:27.160+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:27.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:23:27.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:23:27.190+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:27.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:23:27.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:27.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:23:27.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T15:23:57.609+0000] {processor.py:157} INFO - Started process (PID=99813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:23:57.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:23:57.611+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:57.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:23:57.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:23:57.639+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:57.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:23:57.649+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:57.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:23:57.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T15:24:28.078+0000] {processor.py:157} INFO - Started process (PID=99838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:24:28.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:24:28.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:28.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:24:28.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:24:28.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:28.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:24:28.119+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:28.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:24:28.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:24:58.614+0000] {processor.py:157} INFO - Started process (PID=99863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:24:58.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:24:58.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:58.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:24:58.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:24:58.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:58.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:24:58.691+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:58.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:24:58.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-28T15:25:29.093+0000] {processor.py:157} INFO - Started process (PID=99888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:25:29.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:25:29.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:29.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:25:29.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:25:29.117+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:29.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:25:29.125+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:29.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:25:29.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-28T15:25:59.553+0000] {processor.py:157} INFO - Started process (PID=99913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:25:59.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:25:59.558+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:59.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:25:59.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:25:59.586+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:59.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:25:59.595+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:59.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:25:59.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:26:29.979+0000] {processor.py:157} INFO - Started process (PID=99938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:26:29.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:26:29.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:26:29.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:26:30.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:26:30.027+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:26:30.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:26:30.039+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:26:30.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:26:30.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T15:27:00.410+0000] {processor.py:157} INFO - Started process (PID=99963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:27:00.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:27:00.416+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:00.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:27:00.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:27:00.445+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:00.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:27:00.455+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:00.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:27:00.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T15:27:30.897+0000] {processor.py:157} INFO - Started process (PID=99988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:27:30.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:27:30.902+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:30.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:27:30.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:27:30.935+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:30.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:27:30.944+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:30.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:27:30.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T15:28:01.294+0000] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:28:01.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:28:01.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:01.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:28:01.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:28:01.326+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:01.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:28:01.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:01.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:28:01.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:28:31.764+0000] {processor.py:157} INFO - Started process (PID=339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:28:31.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:28:31.767+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:31.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:28:31.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:28:31.808+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:31.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:28:31.837+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:31.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:28:31.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T15:29:02.231+0000] {processor.py:157} INFO - Started process (PID=364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:29:02.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:29:02.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:02.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:29:02.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:29:02.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:02.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:29:02.265+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:02.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:29:02.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-28T15:29:32.710+0000] {processor.py:157} INFO - Started process (PID=389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:29:32.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:29:32.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:32.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:29:32.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:29:32.745+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:32.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:29:32.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:32.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:29:32.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T15:30:03.212+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:30:03.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:30:03.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:03.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:30:03.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:30:03.250+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:03.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:30:03.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:03.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:30:03.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T15:30:33.695+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:30:33.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:30:33.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:33.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:30:33.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:30:33.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:33.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:30:33.740+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:33.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:30:33.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T15:31:04.145+0000] {processor.py:157} INFO - Started process (PID=464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:31:04.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:31:04.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:04.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:31:04.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:31:04.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:04.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:31:04.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:04.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:31:04.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T15:31:34.621+0000] {processor.py:157} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:31:34.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:31:34.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:34.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:31:34.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:31:34.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:34.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:31:34.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:34.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:31:34.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T15:32:05.127+0000] {processor.py:157} INFO - Started process (PID=514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:32:05.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:32:05.131+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:05.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:32:05.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:32:05.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:05.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:32:05.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:05.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:32:05.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T15:32:35.581+0000] {processor.py:157} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:32:35.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:32:35.585+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:35.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:32:35.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:32:35.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:35.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:32:35.623+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:35.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:32:35.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:33:06.093+0000] {processor.py:157} INFO - Started process (PID=564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:33:06.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:33:06.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:06.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:33:06.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:33:06.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:06.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:33:06.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:06.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:33:06.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-28T15:33:36.591+0000] {processor.py:157} INFO - Started process (PID=588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:33:36.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:33:36.596+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:36.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:33:36.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:33:36.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:36.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:33:36.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:36.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:33:36.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T15:34:07.099+0000] {processor.py:157} INFO - Started process (PID=613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:34:07.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:34:07.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:07.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:34:07.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:34:07.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:07.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:34:07.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:07.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:34:07.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T15:34:37.591+0000] {processor.py:157} INFO - Started process (PID=639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:34:37.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:34:37.594+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:37.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:34:37.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:34:37.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:37.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:34:37.641+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:37.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:34:37.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T15:35:08.113+0000] {processor.py:157} INFO - Started process (PID=663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:35:08.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:35:08.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:08.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:35:08.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:35:08.178+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:08.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:35:08.191+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:08.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:35:08.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T15:35:38.575+0000] {processor.py:157} INFO - Started process (PID=689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:35:38.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:35:38.578+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:38.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:35:38.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:35:38.609+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:38.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:35:38.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:38.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:35:38.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T15:36:09.110+0000] {processor.py:157} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:36:09.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:36:09.122+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:09.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:36:09.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:36:09.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:09.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:36:09.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:09.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:36:09.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T15:36:39.636+0000] {processor.py:157} INFO - Started process (PID=739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:36:39.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:36:39.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:39.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:36:39.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:36:39.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:39.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:36:39.686+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:39.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:36:39.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T15:37:10.163+0000] {processor.py:157} INFO - Started process (PID=764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:37:10.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:37:10.168+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:10.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:37:10.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:37:10.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:10.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:37:10.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:10.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:37:10.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:37:40.629+0000] {processor.py:157} INFO - Started process (PID=789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:37:40.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:37:40.634+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:40.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:37:40.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:37:40.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:40.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:37:40.678+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:40.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:37:40.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T15:38:11.111+0000] {processor.py:157} INFO - Started process (PID=814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:38:11.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:38:11.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:11.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:38:11.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:38:11.145+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:11.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:38:11.155+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:11.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:38:11.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:38:41.618+0000] {processor.py:157} INFO - Started process (PID=839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:38:41.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:38:41.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:41.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:38:41.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:38:41.651+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:41.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:38:41.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:41.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:38:41.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T15:39:12.036+0000] {processor.py:157} INFO - Started process (PID=864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:39:12.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:39:12.038+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:12.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:39:12.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:39:12.067+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:12.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:39:12.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:12.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:39:12.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:39:42.511+0000] {processor.py:157} INFO - Started process (PID=889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:39:42.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:39:42.514+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:42.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:39:42.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:39:42.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:42.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:39:42.553+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:42.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:39:42.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T15:40:12.898+0000] {processor.py:157} INFO - Started process (PID=914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:40:12.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:40:12.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:12.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:40:12.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:40:12.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:12.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:40:12.950+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:12.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:40:12.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T15:40:43.384+0000] {processor.py:157} INFO - Started process (PID=939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:40:43.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:40:43.390+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:43.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:40:43.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:40:43.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:43.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:40:43.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:43.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:40:43.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T15:41:13.860+0000] {processor.py:157} INFO - Started process (PID=964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:41:13.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:41:13.863+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:13.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:41:13.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:41:13.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:13.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:41:13.901+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:13.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:41:13.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T15:41:44.332+0000] {processor.py:157} INFO - Started process (PID=989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:41:44.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:41:44.338+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:44.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:41:44.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:41:44.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:44.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:41:44.380+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:44.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:41:44.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T15:42:14.832+0000] {processor.py:157} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:42:14.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:42:14.834+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:14.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:42:14.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:42:14.860+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:14.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:42:14.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:14.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:42:14.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T15:42:45.273+0000] {processor.py:157} INFO - Started process (PID=1039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:42:45.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:42:45.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:45.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:42:45.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:42:45.309+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:45.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:42:45.323+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:45.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:42:45.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T15:43:15.789+0000] {processor.py:157} INFO - Started process (PID=1064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:43:15.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:43:15.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:15.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:43:15.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:43:15.824+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:15.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:43:15.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:15.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:43:15.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:43:46.141+0000] {processor.py:157} INFO - Started process (PID=1089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:43:46.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:43:46.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:46.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:43:46.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:43:46.172+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:46.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:43:46.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:46.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:43:46.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:44:16.627+0000] {processor.py:157} INFO - Started process (PID=1114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:44:16.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:44:16.633+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:16.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:44:16.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:44:16.661+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:16.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:44:16.672+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:16.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:44:16.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T15:44:47.121+0000] {processor.py:157} INFO - Started process (PID=1139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:44:47.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:44:47.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:47.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:44:47.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:44:47.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:47.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:44:47.199+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:47.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:44:47.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-28T15:45:17.739+0000] {processor.py:157} INFO - Started process (PID=1164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:45:17.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:45:17.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:17.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:45:17.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:45:17.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:17.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:45:17.816+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:17.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:45:17.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-28T15:45:48.208+0000] {processor.py:157} INFO - Started process (PID=1189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:45:48.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:45:48.213+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:48.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:45:48.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:45:48.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:48.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:45:48.258+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:48.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:45:48.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T15:46:18.710+0000] {processor.py:157} INFO - Started process (PID=1214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:46:18.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:46:18.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:18.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:46:18.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:46:18.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:18.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:46:18.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:18.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:46:18.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:46:49.162+0000] {processor.py:157} INFO - Started process (PID=1239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:46:49.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:46:49.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:49.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:46:49.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:46:49.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:49.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:46:49.216+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:49.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:46:49.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T15:47:19.653+0000] {processor.py:157} INFO - Started process (PID=1264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:47:19.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:47:19.657+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:19.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:47:19.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:47:19.683+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:19.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:47:19.693+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:19.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:47:19.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T15:47:50.137+0000] {processor.py:157} INFO - Started process (PID=1289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:47:50.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:47:50.141+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:50.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:47:50.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:47:50.173+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:50.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:47:50.186+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:50.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:47:50.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T15:48:20.620+0000] {processor.py:157} INFO - Started process (PID=1314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:48:20.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:48:20.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:20.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:48:20.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:48:20.657+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:20.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:48:20.667+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:20.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:48:20.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:48:51.068+0000] {processor.py:157} INFO - Started process (PID=1339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:48:51.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:48:51.071+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:51.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:48:51.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:48:51.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:51.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:48:51.114+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:51.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:48:51.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:49:21.436+0000] {processor.py:157} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:49:21.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:49:21.439+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:21.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:49:21.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:49:21.463+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:21.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:49:21.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:21.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:49:21.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T15:49:51.853+0000] {processor.py:157} INFO - Started process (PID=1389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:49:51.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:49:51.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:51.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:49:51.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:49:51.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:51.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:49:51.894+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:51.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:49:51.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T15:50:22.265+0000] {processor.py:157} INFO - Started process (PID=1414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:50:22.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:50:22.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:22.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:50:22.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:50:22.300+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:22.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:50:22.311+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:22.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:50:22.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T15:50:52.777+0000] {processor.py:157} INFO - Started process (PID=1439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:50:52.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:50:52.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:52.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:50:52.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:50:52.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:52.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:50:52.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:52.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:50:52.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T15:51:23.224+0000] {processor.py:157} INFO - Started process (PID=1464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:51:23.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:51:23.228+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:23.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:51:23.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:51:23.258+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:23.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:51:23.270+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:23.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:51:23.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T15:51:53.635+0000] {processor.py:157} INFO - Started process (PID=1489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:51:53.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:51:53.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:53.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:51:53.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:51:53.665+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:53.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:51:53.677+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:53.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:51:53.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T15:52:24.119+0000] {processor.py:157} INFO - Started process (PID=1514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:52:24.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:52:24.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:24.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:52:24.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:52:24.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:24.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:52:24.160+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:24.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:52:24.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T15:52:54.543+0000] {processor.py:157} INFO - Started process (PID=1539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:52:54.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:52:54.547+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:54.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:52:54.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:52:54.580+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:54.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:52:54.592+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:54.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:52:54.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T15:53:25.057+0000] {processor.py:157} INFO - Started process (PID=1564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:53:25.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:53:25.061+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:25.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:53:25.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:53:25.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:25.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:53:25.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:25.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:53:25.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T15:53:55.525+0000] {processor.py:157} INFO - Started process (PID=1589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:53:55.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:53:55.530+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:55.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:53:55.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:53:55.558+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:55.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:53:55.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:55.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:53:55.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T15:54:26.046+0000] {processor.py:157} INFO - Started process (PID=1614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:54:26.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:54:26.049+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:26.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:54:26.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:54:26.076+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:26.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:54:26.086+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:26.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:54:26.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T15:54:56.505+0000] {processor.py:157} INFO - Started process (PID=1639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:54:56.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:54:56.510+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:56.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:54:56.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:54:56.544+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:56.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:54:56.557+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:56.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:54:56.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T15:55:26.977+0000] {processor.py:157} INFO - Started process (PID=1664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:55:26.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:55:26.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:26.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:55:26.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:55:27.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:27.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:55:27.020+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:27.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:55:27.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:55:57.464+0000] {processor.py:157} INFO - Started process (PID=1689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:55:57.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:55:57.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:57.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:55:57.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:55:57.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:57.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:55:57.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:57.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:55:57.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T15:56:27.833+0000] {processor.py:157} INFO - Started process (PID=1714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:56:27.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:56:27.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:27.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:56:27.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:56:27.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:27.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:56:27.867+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:27.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:56:27.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-28T15:56:58.265+0000] {processor.py:157} INFO - Started process (PID=1739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:56:58.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:56:58.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:58.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:56:58.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:56:58.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:58.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:56:58.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:58.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:56:58.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T15:57:28.746+0000] {processor.py:157} INFO - Started process (PID=1764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:57:28.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:57:28.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:28.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:57:28.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:57:28.780+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:28.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:57:28.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:28.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:57:28.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:57:59.209+0000] {processor.py:157} INFO - Started process (PID=1789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:57:59.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:57:59.213+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:59.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:57:59.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:57:59.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:59.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:57:59.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:59.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:57:59.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T15:58:29.697+0000] {processor.py:157} INFO - Started process (PID=1814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:58:29.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:58:29.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:58:29.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:58:29.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:58:29.728+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:58:29.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:58:29.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:58:29.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:58:29.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T15:59:00.106+0000] {processor.py:157} INFO - Started process (PID=1839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:59:00.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:59:00.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:00.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:59:00.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:59:00.139+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:00.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:59:00.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:00.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:59:00.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T15:59:30.609+0000] {processor.py:157} INFO - Started process (PID=1864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:59:30.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T15:59:30.613+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:30.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:59:30.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T15:59:30.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:30.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:59:30.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:30.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T15:59:30.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T16:00:01.078+0000] {processor.py:157} INFO - Started process (PID=1889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:00:01.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:00:01.082+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:01.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:00:01.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:00:01.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:01.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:00:01.129+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:01.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:00:01.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T16:00:31.529+0000] {processor.py:157} INFO - Started process (PID=1914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:00:31.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:00:31.533+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:31.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:00:31.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:00:31.561+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:31.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:00:31.571+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:31.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:00:31.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T16:01:01.951+0000] {processor.py:157} INFO - Started process (PID=1939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:01:01.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:01:01.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:01.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:01:01.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:01:01.985+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:01.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:01:01.998+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:01.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:01:02.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T16:01:32.468+0000] {processor.py:157} INFO - Started process (PID=1964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:01:32.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:01:32.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:32.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:01:32.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:01:32.500+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:32.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:01:32.510+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:32.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:01:32.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T16:02:02.936+0000] {processor.py:157} INFO - Started process (PID=1989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:02:02.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:02:02.940+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:02.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:02:02.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:02:02.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:02.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:02:02.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:02.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:02:02.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T16:02:33.383+0000] {processor.py:157} INFO - Started process (PID=2014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:02:33.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:02:33.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:33.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:02:33.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:02:33.418+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:33.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:02:33.427+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:33.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:02:33.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T16:03:03.847+0000] {processor.py:157} INFO - Started process (PID=2039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:03:03.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:03:03.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:03.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:03:03.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:03:03.886+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:03.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:03:03.901+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:03.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:03:03.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T16:03:34.323+0000] {processor.py:157} INFO - Started process (PID=2064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:03:34.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:03:34.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:34.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:03:34.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:03:34.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:34.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:03:34.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:34.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:03:34.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T16:04:04.735+0000] {processor.py:157} INFO - Started process (PID=2089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:04:04.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:04:04.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:04.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:04:04.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:04:04.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:04.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:04:04.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:04.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:04:04.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T16:04:35.148+0000] {processor.py:157} INFO - Started process (PID=2114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:04:35.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:04:35.152+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:35.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:04:35.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:04:35.180+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:35.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:04:35.190+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:35.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:04:35.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T16:05:05.728+0000] {processor.py:157} INFO - Started process (PID=2139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:05:05.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:05:05.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:05.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:05:05.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:05:05.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:05.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:05:05.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:05.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:05:05.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-28T16:05:36.310+0000] {processor.py:157} INFO - Started process (PID=2164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:05:36.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:05:36.343+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:36.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:05:36.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:05:36.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:36.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:05:36.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:36.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:05:36.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-28T16:06:07.064+0000] {processor.py:157} INFO - Started process (PID=2188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:06:07.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:06:07.072+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:07.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:06:07.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:06:07.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:07.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:06:07.141+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:07.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:06:07.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-28T16:06:37.559+0000] {processor.py:157} INFO - Started process (PID=2214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:06:37.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:06:37.566+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:37.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:06:37.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:06:37.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:37.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:06:37.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:37.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:06:37.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-28T16:07:08.044+0000] {processor.py:157} INFO - Started process (PID=2239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:07:08.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:07:08.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:08.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:07:08.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:07:08.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:08.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:07:08.089+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:08.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:07:08.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T16:07:38.406+0000] {processor.py:157} INFO - Started process (PID=2264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:07:38.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:07:38.414+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:38.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:07:38.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:07:38.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:38.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:07:38.494+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:38.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:07:38.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-28T16:08:08.910+0000] {processor.py:157} INFO - Started process (PID=2289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:08:08.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:08:08.913+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:08.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:08:08.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:08:08.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:08.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:08:08.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:08.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:08:08.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T16:08:39.410+0000] {processor.py:157} INFO - Started process (PID=2314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:08:39.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:08:39.433+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:39.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:08:39.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:08:39.528+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:39.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:08:39.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:39.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:08:39.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-07-28T16:09:10.035+0000] {processor.py:157} INFO - Started process (PID=2339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:09:10.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:09:10.042+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:10.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:09:10.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:09:10.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:10.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:09:10.115+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:10.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:09:10.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-28T16:09:40.654+0000] {processor.py:157} INFO - Started process (PID=2364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:09:40.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:09:40.669+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:40.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:09:40.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:09:40.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:40.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:09:40.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:40.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:09:40.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-28T16:10:11.227+0000] {processor.py:157} INFO - Started process (PID=2389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:10:11.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:10:11.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:11.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:10:11.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:10:11.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:11.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:10:11.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:11.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:10:11.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-28T16:10:41.889+0000] {processor.py:157} INFO - Started process (PID=2413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:10:41.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:10:41.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:41.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:10:41.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:10:41.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:41.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:10:41.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:41.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:10:41.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T16:11:12.383+0000] {processor.py:157} INFO - Started process (PID=2439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:11:12.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:11:12.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:12.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:11:12.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:11:12.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:12.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:11:12.429+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:12.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:11:12.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T16:11:42.830+0000] {processor.py:157} INFO - Started process (PID=2464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:11:42.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:11:42.834+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:42.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:11:42.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:11:42.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:42.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:11:42.883+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:42.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:11:42.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T16:12:13.266+0000] {processor.py:157} INFO - Started process (PID=2489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:12:13.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:12:13.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:13.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:12:13.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:12:13.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:13.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:12:13.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:13.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:12:13.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T16:12:43.812+0000] {processor.py:157} INFO - Started process (PID=2514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:12:43.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:12:43.819+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:43.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:12:43.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:12:43.878+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:43.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:12:43.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:43.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:12:43.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T16:13:14.295+0000] {processor.py:157} INFO - Started process (PID=2539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:13:14.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:13:14.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:14.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:13:14.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:13:14.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:14.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:13:14.371+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:14.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:13:14.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-28T16:13:44.738+0000] {processor.py:157} INFO - Started process (PID=2564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:13:44.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:13:44.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:44.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:13:44.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:13:44.817+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:44.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:13:44.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:44.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:13:44.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-28T16:14:15.253+0000] {processor.py:157} INFO - Started process (PID=2588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:14:15.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:14:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:15.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:14:15.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:14:15.307+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:15.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:14:15.321+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:15.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:14:15.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-28T16:14:45.713+0000] {processor.py:157} INFO - Started process (PID=2614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:14:45.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:14:45.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:45.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:14:45.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:14:45.761+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:45.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:14:45.778+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:45.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:14:45.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-28T16:15:16.181+0000] {processor.py:157} INFO - Started process (PID=2639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:15:16.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:15:16.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:16.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:15:16.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:15:16.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:16.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:15:16.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:16.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:15:16.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T16:15:46.655+0000] {processor.py:157} INFO - Started process (PID=2664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:15:46.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:15:46.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:46.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:15:46.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:15:46.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:46.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:15:46.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:46.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:15:46.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-28T16:16:17.137+0000] {processor.py:157} INFO - Started process (PID=2689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:16:17.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:16:17.141+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:17.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:16:17.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:16:17.177+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:17.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:16:17.192+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:17.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:16:17.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T16:16:47.582+0000] {processor.py:157} INFO - Started process (PID=2714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:16:47.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:16:47.588+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:47.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:16:47.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:16:47.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:47.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:16:47.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:47.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:16:47.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-28T16:17:18.046+0000] {processor.py:157} INFO - Started process (PID=2739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:17:18.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:17:18.050+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:18.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:17:18.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:17:18.086+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:18.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:17:18.099+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:18.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:17:18.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T16:17:48.600+0000] {processor.py:157} INFO - Started process (PID=2764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:17:48.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:17:48.609+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:48.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:17:48.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:17:48.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:48.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:17:48.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:48.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:17:48.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T16:18:19.090+0000] {processor.py:157} INFO - Started process (PID=2789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:18:19.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:18:19.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:19.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:18:19.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:18:19.153+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:19.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:18:19.199+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:19.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:18:19.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-28T16:18:49.656+0000] {processor.py:157} INFO - Started process (PID=2814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:18:49.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:18:49.665+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:49.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:18:49.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:18:49.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:49.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:18:49.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:49.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:18:49.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T16:19:20.187+0000] {processor.py:157} INFO - Started process (PID=2839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:19:20.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:19:20.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:20.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:19:20.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:19:20.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:20.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:19:20.318+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:20.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:19:20.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-28T16:19:50.718+0000] {processor.py:157} INFO - Started process (PID=2864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:19:50.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:19:50.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:50.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:19:50.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:19:50.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:50.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:19:50.785+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:50.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:19:50.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-28T16:20:21.207+0000] {processor.py:157} INFO - Started process (PID=2889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:20:21.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:20:21.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:21.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:20:21.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:20:21.293+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:21.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:20:21.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:21.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:20:21.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-28T16:20:51.721+0000] {processor.py:157} INFO - Started process (PID=2914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:20:51.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:20:51.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:51.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:20:51.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:20:51.762+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:51.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:20:51.775+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:51.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:20:51.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T16:21:22.213+0000] {processor.py:157} INFO - Started process (PID=2939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:21:22.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:21:22.226+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:22.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:21:22.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:21:22.303+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:22.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:21:22.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:22.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:21:22.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-28T16:21:52.772+0000] {processor.py:157} INFO - Started process (PID=2964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:21:52.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:21:52.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:52.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:21:52.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:21:52.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:52.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:21:52.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:52.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:21:52.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-07-28T16:22:23.387+0000] {processor.py:157} INFO - Started process (PID=2989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:22:23.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:22:23.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:23.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:22:23.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:22:23.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:23.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:22:23.458+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:23.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:22:23.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T16:22:53.894+0000] {processor.py:157} INFO - Started process (PID=3014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:22:53.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:22:53.899+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:53.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:22:53.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:22:53.946+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:53.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:22:53.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:53.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:22:53.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-28T16:23:24.388+0000] {processor.py:157} INFO - Started process (PID=3039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:23:24.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:23:24.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:24.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:23:24.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:23:24.448+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:24.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:23:24.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:24.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:23:24.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-28T16:23:54.888+0000] {processor.py:157} INFO - Started process (PID=3064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:23:54.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:23:54.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:54.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:23:54.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:23:54.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:54.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:23:54.957+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:54.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:23:54.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T16:24:25.390+0000] {processor.py:157} INFO - Started process (PID=3089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:24:25.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:24:25.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:25.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:24:25.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:24:25.429+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:25.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:24:25.441+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:25.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:24:25.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T16:24:55.872+0000] {processor.py:157} INFO - Started process (PID=3114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:24:55.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:24:55.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:55.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:24:55.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:24:55.945+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:55.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:24:55.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:55.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:24:55.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-28T16:25:26.396+0000] {processor.py:157} INFO - Started process (PID=3139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:25:26.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:25:26.406+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:26.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:25:26.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:25:26.467+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:26.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:25:26.489+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:26.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:25:26.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T16:25:56.987+0000] {processor.py:157} INFO - Started process (PID=3164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:25:56.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:25:56.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:56.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:25:57.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:25:57.062+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:57.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:25:57.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:57.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:25:57.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-28T16:26:27.528+0000] {processor.py:157} INFO - Started process (PID=3189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:26:27.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:26:27.535+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:27.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:26:27.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:26:27.594+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:27.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:26:27.605+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:27.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:26:27.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T16:26:58.037+0000] {processor.py:157} INFO - Started process (PID=3214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:26:58.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:26:58.047+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:58.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:26:58.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:26:58.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:58.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:26:58.115+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:58.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:26:58.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T16:27:28.464+0000] {processor.py:157} INFO - Started process (PID=3239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:27:28.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:27:28.472+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:28.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:27:28.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:27:28.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:28.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:27:28.530+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:28.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:27:28.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-28T16:27:58.962+0000] {processor.py:157} INFO - Started process (PID=3264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:27:58.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:27:58.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:58.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:27:58.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:27:58.993+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:58.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:27:59.004+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:59.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:27:59.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T16:28:29.426+0000] {processor.py:157} INFO - Started process (PID=3289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:28:29.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:28:29.433+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:28:29.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:28:29.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:28:29.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:28:29.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:28:29.491+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:28:29.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:28:29.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T16:28:59.946+0000] {processor.py:157} INFO - Started process (PID=3314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:28:59.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:28:59.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:28:59.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:28:59.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:29:00.021+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:00.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:29:00.042+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:00.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:29:00.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-28T16:29:30.435+0000] {processor.py:157} INFO - Started process (PID=3339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:29:30.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:29:30.441+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:30.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:29:30.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:29:30.501+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:30.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:29:30.519+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:30.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:29:30.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-28T16:30:00.886+0000] {processor.py:157} INFO - Started process (PID=3363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:30:00.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:30:00.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:00.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:30:00.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:30:00.948+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:00.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:30:00.964+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:00.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:30:00.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T16:30:31.518+0000] {processor.py:157} INFO - Started process (PID=3389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:30:31.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:30:31.526+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:31.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:30:31.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:30:31.572+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:31.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:30:31.587+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:31.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:30:31.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-28T16:31:01.988+0000] {processor.py:157} INFO - Started process (PID=3414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:31:01.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:31:01.994+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:01.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:31:02.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:31:02.041+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:02.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:31:02.055+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:02.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:31:02.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-28T16:31:32.408+0000] {processor.py:157} INFO - Started process (PID=3439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:31:32.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:31:32.415+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:32.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:31:32.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:31:32.463+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:32.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:31:32.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:32.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:31:32.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-28T16:32:02.900+0000] {processor.py:157} INFO - Started process (PID=3464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:32:02.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:32:02.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:02.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:32:02.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:32:02.934+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:02.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:32:02.945+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:02.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:32:02.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T16:32:33.306+0000] {processor.py:157} INFO - Started process (PID=3489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:32:33.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:32:33.312+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:33.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:32:33.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:32:33.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:33.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:32:33.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:33.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:32:33.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T16:33:03.786+0000] {processor.py:157} INFO - Started process (PID=3514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:33:03.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:33:03.791+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:03.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:33:03.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:33:03.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:03.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:33:03.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:03.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:33:03.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T16:33:34.286+0000] {processor.py:157} INFO - Started process (PID=3539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:33:34.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:33:34.289+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:34.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:33:34.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:33:34.316+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:34.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:33:34.332+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:34.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:33:34.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T16:34:04.715+0000] {processor.py:157} INFO - Started process (PID=3564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:34:04.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:34:04.724+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:04.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:34:04.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:34:04.784+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:04.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:34:04.798+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:04.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:34:04.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-28T16:34:35.200+0000] {processor.py:157} INFO - Started process (PID=3589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:34:35.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:34:35.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:35.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:34:35.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:34:35.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:35.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:34:35.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:35.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:34:35.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-28T16:35:05.817+0000] {processor.py:157} INFO - Started process (PID=3614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:35:05.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:35:05.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:05.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:35:05.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:35:05.879+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:05.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:35:05.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:05.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:35:05.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T16:35:36.346+0000] {processor.py:157} INFO - Started process (PID=3639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:35:36.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:35:36.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:36.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:35:36.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:35:36.396+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:36.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:35:36.409+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:36.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:35:36.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-28T16:36:06.804+0000] {processor.py:157} INFO - Started process (PID=3664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:36:06.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:36:06.813+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:06.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:36:06.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:36:06.897+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:06.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:36:06.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:06.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:36:06.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-28T16:36:37.389+0000] {processor.py:157} INFO - Started process (PID=3689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:36:37.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:36:37.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:37.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:36:37.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:36:37.448+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:37.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:36:37.472+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:37.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:36:37.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-28T16:37:07.902+0000] {processor.py:157} INFO - Started process (PID=3714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:37:07.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:37:07.911+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:07.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:37:07.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:37:07.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:07.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:37:07.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:07.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:37:07.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-28T16:37:38.427+0000] {processor.py:157} INFO - Started process (PID=3739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:37:38.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:37:38.436+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:38.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:37:38.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:37:38.516+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:38.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:37:38.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:38.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:37:38.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-28T16:38:08.937+0000] {processor.py:157} INFO - Started process (PID=3764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:38:08.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:38:08.948+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:08.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:38:08.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:38:08.998+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:08.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:38:09.014+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:09.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:38:09.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-28T16:38:39.460+0000] {processor.py:157} INFO - Started process (PID=3789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:38:39.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:38:39.487+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:39.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:38:39.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:38:39.549+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:39.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:38:39.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:39.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:38:39.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-28T16:39:10.001+0000] {processor.py:157} INFO - Started process (PID=3814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:39:10.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:39:10.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:10.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:39:10.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:39:10.053+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:10.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:39:10.081+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:10.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:39:10.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-28T16:39:40.462+0000] {processor.py:157} INFO - Started process (PID=3839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:39:40.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:39:40.468+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:40.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:39:40.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:39:40.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:40.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:39:40.528+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:40.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:39:40.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-28T16:40:10.963+0000] {processor.py:157} INFO - Started process (PID=3864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:40:10.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:40:10.974+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:10.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:40:11.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:40:11.029+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:11.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:40:11.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:11.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:40:11.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-28T16:40:41.436+0000] {processor.py:157} INFO - Started process (PID=3889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:40:41.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:40:41.445+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:41.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:40:41.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:40:41.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:41.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:40:41.509+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:41.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:40:41.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T16:41:11.880+0000] {processor.py:157} INFO - Started process (PID=3914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:41:11.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:41:11.887+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:11.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:41:11.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:41:11.913+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:11.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:41:11.924+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:11.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:41:11.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T16:41:42.252+0000] {processor.py:157} INFO - Started process (PID=3939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:41:42.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:41:42.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:42.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:41:42.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:41:42.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:42.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:41:42.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:42.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:41:42.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-28T16:42:12.672+0000] {processor.py:157} INFO - Started process (PID=3964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:42:12.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:42:12.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:12.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:42:12.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:42:12.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:12.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:42:12.715+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:12.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:42:12.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T16:42:43.144+0000] {processor.py:157} INFO - Started process (PID=3989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:42:43.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:42:43.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:43.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:42:43.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:42:43.197+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:43.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:42:43.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:43.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:42:43.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-28T16:43:13.670+0000] {processor.py:157} INFO - Started process (PID=4014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:43:13.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:43:13.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:13.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:43:13.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:43:13.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:13.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:43:13.753+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:13.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:43:13.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-28T16:43:44.159+0000] {processor.py:157} INFO - Started process (PID=4039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:43:44.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:43:44.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:44.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:43:44.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:43:44.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:44.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:43:44.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:44.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:43:44.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-28T16:44:14.595+0000] {processor.py:157} INFO - Started process (PID=4064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:44:14.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:44:14.602+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:14.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:44:14.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:44:14.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:14.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:44:14.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:14.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:44:14.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-28T16:44:45.125+0000] {processor.py:157} INFO - Started process (PID=4089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:44:45.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:44:45.130+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:45.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:44:45.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:44:45.168+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:45.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:44:45.181+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:45.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:44:45.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T16:45:15.578+0000] {processor.py:157} INFO - Started process (PID=4114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:45:15.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:45:15.581+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:15.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:45:15.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:45:15.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:15.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:45:15.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:15.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:45:15.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T16:45:45.986+0000] {processor.py:157} INFO - Started process (PID=4139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:45:45.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:45:45.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:45.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:45:46.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:45:46.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:46.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:45:46.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:46.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:45:46.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-28T16:46:16.440+0000] {processor.py:157} INFO - Started process (PID=4164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:46:16.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:46:16.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:16.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:46:16.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:46:16.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:16.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:46:16.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:16.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:46:16.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T16:46:46.845+0000] {processor.py:157} INFO - Started process (PID=4189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:46:46.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:46:46.850+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:46.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:46:46.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:46:46.899+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:46.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:46:46.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:46.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:46:46.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T16:47:17.396+0000] {processor.py:157} INFO - Started process (PID=4214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:47:17.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:47:17.401+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:17.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:47:17.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:47:17.443+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:17.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:47:17.458+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:17.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:47:17.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T16:47:47.833+0000] {processor.py:157} INFO - Started process (PID=4239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:47:47.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:47:47.837+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:47.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:47:47.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:47:47.873+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:47.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:47:47.886+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:47.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:47:47.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T16:48:18.319+0000] {processor.py:157} INFO - Started process (PID=4264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:48:18.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:48:18.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:18.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:48:18.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:48:18.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:18.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:48:18.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:18.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:48:18.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T16:48:48.799+0000] {processor.py:157} INFO - Started process (PID=4289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:48:48.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:48:48.805+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:48.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:48:48.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:48:48.842+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:48.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:48:48.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:48.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:48:48.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T16:49:19.229+0000] {processor.py:157} INFO - Started process (PID=4314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:49:19.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:49:19.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:19.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:49:19.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:49:19.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:19.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:49:19.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:19.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:49:19.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T16:49:49.708+0000] {processor.py:157} INFO - Started process (PID=4339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:49:49.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:49:49.711+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:49.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:49:49.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:49:49.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:49.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:49:49.758+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:49.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:49:49.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T16:50:20.201+0000] {processor.py:157} INFO - Started process (PID=4364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:50:20.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:50:20.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:20.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:50:20.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:50:20.236+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:20.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:50:20.250+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:20.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:50:20.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T16:50:50.662+0000] {processor.py:157} INFO - Started process (PID=4389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:50:50.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:50:50.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:50.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:50:50.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:50:50.697+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:50.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:50:50.707+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:50.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:50:50.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T16:51:21.069+0000] {processor.py:157} INFO - Started process (PID=4414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:51:21.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:51:21.076+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:21.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:51:21.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:51:21.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:21.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:51:21.124+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:21.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:51:21.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T16:51:51.527+0000] {processor.py:157} INFO - Started process (PID=4439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:51:51.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:51:51.532+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:51.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:51:51.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:51:51.557+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:51.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:51:51.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:51.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:51:51.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T16:52:21.964+0000] {processor.py:157} INFO - Started process (PID=4464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:52:21.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:52:21.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:21.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:52:21.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:52:21.998+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:21.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:52:22.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:22.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:52:22.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T16:52:52.414+0000] {processor.py:157} INFO - Started process (PID=4489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:52:52.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:52:52.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:52.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:52:52.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:52:52.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:52.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:52:52.472+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:52.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:52:52.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T16:53:22.882+0000] {processor.py:157} INFO - Started process (PID=4514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:53:22.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:53:22.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:22.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:53:22.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:53:22.911+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:22.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:53:22.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:22.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:53:22.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T16:53:53.316+0000] {processor.py:157} INFO - Started process (PID=4539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:53:53.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:53:53.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:53.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:53:53.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:53:53.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:53.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:53:53.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:53.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:53:53.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T16:54:23.807+0000] {processor.py:157} INFO - Started process (PID=4564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:54:23.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:54:23.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:23.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:54:23.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:54:23.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:23.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:54:23.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:23.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:54:23.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T16:54:54.264+0000] {processor.py:157} INFO - Started process (PID=4589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:54:54.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:54:54.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:54.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:54:54.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:54:54.305+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:54.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:54:54.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:54.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:54:54.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T16:55:24.714+0000] {processor.py:157} INFO - Started process (PID=4614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:55:24.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:55:24.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:24.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:55:24.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:55:24.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:24.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:55:24.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:24.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:55:24.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-28T16:55:55.117+0000] {processor.py:157} INFO - Started process (PID=4639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:55:55.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:55:55.121+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:55.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:55:55.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:55:55.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:55.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:55:55.160+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:55.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:55:55.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T16:56:25.583+0000] {processor.py:157} INFO - Started process (PID=4664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:56:25.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:56:25.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:25.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:56:25.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:56:25.618+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:25.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:56:25.628+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:25.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:56:25.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T16:56:56.024+0000] {processor.py:157} INFO - Started process (PID=4689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:56:56.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:56:56.027+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:56.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:56:56.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:56:56.056+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:56.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:56:56.066+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:56.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:56:56.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T16:57:26.488+0000] {processor.py:157} INFO - Started process (PID=4713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:57:26.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:57:26.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:26.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:57:26.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:57:26.555+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:26.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:57:26.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:26.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:57:26.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T16:57:56.957+0000] {processor.py:157} INFO - Started process (PID=4739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:57:56.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:57:56.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:56.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:57:56.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:57:56.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:56.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:57:57.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:57.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:57:57.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T16:58:27.367+0000] {processor.py:157} INFO - Started process (PID=4764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:58:27.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:58:27.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:27.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:58:27.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:58:27.409+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:27.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:58:27.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:27.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:58:27.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T16:58:57.861+0000] {processor.py:157} INFO - Started process (PID=4789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:58:57.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:58:57.865+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:57.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:58:57.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:58:57.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:57.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:58:57.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:57.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:58:57.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T16:59:28.289+0000] {processor.py:157} INFO - Started process (PID=4814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:59:28.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:59:28.293+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:28.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:59:28.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:59:28.323+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:28.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:59:28.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:28.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:59:28.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T16:59:58.765+0000] {processor.py:157} INFO - Started process (PID=4839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:59:58.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T16:59:58.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:58.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:59:58.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T16:59:58.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:58.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:59:58.821+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:58.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T16:59:58.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T17:00:29.187+0000] {processor.py:157} INFO - Started process (PID=4864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:00:29.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:00:29.190+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:29.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:00:29.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:00:29.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:29.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:00:29.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:29.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:00:29.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:00:59.614+0000] {processor.py:157} INFO - Started process (PID=4889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:00:59.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:00:59.618+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:59.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:00:59.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:00:59.649+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:59.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:00:59.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:59.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:00:59.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T17:01:30.030+0000] {processor.py:157} INFO - Started process (PID=4914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:01:30.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:01:30.032+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:01:30.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:01:30.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:01:30.061+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:01:30.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:01:30.073+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:01:30.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:01:30.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T17:02:00.418+0000] {processor.py:157} INFO - Started process (PID=4939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:02:00.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:02:00.420+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:00.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:02:00.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:02:00.450+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:00.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:02:00.461+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:00.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:02:00.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T17:02:30.821+0000] {processor.py:157} INFO - Started process (PID=4964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:02:30.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:02:30.825+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:30.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:02:30.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:02:30.854+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:30.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:02:30.867+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:30.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:02:30.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:03:01.285+0000] {processor.py:157} INFO - Started process (PID=4989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:03:01.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:03:01.292+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:01.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:03:01.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:03:01.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:01.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:03:01.339+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:01.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:03:01.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T17:03:31.758+0000] {processor.py:157} INFO - Started process (PID=5014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:03:31.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:03:31.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:31.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:03:31.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:03:31.792+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:31.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:03:31.802+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:31.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:03:31.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:04:02.198+0000] {processor.py:157} INFO - Started process (PID=5039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:04:02.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:04:02.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:02.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:04:02.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:04:02.231+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:02.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:04:02.243+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:02.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:04:02.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T17:04:32.658+0000] {processor.py:157} INFO - Started process (PID=5064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:04:32.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:04:32.661+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:32.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:04:32.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:04:32.688+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:32.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:04:32.698+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:32.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:04:32.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T17:05:03.143+0000] {processor.py:157} INFO - Started process (PID=5088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:05:03.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:05:03.150+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:03.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:05:03.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:05:03.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:03.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:05:03.208+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:03.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:05:03.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-28T17:05:33.625+0000] {processor.py:157} INFO - Started process (PID=5114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:05:33.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:05:33.629+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:33.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:05:33.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:05:33.657+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:33.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:05:33.669+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:33.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:05:33.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T17:06:04.036+0000] {processor.py:157} INFO - Started process (PID=5139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:06:04.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:06:04.039+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:04.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:06:04.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:06:04.073+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:04.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:06:04.087+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:04.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:06:04.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T17:06:34.452+0000] {processor.py:157} INFO - Started process (PID=5164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:06:34.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:06:34.458+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:34.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:06:34.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:06:34.488+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:34.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:06:34.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:34.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:06:34.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T17:07:04.931+0000] {processor.py:157} INFO - Started process (PID=5189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:07:04.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:07:04.935+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:04.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:07:04.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:07:04.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:04.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:07:04.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:04.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:07:04.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T17:07:35.363+0000] {processor.py:157} INFO - Started process (PID=5214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:07:35.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:07:35.366+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:35.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:07:35.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:07:35.392+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:35.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:07:35.401+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:35.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:07:35.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T17:08:05.824+0000] {processor.py:157} INFO - Started process (PID=5239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:08:05.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:08:05.828+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:05.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:08:05.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:08:05.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:05.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:08:05.866+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:05.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:08:05.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:08:36.276+0000] {processor.py:157} INFO - Started process (PID=5264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:08:36.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:08:36.279+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:36.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:08:36.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:08:36.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:36.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:08:36.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:36.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:08:36.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T17:09:06.703+0000] {processor.py:157} INFO - Started process (PID=5289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:09:06.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:09:06.707+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:06.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:09:06.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:09:06.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:06.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:09:06.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:06.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:09:06.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T17:09:37.130+0000] {processor.py:157} INFO - Started process (PID=5314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:09:37.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:09:37.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:37.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:09:37.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:09:37.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:37.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:09:37.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:37.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:09:37.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T17:10:07.503+0000] {processor.py:157} INFO - Started process (PID=5339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:10:07.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:10:07.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:07.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:10:07.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:10:07.538+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:07.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:10:07.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:07.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:10:07.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T17:10:37.928+0000] {processor.py:157} INFO - Started process (PID=5364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:10:37.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:10:37.933+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:37.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:10:37.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:10:37.959+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:37.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:10:37.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:37.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:10:37.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T17:11:08.325+0000] {processor.py:157} INFO - Started process (PID=5389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:11:08.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:11:08.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:08.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:11:08.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:11:08.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:08.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:11:08.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:08.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:11:08.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T17:11:38.783+0000] {processor.py:157} INFO - Started process (PID=5414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:11:38.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:11:38.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:38.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:11:38.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:11:38.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:38.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:11:38.824+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:38.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:11:38.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T17:12:09.201+0000] {processor.py:157} INFO - Started process (PID=5439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:12:09.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:12:09.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:09.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:12:09.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:12:09.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:09.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:12:09.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:09.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:12:09.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T17:12:39.611+0000] {processor.py:157} INFO - Started process (PID=5464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:12:39.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:12:39.613+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:39.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:12:39.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:12:39.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:39.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:12:39.648+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:39.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:12:39.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T17:13:10.094+0000] {processor.py:157} INFO - Started process (PID=5489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:13:10.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:13:10.099+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:10.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:13:10.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:13:10.135+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:10.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:13:10.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:10.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:13:10.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T17:13:40.560+0000] {processor.py:157} INFO - Started process (PID=5514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:13:40.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:13:40.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:40.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:13:40.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:13:40.591+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:40.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:13:40.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:40.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:13:40.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:14:10.995+0000] {processor.py:157} INFO - Started process (PID=5539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:14:10.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:14:10.998+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:10.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:14:11.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:14:11.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:11.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:14:11.032+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:11.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:14:11.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T17:14:41.476+0000] {processor.py:157} INFO - Started process (PID=5564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:14:41.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:14:41.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:41.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:14:41.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:14:41.510+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:41.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:14:41.518+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:41.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:14:41.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T17:15:11.828+0000] {processor.py:157} INFO - Started process (PID=5589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:15:11.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:15:11.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:11.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:15:11.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:15:11.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:11.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:15:11.864+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:11.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:15:11.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T17:15:42.277+0000] {processor.py:157} INFO - Started process (PID=5614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:15:42.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:15:42.281+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:42.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:15:42.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:15:42.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:42.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:15:42.317+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:42.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:15:42.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T17:16:12.694+0000] {processor.py:157} INFO - Started process (PID=5639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:16:12.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:16:12.696+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:12.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:16:12.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:16:12.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:12.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:16:12.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:12.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:16:12.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-28T17:16:43.140+0000] {processor.py:157} INFO - Started process (PID=5664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:16:43.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:16:43.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:43.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:16:43.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:16:43.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:43.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:16:43.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:43.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:16:43.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T17:17:13.612+0000] {processor.py:157} INFO - Started process (PID=5689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:17:13.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:17:13.615+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:13.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:17:13.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:17:13.645+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:13.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:17:13.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:13.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:17:13.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T17:17:44.093+0000] {processor.py:157} INFO - Started process (PID=5714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:17:44.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:17:44.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:44.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:17:44.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:17:44.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:44.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:17:44.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:44.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:17:44.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T17:18:14.573+0000] {processor.py:157} INFO - Started process (PID=5739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:18:14.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:18:14.578+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:14.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:18:14.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:18:14.607+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:14.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:18:14.621+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:14.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:18:14.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T17:18:44.996+0000] {processor.py:157} INFO - Started process (PID=5764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:18:44.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:18:44.998+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:44.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:18:45.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:18:45.026+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:45.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:18:45.038+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:45.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:18:45.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:19:15.477+0000] {processor.py:157} INFO - Started process (PID=5789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:19:15.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:19:15.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:15.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:19:15.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:19:15.510+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:15.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:19:15.523+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:15.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:19:15.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T17:19:45.921+0000] {processor.py:157} INFO - Started process (PID=5814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:19:45.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:19:45.924+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:45.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:19:45.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:19:45.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:45.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:19:45.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:45.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:19:45.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T17:20:16.373+0000] {processor.py:157} INFO - Started process (PID=5839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:20:16.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:20:16.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:16.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:20:16.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:20:16.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:16.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:20:16.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:16.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:20:16.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-28T17:20:46.792+0000] {processor.py:157} INFO - Started process (PID=5864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:20:46.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:20:46.798+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:46.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:20:46.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:20:46.828+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:46.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:20:46.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:46.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:20:46.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T17:21:17.237+0000] {processor.py:157} INFO - Started process (PID=5889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:21:17.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:21:17.241+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:17.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:21:17.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:21:17.266+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:17.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:21:17.276+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:17.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:21:17.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T17:21:47.712+0000] {processor.py:157} INFO - Started process (PID=5914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:21:47.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:21:47.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:47.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:21:47.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:21:47.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:47.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:21:47.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:47.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:21:47.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T17:22:18.074+0000] {processor.py:157} INFO - Started process (PID=5939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:22:18.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:22:18.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:18.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:22:18.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:22:18.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:18.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:22:18.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:18.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:22:18.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T17:22:48.559+0000] {processor.py:157} INFO - Started process (PID=5964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:22:48.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:22:48.565+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:48.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:22:48.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:22:48.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:48.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:22:48.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:48.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:22:48.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T17:23:19.018+0000] {processor.py:157} INFO - Started process (PID=5989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:23:19.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:23:19.020+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:19.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:23:19.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:23:19.047+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:19.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:23:19.056+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:19.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:23:19.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T17:23:49.434+0000] {processor.py:157} INFO - Started process (PID=6014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:23:49.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:23:49.438+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:49.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:23:49.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:23:49.465+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:49.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:23:49.475+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:49.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:23:49.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T17:24:19.861+0000] {processor.py:157} INFO - Started process (PID=6039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:24:19.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:24:19.864+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:19.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:24:19.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:24:19.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:19.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:24:19.900+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:19.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:24:19.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T17:24:50.319+0000] {processor.py:157} INFO - Started process (PID=6064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:24:50.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:24:50.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:50.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:24:50.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:24:50.352+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:50.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:24:50.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:50.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:24:50.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T17:25:20.796+0000] {processor.py:157} INFO - Started process (PID=6089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:25:20.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:25:20.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:20.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:25:20.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:25:20.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:20.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:25:20.842+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:20.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:25:20.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T17:25:51.182+0000] {processor.py:157} INFO - Started process (PID=6114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:25:51.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:25:51.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:51.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:25:51.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:25:51.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:51.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:25:51.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:51.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:25:51.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T17:26:21.652+0000] {processor.py:157} INFO - Started process (PID=6139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:26:21.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:26:21.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:21.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:26:21.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:26:21.685+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:21.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:26:21.696+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:21.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:26:21.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T17:26:52.011+0000] {processor.py:157} INFO - Started process (PID=6164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:26:52.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:26:52.014+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:52.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:26:52.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:26:52.036+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:52.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:26:52.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:52.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:26:52.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-28T17:27:22.449+0000] {processor.py:157} INFO - Started process (PID=6189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:27:22.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:27:22.453+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:22.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:27:22.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:27:22.480+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:22.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:27:22.491+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:22.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:27:22.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:27:52.949+0000] {processor.py:157} INFO - Started process (PID=6214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:27:52.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:27:52.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:52.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:27:52.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:27:52.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:52.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:27:52.995+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:52.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:27:53.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T17:28:23.357+0000] {processor.py:157} INFO - Started process (PID=6239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:28:23.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:28:23.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:23.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:28:23.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:28:23.384+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:23.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:28:23.393+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:23.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:28:23.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T17:28:53.822+0000] {processor.py:157} INFO - Started process (PID=6264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:28:53.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:28:53.826+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:53.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:28:53.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:28:53.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:53.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:28:53.867+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:53.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:28:53.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T17:29:24.229+0000] {processor.py:157} INFO - Started process (PID=6289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:29:24.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:29:24.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:24.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:29:24.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:29:24.270+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:24.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:29:24.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:24.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:29:24.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T17:29:54.710+0000] {processor.py:157} INFO - Started process (PID=6314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:29:54.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:29:54.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:54.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:29:54.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:29:54.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:54.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:29:54.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:54.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:29:54.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:30:25.193+0000] {processor.py:157} INFO - Started process (PID=6339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:30:25.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:30:25.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:25.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:30:25.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:30:25.216+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:25.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:30:25.226+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:25.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:30:25.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-28T17:30:55.632+0000] {processor.py:157} INFO - Started process (PID=6364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:30:55.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:30:55.634+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:55.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:30:55.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:30:55.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:55.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:30:55.672+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:55.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:30:55.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T17:31:26.119+0000] {processor.py:157} INFO - Started process (PID=6389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:31:26.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:31:26.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:26.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:31:26.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:31:26.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:26.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:31:26.161+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:26.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:31:26.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T17:31:56.599+0000] {processor.py:157} INFO - Started process (PID=6414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:31:56.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:31:56.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:56.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:31:56.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:31:56.628+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:56.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:31:56.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:56.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:31:56.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T17:32:27.109+0000] {processor.py:157} INFO - Started process (PID=6439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:32:27.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:32:27.113+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:27.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:32:27.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:32:27.141+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:27.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:32:27.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:27.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:32:27.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T17:32:57.514+0000] {processor.py:157} INFO - Started process (PID=6463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:32:57.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:32:57.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:57.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:32:57.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:32:57.584+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:57.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:32:57.610+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:57.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:32:57.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-28T17:33:28.058+0000] {processor.py:157} INFO - Started process (PID=6489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:33:28.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:33:28.060+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:28.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:33:28.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:33:28.092+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:28.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:33:28.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:28.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:33:28.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T17:33:58.434+0000] {processor.py:157} INFO - Started process (PID=6514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:33:58.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:33:58.437+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:58.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:33:58.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:33:58.465+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:58.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:33:58.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:58.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:33:58.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T17:34:28.893+0000] {processor.py:157} INFO - Started process (PID=6539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:34:28.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:34:28.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:28.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:34:28.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:34:28.928+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:28.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:34:28.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:28.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:34:28.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T17:34:59.379+0000] {processor.py:157} INFO - Started process (PID=6564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:34:59.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:34:59.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:59.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:34:59.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:34:59.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:59.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:34:59.436+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:59.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:34:59.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T17:35:29.835+0000] {processor.py:157} INFO - Started process (PID=6589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:35:29.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:35:29.841+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:35:29.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:35:29.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:35:29.872+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:35:29.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:35:29.883+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:35:29.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:35:29.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T17:36:00.336+0000] {processor.py:157} INFO - Started process (PID=6614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:36:00.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:36:00.339+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:00.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:36:00.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:36:00.368+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:00.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:36:00.380+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:00.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:36:00.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T17:36:30.879+0000] {processor.py:157} INFO - Started process (PID=6638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:36:30.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:36:30.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:30.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:36:30.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:36:30.949+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:30.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:36:30.962+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:30.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:36:30.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-28T17:37:01.374+0000] {processor.py:157} INFO - Started process (PID=6664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:37:01.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:37:01.375+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:01.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:37:01.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:37:01.403+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:01.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:37:01.413+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:01.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:37:01.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T17:37:31.792+0000] {processor.py:157} INFO - Started process (PID=6689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:37:31.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:37:31.797+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:31.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:37:31.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:37:31.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:31.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:37:31.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:31.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:37:31.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T17:38:02.305+0000] {processor.py:157} INFO - Started process (PID=6714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:38:02.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:38:02.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:02.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:38:02.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:38:02.349+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:02.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:38:02.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:02.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:38:02.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T17:38:32.809+0000] {processor.py:157} INFO - Started process (PID=6739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:38:32.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:38:32.819+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:32.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:38:32.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:38:32.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:32.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:38:32.870+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:32.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:38:32.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-28T17:39:03.328+0000] {processor.py:157} INFO - Started process (PID=6764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:39:03.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:39:03.332+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:03.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:39:03.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:39:03.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:03.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:39:03.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:03.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:39:03.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T17:39:33.803+0000] {processor.py:157} INFO - Started process (PID=6789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:39:33.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:39:33.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:33.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:39:33.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:39:33.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:33.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:39:33.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:33.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:39:33.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T17:40:04.275+0000] {processor.py:157} INFO - Started process (PID=6814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:40:04.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:40:04.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:04.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:40:04.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:40:04.340+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:04.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:40:04.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:04.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:40:04.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T17:40:34.710+0000] {processor.py:157} INFO - Started process (PID=6839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:40:34.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:40:34.715+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:34.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:40:34.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:40:34.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:34.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:40:34.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:34.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:40:34.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T17:41:05.150+0000] {processor.py:157} INFO - Started process (PID=6864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:41:05.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:41:05.153+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:05.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:41:05.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:41:05.192+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:05.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:41:05.204+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:05.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:41:05.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T17:41:35.603+0000] {processor.py:157} INFO - Started process (PID=6889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:41:35.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:41:35.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:35.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:41:35.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:41:35.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:35.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:41:35.649+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:35.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:41:35.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T17:42:05.996+0000] {processor.py:157} INFO - Started process (PID=6914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:42:06.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:42:06.004+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:06.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:42:06.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:42:06.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:06.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:42:06.044+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:06.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:42:06.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T17:42:36.477+0000] {processor.py:157} INFO - Started process (PID=6939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:42:36.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:42:36.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:36.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:42:36.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:42:36.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:36.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:42:36.517+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:36.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:42:36.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T17:43:06.903+0000] {processor.py:157} INFO - Started process (PID=6964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:43:06.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:43:06.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:06.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:43:06.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:43:06.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:06.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:43:06.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:06.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:43:06.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T17:43:37.388+0000] {processor.py:157} INFO - Started process (PID=6989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:43:37.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:43:37.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:37.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:43:37.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:43:37.420+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:37.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:43:37.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:37.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:43:37.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T17:44:07.773+0000] {processor.py:157} INFO - Started process (PID=7014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:44:07.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:44:07.775+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:07.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:44:07.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:44:07.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:07.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:44:07.810+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:07.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:44:07.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T17:44:38.925+0000] {processor.py:157} INFO - Started process (PID=7039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:44:38.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:44:38.945+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:38.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:44:38.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:44:39.038+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:39.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:44:39.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:39.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:44:39.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-07-28T17:45:09.581+0000] {processor.py:157} INFO - Started process (PID=7064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:45:09.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:45:09.585+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:09.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:45:09.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:45:09.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:09.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:45:09.639+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:09.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:45:09.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T17:45:40.090+0000] {processor.py:157} INFO - Started process (PID=7089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:45:40.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:45:40.099+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:40.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:45:40.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:45:40.162+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:40.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:45:40.181+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:40.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:45:40.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-28T17:46:10.672+0000] {processor.py:157} INFO - Started process (PID=7114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:46:10.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:46:10.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:10.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:46:10.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:46:10.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:10.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:46:10.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:10.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:46:10.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T17:46:41.171+0000] {processor.py:157} INFO - Started process (PID=7139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:46:41.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:46:41.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:41.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:46:41.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:46:41.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:41.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:46:41.211+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:41.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:46:41.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T17:47:11.637+0000] {processor.py:157} INFO - Started process (PID=7164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:47:11.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:47:11.641+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:11.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:47:11.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:47:11.672+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:11.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:47:11.682+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:11.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:47:11.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T17:47:42.244+0000] {processor.py:157} INFO - Started process (PID=7189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:47:42.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:47:42.250+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:42.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:47:42.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:47:42.317+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:42.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:47:42.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:42.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:47:42.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-28T17:48:12.691+0000] {processor.py:157} INFO - Started process (PID=7214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:48:12.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:48:12.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:12.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:48:12.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:48:12.721+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:12.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:48:12.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:12.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:48:12.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T17:48:43.092+0000] {processor.py:157} INFO - Started process (PID=7239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:48:43.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:48:43.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:43.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:48:43.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:48:43.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:43.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:48:43.164+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:43.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:48:43.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T17:49:13.583+0000] {processor.py:157} INFO - Started process (PID=7264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:49:13.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:49:13.587+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:13.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:49:13.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:49:13.618+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:13.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:49:13.630+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:13.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:49:13.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T17:49:43.939+0000] {processor.py:157} INFO - Started process (PID=7289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:49:43.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:49:43.942+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:43.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:49:43.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:49:43.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:43.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:49:43.975+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:43.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:49:43.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T17:50:14.354+0000] {processor.py:157} INFO - Started process (PID=7314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:50:14.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:50:14.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:14.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:50:14.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:50:14.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:14.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:50:14.412+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:14.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:50:14.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T17:50:44.827+0000] {processor.py:157} INFO - Started process (PID=7339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:50:44.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:50:44.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:44.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:50:44.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:50:44.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:44.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:50:44.865+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:44.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:50:44.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T17:51:15.254+0000] {processor.py:157} INFO - Started process (PID=7364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:51:15.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:51:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:15.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:51:15.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:51:15.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:15.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:51:15.352+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:15.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:51:15.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-28T17:51:45.854+0000] {processor.py:157} INFO - Started process (PID=7389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:51:45.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:51:45.862+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:45.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:51:45.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:51:45.919+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:45.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:51:45.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:45.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:51:45.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T17:52:16.422+0000] {processor.py:157} INFO - Started process (PID=7414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:52:16.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:52:16.433+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:16.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:52:16.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:52:16.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:16.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:52:16.497+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:16.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:52:16.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-28T17:52:46.865+0000] {processor.py:157} INFO - Started process (PID=7439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:52:46.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:52:46.868+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:46.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:52:46.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:52:46.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:46.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:52:46.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:46.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:52:46.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T17:53:17.245+0000] {processor.py:157} INFO - Started process (PID=7464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:53:17.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:53:17.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:17.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:53:17.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:53:17.298+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:17.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:53:17.311+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:17.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:53:17.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-28T17:53:47.750+0000] {processor.py:157} INFO - Started process (PID=7489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:53:47.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:53:47.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:47.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:53:47.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:53:47.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:47.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:53:47.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:47.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:53:47.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T17:54:18.163+0000] {processor.py:157} INFO - Started process (PID=7514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:54:18.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:54:18.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:18.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:54:18.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:54:18.208+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:18.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:54:18.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:18.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:54:18.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T17:54:48.686+0000] {processor.py:157} INFO - Started process (PID=7539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:54:48.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:54:48.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:48.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:54:48.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:54:48.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:48.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:54:48.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:48.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:54:48.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-28T17:55:19.093+0000] {processor.py:157} INFO - Started process (PID=7564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:55:19.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:55:19.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:19.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:55:19.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:55:19.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:19.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:55:19.154+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:19.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:55:19.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-28T17:55:49.591+0000] {processor.py:157} INFO - Started process (PID=7589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:55:49.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:55:49.594+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:49.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:55:49.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:55:49.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:49.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:55:49.634+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:49.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:55:49.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T17:56:19.989+0000] {processor.py:157} INFO - Started process (PID=7614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:56:19.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:56:19.992+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:19.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:56:20.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:56:20.022+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:20.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:56:20.034+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:20.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:56:20.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T17:56:50.529+0000] {processor.py:157} INFO - Started process (PID=7639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:56:50.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:56:50.534+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:50.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:56:50.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:56:50.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:50.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:56:50.588+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:50.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:56:50.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T17:57:21.076+0000] {processor.py:157} INFO - Started process (PID=7664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:57:21.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:57:21.081+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:21.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:57:21.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:57:21.108+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:21.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:57:21.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:21.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:57:21.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T17:57:51.550+0000] {processor.py:157} INFO - Started process (PID=7688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:57:51.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:57:51.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:51.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:57:51.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:57:51.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:51.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:57:51.647+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:51.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:57:51.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-28T17:58:22.075+0000] {processor.py:157} INFO - Started process (PID=7714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:58:22.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:58:22.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:22.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:58:22.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:58:22.121+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:22.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:58:22.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:22.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:58:22.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-28T17:58:52.509+0000] {processor.py:157} INFO - Started process (PID=7739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:58:52.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:58:52.513+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:52.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:58:52.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:58:52.542+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:52.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:58:52.558+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:52.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:58:52.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T17:59:23.090+0000] {processor.py:157} INFO - Started process (PID=7763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:59:23.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:59:23.098+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:23.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:59:23.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:59:23.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:23.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:59:23.172+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:23.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:59:23.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-28T17:59:53.572+0000] {processor.py:157} INFO - Started process (PID=7789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:59:53.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T17:59:53.575+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:53.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:59:53.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T17:59:53.609+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:53.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:59:53.621+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:53.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T17:59:53.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T18:00:24.061+0000] {processor.py:157} INFO - Started process (PID=7814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:00:24.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:00:24.070+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:24.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:00:24.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:00:24.124+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:24.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:00:24.137+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:24.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:00:24.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-28T18:00:54.496+0000] {processor.py:157} INFO - Started process (PID=7839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:00:54.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:00:54.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:54.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:00:54.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:00:54.535+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:54.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:00:54.545+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:54.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:00:54.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T18:01:24.928+0000] {processor.py:157} INFO - Started process (PID=7864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:01:24.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:01:24.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:24.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:01:24.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:01:24.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:24.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:01:24.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:24.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:01:24.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T18:01:55.320+0000] {processor.py:157} INFO - Started process (PID=7889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:01:55.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:01:55.325+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:55.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:01:55.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:01:55.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:55.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:01:55.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:55.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:01:55.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T18:02:25.746+0000] {processor.py:157} INFO - Started process (PID=7914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:02:25.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:02:25.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:25.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:02:25.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:02:25.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:25.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:02:25.791+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:25.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:02:25.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T18:02:56.249+0000] {processor.py:157} INFO - Started process (PID=7939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:02:56.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:02:56.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:56.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:02:56.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:02:56.293+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:56.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:02:56.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:56.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:02:56.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T18:03:26.752+0000] {processor.py:157} INFO - Started process (PID=7964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:03:26.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:03:26.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:26.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:03:26.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:03:26.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:26.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:03:26.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:26.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:03:26.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T18:03:57.152+0000] {processor.py:157} INFO - Started process (PID=7989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:03:57.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:03:57.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:57.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:03:57.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:03:57.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:57.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:03:57.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:57.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:03:57.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T18:04:27.523+0000] {processor.py:157} INFO - Started process (PID=8014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:04:27.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:04:27.529+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:27.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:04:27.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:04:27.562+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:27.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:04:27.573+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:27.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:04:27.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T18:04:57.877+0000] {processor.py:157} INFO - Started process (PID=8039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:04:57.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:04:57.879+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:57.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:04:57.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:04:57.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:57.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:04:57.915+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:57.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:04:57.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T18:05:28.317+0000] {processor.py:157} INFO - Started process (PID=8064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:05:28.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:05:28.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:28.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:05:28.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:05:28.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:28.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:05:28.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:28.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:05:28.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T18:05:58.745+0000] {processor.py:157} INFO - Started process (PID=8089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:05:58.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:05:58.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:58.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:05:58.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:05:58.797+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:58.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:05:58.810+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:58.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:05:58.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-28T18:06:29.232+0000] {processor.py:157} INFO - Started process (PID=8114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:06:29.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:06:29.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:29.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:06:29.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:06:29.265+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:29.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:06:29.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:29.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:06:29.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T18:06:59.697+0000] {processor.py:157} INFO - Started process (PID=8139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:06:59.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:06:59.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:59.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:06:59.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:06:59.741+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:59.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:06:59.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:59.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:06:59.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-28T18:07:30.078+0000] {processor.py:157} INFO - Started process (PID=8164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:07:30.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:07:30.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:07:30.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:07:30.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:07:30.112+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:07:30.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:07:30.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:07:30.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:07:30.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T18:08:00.518+0000] {processor.py:157} INFO - Started process (PID=8189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:08:00.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:08:00.527+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:00.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:08:00.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:08:00.557+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:00.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:08:00.570+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:00.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:08:00.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T18:08:31.028+0000] {processor.py:157} INFO - Started process (PID=8214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:08:31.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:08:31.036+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:31.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:08:31.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:08:31.075+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:31.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:08:31.089+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:31.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:08:31.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T18:09:01.514+0000] {processor.py:157} INFO - Started process (PID=8239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:09:01.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:09:01.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:01.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:09:01.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:09:01.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:01.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:09:01.562+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:01.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:09:01.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-28T18:09:31.900+0000] {processor.py:157} INFO - Started process (PID=8264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:09:31.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:09:31.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:31.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:09:31.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:09:31.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:31.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:09:31.949+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:31.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:09:31.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T18:10:02.290+0000] {processor.py:157} INFO - Started process (PID=8289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:10:02.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:10:02.292+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:02.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:10:02.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:10:02.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:02.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:10:02.331+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:02.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:10:02.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T18:10:32.658+0000] {processor.py:157} INFO - Started process (PID=8314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:10:32.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:10:32.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:32.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:10:32.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:10:32.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:32.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:10:32.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:32.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:10:32.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T18:11:03.063+0000] {processor.py:157} INFO - Started process (PID=8339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:11:03.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:11:03.068+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:03.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:11:03.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:11:03.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:03.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:11:03.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:03.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:11:03.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T18:11:33.495+0000] {processor.py:157} INFO - Started process (PID=8364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:11:33.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:11:33.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:33.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:11:33.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:11:33.538+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:33.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:11:33.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:33.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:11:33.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-28T18:12:03.965+0000] {processor.py:157} INFO - Started process (PID=8389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:12:03.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:12:03.967+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:03.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:12:03.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:12:03.995+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:03.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:12:04.005+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:04.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:12:04.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T18:12:34.446+0000] {processor.py:157} INFO - Started process (PID=8414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:12:34.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:12:34.448+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:34.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:12:34.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:12:34.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:34.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:12:34.486+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:34.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:12:34.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T18:13:04.831+0000] {processor.py:157} INFO - Started process (PID=8439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:13:04.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:13:04.834+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:04.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:13:04.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:13:04.860+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:04.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:13:04.873+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:04.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:13:04.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T18:13:35.257+0000] {processor.py:157} INFO - Started process (PID=8464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:13:35.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:13:35.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:35.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:13:35.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:13:35.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:35.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:13:35.297+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:35.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:13:35.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T18:14:05.719+0000] {processor.py:157} INFO - Started process (PID=8489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:14:05.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:14:05.723+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:05.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:14:05.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:14:05.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:05.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:14:05.771+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:05.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:14:05.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-28T18:14:36.174+0000] {processor.py:157} INFO - Started process (PID=8514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:14:36.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:14:36.177+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:36.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:14:36.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:14:36.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:36.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:14:36.218+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:36.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:14:36.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T18:15:06.585+0000] {processor.py:157} INFO - Started process (PID=8539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:15:06.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:15:06.590+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:06.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:15:06.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:15:06.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:06.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:15:06.628+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:06.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:15:06.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T18:15:36.965+0000] {processor.py:157} INFO - Started process (PID=8564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:15:36.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:15:36.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:36.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:15:36.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:15:36.993+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:36.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:15:37.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:37.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:15:37.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T18:16:07.419+0000] {processor.py:157} INFO - Started process (PID=8589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:16:07.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:16:07.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:07.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:16:07.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:16:07.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:07.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:16:07.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:07.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:16:07.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T18:16:37.851+0000] {processor.py:157} INFO - Started process (PID=8614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:16:37.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:16:37.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:37.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:16:37.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:16:37.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:37.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:16:37.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:37.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:16:37.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T18:17:08.342+0000] {processor.py:157} INFO - Started process (PID=8639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:17:08.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:17:08.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:08.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:17:08.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:17:08.374+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:08.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:17:08.386+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:08.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:17:08.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T18:17:38.773+0000] {processor.py:157} INFO - Started process (PID=8664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:17:38.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:17:38.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:38.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:17:38.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:17:38.818+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:38.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:17:38.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:38.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:17:38.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T18:18:09.131+0000] {processor.py:157} INFO - Started process (PID=8689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:18:09.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:18:09.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:09.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:18:09.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:18:09.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:09.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:18:09.168+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:09.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:18:09.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T18:18:39.544+0000] {processor.py:157} INFO - Started process (PID=8714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:18:39.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:18:39.549+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:39.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:18:39.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:18:39.577+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:39.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:18:39.588+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:39.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:18:39.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T18:19:09.979+0000] {processor.py:157} INFO - Started process (PID=8739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:19:09.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:19:09.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:09.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:19:09.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:19:10.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:10.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:19:10.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:10.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:19:10.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T18:19:40.437+0000] {processor.py:157} INFO - Started process (PID=8764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:19:40.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:19:40.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:40.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:19:40.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:19:40.467+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:40.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:19:40.480+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:40.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:19:40.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T18:20:10.925+0000] {processor.py:157} INFO - Started process (PID=8789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:20:10.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:20:10.928+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:10.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:20:10.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:20:10.957+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:10.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:20:10.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:10.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:20:10.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T18:20:41.337+0000] {processor.py:157} INFO - Started process (PID=8814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:20:41.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:20:41.338+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:41.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:20:41.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:20:41.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:41.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:20:41.376+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:41.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:20:41.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T18:21:11.783+0000] {processor.py:157} INFO - Started process (PID=8839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:21:11.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:21:11.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:11.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:21:11.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:21:11.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:11.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:21:11.824+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:11.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:21:11.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T18:21:42.251+0000] {processor.py:157} INFO - Started process (PID=8864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:21:42.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:21:42.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:42.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:21:42.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:21:42.284+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:42.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:21:42.294+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:42.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:21:42.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T18:22:12.714+0000] {processor.py:157} INFO - Started process (PID=8889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:22:12.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:22:12.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:12.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:22:12.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:22:12.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:12.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:22:12.767+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:12.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:22:12.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T18:22:43.106+0000] {processor.py:157} INFO - Started process (PID=8914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:22:43.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:22:43.111+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:43.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:22:43.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:22:43.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:43.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:22:43.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:43.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:22:43.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T18:23:13.517+0000] {processor.py:157} INFO - Started process (PID=8939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:23:13.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:23:13.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:13.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:23:13.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:23:13.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:13.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:23:13.559+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:13.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:23:13.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T18:23:43.924+0000] {processor.py:157} INFO - Started process (PID=8964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:23:43.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:23:43.927+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:43.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:23:43.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:23:43.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:43.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:23:43.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:43.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:23:43.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T18:24:14.343+0000] {processor.py:157} INFO - Started process (PID=8989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:24:14.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:24:14.346+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:14.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:24:14.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:24:14.371+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:14.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:24:14.381+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:14.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:24:14.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T18:24:44.789+0000] {processor.py:157} INFO - Started process (PID=9014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:24:44.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:24:44.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:44.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:24:44.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:24:44.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:44.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:24:44.832+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:44.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:24:44.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T18:25:15.232+0000] {processor.py:157} INFO - Started process (PID=9038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:25:15.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:25:15.248+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:15.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:25:15.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:25:15.296+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:15.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:25:15.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:15.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:25:15.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T18:25:45.667+0000] {processor.py:157} INFO - Started process (PID=9064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:25:45.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:25:45.670+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:45.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:25:45.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:25:45.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:45.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:25:45.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:45.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:25:45.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T18:26:16.051+0000] {processor.py:157} INFO - Started process (PID=9089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:26:16.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:26:16.057+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:16.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:26:16.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:26:16.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:16.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:26:16.096+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:16.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:26:16.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T18:26:46.444+0000] {processor.py:157} INFO - Started process (PID=9114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:26:46.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:26:46.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:46.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:26:46.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:26:46.475+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:46.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:26:46.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:46.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:26:46.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T18:27:16.917+0000] {processor.py:157} INFO - Started process (PID=9139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:27:16.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:27:16.922+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:16.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:27:16.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:27:16.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:16.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:27:16.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:16.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:27:16.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T18:27:47.322+0000] {processor.py:157} INFO - Started process (PID=9164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:27:47.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:27:47.326+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:47.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:27:47.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:27:47.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:47.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:27:47.376+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:47.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:27:47.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-28T18:28:17.833+0000] {processor.py:157} INFO - Started process (PID=9188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:28:17.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:28:17.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:17.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:28:17.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:28:17.886+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:17.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:28:17.901+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:17.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:28:17.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-28T18:28:48.351+0000] {processor.py:157} INFO - Started process (PID=9214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:28:48.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:28:48.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:48.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:28:48.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:28:48.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:48.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:28:48.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:48.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:28:48.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-28T18:29:18.952+0000] {processor.py:157} INFO - Started process (PID=9239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:29:18.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:29:18.964+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:18.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:29:19.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:29:19.062+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:19.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:29:19.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:19.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:29:19.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-07-28T18:29:49.487+0000] {processor.py:157} INFO - Started process (PID=9264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:29:49.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:29:49.497+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:49.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:29:49.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:29:49.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:49.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:29:49.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:49.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:29:49.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-28T18:30:20.072+0000] {processor.py:157} INFO - Started process (PID=9289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:30:20.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:30:20.082+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:20.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:30:20.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:30:20.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:20.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:30:20.154+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:20.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:30:20.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-28T18:30:50.636+0000] {processor.py:157} INFO - Started process (PID=9314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:30:50.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:30:50.647+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:50.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:30:50.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:30:50.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:50.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:30:50.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:50.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:30:50.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-28T18:31:21.272+0000] {processor.py:157} INFO - Started process (PID=9339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:31:21.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:31:21.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:21.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:31:21.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:31:21.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:21.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:31:21.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:21.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:31:21.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-28T18:31:52.175+0000] {processor.py:157} INFO - Started process (PID=9364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:31:52.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:31:52.178+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:52.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:31:52.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:31:52.205+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:52.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:31:52.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:52.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:31:52.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T18:47:51.814+0000] {processor.py:157} INFO - Started process (PID=9389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:47:51.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:47:51.816+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:47:51.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:47:51.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:47:51.854+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:47:51.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:47:51.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:47:51.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:47:51.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T18:48:22.305+0000] {processor.py:157} INFO - Started process (PID=9415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:48:22.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T18:48:22.312+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:48:22.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:48:22.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T18:48:22.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:48:22.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:48:22.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:48:22.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T18:48:22.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.543 seconds
[2024-07-28T19:04:09.905+0000] {processor.py:157} INFO - Started process (PID=9441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:04:09.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:04:09.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:09.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:04:09.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:04:10.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:10.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:04:10.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:10.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:04:10.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-07-28T19:04:40.470+0000] {processor.py:157} INFO - Started process (PID=9466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:04:40.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:04:40.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:40.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:04:40.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:04:40.526+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:40.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:04:40.545+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:40.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:04:40.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-28T19:05:10.970+0000] {processor.py:157} INFO - Started process (PID=9491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:05:10.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:05:10.977+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:10.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:05:10.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:05:11.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:11.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:05:11.024+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:11.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:05:11.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T19:05:41.424+0000] {processor.py:157} INFO - Started process (PID=9516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:05:41.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:05:41.429+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:41.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:05:41.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:05:41.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:41.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:05:41.465+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:41.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:05:41.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T19:06:11.877+0000] {processor.py:157} INFO - Started process (PID=9541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:06:11.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:06:11.880+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:11.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:06:11.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:06:11.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:11.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:06:11.915+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:11.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:06:11.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T19:06:42.351+0000] {processor.py:157} INFO - Started process (PID=9566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:06:42.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:06:42.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:42.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:06:42.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:06:42.380+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:42.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:06:42.390+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:42.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:06:42.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T19:07:12.837+0000] {processor.py:157} INFO - Started process (PID=9591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:07:12.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:07:12.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:12.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:07:12.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:07:12.867+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:12.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:07:12.877+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:12.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:07:12.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T19:07:43.294+0000] {processor.py:157} INFO - Started process (PID=9616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:07:43.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:07:43.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:43.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:07:43.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:07:43.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:43.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:07:43.348+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:43.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:07:43.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-28T19:08:13.772+0000] {processor.py:157} INFO - Started process (PID=9641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:08:13.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:08:13.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:13.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:08:13.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:08:13.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:13.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:08:13.808+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:13.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:08:13.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-28T19:08:44.236+0000] {processor.py:157} INFO - Started process (PID=9666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:08:44.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:08:44.241+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:44.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:08:44.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:08:44.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:44.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:08:44.279+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:44.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:08:44.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T19:09:14.662+0000] {processor.py:157} INFO - Started process (PID=9691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:09:14.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:09:14.668+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:14.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:09:14.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:09:14.696+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:14.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:09:14.705+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:14.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:09:14.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T19:09:45.142+0000] {processor.py:157} INFO - Started process (PID=9716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:09:45.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:09:45.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:45.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:09:45.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:09:45.176+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:45.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:09:45.188+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:45.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:09:45.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T19:10:15.635+0000] {processor.py:157} INFO - Started process (PID=9741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:10:15.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:10:15.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:10:15.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:10:15.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:10:15.668+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:10:15.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:10:15.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:10:15.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:10:15.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T19:26:00.211+0000] {processor.py:157} INFO - Started process (PID=9768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:26:00.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:26:00.216+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:00.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:26:00.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:26:00.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:00.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:26:00.295+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:00.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:26:00.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-28T19:26:30.782+0000] {processor.py:157} INFO - Started process (PID=9793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:26:30.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:26:30.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:30.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:26:30.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:26:30.820+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:30.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:26:30.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:30.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:26:30.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-28T19:27:01.227+0000] {processor.py:157} INFO - Started process (PID=9818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:27:01.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:27:01.229+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:01.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:27:01.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:27:01.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:01.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:27:01.264+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:01.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:27:01.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T19:27:31.636+0000] {processor.py:157} INFO - Started process (PID=9843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:27:31.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:27:31.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:31.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:27:31.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:27:31.668+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:31.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:27:31.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:31.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:27:31.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-07-28T19:28:02.339+0000] {processor.py:157} INFO - Started process (PID=9868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:28:02.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:28:02.342+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:28:02.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:28:02.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:28:02.374+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:28:02.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:28:02.385+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:28:02.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:28:02.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T19:43:44.598+0000] {processor.py:157} INFO - Started process (PID=9894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:43:44.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:43:44.604+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:43:44.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:43:44.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:43:44.661+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:43:44.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:43:44.683+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:43:44.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:43:44.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-28T19:44:15.246+0000] {processor.py:157} INFO - Started process (PID=9920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:44:15.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:44:15.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:15.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:44:15.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:44:15.289+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:15.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:44:15.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:15.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:44:15.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T19:44:45.677+0000] {processor.py:157} INFO - Started process (PID=9945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:44:45.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:44:45.680+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:45.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:44:45.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:44:45.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:45.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:44:45.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:45.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:44:45.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-28T19:45:16.211+0000] {processor.py:157} INFO - Started process (PID=9970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:45:16.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:45:16.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:16.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:45:16.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:45:16.239+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:16.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:45:16.248+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:16.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:45:16.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-28T19:45:46.622+0000] {processor.py:157} INFO - Started process (PID=9995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:45:46.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:45:46.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:46.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:45:46.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:45:46.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:46.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:45:46.659+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:46.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:45:46.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-07-28T19:46:17.326+0000] {processor.py:157} INFO - Started process (PID=10020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:46:17.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T19:46:17.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:46:17.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:46:17.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T19:46:17.356+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:46:17.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:46:17.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:46:17.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T19:46:17.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T20:04:13.159+0000] {processor.py:157} INFO - Started process (PID=10047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:04:13.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:04:13.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:13.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:04:13.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:04:13.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:13.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:04:13.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:13.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:04:13.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-28T20:04:43.858+0000] {processor.py:157} INFO - Started process (PID=10072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:04:43.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:04:43.866+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:43.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:04:43.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:04:43.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:43.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:04:43.919+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:43.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:04:43.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-28T20:05:14.410+0000] {processor.py:157} INFO - Started process (PID=10097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:05:14.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:05:14.412+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:14.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:05:14.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:05:14.439+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:14.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:05:14.450+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:14.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:05:14.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-28T20:05:44.804+0000] {processor.py:157} INFO - Started process (PID=10122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:05:44.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:05:44.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:44.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:05:44.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:05:44.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:44.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:05:44.845+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:44.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:05:44.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-28T20:06:15.196+0000] {processor.py:157} INFO - Started process (PID=10147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:06:15.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:06:15.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:06:15.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:06:15.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:06:15.229+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:06:15.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:06:15.242+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:06:15.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:06:15.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T20:21:59.723+0000] {processor.py:157} INFO - Started process (PID=10172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:21:59.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:21:59.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:21:59.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:21:59.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:21:59.811+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:21:59.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:21:59.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:21:59.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:21:59.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-28T20:22:30.263+0000] {processor.py:157} INFO - Started process (PID=10199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:22:30.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:22:30.268+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:22:30.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:22:30.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:22:30.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:22:30.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:22:30.317+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:22:30.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:22:30.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-28T20:23:00.726+0000] {processor.py:157} INFO - Started process (PID=10224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:23:00.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:23:00.728+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:00.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:23:00.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:23:00.759+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:00.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:23:00.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:00.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:23:00.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T20:23:31.118+0000] {processor.py:157} INFO - Started process (PID=10249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:23:31.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:23:31.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:31.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:23:31.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:23:31.154+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:31.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:23:31.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:31.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:23:31.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T20:24:01.502+0000] {processor.py:157} INFO - Started process (PID=10274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:24:01.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:24:01.504+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:24:01.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:24:01.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:24:01.530+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:24:01.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:24:01.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:24:01.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:24:01.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-07-28T20:32:20.110+0000] {processor.py:157} INFO - Started process (PID=10301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:32:20.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:32:20.121+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:20.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:32:20.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:32:20.161+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:20.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:32:20.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:20.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:32:20.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-28T20:32:50.569+0000] {processor.py:157} INFO - Started process (PID=10325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:32:50.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:32:50.575+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:50.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:32:50.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:32:50.609+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:50.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:32:50.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:50.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:32:50.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T20:33:21.011+0000] {processor.py:157} INFO - Started process (PID=10351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:33:21.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:33:21.016+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:21.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:33:21.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:33:21.046+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:21.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:33:21.057+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:21.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:33:21.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-28T20:33:51.427+0000] {processor.py:157} INFO - Started process (PID=10375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:33:51.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:33:51.433+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:51.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:33:51.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:33:51.482+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:51.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:33:51.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:51.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:33:51.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-28T20:34:21.873+0000] {processor.py:157} INFO - Started process (PID=10401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:34:21.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:34:21.876+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:34:21.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:34:21.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:34:21.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:34:21.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:34:21.914+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:34:21.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:34:21.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T20:50:13.353+0000] {processor.py:157} INFO - Started process (PID=10427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:50:13.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:50:13.358+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:13.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:50:13.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:50:13.442+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:13.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:50:13.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:13.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:50:13.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.376 seconds
[2024-07-28T20:50:44.299+0000] {processor.py:157} INFO - Started process (PID=10453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:50:44.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:50:44.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:44.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:50:44.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:50:44.358+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:44.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:50:44.371+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:44.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:50:44.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-28T20:51:14.729+0000] {processor.py:157} INFO - Started process (PID=10478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:51:14.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:51:14.732+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:14.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:51:14.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:51:14.761+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:14.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:51:14.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:14.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:51:14.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T20:51:45.214+0000] {processor.py:157} INFO - Started process (PID=10503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:51:45.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:51:45.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:45.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:51:45.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:51:45.250+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:45.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:51:45.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:45.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:51:45.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T20:52:15.683+0000] {processor.py:157} INFO - Started process (PID=10528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:52:15.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T20:52:15.687+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:52:15.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:52:15.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T20:52:15.717+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:52:15.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:52:15.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:52:15.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T20:52:15.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T21:10:04.475+0000] {processor.py:157} INFO - Started process (PID=10554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:10:04.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:10:04.486+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:04.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:10:04.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:10:04.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:04.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:10:04.568+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:04.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:10:04.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T21:10:35.127+0000] {processor.py:157} INFO - Started process (PID=10579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:10:35.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:10:35.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:35.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:10:35.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:10:35.180+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:35.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:10:35.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:35.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:10:35.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.219 seconds
[2024-07-28T21:11:05.813+0000] {processor.py:157} INFO - Started process (PID=10603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:11:05.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:11:05.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:05.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:11:05.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:11:05.842+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:05.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:11:05.852+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:05.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:11:05.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T21:11:36.225+0000] {processor.py:157} INFO - Started process (PID=10628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:11:36.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:11:36.227+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:36.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:11:36.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:11:36.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:36.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:11:36.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:36.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:11:36.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-28T21:12:06.717+0000] {processor.py:157} INFO - Started process (PID=10654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:12:06.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:12:06.722+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:06.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:12:06.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:12:06.758+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:06.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:12:06.771+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:06.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:12:06.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T21:12:37.212+0000] {processor.py:157} INFO - Started process (PID=10679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:12:37.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:12:37.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:37.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:12:37.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:12:37.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:37.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:12:37.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:37.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:12:37.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-28T21:29:20.342+0000] {processor.py:157} INFO - Started process (PID=10705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:29:20.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:29:20.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:20.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:29:20.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:29:20.403+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:20.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:29:20.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:20.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:29:20.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.299 seconds
[2024-07-28T21:29:51.200+0000] {processor.py:157} INFO - Started process (PID=10731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:29:51.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:29:51.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:51.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:29:51.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:29:51.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:51.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:29:51.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:51.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:29:51.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-28T21:30:21.831+0000] {processor.py:157} INFO - Started process (PID=10756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:30:21.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:30:21.837+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:21.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:30:21.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:30:21.875+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:21.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:30:21.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:21.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:30:21.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T21:30:52.246+0000] {processor.py:157} INFO - Started process (PID=10781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:30:52.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:30:52.248+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:52.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:30:52.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:30:52.276+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:52.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:30:52.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:52.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:30:52.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T21:31:22.740+0000] {processor.py:157} INFO - Started process (PID=10806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:31:22.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:31:22.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:31:22.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:31:22.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:31:22.772+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:31:22.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:31:22.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:31:22.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:31:22.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T21:33:25.216+0000] {processor.py:157} INFO - Started process (PID=10833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:33:25.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:33:25.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:25.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:33:25.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:33:25.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:25.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:33:25.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:25.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:33:25.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-28T21:33:55.959+0000] {processor.py:157} INFO - Started process (PID=10857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:33:55.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:33:55.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:55.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:33:55.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:33:56.010+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:56.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:33:56.022+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:56.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:33:56.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.211 seconds
[2024-07-28T21:34:26.797+0000] {processor.py:157} INFO - Started process (PID=10883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:34:26.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:34:26.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:26.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:34:26.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:34:26.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:26.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:34:26.843+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:26.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:34:26.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T21:34:57.217+0000] {processor.py:157} INFO - Started process (PID=10908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:34:57.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:34:57.224+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:57.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:34:57.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:34:57.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:57.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:34:57.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:57.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:34:57.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-28T21:35:27.656+0000] {processor.py:157} INFO - Started process (PID=10933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:35:27.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:35:27.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:35:27.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:35:27.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:35:27.691+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:35:27.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:35:27.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:35:27.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:35:27.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-28T21:51:03.193+0000] {processor.py:157} INFO - Started process (PID=10960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:51:03.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:51:03.198+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:03.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:51:03.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:51:03.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:03.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:51:03.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:03.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:51:03.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-28T21:51:33.619+0000] {processor.py:157} INFO - Started process (PID=10984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:51:33.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T21:51:33.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:33.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:51:33.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T21:51:33.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:33.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:51:33.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:33.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T21:51:33.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.261 seconds
[2024-07-28T22:09:17.647+0000] {processor.py:157} INFO - Started process (PID=11009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:09:17.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:09:17.657+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:17.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:09:17.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:09:17.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:17.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:09:17.959+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:17.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:09:17.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.328 seconds
[2024-07-28T22:09:48.679+0000] {processor.py:157} INFO - Started process (PID=11034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:09:48.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:09:48.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:48.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:09:48.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:09:48.737+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:48.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:09:48.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:48.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:09:48.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-28T22:10:19.211+0000] {processor.py:157} INFO - Started process (PID=11060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:10:19.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:10:19.213+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:19.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:10:19.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:10:19.242+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:19.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:10:19.251+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:19.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:10:19.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T22:10:49.648+0000] {processor.py:157} INFO - Started process (PID=11085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:10:49.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:10:49.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:49.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:10:49.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:10:49.684+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:49.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:10:49.695+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:49.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:10:49.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T22:11:20.204+0000] {processor.py:157} INFO - Started process (PID=11110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:11:20.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:11:20.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:20.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:11:20.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:11:20.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:20.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:11:20.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:20.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:11:20.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T22:11:50.656+0000] {processor.py:157} INFO - Started process (PID=11135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:11:50.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:11:50.659+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:50.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:11:50.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:11:50.685+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:50.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:11:50.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:50.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:11:50.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-07-28T22:12:21.405+0000] {processor.py:157} INFO - Started process (PID=11160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:12:21.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:12:21.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:12:21.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:12:21.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:12:21.461+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:12:21.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:12:21.583+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:12:21.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:12:21.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-07-28T22:28:01.474+0000] {processor.py:157} INFO - Started process (PID=11185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:28:01.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:28:01.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:01.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:28:01.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:28:01.530+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:01.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:28:01.558+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:01.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:28:01.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-28T22:28:32.002+0000] {processor.py:157} INFO - Started process (PID=11210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:28:32.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:28:32.006+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:32.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:28:32.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:28:32.036+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:32.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:28:32.046+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:32.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:28:32.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T22:29:02.503+0000] {processor.py:157} INFO - Started process (PID=11235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:29:02.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:29:02.509+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:02.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:29:02.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:29:02.545+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:02.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:29:02.557+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:02.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:29:02.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-28T22:29:32.980+0000] {processor.py:157} INFO - Started process (PID=11260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:29:32.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:29:32.985+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:32.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:29:32.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:29:33.012+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:33.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:29:33.024+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:33.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:29:33.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-28T22:30:03.474+0000] {processor.py:157} INFO - Started process (PID=11285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:30:03.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:30:03.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:30:03.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:30:03.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:30:03.510+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:30:03.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:30:03.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:30:03.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:30:03.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-07-28T22:34:46.411+0000] {processor.py:157} INFO - Started process (PID=11310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:34:46.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:34:46.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:34:46.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:34:46.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:34:46.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:34:46.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:34:46.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:34:46.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:34:46.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.376 seconds
[2024-07-28T22:50:46.351+0000] {processor.py:157} INFO - Started process (PID=11336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:50:46.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:50:46.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:50:46.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:50:46.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:50:46.439+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:50:46.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:50:46.466+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:50:46.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:50:46.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-28T22:51:16.930+0000] {processor.py:157} INFO - Started process (PID=11362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:51:16.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:51:16.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:16.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:51:16.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:51:16.988+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:16.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:51:17.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:17.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:51:17.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-28T22:51:47.512+0000] {processor.py:157} INFO - Started process (PID=11387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:51:47.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:51:47.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:47.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:51:47.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:51:47.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:47.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:51:47.561+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:47.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:51:47.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T22:52:18.072+0000] {processor.py:157} INFO - Started process (PID=11412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:52:18.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:52:18.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:18.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:52:18.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:52:18.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:18.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:52:18.117+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:18.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:52:18.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-07-28T22:52:48.826+0000] {processor.py:157} INFO - Started process (PID=11437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:52:48.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:52:48.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:48.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:52:48.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:52:48.865+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:48.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:52:48.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:48.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:52:48.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-28T22:53:19.396+0000] {processor.py:157} INFO - Started process (PID=11462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:53:19.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:53:19.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:19.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:53:19.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:53:19.419+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:19.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:53:19.428+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:19.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:53:19.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-28T22:53:49.819+0000] {processor.py:157} INFO - Started process (PID=11487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:53:49.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:53:49.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:49.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:53:49.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:53:49.847+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:49.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:53:49.856+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:49.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:53:49.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-28T22:54:20.300+0000] {processor.py:157} INFO - Started process (PID=11512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:54:20.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T22:54:20.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:54:20.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:54:20.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T22:54:20.335+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:54:20.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:54:20.344+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:54:20.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T22:54:20.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-28T23:12:15.095+0000] {processor.py:157} INFO - Started process (PID=11538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:12:15.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:12:15.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:15.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:12:15.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:12:15.155+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:15.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:12:15.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:15.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:12:15.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-28T23:12:45.667+0000] {processor.py:157} INFO - Started process (PID=11564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:12:45.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:12:45.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:45.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:12:45.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:12:45.707+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:45.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:12:45.721+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:45.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:12:45.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-07-28T23:13:16.541+0000] {processor.py:157} INFO - Started process (PID=11589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:13:16.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:13:16.544+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:16.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:13:16.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:13:16.573+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:16.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:13:16.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:16.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:13:16.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-28T23:13:47.127+0000] {processor.py:157} INFO - Started process (PID=11614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:13:47.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:13:47.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:47.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:13:47.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:13:47.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:47.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:13:47.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:47.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:13:47.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-28T23:14:17.667+0000] {processor.py:157} INFO - Started process (PID=11639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:14:17.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:14:17.677+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:14:17.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:14:17.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:14:17.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:14:17.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:14:17.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:14:17.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:14:17.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-28T23:30:02.311+0000] {processor.py:157} INFO - Started process (PID=11664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:30:02.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:30:02.321+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:02.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:30:02.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:30:02.375+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:02.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:30:02.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:02.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:30:02.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-28T23:30:32.978+0000] {processor.py:157} INFO - Started process (PID=11689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:30:32.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:30:32.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:32.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:30:32.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:30:33.024+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:33.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:30:33.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:33.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:30:33.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-28T23:31:03.475+0000] {processor.py:157} INFO - Started process (PID=11714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:31:03.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:31:03.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:03.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:31:03.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:31:03.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:03.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:31:03.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:03.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:31:03.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-07-28T23:31:34.174+0000] {processor.py:157} INFO - Started process (PID=11739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:31:34.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:31:34.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:34.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:31:34.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:31:34.209+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:34.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:31:34.291+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:34.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:31:34.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-28T23:32:04.861+0000] {processor.py:157} INFO - Started process (PID=11764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:32:04.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:32:04.865+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:32:04.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:32:04.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:32:04.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:32:04.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:32:04.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:32:04.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:32:04.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-28T23:48:32.197+0000] {processor.py:157} INFO - Started process (PID=11788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:48:32.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:48:32.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:48:32.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:48:32.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:48:32.249+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:48:32.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:48:32.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:48:32.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:48:32.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-28T23:49:02.781+0000] {processor.py:157} INFO - Started process (PID=11814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:49:02.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:49:02.788+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:02.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:49:02.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:49:02.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:02.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:49:02.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:02.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:49:02.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-28T23:49:43.799+0000] {processor.py:157} INFO - Started process (PID=11839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:49:43.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:49:43.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:43.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:49:43.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:49:43.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:43.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:49:43.841+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:43.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:49:43.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-28T23:50:14.391+0000] {processor.py:157} INFO - Started process (PID=11864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:50:14.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:50:14.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:14.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:50:14.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:50:14.420+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:14.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:50:14.507+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:14.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:50:14.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-28T23:50:44.943+0000] {processor.py:157} INFO - Started process (PID=11889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:50:44.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:50:44.946+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:44.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:50:44.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:50:44.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:44.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:50:45.049+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:45.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:50:45.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-28T23:51:15.493+0000] {processor.py:157} INFO - Started process (PID=11914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:51:15.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-28T23:51:15.495+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:51:15.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:51:15.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-28T23:51:15.525+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:51:15.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:51:15.534+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:51:15.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-28T23:51:15.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
