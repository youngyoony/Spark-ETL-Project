[2024-07-21T00:01:52.588+0000] {processor.py:157} INFO - Started process (PID=21837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:01:52.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:01:52.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:01:52.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:01:52.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:01:52.679+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:01:52.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:01:52.716+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:01:52.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:01:52.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-21T00:02:23.415+0000] {processor.py:157} INFO - Started process (PID=21862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:02:23.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:02:23.418+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:02:23.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:02:23.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:02:23.460+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:02:23.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:02:23.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:02:23.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:02:23.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T00:02:53.895+0000] {processor.py:157} INFO - Started process (PID=21887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:02:53.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:02:53.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:02:53.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:02:53.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:02:53.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:02:53.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:02:53.956+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:02:53.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:02:53.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-21T00:03:24.496+0000] {processor.py:157} INFO - Started process (PID=21912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:03:24.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:03:24.499+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:03:24.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:03:24.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:03:24.540+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:03:24.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:03:24.557+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:03:24.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:03:24.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T00:03:54.941+0000] {processor.py:157} INFO - Started process (PID=21937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:03:54.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:03:54.944+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:03:54.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:03:54.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:03:54.973+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:03:54.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:03:54.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:03:54.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:03:54.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T00:04:25.386+0000] {processor.py:157} INFO - Started process (PID=21962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:04:25.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:04:25.391+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:04:25.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:04:25.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:04:25.441+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:04:25.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:04:25.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:04:25.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:04:25.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-21T00:04:55.833+0000] {processor.py:157} INFO - Started process (PID=21987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:04:55.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:04:55.840+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:04:55.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:04:55.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:04:55.884+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:04:55.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:04:55.899+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:04:55.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:04:55.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-21T00:05:26.286+0000] {processor.py:157} INFO - Started process (PID=22012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:05:26.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:05:26.290+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:05:26.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:05:26.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:05:26.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:05:26.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:05:26.346+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:05:26.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:05:26.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T00:05:56.781+0000] {processor.py:157} INFO - Started process (PID=22037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:05:56.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:05:56.787+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:05:56.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:05:56.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:05:56.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:05:56.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:05:56.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:05:56.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:05:56.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-21T00:06:27.440+0000] {processor.py:157} INFO - Started process (PID=22060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:06:27.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:06:27.446+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:06:27.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:06:27.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:06:27.496+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:06:27.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:06:27.510+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:06:27.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:06:27.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-21T00:06:57.918+0000] {processor.py:157} INFO - Started process (PID=22086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:06:57.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:06:57.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:06:57.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:06:57.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:06:57.972+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:06:57.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:06:57.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:06:57.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:06:57.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-21T00:07:28.385+0000] {processor.py:157} INFO - Started process (PID=22112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:07:28.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:07:28.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:07:28.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:07:28.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:07:28.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:07:28.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:07:28.432+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:07:28.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:07:28.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T00:07:58.852+0000] {processor.py:157} INFO - Started process (PID=22137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:07:58.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:07:58.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:07:58.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:07:58.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:07:58.882+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:07:58.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:07:58.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:07:58.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:07:58.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T00:08:29.268+0000] {processor.py:157} INFO - Started process (PID=22162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:08:29.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:08:29.273+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:08:29.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:08:29.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:08:29.308+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:08:29.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:08:29.321+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:08:29.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:08:29.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T00:08:59.689+0000] {processor.py:157} INFO - Started process (PID=22187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:08:59.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:08:59.692+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:08:59.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:08:59.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:08:59.718+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:08:59.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:08:59.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:08:59.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:08:59.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T00:09:30.125+0000] {processor.py:157} INFO - Started process (PID=22212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:09:30.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:09:30.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:09:30.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:09:30.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:09:30.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:09:30.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:09:30.164+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:09:30.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:09:30.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T00:10:00.627+0000] {processor.py:157} INFO - Started process (PID=22236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:10:00.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:10:00.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:10:00.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:10:00.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:10:00.693+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:10:00.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:10:00.711+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:10:00.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:10:00.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-21T00:10:31.148+0000] {processor.py:157} INFO - Started process (PID=22262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:10:31.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:10:31.153+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:10:31.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:10:31.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:10:31.205+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:10:31.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:10:31.219+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:10:31.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:10:31.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-21T00:11:01.933+0000] {processor.py:157} INFO - Started process (PID=22287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:11:01.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:11:01.941+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:11:01.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:11:01.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:11:02.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:11:02.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:11:02.025+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:11:02.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:11:02.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-21T00:11:32.537+0000] {processor.py:157} INFO - Started process (PID=22311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:11:32.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:11:32.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:11:32.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:11:32.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:11:32.586+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:11:32.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:11:32.598+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:11:32.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:11:32.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-21T00:12:03.056+0000] {processor.py:157} INFO - Started process (PID=22337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:12:03.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:12:03.058+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:12:03.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:12:03.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:12:03.095+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:12:03.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:12:03.108+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:12:03.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:12:03.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T00:12:33.614+0000] {processor.py:157} INFO - Started process (PID=22362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:12:33.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:12:33.620+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:12:33.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:12:33.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:12:33.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:12:33.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:12:33.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:12:33.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:12:33.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-21T00:13:04.185+0000] {processor.py:157} INFO - Started process (PID=22387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:13:04.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:13:04.204+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:13:04.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:13:04.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:13:04.244+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:13:04.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:13:04.258+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:13:04.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:13:04.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-21T00:13:34.628+0000] {processor.py:157} INFO - Started process (PID=22412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:13:34.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:13:34.632+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:13:34.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:13:34.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:13:34.663+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:13:34.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:13:34.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:13:34.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:13:34.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T00:14:05.050+0000] {processor.py:157} INFO - Started process (PID=22435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:14:05.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:14:05.054+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:14:05.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:14:05.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:14:05.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:14:05.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:14:05.184+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:14:05.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:14:05.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-21T00:14:35.802+0000] {processor.py:157} INFO - Started process (PID=22462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:14:35.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:14:35.805+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:14:35.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:14:35.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:14:35.833+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:14:35.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:14:35.842+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:14:35.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:14:35.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T00:15:06.274+0000] {processor.py:157} INFO - Started process (PID=22487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:15:06.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:15:06.278+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:15:06.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:15:06.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:15:06.312+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:15:06.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:15:06.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:15:06.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:15:06.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T00:15:36.705+0000] {processor.py:157} INFO - Started process (PID=22512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:15:36.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:15:36.709+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:15:36.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:15:36.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:15:36.745+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:15:36.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:15:36.758+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:15:36.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:15:36.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T00:16:07.163+0000] {processor.py:157} INFO - Started process (PID=22537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:16:07.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:16:07.166+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:16:07.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:16:07.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:16:07.195+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:16:07.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:16:07.207+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:16:07.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:16:07.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T00:16:37.549+0000] {processor.py:157} INFO - Started process (PID=22562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:16:37.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:16:37.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:16:37.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:16:37.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:16:37.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:16:37.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:16:37.588+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:16:37.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:16:37.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T00:17:07.982+0000] {processor.py:157} INFO - Started process (PID=22587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:17:07.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:17:07.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:17:07.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:17:08.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:17:08.016+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:17:08.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:17:08.027+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:17:08.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:17:08.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T00:17:38.398+0000] {processor.py:157} INFO - Started process (PID=22612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:17:38.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:17:38.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:17:38.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:17:38.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:17:38.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:17:38.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:17:38.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:17:38.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:17:38.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T00:18:08.814+0000] {processor.py:157} INFO - Started process (PID=22637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:18:08.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:18:08.818+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:18:08.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:18:08.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:18:08.848+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:18:08.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:18:08.860+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:18:08.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:18:08.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T00:18:39.275+0000] {processor.py:157} INFO - Started process (PID=22662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:18:39.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:18:39.279+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:18:39.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:18:39.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:18:39.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:18:39.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:18:39.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:18:39.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:18:39.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T00:19:09.742+0000] {processor.py:157} INFO - Started process (PID=22687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:19:09.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:19:09.746+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:19:09.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:19:09.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:19:09.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:19:09.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:19:09.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:19:09.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:19:09.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T00:19:40.149+0000] {processor.py:157} INFO - Started process (PID=22712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:19:40.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:19:40.152+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:19:40.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:19:40.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:19:40.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:19:40.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:19:40.187+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:19:40.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:19:40.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T00:20:10.623+0000] {processor.py:157} INFO - Started process (PID=22737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:20:10.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:20:10.626+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:20:10.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:20:10.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:20:10.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:20:10.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:20:10.669+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:20:10.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:20:10.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T00:20:41.039+0000] {processor.py:157} INFO - Started process (PID=22762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:20:41.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:20:41.043+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:20:41.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:20:41.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:20:41.073+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:20:41.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:20:41.085+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:20:41.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:20:41.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T00:21:11.486+0000] {processor.py:157} INFO - Started process (PID=22787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:21:11.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:21:11.489+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:21:11.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:21:11.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:21:11.518+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:21:11.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:21:11.528+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:21:11.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:21:11.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T00:21:41.914+0000] {processor.py:157} INFO - Started process (PID=22812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:21:41.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:21:41.916+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:21:41.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:21:41.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:21:41.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:21:41.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:21:41.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:21:41.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:21:41.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T00:22:12.367+0000] {processor.py:157} INFO - Started process (PID=22837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:22:12.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:22:12.369+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:22:12.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:22:12.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:22:12.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:22:12.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:22:12.410+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:22:12.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:22:12.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T00:22:42.927+0000] {processor.py:157} INFO - Started process (PID=22861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:22:42.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:22:42.938+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:22:42.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:22:42.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:22:43.027+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:22:43.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:22:43.135+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:22:43.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:22:43.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-07-21T00:23:13.778+0000] {processor.py:157} INFO - Started process (PID=22887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:23:13.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:23:13.784+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:23:13.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:23:13.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:23:13.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:23:13.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:23:13.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:23:13.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:23:13.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T00:23:44.271+0000] {processor.py:157} INFO - Started process (PID=22912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:23:44.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:23:44.276+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:23:44.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:23:44.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:23:44.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:23:44.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:23:44.376+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:23:44.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:23:44.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-21T00:24:14.816+0000] {processor.py:157} INFO - Started process (PID=22937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:24:14.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:24:14.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:24:14.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:24:14.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:24:14.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:24:14.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:24:14.872+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:24:14.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:24:14.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T00:24:45.263+0000] {processor.py:157} INFO - Started process (PID=22962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:24:45.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:24:45.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:24:45.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:24:45.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:24:45.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:24:45.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:24:45.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:24:45.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:24:45.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T00:25:15.764+0000] {processor.py:157} INFO - Started process (PID=22987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:25:15.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:25:15.774+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:25:15.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:25:15.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:25:15.823+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:25:15.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:25:15.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:25:15.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:25:15.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T00:25:46.254+0000] {processor.py:157} INFO - Started process (PID=23011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:25:46.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:25:46.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:25:46.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:25:46.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:25:46.317+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:25:46.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:25:46.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:25:46.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:25:46.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-21T00:26:16.770+0000] {processor.py:157} INFO - Started process (PID=23037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:26:16.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:26:16.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:26:16.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:26:16.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:26:16.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:26:16.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:26:16.836+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:26:16.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:26:16.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-21T00:26:47.301+0000] {processor.py:157} INFO - Started process (PID=23062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:26:47.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:26:47.310+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:26:47.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:26:47.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:26:47.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:26:47.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:26:47.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:26:47.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:26:47.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-21T00:27:17.887+0000] {processor.py:157} INFO - Started process (PID=23087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:27:17.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:27:17.890+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:27:17.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:27:17.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:27:17.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:27:17.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:27:17.948+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:27:17.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:27:17.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T00:27:48.413+0000] {processor.py:157} INFO - Started process (PID=23112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:27:48.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:27:48.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:27:48.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:27:48.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:27:48.462+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:27:48.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:27:48.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:27:48.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:27:48.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-21T00:28:18.934+0000] {processor.py:157} INFO - Started process (PID=23136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:28:18.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:28:18.940+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:28:18.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:28:18.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:28:18.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:28:18.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:28:19.001+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:28:19.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:28:19.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-21T00:28:49.458+0000] {processor.py:157} INFO - Started process (PID=23161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:28:49.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:28:49.470+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:28:49.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:28:49.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:28:49.508+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:28:49.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:28:49.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:28:49.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:28:49.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-21T00:29:19.956+0000] {processor.py:157} INFO - Started process (PID=23187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:29:19.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:29:19.960+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:29:19.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:29:19.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:29:19.999+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:29:19.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:29:20.017+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:29:20.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:29:20.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-21T00:29:50.439+0000] {processor.py:157} INFO - Started process (PID=23212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:29:50.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:29:50.445+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:29:50.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:29:50.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:29:50.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:29:50.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:29:50.498+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:29:50.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:29:50.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T00:30:20.815+0000] {processor.py:157} INFO - Started process (PID=23636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:30:20.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:30:20.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:30:20.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:30:20.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:30:20.857+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:30:20.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:30:20.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:30:20.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:30:20.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T00:30:51.507+0000] {processor.py:157} INFO - Started process (PID=23661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:30:51.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:30:51.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:30:51.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:30:51.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:30:51.566+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:30:51.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:30:51.580+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:30:51.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:30:51.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-21T00:31:22.098+0000] {processor.py:157} INFO - Started process (PID=23686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:31:22.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:31:22.107+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:31:22.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:31:22.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:31:22.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:31:22.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:31:22.165+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:31:22.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:31:22.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T00:31:52.473+0000] {processor.py:157} INFO - Started process (PID=23711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:31:52.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:31:52.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:31:52.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:31:52.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:31:52.502+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:31:52.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:31:52.512+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:31:52.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:31:52.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T00:32:22.878+0000] {processor.py:157} INFO - Started process (PID=23739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:32:22.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:32:22.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:32:22.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:32:22.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:32:22.909+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:32:22.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:32:22.920+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:32:22.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:32:22.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T00:32:53.312+0000] {processor.py:157} INFO - Started process (PID=23764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:32:53.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:32:53.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:32:53.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:32:53.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:32:53.382+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:32:53.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:32:53.397+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:32:53.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:32:53.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-21T00:33:23.875+0000] {processor.py:157} INFO - Started process (PID=23789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:33:23.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:33:23.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:33:23.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:33:23.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:33:23.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:33:23.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:33:23.941+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:33:23.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:33:23.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-21T00:33:54.448+0000] {processor.py:157} INFO - Started process (PID=23814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:33:54.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:33:54.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:33:54.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:33:54.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:33:54.498+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:33:54.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:33:54.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:33:54.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:33:54.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-21T00:34:24.917+0000] {processor.py:157} INFO - Started process (PID=23839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:34:24.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:34:24.923+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:34:24.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:34:24.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:34:24.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:34:24.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:34:24.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:34:24.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:34:24.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T00:34:55.409+0000] {processor.py:157} INFO - Started process (PID=23864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:34:55.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:34:55.412+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:34:55.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:34:55.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:34:55.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:34:55.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:34:55.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:34:55.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:34:55.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T00:35:25.783+0000] {processor.py:157} INFO - Started process (PID=23889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:35:25.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:35:25.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:35:25.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:35:25.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:35:25.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:35:25.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:35:25.824+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:35:25.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:35:25.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T00:35:56.355+0000] {processor.py:157} INFO - Started process (PID=23913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:35:56.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:35:56.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:35:56.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:35:56.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:35:56.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:35:56.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:35:56.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:35:56.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:35:56.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-21T00:36:27.089+0000] {processor.py:157} INFO - Started process (PID=23939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:36:27.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:36:27.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:36:27.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:36:27.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:36:27.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:36:27.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:36:27.160+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:36:27.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:36:27.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-21T00:36:57.596+0000] {processor.py:157} INFO - Started process (PID=23964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:36:57.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:36:57.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:36:57.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:36:57.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:36:57.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:36:57.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:36:57.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:36:57.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:36:57.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T00:37:28.016+0000] {processor.py:157} INFO - Started process (PID=23988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:37:28.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:37:28.026+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:37:28.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:37:28.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:37:28.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:37:28.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:37:28.100+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:37:28.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:37:28.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-21T00:37:58.506+0000] {processor.py:157} INFO - Started process (PID=24014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:37:58.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:37:58.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:37:58.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:37:58.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:37:58.544+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:37:58.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:37:58.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:37:58.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:37:58.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T00:38:28.972+0000] {processor.py:157} INFO - Started process (PID=24038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:38:28.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:38:28.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:38:28.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:38:29.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:38:29.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:38:29.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:38:29.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:38:29.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:38:29.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-21T00:38:59.478+0000] {processor.py:157} INFO - Started process (PID=24064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:38:59.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:38:59.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:38:59.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:38:59.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:38:59.526+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:38:59.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:38:59.540+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:38:59.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:38:59.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T00:39:29.965+0000] {processor.py:157} INFO - Started process (PID=24089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:39:29.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:39:29.971+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:39:29.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:39:29.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:39:30.009+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:39:30.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:39:30.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:39:30.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:39:30.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T00:40:00.549+0000] {processor.py:157} INFO - Started process (PID=24112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:40:00.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:40:00.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:40:00.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:40:00.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:40:00.643+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:40:00.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:40:00.664+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:40:00.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:40:00.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-21T00:40:31.130+0000] {processor.py:157} INFO - Started process (PID=24139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:40:31.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:40:31.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:40:31.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:40:31.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:40:31.198+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:40:31.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:40:31.220+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:40:31.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:40:31.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-21T00:41:01.645+0000] {processor.py:157} INFO - Started process (PID=24164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:41:01.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:41:01.653+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:41:01.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:41:01.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:41:01.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:41:01.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:41:01.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:41:01.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:41:01.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-21T00:41:32.046+0000] {processor.py:157} INFO - Started process (PID=24189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:41:32.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:41:32.051+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:41:32.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:41:32.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:41:32.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:41:32.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:41:32.097+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:41:32.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:41:32.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T00:42:02.491+0000] {processor.py:157} INFO - Started process (PID=24213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:42:02.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:42:02.496+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:42:02.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:42:02.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:42:02.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:42:02.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:42:02.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:42:02.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:42:02.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-21T00:42:32.975+0000] {processor.py:157} INFO - Started process (PID=24239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:42:32.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:42:32.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:42:32.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:42:33.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:42:33.027+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:42:33.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:42:33.041+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:42:33.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:42:33.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T00:43:03.451+0000] {processor.py:157} INFO - Started process (PID=24264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:43:03.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:43:03.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:43:03.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:43:03.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:43:03.481+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:43:03.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:43:03.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:43:03.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:43:03.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T00:43:33.873+0000] {processor.py:157} INFO - Started process (PID=24289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:43:33.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:43:33.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:43:33.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:43:33.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:43:33.954+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:43:33.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:43:33.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:43:33.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:43:33.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-21T00:44:04.403+0000] {processor.py:157} INFO - Started process (PID=24314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:44:04.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:44:04.405+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:44:04.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:44:04.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:44:04.438+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:44:04.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:44:04.452+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:44:04.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:44:04.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T00:44:34.869+0000] {processor.py:157} INFO - Started process (PID=24339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:44:34.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:44:34.875+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:44:34.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:44:34.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:44:34.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:44:34.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:44:34.933+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:44:34.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:44:34.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T00:45:05.344+0000] {processor.py:157} INFO - Started process (PID=24364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:45:05.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:45:05.349+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:45:05.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:45:05.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:45:05.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:45:05.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:45:05.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:45:05.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:45:05.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T00:45:35.767+0000] {processor.py:157} INFO - Started process (PID=24389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:45:35.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:45:35.772+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:45:35.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:45:35.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:45:35.811+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:45:35.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:45:35.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:45:35.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:45:35.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T00:46:06.331+0000] {processor.py:157} INFO - Started process (PID=24414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:46:06.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:46:06.337+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:46:06.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:46:06.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:46:06.377+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:46:06.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:46:06.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:46:06.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:46:06.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T00:46:36.817+0000] {processor.py:157} INFO - Started process (PID=24439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:46:36.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:46:36.827+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:46:36.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:46:36.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:46:36.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:46:36.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:46:36.923+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:46:36.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:46:36.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-21T00:47:07.402+0000] {processor.py:157} INFO - Started process (PID=24464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:47:07.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:47:07.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:47:07.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:47:07.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:47:07.458+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:47:07.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:47:07.471+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:47:07.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:47:07.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-21T00:47:38.216+0000] {processor.py:157} INFO - Started process (PID=24488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:47:38.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:47:38.252+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:47:38.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:47:38.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:47:38.357+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:47:38.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:47:38.377+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:47:38.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:47:38.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.375 seconds
[2024-07-21T00:48:09.276+0000] {processor.py:157} INFO - Started process (PID=24514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:48:09.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:48:09.287+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:48:09.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:48:09.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:48:09.367+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:48:09.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:48:09.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:48:09.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:48:09.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-21T00:48:39.820+0000] {processor.py:157} INFO - Started process (PID=24539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:48:39.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:48:39.824+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:48:39.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:48:39.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:48:39.852+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:48:39.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:48:39.864+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:48:39.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:48:39.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T00:49:10.272+0000] {processor.py:157} INFO - Started process (PID=24564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:49:10.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:49:10.281+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:49:10.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:49:10.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:49:10.338+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:49:10.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:49:10.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:49:10.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:49:10.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-21T00:49:40.721+0000] {processor.py:157} INFO - Started process (PID=24589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:49:40.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:49:40.725+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:49:40.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:49:40.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:49:40.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:49:40.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:49:40.766+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:49:40.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:49:40.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T00:50:11.165+0000] {processor.py:157} INFO - Started process (PID=24614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:50:11.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:50:11.169+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:50:11.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:50:11.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:50:11.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:50:11.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:50:11.210+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:50:11.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:50:11.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T00:50:41.572+0000] {processor.py:157} INFO - Started process (PID=24639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:50:41.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:50:41.575+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:50:41.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:50:41.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:50:41.605+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:50:41.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:50:41.615+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:50:41.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:50:41.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T00:51:12.075+0000] {processor.py:157} INFO - Started process (PID=24664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:51:12.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:51:12.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:51:12.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:51:12.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:51:12.144+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:51:12.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:51:12.167+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:51:12.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:51:12.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-21T00:51:42.568+0000] {processor.py:157} INFO - Started process (PID=24689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:51:42.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:51:42.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:51:42.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:51:42.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:51:42.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:51:42.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:51:42.608+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:51:42.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:51:42.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T00:52:13.080+0000] {processor.py:157} INFO - Started process (PID=24713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:52:13.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:52:13.092+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:52:13.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:52:13.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:52:13.144+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:52:13.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:52:13.158+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:52:13.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:52:13.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-21T00:52:43.579+0000] {processor.py:157} INFO - Started process (PID=24739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:52:43.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:52:43.591+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:52:43.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:52:43.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:52:43.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:52:43.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:52:43.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:52:43.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:52:43.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-21T00:53:14.262+0000] {processor.py:157} INFO - Started process (PID=24764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:53:14.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:53:14.272+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:53:14.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:53:14.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:53:14.366+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:53:14.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:53:14.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:53:14.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:53:14.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-21T00:53:44.902+0000] {processor.py:157} INFO - Started process (PID=24789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:53:44.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:53:44.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:53:44.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:53:44.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:53:44.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:53:44.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:53:44.981+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:53:44.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:53:44.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-21T00:54:15.410+0000] {processor.py:157} INFO - Started process (PID=24813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:54:15.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:54:15.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:54:15.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:54:15.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:54:15.477+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:54:15.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:54:15.501+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:54:15.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:54:15.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-21T00:54:45.967+0000] {processor.py:157} INFO - Started process (PID=24839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:54:45.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:54:45.970+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:54:45.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:54:45.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:54:45.995+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:54:45.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:54:46.005+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:54:46.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:54:46.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T00:55:16.357+0000] {processor.py:157} INFO - Started process (PID=24864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:55:16.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:55:16.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:55:16.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:55:16.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:55:16.393+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:55:16.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:55:16.404+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:55:16.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:55:16.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T00:55:46.789+0000] {processor.py:157} INFO - Started process (PID=24889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:55:46.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:55:46.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:55:46.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:55:46.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:55:46.817+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:55:46.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:55:46.827+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:55:46.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:55:46.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T00:56:17.196+0000] {processor.py:157} INFO - Started process (PID=24914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:56:17.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:56:17.200+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:56:17.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:56:17.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:56:17.240+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:56:17.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:56:17.252+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:56:17.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:56:17.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T00:56:47.683+0000] {processor.py:157} INFO - Started process (PID=24939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:56:47.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:56:47.690+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:56:47.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:56:47.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:56:47.750+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:56:47.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:56:47.765+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:56:47.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:56:47.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-21T00:57:18.226+0000] {processor.py:157} INFO - Started process (PID=24964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:57:18.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:57:18.237+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:57:18.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:57:18.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:57:18.286+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:57:18.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:57:18.304+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:57:18.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:57:18.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-21T00:57:48.699+0000] {processor.py:157} INFO - Started process (PID=24989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:57:48.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:57:48.707+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:57:48.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:57:48.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:57:48.733+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:57:48.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:57:48.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:57:48.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:57:48.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T00:58:19.105+0000] {processor.py:157} INFO - Started process (PID=25014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:58:19.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:58:19.108+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:58:19.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:58:19.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:58:19.139+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:58:19.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:58:19.151+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:58:19.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:58:19.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T00:58:49.611+0000] {processor.py:157} INFO - Started process (PID=25039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:58:49.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:58:49.621+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:58:49.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:58:49.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:58:49.684+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:58:49.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:58:49.701+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:58:49.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:58:49.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-21T00:59:20.135+0000] {processor.py:157} INFO - Started process (PID=25064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:59:20.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:59:20.145+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:59:20.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:59:20.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:59:20.226+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:59:20.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:59:20.256+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:59:20.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:59:20.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-21T00:59:50.672+0000] {processor.py:157} INFO - Started process (PID=25089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:59:50.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T00:59:50.681+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:59:50.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:59:50.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T00:59:50.742+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:59:50.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T00:59:50.756+0000] {logging_mixin.py:151} INFO - [2024-07-21T00:59:50.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-20T01:00:00+00:00, run_after=2024-07-21T01:00:00+00:00
[2024-07-21T00:59:50.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-21T01:00:21.121+0000] {processor.py:157} INFO - Started process (PID=25506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:00:21.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:00:21.129+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:00:21.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:00:21.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:00:21.184+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:00:21.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:00:21.200+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:00:21.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:00:21.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-21T01:00:51.699+0000] {processor.py:157} INFO - Started process (PID=25531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:00:51.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:00:51.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:00:51.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:00:51.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:00:51.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:00:51.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:00:51.817+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:00:51.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:00:51.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-21T01:01:22.393+0000] {processor.py:157} INFO - Started process (PID=25555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:01:22.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:01:22.403+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:01:22.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:01:22.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:01:22.488+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:01:22.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:01:22.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:01:22.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:01:22.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-21T01:01:52.955+0000] {processor.py:157} INFO - Started process (PID=25581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:01:52.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:01:52.960+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:01:52.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:01:52.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:01:53.011+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:01:53.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:01:53.034+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:01:53.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:01:53.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-21T01:02:23.485+0000] {processor.py:157} INFO - Started process (PID=25606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:02:23.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:02:23.497+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:02:23.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:02:23.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:02:23.575+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:02:23.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:02:23.596+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:02:23.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:02:23.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-21T01:02:54.020+0000] {processor.py:157} INFO - Started process (PID=25631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:02:54.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:02:54.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:02:54.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:02:54.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:02:54.059+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:02:54.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:02:54.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:02:54.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:02:54.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T01:03:24.400+0000] {processor.py:157} INFO - Started process (PID=25656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:03:24.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:03:24.403+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:03:24.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:03:24.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:03:24.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:03:24.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:03:24.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:03:24.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:03:24.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T01:03:54.847+0000] {processor.py:157} INFO - Started process (PID=25681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:03:54.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:03:54.854+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:03:54.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:03:54.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:03:54.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:03:54.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:03:54.919+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:03:54.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:03:54.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-21T01:04:25.265+0000] {processor.py:157} INFO - Started process (PID=25706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:04:25.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:04:25.268+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:04:25.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:04:25.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:04:25.303+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:04:25.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:04:25.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:04:25.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:04:25.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-21T01:04:55.698+0000] {processor.py:157} INFO - Started process (PID=25731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:04:55.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:04:55.700+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:04:55.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:04:55.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:04:55.726+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:04:55.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:04:55.739+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:04:55.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:04:55.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T01:05:26.103+0000] {processor.py:157} INFO - Started process (PID=25756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:05:26.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:05:26.105+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:05:26.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:05:26.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:05:26.144+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:05:26.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:05:26.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:05:26.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:05:26.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T01:05:56.510+0000] {processor.py:157} INFO - Started process (PID=25781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:05:56.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:05:56.517+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:05:56.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:05:56.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:05:56.574+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:05:56.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:05:56.587+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:05:56.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:05:56.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-21T01:06:26.895+0000] {processor.py:157} INFO - Started process (PID=25806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:06:26.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:06:26.899+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:06:26.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:06:26.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:06:26.944+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:06:26.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:06:26.957+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:06:26.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:06:26.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-21T01:06:57.393+0000] {processor.py:157} INFO - Started process (PID=25831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:06:57.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:06:57.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:06:57.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:06:57.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:06:57.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:06:57.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:06:57.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:06:57.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:06:57.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T01:07:27.874+0000] {processor.py:157} INFO - Started process (PID=25855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:07:27.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:07:27.891+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:07:27.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:07:27.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:07:27.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:07:27.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:07:27.982+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:07:27.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:07:27.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-21T01:07:58.395+0000] {processor.py:157} INFO - Started process (PID=25881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:07:58.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:07:58.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:07:58.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:07:58.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:07:58.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:07:58.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:07:58.468+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:07:58.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:07:58.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-21T01:08:28.900+0000] {processor.py:157} INFO - Started process (PID=25906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:08:28.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:08:28.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:08:28.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:08:28.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:08:28.949+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:08:28.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:08:28.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:08:28.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:08:29.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-21T01:08:59.494+0000] {processor.py:157} INFO - Started process (PID=25931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:08:59.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:08:59.498+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:08:59.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:08:59.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:08:59.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:08:59.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:08:59.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:08:59.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:08:59.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-21T01:09:29.942+0000] {processor.py:157} INFO - Started process (PID=25956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:09:29.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:09:29.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:09:29.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:09:29.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:09:30.035+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:09:30.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:09:30.057+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:09:30.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:09:30.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-21T01:10:00.458+0000] {processor.py:157} INFO - Started process (PID=25981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:10:00.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:10:00.461+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:10:00.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:10:00.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:10:00.494+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:10:00.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:10:00.512+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:10:00.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:10:00.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T01:10:30.926+0000] {processor.py:157} INFO - Started process (PID=26006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:10:30.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:10:30.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:10:30.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:10:30.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:10:30.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:10:30.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:10:30.983+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:10:30.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:10:30.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T01:11:01.398+0000] {processor.py:157} INFO - Started process (PID=26031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:11:01.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:11:01.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:11:01.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:11:01.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:11:01.438+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:11:01.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:11:01.452+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:11:01.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:11:01.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T01:11:31.946+0000] {processor.py:157} INFO - Started process (PID=26056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:11:31.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:11:31.953+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:11:31.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:11:31.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:11:32.036+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:11:32.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:11:32.058+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:11:32.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:11:32.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-21T01:12:02.575+0000] {processor.py:157} INFO - Started process (PID=26081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:12:02.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:12:02.587+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:12:02.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:12:02.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:12:02.662+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:12:02.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:12:02.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:12:02.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:12:02.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-21T01:12:33.122+0000] {processor.py:157} INFO - Started process (PID=26106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:12:33.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:12:33.144+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:12:33.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:12:33.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:12:33.213+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:12:33.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:12:33.235+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:12:33.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:12:33.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-21T01:13:03.715+0000] {processor.py:157} INFO - Started process (PID=26131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:13:03.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:13:03.723+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:13:03.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:13:03.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:13:03.784+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:13:03.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:13:03.806+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:13:03.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:13:03.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-21T01:13:34.217+0000] {processor.py:157} INFO - Started process (PID=26156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:13:34.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:13:34.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:13:34.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:13:34.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:13:34.284+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:13:34.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:13:34.301+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:13:34.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:13:34.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-21T01:14:04.736+0000] {processor.py:157} INFO - Started process (PID=26181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:14:04.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:14:04.746+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:14:04.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:14:04.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:14:04.803+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:14:04.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:14:04.821+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:14:04.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:14:04.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-21T01:14:35.232+0000] {processor.py:157} INFO - Started process (PID=26206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:14:35.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:14:35.237+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:14:35.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:14:35.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:14:35.286+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:14:35.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:14:35.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:14:35.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:14:35.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-21T01:15:05.778+0000] {processor.py:157} INFO - Started process (PID=26231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:15:05.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:15:05.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:15:05.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:15:05.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:15:05.852+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:15:05.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:15:05.867+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:15:05.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:15:05.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-21T01:15:36.195+0000] {processor.py:157} INFO - Started process (PID=26256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:15:36.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:15:36.201+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:15:36.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:15:36.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:15:36.247+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:15:36.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:15:36.268+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:15:36.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:15:36.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T01:16:06.646+0000] {processor.py:157} INFO - Started process (PID=26281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:16:06.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:16:06.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:16:06.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:16:06.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:16:06.694+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:16:06.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:16:06.708+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:16:06.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:16:06.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-21T01:16:37.076+0000] {processor.py:157} INFO - Started process (PID=26306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:16:37.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:16:37.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:16:37.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:16:37.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:16:37.116+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:16:37.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:16:37.129+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:16:37.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:16:37.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T01:17:07.602+0000] {processor.py:157} INFO - Started process (PID=26331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:17:07.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:17:07.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:17:07.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:17:07.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:17:07.682+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:17:07.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:17:07.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:17:07.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:17:07.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-21T01:17:38.127+0000] {processor.py:157} INFO - Started process (PID=26356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:17:38.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:17:38.131+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:17:38.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:17:38.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:17:38.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:17:38.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:17:38.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:17:38.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:17:38.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-21T01:18:08.646+0000] {processor.py:157} INFO - Started process (PID=26381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:18:08.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:18:08.683+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:18:08.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:18:08.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:18:08.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:18:08.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:18:08.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:18:08.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:18:08.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-07-21T01:18:39.238+0000] {processor.py:157} INFO - Started process (PID=26406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:18:39.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:18:39.249+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:18:39.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:18:39.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:18:39.326+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:18:39.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:18:39.348+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:18:39.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:18:39.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-21T01:19:09.846+0000] {processor.py:157} INFO - Started process (PID=26431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:19:09.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:19:09.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:19:09.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:19:09.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:19:09.937+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:19:09.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:19:09.954+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:19:09.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:19:09.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-21T01:19:40.421+0000] {processor.py:157} INFO - Started process (PID=26456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:19:40.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:19:40.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:19:40.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:19:40.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:19:40.500+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:19:40.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:19:40.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:19:40.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:19:40.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-21T01:20:10.978+0000] {processor.py:157} INFO - Started process (PID=26481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:20:10.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:20:10.989+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:20:10.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:20:11.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:20:11.073+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:20:11.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:20:11.092+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:20:11.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:20:11.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-21T01:20:41.604+0000] {processor.py:157} INFO - Started process (PID=26506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:20:41.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:20:41.620+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:20:41.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:20:41.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:20:41.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:20:41.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:20:41.725+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:20:41.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:20:41.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-21T01:21:12.177+0000] {processor.py:157} INFO - Started process (PID=26531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:21:12.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:21:12.184+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:21:12.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:21:12.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:21:12.233+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:21:12.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:21:12.250+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:21:12.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:21:12.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-21T01:21:42.626+0000] {processor.py:157} INFO - Started process (PID=26556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:21:42.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:21:42.630+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:21:42.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:21:42.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:21:42.659+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:21:42.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:21:42.672+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:21:42.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:21:42.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T01:22:13.107+0000] {processor.py:157} INFO - Started process (PID=26581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:22:13.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:22:13.114+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:22:13.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:22:13.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:22:13.196+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:22:13.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:22:13.215+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:22:13.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:22:13.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-21T01:22:43.683+0000] {processor.py:157} INFO - Started process (PID=26606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:22:43.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:22:43.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:22:43.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:22:43.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:22:43.782+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:22:43.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:22:43.803+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:22:43.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:22:43.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-21T01:23:14.340+0000] {processor.py:157} INFO - Started process (PID=26630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:23:14.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:23:14.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:23:14.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:23:14.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:23:14.461+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:23:14.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:23:14.480+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:23:14.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:23:14.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-21T01:23:44.900+0000] {processor.py:157} INFO - Started process (PID=26656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:23:44.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:23:44.904+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:23:44.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:23:44.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:23:44.944+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:23:44.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:23:44.960+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:23:44.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:23:44.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-21T01:24:15.379+0000] {processor.py:157} INFO - Started process (PID=26681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:24:15.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:24:15.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:24:15.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:24:15.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:24:15.436+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:24:15.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:24:15.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:24:15.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:24:15.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-21T01:24:45.912+0000] {processor.py:157} INFO - Started process (PID=26706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:24:45.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:24:45.926+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:24:45.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:24:45.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:24:45.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:24:45.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:24:46.012+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:24:46.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:24:46.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-21T01:25:16.417+0000] {processor.py:157} INFO - Started process (PID=26731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:25:16.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:25:16.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:25:16.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:25:16.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:25:16.452+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:25:16.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:25:16.466+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:25:16.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:25:16.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T01:25:46.928+0000] {processor.py:157} INFO - Started process (PID=26756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:25:46.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:25:46.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:25:46.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:25:46.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:25:47.007+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:25:47.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:25:47.041+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:25:47.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:25:47.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-21T01:26:17.436+0000] {processor.py:157} INFO - Started process (PID=26781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:26:17.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:26:17.472+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:26:17.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:26:17.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:26:17.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:26:17.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:26:17.565+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:26:17.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:26:17.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-21T01:26:48.079+0000] {processor.py:157} INFO - Started process (PID=26806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:26:48.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:26:48.091+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:26:48.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:26:48.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:26:48.185+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:26:48.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:26:48.202+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:26:48.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:26:48.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-21T01:27:18.709+0000] {processor.py:157} INFO - Started process (PID=26830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:27:18.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:27:18.717+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:27:18.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:27:18.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:27:18.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:27:18.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:27:18.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:27:18.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:27:18.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-21T01:27:49.298+0000] {processor.py:157} INFO - Started process (PID=26856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:27:49.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:27:49.311+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:27:49.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:27:49.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:27:49.403+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:27:49.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:27:49.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:27:49.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:27:49.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-21T01:28:19.884+0000] {processor.py:157} INFO - Started process (PID=26881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:28:19.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:28:19.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:28:19.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:28:19.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:28:19.925+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:28:19.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:28:19.940+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:28:19.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:28:19.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T01:28:50.384+0000] {processor.py:157} INFO - Started process (PID=26904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:28:50.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:28:50.391+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:28:50.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:28:50.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:28:50.488+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:28:50.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:28:50.507+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:28:50.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:28:50.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-21T01:29:20.888+0000] {processor.py:157} INFO - Started process (PID=26931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:29:20.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:29:20.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:29:20.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:29:20.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:29:20.985+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:29:20.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:29:21.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:29:21.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:29:21.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-21T01:29:51.538+0000] {processor.py:157} INFO - Started process (PID=26956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:29:51.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:29:51.551+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:29:51.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:29:51.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:29:51.645+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:29:51.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:29:51.676+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:29:51.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:29:51.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-07-21T01:30:22.203+0000] {processor.py:157} INFO - Started process (PID=26981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:30:22.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:30:22.209+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:30:22.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:30:22.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:30:22.304+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:30:22.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:30:22.320+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:30:22.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:30:22.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-21T01:30:52.745+0000] {processor.py:157} INFO - Started process (PID=27006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:30:52.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:30:52.753+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:30:52.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:30:52.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:30:52.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:30:52.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:30:52.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:30:52.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:30:52.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-21T01:31:23.237+0000] {processor.py:157} INFO - Started process (PID=27031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:31:23.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:31:23.246+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:31:23.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:31:23.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:31:23.298+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:31:23.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:31:23.316+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:31:23.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:31:23.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-21T01:31:53.804+0000] {processor.py:157} INFO - Started process (PID=27055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:31:53.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:31:53.830+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:31:53.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:31:53.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:31:53.928+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:31:53.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:31:53.947+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:31:53.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:31:53.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-07-21T01:32:24.336+0000] {processor.py:157} INFO - Started process (PID=27081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:32:24.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:32:24.340+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:32:24.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:32:24.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:32:24.382+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:32:24.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:32:24.397+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:32:24.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:32:24.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T01:32:54.831+0000] {processor.py:157} INFO - Started process (PID=27106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:32:54.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:32:54.836+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:32:54.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:32:54.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:32:54.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:32:54.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:32:54.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:32:54.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:32:54.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-21T01:33:25.324+0000] {processor.py:157} INFO - Started process (PID=27131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:33:25.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:33:25.327+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:33:25.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:33:25.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:33:25.368+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:33:25.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:33:25.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:33:25.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:33:25.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T01:33:55.800+0000] {processor.py:157} INFO - Started process (PID=27156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:33:55.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:33:55.804+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:33:55.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:33:55.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:33:55.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:33:55.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:33:55.858+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:33:55.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:33:55.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T01:34:26.372+0000] {processor.py:157} INFO - Started process (PID=27181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:34:26.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:34:26.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:34:26.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:34:26.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:34:26.434+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:34:26.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:34:26.452+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:34:26.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:34:26.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-21T01:34:56.853+0000] {processor.py:157} INFO - Started process (PID=27206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:34:56.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:34:56.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:34:56.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:34:56.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:34:56.897+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:34:56.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:34:56.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:34:56.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:34:56.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T01:35:27.323+0000] {processor.py:157} INFO - Started process (PID=27231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:35:27.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:35:27.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:35:27.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:35:27.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:35:27.398+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:35:27.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:35:27.416+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:35:27.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:35:27.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-21T01:35:57.818+0000] {processor.py:157} INFO - Started process (PID=27256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:35:57.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:35:57.821+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:35:57.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:35:57.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:35:57.853+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:35:57.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:35:57.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:35:57.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:35:57.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T01:36:28.266+0000] {processor.py:157} INFO - Started process (PID=27281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:36:28.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:36:28.274+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:36:28.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:36:28.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:36:28.343+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:36:28.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:36:28.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:36:28.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:36:28.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-21T01:36:58.823+0000] {processor.py:157} INFO - Started process (PID=27306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:36:58.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:36:58.847+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:36:58.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:36:58.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:36:58.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:36:58.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:36:58.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:36:58.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:36:58.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-21T01:37:29.424+0000] {processor.py:157} INFO - Started process (PID=27330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:37:29.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:37:29.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:37:29.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:37:29.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:37:29.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:37:29.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:37:29.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:37:29.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:37:29.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-07-21T01:37:59.990+0000] {processor.py:157} INFO - Started process (PID=27356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:37:59.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:38:00.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:38:00.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:38:00.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:38:00.114+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:38:00.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:38:00.133+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:38:00.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:38:00.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-21T01:38:30.603+0000] {processor.py:157} INFO - Started process (PID=27381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:38:30.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:38:30.611+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:38:30.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:38:30.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:38:30.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:38:30.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:38:30.698+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:38:30.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:38:30.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-21T01:39:01.195+0000] {processor.py:157} INFO - Started process (PID=27405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:39:01.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:39:01.205+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:39:01.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:39:01.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:39:01.284+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:39:01.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:39:01.302+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:39:01.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:39:01.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-21T01:39:31.818+0000] {processor.py:157} INFO - Started process (PID=27431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:39:31.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:39:31.847+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:39:31.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:39:31.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:39:31.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:39:31.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:39:31.992+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:39:31.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:39:32.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-07-21T01:40:02.458+0000] {processor.py:157} INFO - Started process (PID=27456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:40:02.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:40:02.466+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:40:02.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:40:02.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:40:02.541+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:40:02.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:40:02.564+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:40:02.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:40:02.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-21T01:40:32.995+0000] {processor.py:157} INFO - Started process (PID=27481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:40:32.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:40:33.006+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:40:33.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:40:33.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:40:33.071+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:40:33.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:40:33.088+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:40:33.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:40:33.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-21T01:41:03.525+0000] {processor.py:157} INFO - Started process (PID=27506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:41:03.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:41:03.531+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:41:03.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:41:03.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:41:03.579+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:41:03.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:41:03.598+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:41:03.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:41:03.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-21T01:41:33.926+0000] {processor.py:157} INFO - Started process (PID=27531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:41:33.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:41:33.927+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:41:33.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:41:33.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:41:33.961+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:41:33.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:41:33.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:41:33.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:41:33.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T01:42:04.414+0000] {processor.py:157} INFO - Started process (PID=27556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:42:04.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:42:04.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:42:04.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:42:04.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:42:04.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:42:04.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:42:04.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:42:04.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:42:04.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T01:42:34.899+0000] {processor.py:157} INFO - Started process (PID=27581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:42:34.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:42:34.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:42:34.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:42:34.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:42:34.956+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:42:34.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:42:34.974+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:42:34.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:42:34.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-21T01:43:05.390+0000] {processor.py:157} INFO - Started process (PID=27606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:43:05.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:43:05.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:43:05.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:43:05.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:43:05.466+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:43:05.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:43:05.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:43:05.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:43:05.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-21T01:43:35.895+0000] {processor.py:157} INFO - Started process (PID=27631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:43:35.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:43:35.900+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:43:35.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:43:35.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:43:35.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:43:35.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:43:35.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:43:35.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:43:35.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T01:44:06.368+0000] {processor.py:157} INFO - Started process (PID=27656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:44:06.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:44:06.371+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:44:06.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:44:06.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:44:06.407+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:44:06.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:44:06.420+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:44:06.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:44:06.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T01:44:36.840+0000] {processor.py:157} INFO - Started process (PID=27681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:44:36.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:44:36.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:44:36.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:44:36.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:44:36.895+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:44:36.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:44:36.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:44:36.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:44:36.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-21T01:45:07.319+0000] {processor.py:157} INFO - Started process (PID=27706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:45:07.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:45:07.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:45:07.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:45:07.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:45:07.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:45:07.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:45:07.372+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:45:07.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:45:07.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T01:45:37.712+0000] {processor.py:157} INFO - Started process (PID=27731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:45:37.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:45:37.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:45:37.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:45:37.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:45:37.746+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:45:37.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:45:37.761+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:45:37.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:45:37.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T01:46:08.115+0000] {processor.py:157} INFO - Started process (PID=27756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:46:08.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:46:08.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:46:08.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:46:08.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:46:08.153+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:46:08.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:46:08.165+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:46:08.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:46:08.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T01:46:38.569+0000] {processor.py:157} INFO - Started process (PID=27781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:46:38.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:46:38.574+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:46:38.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:46:38.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:46:38.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:46:38.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:46:38.625+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:46:38.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:46:38.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T01:47:09.069+0000] {processor.py:157} INFO - Started process (PID=27806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:47:09.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:47:09.078+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:47:09.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:47:09.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:47:09.123+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:47:09.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:47:09.140+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:47:09.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:47:09.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-21T01:47:39.549+0000] {processor.py:157} INFO - Started process (PID=27831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:47:39.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:47:39.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:47:39.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:47:39.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:47:39.589+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:47:39.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:47:39.605+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:47:39.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:47:39.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T01:48:10.020+0000] {processor.py:157} INFO - Started process (PID=27856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:48:10.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:48:10.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:48:10.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:48:10.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:48:10.060+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:48:10.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:48:10.074+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:48:10.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:48:10.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T01:48:40.439+0000] {processor.py:157} INFO - Started process (PID=27881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:48:40.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:48:40.446+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:48:40.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:48:40.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:48:40.497+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:48:40.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:48:40.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:48:40.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:48:40.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-21T01:49:10.947+0000] {processor.py:157} INFO - Started process (PID=27906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:49:10.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:49:10.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:49:10.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:49:10.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:49:10.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:49:10.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:49:10.997+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:49:10.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:49:11.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T01:49:41.319+0000] {processor.py:157} INFO - Started process (PID=27931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:49:41.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:49:41.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:49:41.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:49:41.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:49:41.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:49:41.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:49:41.368+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:49:41.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:49:41.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T01:50:11.843+0000] {processor.py:157} INFO - Started process (PID=27955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:50:11.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:50:11.854+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:50:11.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:50:11.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:50:11.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:50:11.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:50:11.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:50:11.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:50:11.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-21T01:50:42.371+0000] {processor.py:157} INFO - Started process (PID=27981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:50:42.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:50:42.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:50:42.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:50:42.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:50:42.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:50:42.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:50:42.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:50:42.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:50:42.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T01:51:12.905+0000] {processor.py:157} INFO - Started process (PID=28006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:51:12.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:51:12.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:51:12.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:51:12.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:51:12.983+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:51:12.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:51:13.028+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:51:13.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:51:13.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-21T01:51:43.520+0000] {processor.py:157} INFO - Started process (PID=28031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:51:43.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:51:43.535+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:51:43.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:51:43.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:51:43.631+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:51:43.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:51:43.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:51:43.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:51:43.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-07-21T01:52:14.120+0000] {processor.py:157} INFO - Started process (PID=28055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:52:14.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:52:14.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:52:14.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:52:14.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:52:14.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:52:14.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:52:14.273+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:52:14.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:52:14.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-07-21T01:52:44.792+0000] {processor.py:157} INFO - Started process (PID=28081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:52:44.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:52:44.796+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:52:44.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:52:44.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:52:44.834+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:52:44.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:52:44.851+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:52:44.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:52:44.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-21T01:53:15.280+0000] {processor.py:157} INFO - Started process (PID=28106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:53:15.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:53:15.287+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:53:15.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:53:15.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:53:15.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:53:15.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:53:15.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:53:15.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:53:15.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-21T01:53:45.823+0000] {processor.py:157} INFO - Started process (PID=28131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:53:45.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:53:45.828+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:53:45.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:53:45.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:53:45.864+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:53:45.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:53:45.877+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:53:45.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:53:45.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T01:54:16.253+0000] {processor.py:157} INFO - Started process (PID=28155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:54:16.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:54:16.261+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:54:16.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:54:16.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:54:16.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:54:16.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:54:16.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:54:16.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:54:16.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-21T01:54:46.812+0000] {processor.py:157} INFO - Started process (PID=28181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:54:46.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:54:46.818+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:54:46.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:54:46.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:54:46.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:54:46.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:54:46.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:54:46.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:54:46.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T01:55:17.337+0000] {processor.py:157} INFO - Started process (PID=28206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:55:17.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:55:17.343+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:55:17.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:55:17.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:55:17.404+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:55:17.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:55:17.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:55:17.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:55:17.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-21T01:55:47.830+0000] {processor.py:157} INFO - Started process (PID=28231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:55:47.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:55:47.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:55:47.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:55:47.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:55:47.920+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:55:47.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:55:47.940+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:55:47.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:55:47.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-21T01:56:18.376+0000] {processor.py:157} INFO - Started process (PID=28255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:56:18.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:56:18.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:56:18.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:56:18.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:56:18.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:56:18.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:56:18.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:56:18.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:56:18.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-21T01:56:48.871+0000] {processor.py:157} INFO - Started process (PID=28281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:56:48.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:56:48.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:56:48.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:56:48.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:56:48.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:56:48.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:56:48.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:56:48.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:56:48.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-21T01:57:19.417+0000] {processor.py:157} INFO - Started process (PID=28306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:57:19.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:57:19.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:57:19.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:57:19.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:57:19.458+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:57:19.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:57:19.473+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:57:19.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:57:19.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T01:57:49.913+0000] {processor.py:157} INFO - Started process (PID=28331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:57:49.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:57:49.925+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:57:49.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:57:49.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:57:50.037+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:57:50.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:57:50.055+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:57:50.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:57:50.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-21T01:58:20.529+0000] {processor.py:157} INFO - Started process (PID=28356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:58:20.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:58:20.546+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:58:20.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:58:20.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:58:20.623+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:58:20.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:58:20.643+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:58:20.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:58:20.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-21T01:58:51.063+0000] {processor.py:157} INFO - Started process (PID=28381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:58:51.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:58:51.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:58:51.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:58:51.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:58:51.148+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:58:51.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:58:51.172+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:58:51.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:58:51.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-21T01:59:21.654+0000] {processor.py:157} INFO - Started process (PID=28406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:59:21.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:59:21.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:59:21.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:59:21.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:59:21.729+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:59:21.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:59:21.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:59:21.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:59:21.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-21T01:59:52.227+0000] {processor.py:157} INFO - Started process (PID=28431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:59:52.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T01:59:52.231+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:59:52.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:59:52.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T01:59:52.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:59:52.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T01:59:52.279+0000] {logging_mixin.py:151} INFO - [2024-07-21T01:59:52.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T01:59:52.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T02:00:22.751+0000] {processor.py:157} INFO - Started process (PID=28456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:00:22.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:00:22.758+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:00:22.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:00:22.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:00:22.816+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:00:22.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:00:22.848+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:00:22.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:00:22.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-21T02:00:53.248+0000] {processor.py:157} INFO - Started process (PID=28480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:00:53.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:00:53.258+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:00:53.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:00:53.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:00:53.337+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:00:53.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:00:53.357+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:00:53.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:00:53.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-21T02:01:23.773+0000] {processor.py:157} INFO - Started process (PID=28506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:01:23.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:01:23.777+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:01:23.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:01:23.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:01:23.811+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:01:23.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:01:23.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:01:23.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:01:23.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T02:01:54.303+0000] {processor.py:157} INFO - Started process (PID=28531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:01:54.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:01:54.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:01:54.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:01:54.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:01:54.377+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:01:54.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:01:54.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:01:54.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:01:54.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-21T02:02:24.893+0000] {processor.py:157} INFO - Started process (PID=28556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:02:24.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:02:24.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:02:24.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:02:24.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:02:24.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:02:24.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:02:25.004+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:02:25.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:02:25.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-21T02:02:55.507+0000] {processor.py:157} INFO - Started process (PID=28581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:02:55.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:02:55.535+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:02:55.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:02:55.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:02:55.610+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:02:55.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:02:55.649+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:02:55.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:02:55.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-21T02:03:26.108+0000] {processor.py:157} INFO - Started process (PID=28606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:03:26.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:03:26.111+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:03:26.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:03:26.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:03:26.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:03:26.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:03:26.160+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:03:26.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:03:26.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T02:03:56.627+0000] {processor.py:157} INFO - Started process (PID=28630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:03:56.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:03:56.645+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:03:56.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:03:56.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:03:56.738+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:03:56.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:03:56.764+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:03:56.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:03:56.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-07-21T02:04:27.213+0000] {processor.py:157} INFO - Started process (PID=28656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:04:27.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:04:27.218+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:04:27.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:04:27.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:04:27.258+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:04:27.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:04:27.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:04:27.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:04:27.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-21T02:04:57.704+0000] {processor.py:157} INFO - Started process (PID=28681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:04:57.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:04:57.707+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:04:57.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:04:57.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:04:57.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:04:57.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:04:57.814+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:04:57.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:04:57.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-21T02:05:28.272+0000] {processor.py:157} INFO - Started process (PID=28706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:05:28.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:05:28.281+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:05:28.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:05:28.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:05:28.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:05:28.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:05:28.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:05:28.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:05:28.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-21T02:05:58.800+0000] {processor.py:157} INFO - Started process (PID=28731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:05:58.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:05:58.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:05:58.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:05:58.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:05:58.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:05:58.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:05:58.915+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:05:58.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:05:58.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-21T02:06:29.413+0000] {processor.py:157} INFO - Started process (PID=28756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:06:29.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:06:29.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:06:29.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:06:29.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:06:29.531+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:06:29.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:06:29.550+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:06:29.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:06:29.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-21T02:07:00.069+0000] {processor.py:157} INFO - Started process (PID=28781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:07:00.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:07:00.077+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:07:00.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:07:00.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:07:00.151+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:07:00.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:07:00.167+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:07:00.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:07:00.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-21T02:07:30.625+0000] {processor.py:157} INFO - Started process (PID=28806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:07:30.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:07:30.633+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:07:30.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:07:30.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:07:30.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:07:30.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:07:30.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:07:30.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:07:30.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-21T02:08:01.145+0000] {processor.py:157} INFO - Started process (PID=28831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:08:01.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:08:01.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:08:01.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:08:01.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:08:01.217+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:08:01.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:08:01.238+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:08:01.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:08:01.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-21T02:08:31.969+0000] {processor.py:157} INFO - Started process (PID=28856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:08:31.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:08:31.976+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:08:31.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:08:32.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:08:32.096+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:08:32.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:08:32.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:08:32.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:08:32.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-07-21T02:09:02.378+0000] {processor.py:157} INFO - Started process (PID=28881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:09:02.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:09:02.383+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:09:02.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:09:02.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:09:02.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:09:02.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:09:02.425+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:09:02.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:09:02.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T02:09:32.783+0000] {processor.py:157} INFO - Started process (PID=28906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:09:32.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:09:32.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:09:32.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:09:32.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:09:32.818+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:09:32.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:09:32.831+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:09:32.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:09:32.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T02:24:56.977+0000] {processor.py:157} INFO - Started process (PID=28933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:24:56.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:24:56.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:24:56.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:24:56.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:24:57.003+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:24:57.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:24:57.012+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:24:57.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:24:57.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T02:25:27.740+0000] {processor.py:157} INFO - Started process (PID=28958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:25:27.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:25:27.742+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:25:27.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:25:27.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:25:27.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:25:27.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:25:27.783+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:25:27.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:25:27.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T02:40:55.129+0000] {processor.py:157} INFO - Started process (PID=28981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:40:55.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:40:55.134+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:40:55.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:40:55.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:40:55.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:40:55.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:40:55.211+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:40:55.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:40:55.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-21T02:41:25.690+0000] {processor.py:157} INFO - Started process (PID=29008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:41:25.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:41:25.697+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:41:25.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:41:25.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:41:25.738+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:41:25.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:41:25.753+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:41:25.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:41:25.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T02:56:53.329+0000] {processor.py:157} INFO - Started process (PID=29035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:56:53.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:56:53.339+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:56:53.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:56:53.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:56:53.403+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:56:53.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:56:53.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:56:53.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:56:53.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-21T02:57:23.915+0000] {processor.py:157} INFO - Started process (PID=29060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:57:23.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:57:23.919+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:57:23.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:57:23.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:57:23.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:57:23.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:57:23.967+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:57:23.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:57:23.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T02:57:54.437+0000] {processor.py:157} INFO - Started process (PID=29085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:57:54.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:57:54.442+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:57:54.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:57:54.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:57:54.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:57:54.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:57:54.495+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:57:54.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:57:54.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T02:58:24.945+0000] {processor.py:157} INFO - Started process (PID=29110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:58:24.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:58:24.949+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:58:24.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:58:24.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:58:24.981+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:58:24.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:58:24.991+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:58:24.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:58:24.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T02:58:55.573+0000] {processor.py:157} INFO - Started process (PID=29135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:58:55.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T02:58:55.581+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:58:55.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:58:55.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T02:58:55.614+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:58:55.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T02:58:55.630+0000] {logging_mixin.py:151} INFO - [2024-07-21T02:58:55.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T02:58:55.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T03:15:47.094+0000] {processor.py:157} INFO - Started process (PID=29162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:15:47.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:15:47.104+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:15:47.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:15:47.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:15:47.153+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:15:47.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:15:47.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:15:47.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:15:47.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-21T03:16:19.832+0000] {processor.py:157} INFO - Started process (PID=29187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:16:19.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:16:19.838+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:16:19.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:16:19.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:16:19.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:16:19.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:16:19.886+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:16:19.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:16:19.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T03:16:50.319+0000] {processor.py:157} INFO - Started process (PID=29212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:16:50.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:16:50.325+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:16:50.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:16:50.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:16:50.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:16:50.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:16:50.367+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:16:50.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:16:50.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T03:17:20.725+0000] {processor.py:157} INFO - Started process (PID=29237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:17:20.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:17:20.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:17:20.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:17:20.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:17:20.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:17:20.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:17:20.770+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:17:20.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:17:20.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T03:17:51.174+0000] {processor.py:157} INFO - Started process (PID=29262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:17:51.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:17:51.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:17:51.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:17:51.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:17:51.206+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:17:51.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:17:51.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:17:51.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:17:51.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T03:33:48.290+0000] {processor.py:157} INFO - Started process (PID=29287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:33:48.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:33:48.294+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:33:48.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:33:48.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:33:48.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:33:48.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:33:48.375+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:33:48.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:33:48.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-21T03:34:18.902+0000] {processor.py:157} INFO - Started process (PID=29312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:34:18.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:34:18.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:34:18.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:34:18.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:34:19.009+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:34:19.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:34:19.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:34:19.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:34:19.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-21T03:41:18.995+0000] {processor.py:157} INFO - Started process (PID=29337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:41:18.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:41:18.997+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:41:18.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:41:19.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:41:19.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:41:19.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:41:19.033+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:41:19.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:41:19.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T03:41:49.478+0000] {processor.py:157} INFO - Started process (PID=29361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:41:49.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:41:49.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:41:49.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:41:49.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:41:49.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:41:49.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:41:49.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:41:49.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:41:49.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T03:42:20.031+0000] {processor.py:157} INFO - Started process (PID=29387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:42:20.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:42:20.034+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:42:20.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:42:20.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:42:20.065+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:42:20.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:42:20.076+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:42:20.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:42:20.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T03:42:50.470+0000] {processor.py:157} INFO - Started process (PID=29412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:42:50.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:42:50.473+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:42:50.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:42:50.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:42:50.503+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:42:50.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:42:50.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:42:50.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:42:50.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T03:43:20.971+0000] {processor.py:157} INFO - Started process (PID=29437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:43:20.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:43:20.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:43:20.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:43:20.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:43:21.004+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:43:21.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:43:21.017+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:43:21.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:43:21.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T03:43:51.468+0000] {processor.py:157} INFO - Started process (PID=29462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:43:51.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:43:51.474+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:43:51.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:43:51.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:43:51.510+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:43:51.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:43:51.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:43:51.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:43:51.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T03:44:21.949+0000] {processor.py:157} INFO - Started process (PID=29487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:44:21.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:44:21.953+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:44:21.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:44:21.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:44:21.983+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:44:21.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:44:21.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:44:21.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:44:22.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T03:44:52.436+0000] {processor.py:157} INFO - Started process (PID=29512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:44:52.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:44:52.439+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:44:52.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:44:52.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:44:52.469+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:44:52.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:44:52.481+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:44:52.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:44:52.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T03:45:22.956+0000] {processor.py:157} INFO - Started process (PID=29537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:45:22.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:45:22.958+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:45:22.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:45:22.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:45:22.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:45:22.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:45:22.996+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:45:22.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:45:23.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T03:45:53.436+0000] {processor.py:157} INFO - Started process (PID=29562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:45:53.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:45:53.438+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:45:53.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:45:53.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:45:53.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:45:53.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:45:53.479+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:45:53.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:45:53.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T03:46:23.943+0000] {processor.py:157} INFO - Started process (PID=29587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:46:23.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:46:23.947+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:46:23.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:46:23.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:46:23.973+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:46:23.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:46:23.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:46:23.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:46:23.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T03:46:54.461+0000] {processor.py:157} INFO - Started process (PID=29612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:46:54.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:46:54.464+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:46:54.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:46:54.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:46:54.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:46:54.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:46:54.502+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:46:54.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:46:54.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T03:47:24.862+0000] {processor.py:157} INFO - Started process (PID=29637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:47:24.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:47:24.866+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:47:24.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:47:24.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:47:24.897+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:47:24.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:47:24.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:47:24.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:47:24.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T03:47:55.310+0000] {processor.py:157} INFO - Started process (PID=29662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:47:55.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:47:55.314+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:47:55.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:47:55.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:47:55.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:47:55.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:47:55.350+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:47:55.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:47:55.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T03:48:25.789+0000] {processor.py:157} INFO - Started process (PID=29687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:48:25.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:48:25.793+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:48:25.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:48:25.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:48:25.826+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:48:25.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:48:25.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:48:25.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:48:25.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T03:48:56.233+0000] {processor.py:157} INFO - Started process (PID=29712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:48:56.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:48:56.236+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:48:56.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:48:56.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:48:56.266+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:48:56.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:48:56.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:48:56.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:48:56.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T03:49:26.741+0000] {processor.py:157} INFO - Started process (PID=29737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:49:26.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:49:26.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:49:26.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:49:26.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:49:26.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:49:26.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:49:26.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:49:26.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:49:26.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T03:49:57.156+0000] {processor.py:157} INFO - Started process (PID=29762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:49:57.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:49:57.158+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:49:57.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:49:57.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:49:57.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:49:57.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:49:57.191+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:49:57.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:49:57.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T03:50:27.608+0000] {processor.py:157} INFO - Started process (PID=29787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:50:27.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:50:27.613+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:50:27.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:50:27.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:50:27.640+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:50:27.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:50:27.652+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:50:27.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:50:27.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T03:50:58.061+0000] {processor.py:157} INFO - Started process (PID=29812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:50:58.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:50:58.067+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:50:58.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:50:58.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:50:58.103+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:50:58.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:50:58.115+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:50:58.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:50:58.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T03:51:28.599+0000] {processor.py:157} INFO - Started process (PID=29837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:51:28.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:51:28.602+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:51:28.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:51:28.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:51:28.632+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:51:28.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:51:28.642+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:51:28.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:51:28.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T03:51:59.011+0000] {processor.py:157} INFO - Started process (PID=29862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:51:59.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:51:59.015+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:51:59.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:51:59.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:51:59.046+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:51:59.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:51:59.056+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:51:59.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:51:59.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T03:52:29.531+0000] {processor.py:157} INFO - Started process (PID=29887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:52:29.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:52:29.534+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:52:29.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:52:29.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:52:29.562+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:52:29.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:52:29.574+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:52:29.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:52:29.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T03:52:59.992+0000] {processor.py:157} INFO - Started process (PID=29912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:52:59.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:52:59.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:52:59.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:53:00.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:53:00.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:53:00.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:53:00.035+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:53:00.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:53:00.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T03:53:30.497+0000] {processor.py:157} INFO - Started process (PID=29937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:53:30.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:53:30.502+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:53:30.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:53:30.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:53:30.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:53:30.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:53:30.540+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:53:30.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:53:30.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T03:54:00.939+0000] {processor.py:157} INFO - Started process (PID=29962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:54:00.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:54:00.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:54:00.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:54:00.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:54:00.970+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:54:00.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:54:00.982+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:54:00.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:54:00.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T03:54:31.507+0000] {processor.py:157} INFO - Started process (PID=29987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:54:31.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:54:31.510+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:54:31.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:54:31.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:54:31.538+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:54:31.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:54:31.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:54:31.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:54:31.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T03:55:01.994+0000] {processor.py:157} INFO - Started process (PID=30012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:55:01.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:55:01.997+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:55:01.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:55:02.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:55:02.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:55:02.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:55:02.032+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:55:02.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:55:02.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T03:55:32.470+0000] {processor.py:157} INFO - Started process (PID=30037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:55:32.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:55:32.473+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:55:32.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:55:32.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:55:32.502+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:55:32.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:55:32.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:55:32.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:55:32.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T03:56:02.939+0000] {processor.py:157} INFO - Started process (PID=30062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:56:02.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:56:02.944+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:56:02.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:56:02.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:56:02.981+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:56:02.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:56:02.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:56:02.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:56:03.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T03:56:33.473+0000] {processor.py:157} INFO - Started process (PID=30087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:56:33.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:56:33.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:56:33.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:56:33.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:56:33.502+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:56:33.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:56:33.512+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:56:33.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:56:33.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T03:57:03.985+0000] {processor.py:157} INFO - Started process (PID=30112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:57:03.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:57:03.989+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:57:03.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:57:04.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:57:04.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:57:04.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:57:04.032+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:57:04.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:57:04.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T03:57:34.384+0000] {processor.py:157} INFO - Started process (PID=30137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:57:34.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:57:34.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:57:34.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:57:34.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:57:34.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:57:34.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:57:34.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:57:34.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:57:34.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T03:58:04.876+0000] {processor.py:157} INFO - Started process (PID=30162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:58:04.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:58:04.878+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:58:04.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:58:04.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:58:04.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:58:04.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:58:04.918+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:58:04.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:58:04.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T03:58:35.321+0000] {processor.py:157} INFO - Started process (PID=30187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:58:35.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:58:35.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:58:35.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:58:35.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:58:35.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:58:35.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:58:35.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:58:35.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:58:35.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T03:59:05.813+0000] {processor.py:157} INFO - Started process (PID=30212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:59:05.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:59:05.816+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:59:05.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:59:05.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:59:05.843+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:59:05.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:59:05.853+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:59:05.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:59:05.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T03:59:36.312+0000] {processor.py:157} INFO - Started process (PID=30237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:59:36.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T03:59:36.314+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:59:36.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:59:36.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T03:59:36.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:59:36.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T03:59:36.350+0000] {logging_mixin.py:151} INFO - [2024-07-21T03:59:36.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T03:59:36.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T04:00:06.821+0000] {processor.py:157} INFO - Started process (PID=30262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:00:06.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:00:06.827+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:00:06.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:00:06.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:00:06.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:00:06.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:00:06.869+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:00:06.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:00:06.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T04:00:37.274+0000] {processor.py:157} INFO - Started process (PID=30287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:00:37.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:00:37.280+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:00:37.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:00:37.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:00:37.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:00:37.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:00:37.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:00:37.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:00:37.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T04:01:07.774+0000] {processor.py:157} INFO - Started process (PID=30312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:01:07.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:01:07.778+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:01:07.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:01:07.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:01:07.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:01:07.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:01:07.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:01:07.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:01:07.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T04:01:38.342+0000] {processor.py:157} INFO - Started process (PID=30337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:01:38.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:01:38.346+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:01:38.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:01:38.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:01:38.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:01:38.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:01:38.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:01:38.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:01:38.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T04:02:08.758+0000] {processor.py:157} INFO - Started process (PID=30362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:02:08.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:02:08.761+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:02:08.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:02:08.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:02:08.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:02:08.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:02:08.802+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:02:08.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:02:08.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:02:39.265+0000] {processor.py:157} INFO - Started process (PID=30387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:02:39.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:02:39.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:02:39.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:02:39.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:02:39.297+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:02:39.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:02:39.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:02:39.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:02:39.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:03:09.661+0000] {processor.py:157} INFO - Started process (PID=30412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:03:09.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:03:09.664+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:03:09.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:03:09.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:03:09.693+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:03:09.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:03:09.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:03:09.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:03:09.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:03:40.096+0000] {processor.py:157} INFO - Started process (PID=30437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:03:40.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:03:40.098+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:03:40.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:03:40.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:03:40.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:03:40.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:03:40.136+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:03:40.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:03:40.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T04:04:10.625+0000] {processor.py:157} INFO - Started process (PID=30462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:04:10.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:04:10.629+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:04:10.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:04:10.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:04:10.659+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:04:10.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:04:10.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:04:10.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:04:10.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:04:41.118+0000] {processor.py:157} INFO - Started process (PID=30487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:04:41.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:04:41.122+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:04:41.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:04:41.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:04:41.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:04:41.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:04:41.162+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:04:41.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:04:41.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T04:05:11.555+0000] {processor.py:157} INFO - Started process (PID=30512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:05:11.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:05:11.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:05:11.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:05:11.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:05:11.593+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:05:11.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:05:11.605+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:05:11.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:05:11.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T04:05:42.058+0000] {processor.py:157} INFO - Started process (PID=30537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:05:42.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:05:42.060+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:05:42.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:05:42.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:05:42.091+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:05:42.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:05:42.102+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:05:42.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:05:42.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:06:12.602+0000] {processor.py:157} INFO - Started process (PID=30562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:06:12.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:06:12.605+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:06:12.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:06:12.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:06:12.632+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:06:12.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:06:12.646+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:06:12.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:06:12.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:06:43.071+0000] {processor.py:157} INFO - Started process (PID=30587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:06:43.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:06:43.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:06:43.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:06:43.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:06:43.106+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:06:43.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:06:43.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:06:43.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:06:43.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T04:07:13.517+0000] {processor.py:157} INFO - Started process (PID=30612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:07:13.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:07:13.521+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:07:13.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:07:13.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:07:13.549+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:07:13.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:07:13.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:07:13.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:07:13.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:07:44.033+0000] {processor.py:157} INFO - Started process (PID=30637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:07:44.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:07:44.037+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:07:44.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:07:44.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:07:44.063+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:07:44.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:07:44.076+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:07:44.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:07:44.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:08:14.526+0000] {processor.py:157} INFO - Started process (PID=30662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:08:14.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:08:14.531+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:08:14.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:08:14.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:08:14.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:08:14.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:08:14.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:08:14.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:08:14.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T04:08:45.048+0000] {processor.py:157} INFO - Started process (PID=30687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:08:45.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:08:45.051+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:08:45.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:08:45.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:08:45.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:08:45.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:08:45.090+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:08:45.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:08:45.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T04:09:15.499+0000] {processor.py:157} INFO - Started process (PID=30712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:09:15.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:09:15.503+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:09:15.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:09:15.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:09:15.534+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:09:15.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:09:15.544+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:09:15.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:09:15.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T04:09:45.914+0000] {processor.py:157} INFO - Started process (PID=30737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:09:45.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:09:45.919+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:09:45.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:09:45.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:09:45.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:09:45.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:09:45.967+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:09:45.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:09:45.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T04:10:16.362+0000] {processor.py:157} INFO - Started process (PID=30762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:10:16.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:10:16.365+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:10:16.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:10:16.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:10:16.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:10:16.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:10:16.406+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:10:16.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:10:16.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:10:46.836+0000] {processor.py:157} INFO - Started process (PID=30787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:10:46.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:10:46.839+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:10:46.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:10:46.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:10:46.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:10:46.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:10:46.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:10:46.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:10:46.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:11:17.338+0000] {processor.py:157} INFO - Started process (PID=30812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:11:17.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:11:17.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:11:17.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:11:17.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:11:17.366+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:11:17.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:11:17.376+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:11:17.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:11:17.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T04:11:47.833+0000] {processor.py:157} INFO - Started process (PID=30837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:11:47.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:11:47.838+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:11:47.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:11:47.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:11:47.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:11:47.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:11:47.885+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:11:47.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:11:47.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T04:12:18.348+0000] {processor.py:157} INFO - Started process (PID=30862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:12:18.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:12:18.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:12:18.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:12:18.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:12:18.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:12:18.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:12:18.395+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:12:18.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:12:18.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T04:12:48.807+0000] {processor.py:157} INFO - Started process (PID=30887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:12:48.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:12:48.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:12:48.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:12:48.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:12:48.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:12:48.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:12:48.847+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:12:48.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:12:48.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T04:13:19.293+0000] {processor.py:157} INFO - Started process (PID=30912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:13:19.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:13:19.297+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:13:19.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:13:19.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:13:19.326+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:13:19.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:13:19.339+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:13:19.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:13:19.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T04:13:49.825+0000] {processor.py:157} INFO - Started process (PID=30937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:13:49.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:13:49.832+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:13:49.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:13:49.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:13:49.867+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:13:49.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:13:49.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:13:49.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:13:49.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T04:14:20.318+0000] {processor.py:157} INFO - Started process (PID=30962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:14:20.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:14:20.321+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:14:20.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:14:20.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:14:20.348+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:14:20.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:14:20.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:14:20.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:14:20.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:14:50.863+0000] {processor.py:157} INFO - Started process (PID=30987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:14:50.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:14:50.867+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:14:50.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:14:50.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:14:50.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:14:50.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:14:50.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:14:50.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:14:50.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:15:21.327+0000] {processor.py:157} INFO - Started process (PID=31012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:15:21.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:15:21.330+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:15:21.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:15:21.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:15:21.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:15:21.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:15:21.373+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:15:21.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:15:21.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:15:51.893+0000] {processor.py:157} INFO - Started process (PID=31037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:15:51.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:15:51.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:15:51.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:15:51.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:15:51.927+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:15:51.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:15:51.937+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:15:51.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:15:51.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:16:22.406+0000] {processor.py:157} INFO - Started process (PID=31062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:16:22.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:16:22.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:16:22.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:16:22.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:16:22.434+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:16:22.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:16:22.448+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:16:22.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:16:22.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T04:16:52.819+0000] {processor.py:157} INFO - Started process (PID=31087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:16:52.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:16:52.823+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:16:52.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:16:52.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:16:52.852+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:16:52.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:16:52.861+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:16:52.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:16:52.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:17:23.333+0000] {processor.py:157} INFO - Started process (PID=31112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:17:23.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:17:23.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:17:23.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:17:23.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:17:23.362+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:17:23.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:17:23.372+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:17:23.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:17:23.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T04:17:53.772+0000] {processor.py:157} INFO - Started process (PID=31137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:17:53.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:17:53.776+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:17:53.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:17:53.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:17:53.804+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:17:53.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:17:53.816+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:17:53.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:17:53.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:18:24.160+0000] {processor.py:157} INFO - Started process (PID=31162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:18:24.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:18:24.162+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:18:24.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:18:24.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:18:24.188+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:18:24.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:18:24.197+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:18:24.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:18:24.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T04:18:54.655+0000] {processor.py:157} INFO - Started process (PID=31187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:18:54.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:18:54.660+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:18:54.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:18:54.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:18:54.700+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:18:54.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:18:54.712+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:18:54.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:18:54.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T04:19:25.209+0000] {processor.py:157} INFO - Started process (PID=31212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:19:25.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:19:25.212+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:19:25.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:19:25.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:19:25.241+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:19:25.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:19:25.254+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:19:25.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:19:25.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T04:19:55.726+0000] {processor.py:157} INFO - Started process (PID=31237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:19:55.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:19:55.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:19:55.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:19:55.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:19:55.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:19:55.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:19:55.772+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:19:55.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:19:55.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T04:20:26.166+0000] {processor.py:157} INFO - Started process (PID=31262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:20:26.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:20:26.169+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:20:26.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:20:26.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:20:26.198+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:20:26.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:20:26.208+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:20:26.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:20:26.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:20:56.651+0000] {processor.py:157} INFO - Started process (PID=31287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:20:56.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:20:56.654+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:20:56.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:20:56.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:20:56.682+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:20:56.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:20:56.692+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:20:56.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:20:56.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:21:27.115+0000] {processor.py:157} INFO - Started process (PID=31312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:21:27.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:21:27.119+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:21:27.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:21:27.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:21:27.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:21:27.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:21:27.159+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:21:27.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:21:27.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:21:57.625+0000] {processor.py:157} INFO - Started process (PID=31337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:21:57.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:21:57.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:21:57.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:21:57.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:21:57.656+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:21:57.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:21:57.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:21:57.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:21:57.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:22:28.097+0000] {processor.py:157} INFO - Started process (PID=31362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:22:28.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:22:28.100+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:22:28.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:22:28.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:22:28.124+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:22:28.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:22:28.133+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:22:28.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:22:28.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T04:22:58.464+0000] {processor.py:157} INFO - Started process (PID=31387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:22:58.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:22:58.469+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:22:58.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:22:58.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:22:58.496+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:22:58.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:22:58.507+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:22:58.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:22:58.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:23:28.988+0000] {processor.py:157} INFO - Started process (PID=31412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:23:28.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:23:28.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:23:28.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:23:29.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:23:29.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:23:29.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:23:29.042+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:23:29.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:23:29.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T04:23:59.467+0000] {processor.py:157} INFO - Started process (PID=31437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:23:59.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:23:59.470+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:23:59.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:23:59.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:23:59.497+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:23:59.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:23:59.507+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:23:59.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:23:59.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T04:24:30.006+0000] {processor.py:157} INFO - Started process (PID=31462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:24:30.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:24:30.010+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:24:30.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:24:30.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:24:30.037+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:24:30.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:24:30.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:24:30.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:24:30.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T04:25:00.469+0000] {processor.py:157} INFO - Started process (PID=31487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:25:00.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:25:00.471+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:25:00.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:25:00.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:25:00.498+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:25:00.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:25:00.508+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:25:00.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:25:00.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T04:25:30.947+0000] {processor.py:157} INFO - Started process (PID=31512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:25:30.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:25:30.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:25:30.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:25:30.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:25:30.978+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:25:30.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:25:30.990+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:25:30.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:25:30.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:26:01.395+0000] {processor.py:157} INFO - Started process (PID=31537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:26:01.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:26:01.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:26:01.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:26:01.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:26:01.429+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:26:01.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:26:01.439+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:26:01.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:26:01.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:26:31.880+0000] {processor.py:157} INFO - Started process (PID=31562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:26:31.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:26:31.882+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:26:31.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:26:31.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:26:31.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:26:31.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:26:31.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:26:31.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:26:31.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T04:27:02.375+0000] {processor.py:157} INFO - Started process (PID=31587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:27:02.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:27:02.379+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:27:02.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:27:02.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:27:02.407+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:27:02.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:27:02.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:27:02.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:27:02.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T04:27:32.803+0000] {processor.py:157} INFO - Started process (PID=31612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:27:32.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:27:32.807+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:27:32.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:27:32.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:27:32.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:27:32.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:27:32.847+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:27:32.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:27:32.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T04:28:03.304+0000] {processor.py:157} INFO - Started process (PID=31637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:28:03.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:28:03.307+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:28:03.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:28:03.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:28:03.333+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:28:03.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:28:03.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:28:03.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:28:03.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T04:28:33.718+0000] {processor.py:157} INFO - Started process (PID=31662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:28:33.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:28:33.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:28:33.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:28:33.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:28:33.741+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:28:33.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:28:33.753+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:28:33.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:28:33.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T04:29:04.199+0000] {processor.py:157} INFO - Started process (PID=31687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:29:04.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:29:04.204+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:29:04.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:29:04.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:29:04.229+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:29:04.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:29:04.238+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:29:04.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:29:04.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T04:29:34.685+0000] {processor.py:157} INFO - Started process (PID=31712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:29:34.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:29:34.691+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:29:34.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:29:34.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:29:34.727+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:29:34.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:29:34.739+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:29:34.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:29:34.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T04:30:05.186+0000] {processor.py:157} INFO - Started process (PID=31737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:30:05.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:30:05.191+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:30:05.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:30:05.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:30:05.219+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:30:05.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:30:05.230+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:30:05.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:30:05.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:30:35.684+0000] {processor.py:157} INFO - Started process (PID=31762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:30:35.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:30:35.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:30:35.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:30:35.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:30:35.718+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:30:35.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:30:35.727+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:30:35.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:30:35.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T04:31:06.097+0000] {processor.py:157} INFO - Started process (PID=31787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:31:06.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:31:06.100+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:31:06.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:31:06.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:31:06.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:31:06.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:31:06.137+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:31:06.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:31:06.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:31:36.672+0000] {processor.py:157} INFO - Started process (PID=31812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:31:36.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:31:36.675+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:31:36.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:31:36.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:31:36.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:31:36.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:31:36.716+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:31:36.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:31:36.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T04:32:07.174+0000] {processor.py:157} INFO - Started process (PID=31837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:32:07.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:32:07.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:32:07.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:32:07.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:32:07.208+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:32:07.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:32:07.221+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:32:07.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:32:07.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T04:32:37.625+0000] {processor.py:157} INFO - Started process (PID=31862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:32:37.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:32:37.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:32:37.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:32:37.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:32:37.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:32:37.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:32:37.667+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:32:37.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:32:37.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T04:33:08.047+0000] {processor.py:157} INFO - Started process (PID=31887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:33:08.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:33:08.051+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:33:08.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:33:08.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:33:08.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:33:08.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:33:08.090+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:33:08.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:33:08.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:33:38.541+0000] {processor.py:157} INFO - Started process (PID=31912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:33:38.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:33:38.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:33:38.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:33:38.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:33:38.576+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:33:38.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:33:38.586+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:33:38.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:33:38.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:34:09.074+0000] {processor.py:157} INFO - Started process (PID=31937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:34:09.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:34:09.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:34:09.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:34:09.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:34:09.131+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:34:09.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:34:09.145+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:34:09.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:34:09.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-21T04:34:39.638+0000] {processor.py:157} INFO - Started process (PID=31962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:34:39.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:34:39.642+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:34:39.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:34:39.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:34:39.670+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:34:39.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:34:39.681+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:34:39.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:34:39.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:35:10.054+0000] {processor.py:157} INFO - Started process (PID=31987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:35:10.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:35:10.056+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:35:10.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:35:10.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:35:10.079+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:35:10.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:35:10.087+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:35:10.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:35:10.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T04:35:40.470+0000] {processor.py:157} INFO - Started process (PID=32012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:35:40.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:35:40.474+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:35:40.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:35:40.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:35:40.501+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:35:40.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:35:40.515+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:35:40.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:35:40.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T04:36:10.973+0000] {processor.py:157} INFO - Started process (PID=32037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:36:10.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:36:10.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:36:10.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:36:10.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:36:11.007+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:36:11.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:36:11.020+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:36:11.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:36:11.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T04:36:41.487+0000] {processor.py:157} INFO - Started process (PID=32062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:36:41.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:36:41.491+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:36:41.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:36:41.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:36:41.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:36:41.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:36:41.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:36:41.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:36:41.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T04:37:12.025+0000] {processor.py:157} INFO - Started process (PID=32087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:37:12.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:37:12.031+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:37:12.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:37:12.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:37:12.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:37:12.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:37:12.078+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:37:12.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:37:12.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T04:37:42.478+0000] {processor.py:157} INFO - Started process (PID=32112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:37:42.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:37:42.481+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:37:42.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:37:42.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:37:42.506+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:37:42.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:37:42.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:37:42.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:37:42.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T04:38:12.985+0000] {processor.py:157} INFO - Started process (PID=32137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:38:12.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:38:12.987+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:38:12.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:38:12.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:38:13.015+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:38:13.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:38:13.027+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:38:13.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:38:13.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T04:38:43.377+0000] {processor.py:157} INFO - Started process (PID=32162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:38:43.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:38:43.379+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:38:43.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:38:43.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:38:43.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:38:43.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:38:43.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:38:43.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:38:43.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T04:39:13.902+0000] {processor.py:157} INFO - Started process (PID=32187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:39:13.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:39:13.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:39:13.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:39:13.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:39:13.933+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:39:13.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:39:13.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:39:13.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:39:13.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:39:44.318+0000] {processor.py:157} INFO - Started process (PID=32212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:39:44.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:39:44.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:39:44.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:39:44.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:39:44.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:39:44.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:39:44.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:39:44.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:39:44.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T04:40:14.739+0000] {processor.py:157} INFO - Started process (PID=32237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:40:14.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:40:14.743+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:40:14.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:40:14.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:40:14.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:40:14.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:40:14.778+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:40:14.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:40:14.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T04:40:45.294+0000] {processor.py:157} INFO - Started process (PID=32262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:40:45.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:40:45.298+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:40:45.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:40:45.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:40:45.328+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:40:45.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:40:45.338+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:40:45.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:40:45.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T04:41:15.870+0000] {processor.py:157} INFO - Started process (PID=32287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:41:15.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:41:15.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:41:15.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:41:15.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:41:15.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:41:15.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:41:15.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:41:15.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:41:15.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T04:41:46.425+0000] {processor.py:157} INFO - Started process (PID=32312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:41:46.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:41:46.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:41:46.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:41:46.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:41:46.474+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:41:46.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:41:46.487+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:41:46.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:41:46.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T04:58:51.921+0000] {processor.py:157} INFO - Started process (PID=32337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:58:51.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:58:51.924+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:58:51.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:58:51.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:58:51.952+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:58:51.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:58:51.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:58:51.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:58:51.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T04:59:22.407+0000] {processor.py:157} INFO - Started process (PID=32363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:59:22.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:59:22.420+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:59:22.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:59:22.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:59:22.459+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:59:22.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:59:22.472+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:59:22.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:59:22.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-21T04:59:52.931+0000] {processor.py:157} INFO - Started process (PID=32389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:59:52.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T04:59:52.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:59:52.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:59:52.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T04:59:52.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:59:52.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T04:59:52.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T04:59:52.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T04:59:52.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T05:00:23.378+0000] {processor.py:157} INFO - Started process (PID=32413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:00:23.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:00:23.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:00:23.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:00:23.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:00:23.420+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:00:23.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:00:23.432+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:00:23.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:00:23.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T05:00:53.830+0000] {processor.py:157} INFO - Started process (PID=32439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:00:53.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:00:53.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:00:53.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:00:53.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:00:53.862+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:00:53.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:00:53.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:00:53.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:00:53.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:01:24.320+0000] {processor.py:157} INFO - Started process (PID=32464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:01:24.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:01:24.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:01:24.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:01:24.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:01:24.350+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:01:24.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:01:24.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:01:24.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:01:24.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T05:01:54.745+0000] {processor.py:157} INFO - Started process (PID=32489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:01:54.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:01:54.747+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:01:54.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:01:54.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:01:54.775+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:01:54.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:01:54.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:01:54.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:01:54.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:02:25.224+0000] {processor.py:157} INFO - Started process (PID=32514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:02:25.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:02:25.227+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:02:25.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:02:25.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:02:25.257+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:02:25.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:02:25.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:02:25.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:02:25.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T05:02:55.714+0000] {processor.py:157} INFO - Started process (PID=32539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:02:55.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:02:55.721+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:02:55.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:02:55.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:02:55.756+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:02:55.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:02:55.769+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:02:55.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:02:55.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T05:03:26.181+0000] {processor.py:157} INFO - Started process (PID=32564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:03:26.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:03:26.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:03:26.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:03:26.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:03:26.210+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:03:26.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:03:26.220+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:03:26.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:03:26.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T05:03:56.655+0000] {processor.py:157} INFO - Started process (PID=32588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:03:56.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:03:56.658+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:03:56.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:03:56.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:03:56.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:03:56.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:03:56.697+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:03:56.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:03:56.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:04:27.127+0000] {processor.py:157} INFO - Started process (PID=32614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:04:27.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:04:27.129+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:04:27.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:04:27.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:04:27.159+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:04:27.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:04:27.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:04:27.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:04:27.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:04:57.640+0000] {processor.py:157} INFO - Started process (PID=32639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:04:57.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:04:57.643+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:04:57.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:04:57.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:04:57.673+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:04:57.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:04:57.682+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:04:57.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:04:57.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:05:28.098+0000] {processor.py:157} INFO - Started process (PID=32664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:05:28.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:05:28.099+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:05:28.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:05:28.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:05:28.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:05:28.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:05:28.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:05:28.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:05:28.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:05:58.548+0000] {processor.py:157} INFO - Started process (PID=32689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:05:58.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:05:58.551+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:05:58.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:05:58.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:05:58.579+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:05:58.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:05:58.588+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:05:58.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:05:58.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:06:29.019+0000] {processor.py:157} INFO - Started process (PID=32714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:06:29.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:06:29.021+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:06:29.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:06:29.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:06:29.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:06:29.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:06:29.059+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:06:29.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:06:29.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:06:59.555+0000] {processor.py:157} INFO - Started process (PID=32739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:06:59.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:06:59.558+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:06:59.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:06:59.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:06:59.585+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:06:59.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:06:59.595+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:06:59.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:06:59.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T05:07:30.001+0000] {processor.py:157} INFO - Started process (PID=32764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:07:30.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:07:30.005+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:07:30.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:07:30.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:07:30.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:07:30.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:07:30.052+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:07:30.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:07:30.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T05:08:00.462+0000] {processor.py:157} INFO - Started process (PID=32789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:08:00.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:08:00.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:08:00.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:08:00.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:08:00.495+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:08:00.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:08:00.505+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:08:00.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:08:00.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T05:08:30.962+0000] {processor.py:157} INFO - Started process (PID=32814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:08:30.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:08:30.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:08:30.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:08:30.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:08:30.995+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:08:30.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:08:31.005+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:08:31.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:08:31.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:09:01.447+0000] {processor.py:157} INFO - Started process (PID=32839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:09:01.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:09:01.450+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:09:01.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:09:01.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:09:01.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:09:01.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:09:01.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:09:01.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:09:01.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T05:09:31.908+0000] {processor.py:157} INFO - Started process (PID=32864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:09:31.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:09:31.911+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:09:31.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:09:31.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:09:31.940+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:09:31.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:09:31.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:09:31.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:09:31.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:10:02.369+0000] {processor.py:157} INFO - Started process (PID=32889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:10:02.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:10:02.371+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:10:02.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:10:02.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:10:02.397+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:10:02.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:10:02.407+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:10:02.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:10:02.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T05:10:32.869+0000] {processor.py:157} INFO - Started process (PID=32914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:10:32.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:10:32.873+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:10:32.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:10:32.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:10:32.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:10:32.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:10:32.919+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:10:32.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:10:32.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T05:11:03.395+0000] {processor.py:157} INFO - Started process (PID=32939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:11:03.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:11:03.398+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:11:03.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:11:03.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:11:03.429+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:11:03.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:11:03.439+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:11:03.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:11:03.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:11:33.878+0000] {processor.py:157} INFO - Started process (PID=32964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:11:33.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:11:33.882+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:11:33.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:11:33.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:11:33.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:11:33.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:11:33.924+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:11:33.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:11:33.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T05:12:04.349+0000] {processor.py:157} INFO - Started process (PID=32989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:12:04.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:12:04.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:12:04.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:12:04.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:12:04.380+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:12:04.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:12:04.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:12:04.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:12:04.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T05:12:34.786+0000] {processor.py:157} INFO - Started process (PID=33014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:12:34.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:12:34.789+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:12:34.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:12:34.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:12:34.823+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:12:34.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:12:34.836+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:12:34.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:12:34.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T05:13:05.313+0000] {processor.py:157} INFO - Started process (PID=33039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:13:05.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:13:05.317+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:13:05.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:13:05.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:13:05.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:13:05.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:13:05.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:13:05.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:13:05.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T05:13:35.805+0000] {processor.py:157} INFO - Started process (PID=33064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:13:35.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:13:35.809+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:13:35.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:13:35.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:13:35.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:13:35.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:13:35.849+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:13:35.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:13:35.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:14:06.348+0000] {processor.py:157} INFO - Started process (PID=33089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:14:06.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:14:06.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:14:06.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:14:06.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:14:06.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:14:06.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:14:06.400+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:14:06.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:14:06.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T05:14:36.818+0000] {processor.py:157} INFO - Started process (PID=33114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:14:36.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:14:36.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:14:36.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:14:36.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:14:36.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:14:36.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:14:36.860+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:14:36.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:14:36.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:15:07.317+0000] {processor.py:157} INFO - Started process (PID=33139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:15:07.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:15:07.319+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:15:07.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:15:07.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:15:07.347+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:15:07.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:15:07.359+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:15:07.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:15:07.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:15:37.735+0000] {processor.py:157} INFO - Started process (PID=33164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:15:37.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:15:37.737+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:15:37.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:15:37.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:15:37.767+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:15:37.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:15:37.778+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:15:37.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:15:37.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:16:08.245+0000] {processor.py:157} INFO - Started process (PID=33189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:16:08.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:16:08.248+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:16:08.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:16:08.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:16:08.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:16:08.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:16:08.289+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:16:08.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:16:08.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:16:38.668+0000] {processor.py:157} INFO - Started process (PID=33214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:16:38.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:16:38.670+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:16:38.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:16:38.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:16:38.698+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:16:38.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:16:38.708+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:16:38.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:16:38.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T05:17:09.190+0000] {processor.py:157} INFO - Started process (PID=33239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:17:09.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:17:09.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:17:09.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:17:09.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:17:09.219+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:17:09.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:17:09.231+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:17:09.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:17:09.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:17:39.691+0000] {processor.py:157} INFO - Started process (PID=33264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:17:39.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:17:39.694+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:17:39.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:17:39.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:17:39.727+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:17:39.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:17:39.739+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:17:39.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:17:39.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T05:18:10.256+0000] {processor.py:157} INFO - Started process (PID=33289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:18:10.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:18:10.259+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:18:10.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:18:10.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:18:10.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:18:10.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:18:10.298+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:18:10.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:18:10.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:18:40.710+0000] {processor.py:157} INFO - Started process (PID=33314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:18:40.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:18:40.713+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:18:40.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:18:40.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:18:40.739+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:18:40.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:18:40.749+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:18:40.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:18:40.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:19:11.168+0000] {processor.py:157} INFO - Started process (PID=33339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:19:11.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:19:11.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:19:11.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:19:11.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:19:11.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:19:11.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:19:11.211+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:19:11.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:19:11.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:19:41.676+0000] {processor.py:157} INFO - Started process (PID=33364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:19:41.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:19:41.679+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:19:41.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:19:41.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:19:41.707+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:19:41.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:19:41.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:19:41.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:19:41.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:20:12.092+0000] {processor.py:157} INFO - Started process (PID=33389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:20:12.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:20:12.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:20:12.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:20:12.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:20:12.121+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:20:12.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:20:12.130+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:20:12.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:20:12.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:20:42.608+0000] {processor.py:157} INFO - Started process (PID=33414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:20:42.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:20:42.611+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:20:42.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:20:42.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:20:42.640+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:20:42.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:20:42.651+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:20:42.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:20:42.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:21:13.148+0000] {processor.py:157} INFO - Started process (PID=33439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:21:13.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:21:13.153+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:21:13.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:21:13.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:21:13.187+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:21:13.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:21:13.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:21:13.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:21:13.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T05:21:43.646+0000] {processor.py:157} INFO - Started process (PID=33464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:21:43.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:21:43.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:21:43.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:21:43.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:21:43.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:21:43.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:21:43.684+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:21:43.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:21:43.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:22:14.135+0000] {processor.py:157} INFO - Started process (PID=33489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:22:14.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:22:14.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:22:14.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:22:14.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:22:14.163+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:22:14.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:22:14.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:22:14.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:22:14.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T05:22:44.613+0000] {processor.py:157} INFO - Started process (PID=33514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:22:44.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:22:44.616+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:22:44.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:22:44.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:22:44.646+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:22:44.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:22:44.658+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:22:44.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:22:44.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:23:15.084+0000] {processor.py:157} INFO - Started process (PID=33539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:23:15.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:23:15.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:23:15.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:23:15.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:23:15.114+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:23:15.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:23:15.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:23:15.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:23:15.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:23:45.593+0000] {processor.py:157} INFO - Started process (PID=33564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:23:45.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:23:45.596+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:23:45.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:23:45.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:23:45.622+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:23:45.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:23:45.632+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:23:45.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:23:45.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T05:24:16.062+0000] {processor.py:157} INFO - Started process (PID=33589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:24:16.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:24:16.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:24:16.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:24:16.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:24:16.092+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:24:16.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:24:16.105+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:24:16.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:24:16.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:24:46.538+0000] {processor.py:157} INFO - Started process (PID=33614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:24:46.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:24:46.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:24:46.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:24:46.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:24:46.578+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:24:46.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:24:46.590+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:24:46.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:24:46.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T05:25:17.023+0000] {processor.py:157} INFO - Started process (PID=33639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:25:17.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:25:17.026+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:25:17.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:25:17.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:25:17.056+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:25:17.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:25:17.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:25:17.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:25:17.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:25:47.462+0000] {processor.py:157} INFO - Started process (PID=33664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:25:47.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:25:47.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:25:47.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:25:47.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:25:47.495+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:25:47.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:25:47.507+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:25:47.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:25:47.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:26:18.003+0000] {processor.py:157} INFO - Started process (PID=33689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:26:18.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:26:18.007+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:26:18.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:26:18.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:26:18.034+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:26:18.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:26:18.044+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:26:18.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:26:18.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:26:48.513+0000] {processor.py:157} INFO - Started process (PID=33714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:26:48.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:26:48.517+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:26:48.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:26:48.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:26:48.546+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:26:48.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:26:48.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:26:48.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:26:48.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T05:27:19.010+0000] {processor.py:157} INFO - Started process (PID=33739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:27:19.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:27:19.013+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:27:19.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:27:19.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:27:19.040+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:27:19.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:27:19.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:27:19.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:27:19.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:27:49.493+0000] {processor.py:157} INFO - Started process (PID=33764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:27:49.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:27:49.495+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:27:49.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:27:49.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:27:49.521+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:27:49.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:27:49.533+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:27:49.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:27:49.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T05:28:20.025+0000] {processor.py:157} INFO - Started process (PID=33789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:28:20.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:28:20.029+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:28:20.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:28:20.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:28:20.055+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:28:20.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:28:20.064+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:28:20.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:28:20.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:28:50.442+0000] {processor.py:157} INFO - Started process (PID=33813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:28:50.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:28:50.448+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:28:50.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:28:50.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:28:50.491+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:28:50.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:28:50.509+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:28:50.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:28:50.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-21T05:29:20.971+0000] {processor.py:157} INFO - Started process (PID=33838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:29:20.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:29:20.974+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:29:20.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:29:20.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:29:21.004+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:29:21.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:29:21.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:29:21.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:29:21.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T05:29:51.395+0000] {processor.py:157} INFO - Started process (PID=33864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:29:51.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:29:51.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:29:51.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:29:51.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:29:51.441+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:29:51.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:29:51.457+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:29:51.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:29:51.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T05:30:21.907+0000] {processor.py:157} INFO - Started process (PID=33889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:30:21.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:30:21.911+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:30:21.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:30:21.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:30:21.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:30:21.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:30:21.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:30:21.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:30:21.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:30:52.404+0000] {processor.py:157} INFO - Started process (PID=33914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:30:52.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:30:52.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:30:52.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:30:52.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:30:52.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:30:52.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:30:52.448+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:30:52.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:30:52.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:31:22.858+0000] {processor.py:157} INFO - Started process (PID=33939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:31:22.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:31:22.863+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:31:22.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:31:22.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:31:22.897+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:31:22.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:31:22.909+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:31:22.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:31:22.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T05:31:53.358+0000] {processor.py:157} INFO - Started process (PID=33964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:31:53.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:31:53.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:31:53.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:31:53.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:31:53.391+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:31:53.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:31:53.404+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:31:53.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:31:53.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T05:32:23.810+0000] {processor.py:157} INFO - Started process (PID=33989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:32:23.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:32:23.813+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:32:23.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:32:23.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:32:23.843+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:32:23.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:32:23.853+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:32:23.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:32:23.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:32:54.327+0000] {processor.py:157} INFO - Started process (PID=34014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:32:54.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:32:54.330+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:32:54.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:32:54.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:32:54.357+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:32:54.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:32:54.369+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:32:54.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:32:54.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T05:33:24.828+0000] {processor.py:157} INFO - Started process (PID=34039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:33:24.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:33:24.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:33:24.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:33:24.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:33:24.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:33:24.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:33:24.882+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:33:24.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:33:24.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T05:33:55.313+0000] {processor.py:157} INFO - Started process (PID=34064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:33:55.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:33:55.321+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:33:55.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:33:55.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:33:55.357+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:33:55.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:33:55.370+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:33:55.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:33:55.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T05:34:25.820+0000] {processor.py:157} INFO - Started process (PID=34089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:34:25.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:34:25.829+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:34:25.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:34:25.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:34:25.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:34:25.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:34:25.861+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:34:25.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:34:25.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T05:34:56.265+0000] {processor.py:157} INFO - Started process (PID=34114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:34:56.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:34:56.269+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:34:56.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:34:56.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:34:56.301+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:34:56.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:34:56.311+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:34:56.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:34:56.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T05:35:26.672+0000] {processor.py:157} INFO - Started process (PID=34139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:35:26.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:35:26.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:35:26.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:35:26.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:35:26.700+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:35:26.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:35:26.710+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:35:26.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:35:26.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T05:35:57.146+0000] {processor.py:157} INFO - Started process (PID=34164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:35:57.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:35:57.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:35:57.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:35:57.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:35:57.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:35:57.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:35:57.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:35:57.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:35:57.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T05:36:27.672+0000] {processor.py:157} INFO - Started process (PID=34189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:36:27.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:36:27.675+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:36:27.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:36:27.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:36:27.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:36:27.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:36:27.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:36:27.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:36:27.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:36:58.174+0000] {processor.py:157} INFO - Started process (PID=34214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:36:58.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:36:58.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:36:58.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:36:58.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:36:58.205+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:36:58.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:36:58.215+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:36:58.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:36:58.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:37:28.683+0000] {processor.py:157} INFO - Started process (PID=34239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:37:28.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:37:28.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:37:28.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:37:28.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:37:28.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:37:28.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:37:28.724+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:37:28.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:37:28.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:37:59.152+0000] {processor.py:157} INFO - Started process (PID=34264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:37:59.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:37:59.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:37:59.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:37:59.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:37:59.180+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:37:59.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:37:59.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:37:59.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:37:59.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:38:29.547+0000] {processor.py:157} INFO - Started process (PID=34289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:38:29.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:38:29.553+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:38:29.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:38:29.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:38:29.586+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:38:29.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:38:29.596+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:38:29.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:38:29.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T05:39:00.139+0000] {processor.py:157} INFO - Started process (PID=34314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:39:00.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:39:00.144+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:39:00.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:39:00.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:39:00.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:39:00.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:39:00.191+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:39:00.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:39:00.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T05:39:30.684+0000] {processor.py:157} INFO - Started process (PID=34339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:39:30.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:39:30.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:39:30.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:39:30.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:39:30.713+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:39:30.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:39:30.726+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:39:30.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:39:30.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:40:01.083+0000] {processor.py:157} INFO - Started process (PID=34364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:40:01.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:40:01.087+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:40:01.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:40:01.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:40:01.113+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:40:01.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:40:01.122+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:40:01.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:40:01.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:40:31.548+0000] {processor.py:157} INFO - Started process (PID=34389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:40:31.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:40:31.551+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:40:31.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:40:31.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:40:31.581+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:40:31.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:40:31.592+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:40:31.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:40:31.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T05:41:01.947+0000] {processor.py:157} INFO - Started process (PID=34414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:41:01.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:41:01.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:41:01.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:41:01.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:41:01.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:41:01.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:41:01.991+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:41:01.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:41:01.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:41:32.439+0000] {processor.py:157} INFO - Started process (PID=34439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:41:32.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:41:32.445+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:41:32.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:41:32.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:41:32.481+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:41:32.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:41:32.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:41:32.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:41:32.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T05:42:02.978+0000] {processor.py:157} INFO - Started process (PID=34464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:42:02.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:42:02.982+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:42:02.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:42:02.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:42:03.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:42:03.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:42:03.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:42:03.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:42:03.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:42:33.508+0000] {processor.py:157} INFO - Started process (PID=34489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:42:33.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:42:33.517+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:42:33.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:42:33.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:42:33.543+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:42:33.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:42:33.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:42:33.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:42:33.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:43:03.909+0000] {processor.py:157} INFO - Started process (PID=34514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:43:03.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:43:03.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:43:03.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:43:03.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:43:03.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:43:03.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:43:03.945+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:43:03.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:43:03.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T05:43:34.350+0000] {processor.py:157} INFO - Started process (PID=34539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:43:34.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:43:34.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:43:34.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:43:34.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:43:34.379+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:43:34.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:43:34.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:43:34.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:43:34.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:44:04.901+0000] {processor.py:157} INFO - Started process (PID=34564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:44:04.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:44:04.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:44:04.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:44:04.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:44:04.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:44:04.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:44:04.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:44:04.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:44:04.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T05:44:35.427+0000] {processor.py:157} INFO - Started process (PID=34589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:44:35.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:44:35.430+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:44:35.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:44:35.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:44:35.459+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:44:35.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:44:35.469+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:44:35.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:44:35.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:45:05.899+0000] {processor.py:157} INFO - Started process (PID=34614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:45:05.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:45:05.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:45:05.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:45:05.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:45:05.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:45:05.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:45:05.948+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:45:05.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:45:05.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T05:45:36.534+0000] {processor.py:157} INFO - Started process (PID=34639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:45:36.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:45:36.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:45:36.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:45:36.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:45:36.567+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:45:36.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:45:36.578+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:45:36.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:45:36.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:46:07.038+0000] {processor.py:157} INFO - Started process (PID=34664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:46:07.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:46:07.042+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:46:07.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:46:07.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:46:07.071+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:46:07.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:46:07.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:46:07.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:46:07.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:46:37.506+0000] {processor.py:157} INFO - Started process (PID=34689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:46:37.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:46:37.509+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:46:37.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:46:37.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:46:37.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:46:37.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:46:37.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:46:37.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:46:37.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:47:08.026+0000] {processor.py:157} INFO - Started process (PID=34714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:47:08.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:47:08.029+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:47:08.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:47:08.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:47:08.056+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:47:08.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:47:08.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:47:08.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:47:08.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:47:38.469+0000] {processor.py:157} INFO - Started process (PID=34739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:47:38.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:47:38.472+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:47:38.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:47:38.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:47:38.500+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:47:38.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:47:38.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:47:38.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:47:38.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:48:08.963+0000] {processor.py:157} INFO - Started process (PID=34764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:48:08.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:48:08.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:48:08.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:48:08.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:48:08.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:48:08.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:48:09.009+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:48:09.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:48:09.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T05:48:39.445+0000] {processor.py:157} INFO - Started process (PID=34789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:48:39.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:48:39.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:48:39.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:48:39.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:48:39.487+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:48:39.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:48:39.499+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:48:39.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:48:39.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T05:49:09.939+0000] {processor.py:157} INFO - Started process (PID=34814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:49:09.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:49:09.941+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:49:09.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:49:09.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:49:09.973+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:49:09.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:49:09.981+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:49:09.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:49:09.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:49:40.382+0000] {processor.py:157} INFO - Started process (PID=34839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:49:40.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:49:40.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:49:40.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:49:40.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:49:40.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:49:40.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:49:40.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:49:40.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:49:40.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T05:50:10.749+0000] {processor.py:157} INFO - Started process (PID=34864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:50:10.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:50:10.752+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:50:10.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:50:10.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:50:10.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:50:10.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:50:10.789+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:50:10.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:50:10.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T05:50:41.256+0000] {processor.py:157} INFO - Started process (PID=34889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:50:41.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:50:41.260+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:50:41.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:50:41.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:50:41.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:50:41.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:50:41.302+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:50:41.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:50:41.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T05:51:11.678+0000] {processor.py:157} INFO - Started process (PID=34914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:51:11.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:51:11.681+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:51:11.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:51:11.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:51:11.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:51:11.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:51:11.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:51:11.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:51:11.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T05:51:42.208+0000] {processor.py:157} INFO - Started process (PID=34939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:51:42.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:51:42.211+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:51:42.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:51:42.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:51:42.237+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:51:42.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:51:42.250+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:51:42.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:51:42.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:52:12.610+0000] {processor.py:157} INFO - Started process (PID=34964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:52:12.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:52:12.613+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:52:12.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:52:12.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:52:12.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:52:12.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:52:12.647+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:52:12.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:52:12.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T05:52:43.077+0000] {processor.py:157} INFO - Started process (PID=34989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:52:43.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:52:43.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:52:43.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:52:43.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:52:43.104+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:52:43.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:52:43.119+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:52:43.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:52:43.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:53:13.537+0000] {processor.py:157} INFO - Started process (PID=35014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:53:13.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:53:13.540+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:53:13.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:53:13.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:53:13.578+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:53:13.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:53:13.590+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:53:13.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:53:13.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T05:53:44.050+0000] {processor.py:157} INFO - Started process (PID=35039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:53:44.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:53:44.055+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:53:44.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:53:44.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:53:44.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:53:44.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:53:44.096+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:53:44.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:53:44.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T05:54:14.549+0000] {processor.py:157} INFO - Started process (PID=35064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:54:14.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:54:14.551+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:54:14.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:54:14.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:54:14.581+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:54:14.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:54:14.592+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:54:14.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:54:14.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T05:54:45.049+0000] {processor.py:157} INFO - Started process (PID=35089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:54:45.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:54:45.051+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:54:45.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:54:45.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:54:45.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:54:45.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:54:45.091+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:54:45.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:54:45.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T05:55:15.480+0000] {processor.py:157} INFO - Started process (PID=35114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:55:15.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:55:15.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:55:15.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:55:15.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:55:15.507+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:55:15.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:55:15.518+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:55:15.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:55:15.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:55:45.945+0000] {processor.py:157} INFO - Started process (PID=35139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:55:45.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:55:45.948+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:55:45.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:55:45.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:55:45.978+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:55:45.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:55:45.990+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:55:45.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:55:45.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T05:56:16.473+0000] {processor.py:157} INFO - Started process (PID=35164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:56:16.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:56:16.477+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:56:16.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:56:16.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:56:16.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:56:16.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:56:16.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:56:16.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:56:16.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:56:46.925+0000] {processor.py:157} INFO - Started process (PID=35189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:56:46.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:56:46.928+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:56:46.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:56:46.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:56:46.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:56:46.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:56:46.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:56:46.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:56:46.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T05:57:17.413+0000] {processor.py:157} INFO - Started process (PID=35214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:57:17.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:57:17.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:57:17.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:57:17.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:57:17.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:57:17.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:57:17.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:57:17.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:57:17.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T05:57:47.930+0000] {processor.py:157} INFO - Started process (PID=35239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:57:47.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:57:47.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:57:47.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:57:47.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:57:47.971+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:57:47.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:57:47.985+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:57:47.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:57:47.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T05:58:18.413+0000] {processor.py:157} INFO - Started process (PID=35264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:58:18.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:58:18.416+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:58:18.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:58:18.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:58:18.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:58:18.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:58:18.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:58:18.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:58:18.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T05:58:48.895+0000] {processor.py:157} INFO - Started process (PID=35289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:58:48.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:58:48.897+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:58:48.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:58:48.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:58:48.919+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:58:48.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:58:48.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:58:48.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:58:48.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-21T05:59:19.451+0000] {processor.py:157} INFO - Started process (PID=35313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:59:19.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T05:59:19.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:59:19.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:59:19.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T05:59:19.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:59:19.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T05:59:19.517+0000] {logging_mixin.py:151} INFO - [2024-07-21T05:59:19.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T05:59:19.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-21T06:09:56.001+0000] {processor.py:157} INFO - Started process (PID=35339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:09:56.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T06:09:56.003+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:09:56.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:09:56.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:09:56.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:09:56.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T06:09:56.047+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:09:56.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T06:09:56.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T06:10:26.654+0000] {processor.py:157} INFO - Started process (PID=35366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:10:26.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T06:10:26.659+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:10:26.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:10:26.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:10:26.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:10:26.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T06:10:26.741+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:10:26.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T06:10:26.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-21T06:26:02.097+0000] {processor.py:157} INFO - Started process (PID=35392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:26:02.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T06:26:02.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:26:02.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:26:02.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:26:02.165+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:26:02.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T06:26:02.179+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:26:02.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T06:26:02.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-21T06:43:54.731+0000] {processor.py:157} INFO - Started process (PID=35417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:43:54.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T06:43:54.739+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:43:54.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:43:54.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:43:54.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:43:54.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T06:43:54.817+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:43:54.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T06:43:54.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-21T06:44:25.462+0000] {processor.py:157} INFO - Started process (PID=35443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:44:25.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T06:44:25.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:44:25.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:44:25.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:44:25.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:44:25.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T06:44:25.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:44:25.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T06:44:25.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-21T06:44:55.974+0000] {processor.py:157} INFO - Started process (PID=35468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:44:55.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T06:44:55.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:44:55.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:44:55.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:44:56.002+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:44:56.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T06:44:56.011+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:44:56.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T06:44:56.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T06:45:26.481+0000] {processor.py:157} INFO - Started process (PID=35493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:45:26.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T06:45:26.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:45:26.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:45:26.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T06:45:26.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:45:26.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T06:45:26.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T06:45:26.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T06:45:26.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:02:10.673+0000] {processor.py:157} INFO - Started process (PID=35518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:02:10.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:02:10.680+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:02:10.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:02:10.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:02:10.741+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:02:10.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:02:10.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:02:10.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:02:10.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-21T07:02:41.302+0000] {processor.py:157} INFO - Started process (PID=35543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:02:41.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:02:41.306+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:02:41.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:02:41.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:02:41.348+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:02:41.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:02:41.362+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:02:41.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:02:41.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T07:10:58.765+0000] {processor.py:157} INFO - Started process (PID=35570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:10:58.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:10:58.778+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:10:58.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:10:58.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:10:58.834+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:10:58.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:10:58.849+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:10:58.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:10:58.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-21T07:11:29.359+0000] {processor.py:157} INFO - Started process (PID=35595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:11:29.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:11:29.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:11:29.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:11:29.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:11:29.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:11:29.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:11:29.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:11:29.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:11:29.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-21T07:11:59.823+0000] {processor.py:157} INFO - Started process (PID=35620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:11:59.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:11:59.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:11:59.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:11:59.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:11:59.849+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:11:59.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:11:59.859+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:11:59.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:11:59.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T07:12:30.299+0000] {processor.py:157} INFO - Started process (PID=35645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:12:30.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:12:30.303+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:12:30.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:12:30.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:12:30.330+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:12:30.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:12:30.339+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:12:30.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:12:30.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:13:00.779+0000] {processor.py:157} INFO - Started process (PID=35670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:13:00.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:13:00.781+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:13:00.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:13:00.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:13:00.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:13:00.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:13:00.809+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:13:00.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:13:00.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-21T07:13:31.277+0000] {processor.py:157} INFO - Started process (PID=35695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:13:31.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:13:31.280+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:13:31.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:13:31.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:13:31.306+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:13:31.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:13:31.320+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:13:31.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:13:31.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:14:01.747+0000] {processor.py:157} INFO - Started process (PID=35720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:14:01.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:14:01.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:14:01.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:14:01.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:14:01.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:14:01.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:14:01.793+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:14:01.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:14:01.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T07:14:32.210+0000] {processor.py:157} INFO - Started process (PID=35745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:14:32.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:14:32.215+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:14:32.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:14:32.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:14:32.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:14:32.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:14:32.252+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:14:32.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:14:32.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:15:02.748+0000] {processor.py:157} INFO - Started process (PID=35770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:15:02.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:15:02.752+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:15:02.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:15:02.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:15:02.793+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:15:02.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:15:02.809+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:15:02.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:15:02.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T07:15:33.264+0000] {processor.py:157} INFO - Started process (PID=35795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:15:33.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:15:33.268+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:15:33.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:15:33.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:15:33.294+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:15:33.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:15:33.304+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:15:33.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:15:33.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:16:03.798+0000] {processor.py:157} INFO - Started process (PID=35820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:16:03.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:16:03.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:16:03.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:16:03.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:16:03.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:16:03.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:16:03.834+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:16:03.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:16:03.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T07:16:34.242+0000] {processor.py:157} INFO - Started process (PID=35845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:16:34.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:16:34.246+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:16:34.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:16:34.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:16:34.281+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:16:34.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:16:34.294+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:16:34.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:16:34.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T07:17:04.800+0000] {processor.py:157} INFO - Started process (PID=35870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:17:04.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:17:04.804+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:17:04.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:17:04.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:17:04.831+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:17:04.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:17:04.842+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:17:04.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:17:04.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T07:17:35.225+0000] {processor.py:157} INFO - Started process (PID=35895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:17:35.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:17:35.228+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:17:35.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:17:35.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:17:35.253+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:17:35.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:17:35.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:17:35.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:17:35.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T07:18:05.750+0000] {processor.py:157} INFO - Started process (PID=35920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:18:05.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:18:05.754+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:18:05.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:18:05.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:18:05.781+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:18:05.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:18:05.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:18:05.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:18:05.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T07:18:36.128+0000] {processor.py:157} INFO - Started process (PID=35945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:18:36.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:18:36.137+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:18:36.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:18:36.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:18:36.159+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:18:36.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:18:36.169+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:18:36.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:18:36.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:19:06.684+0000] {processor.py:157} INFO - Started process (PID=35970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:19:06.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:19:06.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:19:06.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:19:06.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:19:06.712+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:19:06.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:19:06.722+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:19:06.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:19:06.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:19:37.163+0000] {processor.py:157} INFO - Started process (PID=35995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:19:37.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:19:37.166+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:19:37.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:19:37.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:19:37.194+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:19:37.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:19:37.204+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:19:37.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:19:37.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:20:07.616+0000] {processor.py:157} INFO - Started process (PID=36020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:20:07.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:20:07.620+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:20:07.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:20:07.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:20:07.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:20:07.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:20:07.671+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:20:07.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:20:07.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T07:20:38.100+0000] {processor.py:157} INFO - Started process (PID=36045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:20:38.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:20:38.104+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:20:38.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:20:38.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:20:38.129+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:20:38.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:20:38.139+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:20:38.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:20:38.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:21:08.636+0000] {processor.py:157} INFO - Started process (PID=36070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:21:08.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:21:08.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:21:08.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:21:08.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:21:08.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:21:08.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:21:08.677+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:21:08.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:21:08.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:21:39.155+0000] {processor.py:157} INFO - Started process (PID=36094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:21:39.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:21:39.159+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:21:39.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:21:39.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:21:39.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:21:39.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:21:39.194+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:21:39.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:21:39.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:22:09.602+0000] {processor.py:157} INFO - Started process (PID=36120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:22:09.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:22:09.605+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:22:09.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:22:09.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:22:09.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:22:09.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:22:09.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:22:09.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:22:09.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T07:22:40.040+0000] {processor.py:157} INFO - Started process (PID=36145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:22:40.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:22:40.043+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:22:40.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:22:40.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:22:40.071+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:22:40.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:22:40.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:22:40.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:22:40.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:23:10.416+0000] {processor.py:157} INFO - Started process (PID=36170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:23:10.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:23:10.418+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:23:10.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:23:10.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:23:10.446+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:23:10.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:23:10.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:23:10.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:23:10.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:23:40.890+0000] {processor.py:157} INFO - Started process (PID=36195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:23:40.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:23:40.894+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:23:40.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:23:40.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:23:40.920+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:23:40.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:23:40.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:23:40.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:23:40.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T07:24:11.370+0000] {processor.py:157} INFO - Started process (PID=36220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:24:11.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:24:11.373+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:24:11.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:24:11.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:24:11.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:24:11.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:24:11.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:24:11.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:24:11.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T07:24:41.865+0000] {processor.py:157} INFO - Started process (PID=36245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:24:41.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:24:41.872+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:24:41.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:24:41.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:24:41.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:24:41.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:24:41.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:24:41.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:24:41.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T07:25:12.341+0000] {processor.py:157} INFO - Started process (PID=36270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:25:12.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:25:12.344+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:25:12.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:25:12.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:25:12.371+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:25:12.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:25:12.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:25:12.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:25:12.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T07:25:42.843+0000] {processor.py:157} INFO - Started process (PID=36295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:25:42.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:25:42.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:25:42.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:25:42.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:25:42.873+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:25:42.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:25:42.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:25:42.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:25:42.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T07:26:13.301+0000] {processor.py:157} INFO - Started process (PID=36320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:26:13.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:26:13.305+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:26:13.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:26:13.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:26:13.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:26:13.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:26:13.346+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:26:13.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:26:13.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T07:26:43.804+0000] {processor.py:157} INFO - Started process (PID=36345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:26:43.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:26:43.808+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:26:43.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:26:43.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:26:43.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:26:43.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:26:43.844+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:26:43.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:26:43.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:27:14.317+0000] {processor.py:157} INFO - Started process (PID=36370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:27:14.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:27:14.320+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:27:14.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:27:14.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:27:14.347+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:27:14.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:27:14.357+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:27:14.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:27:14.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T07:27:44.767+0000] {processor.py:157} INFO - Started process (PID=36395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:27:44.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:27:44.769+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:27:44.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:27:44.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:27:44.794+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:27:44.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:27:44.805+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:27:44.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:27:44.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T07:28:15.276+0000] {processor.py:157} INFO - Started process (PID=36420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:28:15.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:28:15.284+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:28:15.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:28:15.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:28:15.311+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:28:15.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:28:15.321+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:28:15.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:28:15.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T07:28:45.702+0000] {processor.py:157} INFO - Started process (PID=36445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:28:45.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:28:45.706+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:28:45.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:28:45.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:28:45.740+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:28:45.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:28:45.752+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:28:45.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:28:45.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T07:29:16.220+0000] {processor.py:157} INFO - Started process (PID=36470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:29:16.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:29:16.223+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:29:16.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:29:16.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:29:16.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:29:16.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:29:16.263+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:29:16.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:29:16.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T07:29:46.612+0000] {processor.py:157} INFO - Started process (PID=36495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:29:46.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:29:46.614+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:29:46.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:29:46.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:29:46.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:29:46.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:29:46.647+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:29:46.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:29:46.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T07:30:17.026+0000] {processor.py:157} INFO - Started process (PID=36520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:30:17.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:30:17.029+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:30:17.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:30:17.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:30:17.055+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:30:17.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:30:17.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:30:17.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:30:17.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T07:30:47.501+0000] {processor.py:157} INFO - Started process (PID=36545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:30:47.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:30:47.503+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:30:47.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:30:47.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:30:47.530+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:30:47.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:30:47.540+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:30:47.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:30:47.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:31:17.999+0000] {processor.py:157} INFO - Started process (PID=36570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:31:18.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:31:18.003+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:31:18.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:31:18.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:31:18.032+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:31:18.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:31:18.042+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:31:18.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:31:18.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T07:31:48.480+0000] {processor.py:157} INFO - Started process (PID=36595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:31:48.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:31:48.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:31:48.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:31:48.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:31:48.509+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:31:48.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:31:48.518+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:31:48.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:31:48.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:32:18.902+0000] {processor.py:157} INFO - Started process (PID=36620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:32:18.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:32:18.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:32:18.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:32:18.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:32:18.933+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:32:18.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:32:18.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:32:18.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:32:18.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:32:49.356+0000] {processor.py:157} INFO - Started process (PID=36645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:32:49.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:32:49.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:32:49.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:32:49.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:32:49.396+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:32:49.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:32:49.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:32:49.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:32:49.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T07:33:19.835+0000] {processor.py:157} INFO - Started process (PID=36670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:33:19.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:33:19.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:33:19.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:33:19.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:33:19.859+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:33:19.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:33:19.869+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:33:19.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:33:19.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T07:33:50.364+0000] {processor.py:157} INFO - Started process (PID=36695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:33:50.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:33:50.367+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:33:50.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:33:50.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:33:50.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:33:50.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:33:50.414+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:33:50.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:33:50.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T07:34:20.895+0000] {processor.py:157} INFO - Started process (PID=36720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:34:20.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:34:20.900+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:34:20.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:34:20.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:34:20.927+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:34:20.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:34:20.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:34:20.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:34:20.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:34:51.336+0000] {processor.py:157} INFO - Started process (PID=36745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:34:51.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:34:51.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:34:51.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:34:51.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:34:51.370+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:34:51.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:34:51.383+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:34:51.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:34:51.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T07:35:21.885+0000] {processor.py:157} INFO - Started process (PID=36770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:35:21.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:35:21.890+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:35:21.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:35:21.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:35:21.928+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:35:21.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:35:21.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:35:21.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:35:21.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T07:35:52.374+0000] {processor.py:157} INFO - Started process (PID=36795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:35:52.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:35:52.380+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:35:52.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:35:52.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:35:52.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:35:52.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:35:52.420+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:35:52.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:35:52.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T07:36:22.872+0000] {processor.py:157} INFO - Started process (PID=36820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:36:22.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:36:22.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:36:22.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:36:22.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:36:22.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:36:22.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:36:22.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:36:22.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:36:22.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T07:36:53.352+0000] {processor.py:157} INFO - Started process (PID=36845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:36:53.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:36:53.354+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:36:53.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:36:53.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:36:53.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:36:53.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:36:53.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:36:53.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:36:53.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T07:37:23.859+0000] {processor.py:157} INFO - Started process (PID=36870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:37:23.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:37:23.864+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:37:23.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:37:23.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:37:23.915+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:37:23.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:37:23.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:37:23.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:37:23.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-21T07:37:54.360+0000] {processor.py:157} INFO - Started process (PID=36895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:37:54.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:37:54.362+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:37:54.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:37:54.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:37:54.393+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:37:54.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:37:54.406+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:37:54.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:37:54.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T07:38:24.824+0000] {processor.py:157} INFO - Started process (PID=36920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:38:24.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:38:24.827+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:38:24.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:38:24.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:38:24.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:38:24.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:38:24.865+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:38:24.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:38:24.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:38:55.278+0000] {processor.py:157} INFO - Started process (PID=36945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:38:55.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:38:55.282+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:38:55.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:38:55.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:38:55.308+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:38:55.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:38:55.318+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:38:55.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:38:55.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:39:25.716+0000] {processor.py:157} INFO - Started process (PID=36970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:39:25.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:39:25.724+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:39:25.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:39:25.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:39:25.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:39:25.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:39:25.771+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:39:25.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:39:25.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T07:39:56.209+0000] {processor.py:157} INFO - Started process (PID=36995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:39:56.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:39:56.212+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:39:56.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:39:56.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:39:56.238+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:39:56.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:39:56.250+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:39:56.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:39:56.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:40:26.629+0000] {processor.py:157} INFO - Started process (PID=37020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:40:26.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:40:26.631+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:40:26.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:40:26.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:40:26.658+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:40:26.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:40:26.669+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:40:26.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:40:26.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:40:57.079+0000] {processor.py:157} INFO - Started process (PID=37045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:40:57.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:40:57.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:40:57.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:40:57.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:40:57.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:40:57.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:40:57.122+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:40:57.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:40:57.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T07:41:27.491+0000] {processor.py:157} INFO - Started process (PID=37070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:41:27.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:41:27.494+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:41:27.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:41:27.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:41:27.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:41:27.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:41:27.534+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:41:27.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:41:27.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T07:41:57.886+0000] {processor.py:157} INFO - Started process (PID=37095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:41:57.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:41:57.889+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:41:57.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:41:57.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:41:57.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:41:57.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:41:57.924+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:41:57.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:41:57.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:42:28.415+0000] {processor.py:157} INFO - Started process (PID=37120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:42:28.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:42:28.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:42:28.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:42:28.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:42:28.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:42:28.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:42:28.460+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:42:28.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:42:28.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T07:42:58.923+0000] {processor.py:157} INFO - Started process (PID=37145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:42:58.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:42:58.926+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:42:58.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:42:58.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:42:58.952+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:42:58.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:42:58.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:42:58.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:42:58.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:43:29.407+0000] {processor.py:157} INFO - Started process (PID=37170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:43:29.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:43:29.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:43:29.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:43:29.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:43:29.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:43:29.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:43:29.436+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:43:29.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:43:29.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-21T07:43:59.916+0000] {processor.py:157} INFO - Started process (PID=37195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:43:59.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:43:59.919+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:43:59.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:43:59.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:43:59.946+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:43:59.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:43:59.956+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:43:59.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:43:59.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:44:30.379+0000] {processor.py:157} INFO - Started process (PID=37220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:44:30.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:44:30.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:44:30.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:44:30.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:44:30.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:44:30.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:44:30.432+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:44:30.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:44:30.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T07:45:00.922+0000] {processor.py:157} INFO - Started process (PID=37245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:45:00.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:45:00.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:45:00.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:45:00.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:45:00.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:45:00.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:45:00.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:45:00.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:45:00.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T07:45:31.415+0000] {processor.py:157} INFO - Started process (PID=37270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:45:31.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:45:31.418+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:45:31.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:45:31.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:45:31.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:45:31.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:45:31.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:45:31.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:45:31.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T07:46:01.948+0000] {processor.py:157} INFO - Started process (PID=37295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:46:01.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:46:01.952+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:46:01.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:46:01.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:46:01.982+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:46:01.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:46:01.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:46:01.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:46:02.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T07:46:32.397+0000] {processor.py:157} INFO - Started process (PID=37320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:46:32.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:46:32.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:46:32.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:46:32.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:46:32.434+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:46:32.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:46:32.445+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:46:32.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:46:32.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T07:47:02.788+0000] {processor.py:157} INFO - Started process (PID=37345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:47:02.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:47:02.791+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:47:02.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:47:02.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:47:02.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:47:02.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:47:02.836+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:47:02.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:47:02.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T07:47:33.346+0000] {processor.py:157} INFO - Started process (PID=37370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:47:33.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:47:33.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:47:33.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:47:33.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:47:33.382+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:47:33.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:47:33.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:47:33.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:47:33.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T07:48:03.816+0000] {processor.py:157} INFO - Started process (PID=37395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:48:03.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:48:03.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:48:03.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:48:03.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:48:03.848+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:48:03.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:48:03.858+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:48:03.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:48:03.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T07:48:34.319+0000] {processor.py:157} INFO - Started process (PID=37420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:48:34.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:48:34.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:48:34.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:48:34.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:48:34.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:48:34.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:48:34.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:48:34.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:48:34.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T07:49:04.718+0000] {processor.py:157} INFO - Started process (PID=37445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:49:04.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:49:04.722+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:49:04.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:49:04.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:49:04.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:49:04.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:49:04.758+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:49:04.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:49:04.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T07:49:35.271+0000] {processor.py:157} INFO - Started process (PID=37470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:49:35.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:49:35.276+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:49:35.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:49:35.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:49:35.302+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:49:35.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:49:35.312+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:49:35.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:49:35.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:50:05.749+0000] {processor.py:157} INFO - Started process (PID=37495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:50:05.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:50:05.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:50:05.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:50:05.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:50:05.777+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:50:05.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:50:05.789+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:50:05.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:50:05.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T07:50:36.186+0000] {processor.py:157} INFO - Started process (PID=37520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:50:36.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:50:36.189+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:50:36.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:50:36.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:50:36.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:50:36.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:50:36.228+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:50:36.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:50:36.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T07:51:06.679+0000] {processor.py:157} INFO - Started process (PID=37545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:51:06.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:51:06.682+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:51:06.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:51:06.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:51:06.705+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:51:06.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:51:06.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:51:06.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:51:06.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T07:51:37.084+0000] {processor.py:157} INFO - Started process (PID=37570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:51:37.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:51:37.089+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:51:37.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:51:37.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:51:37.125+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:51:37.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:51:37.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:51:37.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:51:37.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T07:52:07.555+0000] {processor.py:157} INFO - Started process (PID=37595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:52:07.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:52:07.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:52:07.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:52:07.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:52:07.586+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:52:07.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:52:07.598+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:52:07.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:52:07.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:52:38.039+0000] {processor.py:157} INFO - Started process (PID=37620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:52:38.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:52:38.044+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:52:38.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:52:38.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:52:38.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:52:38.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:52:38.083+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:52:38.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:52:38.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T07:53:08.529+0000] {processor.py:157} INFO - Started process (PID=37645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:53:08.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:53:08.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:53:08.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:53:08.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:53:08.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:53:08.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:53:08.574+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:53:08.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:53:08.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T07:53:38.929+0000] {processor.py:157} INFO - Started process (PID=37670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:53:38.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:53:38.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:53:38.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:53:38.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:53:38.952+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:53:38.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:53:38.961+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:53:38.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:53:38.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T07:54:09.415+0000] {processor.py:157} INFO - Started process (PID=37695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:54:09.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:54:09.418+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:54:09.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:54:09.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:54:09.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:54:09.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:54:09.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:54:09.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:54:09.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:54:39.873+0000] {processor.py:157} INFO - Started process (PID=37720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:54:39.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:54:39.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:54:39.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:54:39.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:54:39.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:54:39.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:54:39.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:54:39.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:54:39.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T07:55:10.336+0000] {processor.py:157} INFO - Started process (PID=37745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:55:10.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:55:10.340+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:55:10.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:55:10.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:55:10.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:55:10.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:55:10.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:55:10.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:55:10.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T07:55:40.875+0000] {processor.py:157} INFO - Started process (PID=37770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:55:40.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:55:40.878+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:55:40.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:55:40.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:55:40.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:55:40.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:55:40.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:55:40.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:55:40.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T07:56:11.390+0000] {processor.py:157} INFO - Started process (PID=37795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:56:11.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:56:11.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:56:11.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:56:11.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:56:11.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:56:11.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:56:11.433+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:56:11.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:56:11.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T07:56:41.820+0000] {processor.py:157} INFO - Started process (PID=37820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:56:41.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:56:41.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:56:41.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:56:41.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:56:41.853+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:56:41.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:56:41.863+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:56:41.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:56:41.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T07:57:12.211+0000] {processor.py:157} INFO - Started process (PID=37845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:57:12.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:57:12.214+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:57:12.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:57:12.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:57:12.240+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:57:12.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:57:12.249+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:57:12.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:57:12.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T07:57:42.711+0000] {processor.py:157} INFO - Started process (PID=37870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:57:42.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:57:42.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:57:42.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:57:42.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:57:42.750+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:57:42.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:57:42.762+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:57:42.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:57:42.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T07:58:13.148+0000] {processor.py:157} INFO - Started process (PID=37895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:58:13.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:58:13.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:58:13.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:58:13.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:58:13.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:58:13.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:58:13.190+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:58:13.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:58:13.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:58:43.643+0000] {processor.py:157} INFO - Started process (PID=37920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:58:43.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:58:43.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:58:43.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:58:43.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:58:43.681+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:58:43.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:58:43.693+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:58:43.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:58:43.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T07:59:14.156+0000] {processor.py:157} INFO - Started process (PID=37945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:59:14.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:59:14.159+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:59:14.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:59:14.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:59:14.185+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:59:14.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:59:14.195+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:59:14.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:59:14.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T07:59:44.652+0000] {processor.py:157} INFO - Started process (PID=37970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:59:44.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T07:59:44.656+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:59:44.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:59:44.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T07:59:44.684+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:59:44.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T07:59:44.695+0000] {logging_mixin.py:151} INFO - [2024-07-21T07:59:44.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T07:59:44.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:00:15.134+0000] {processor.py:157} INFO - Started process (PID=37995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:00:15.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:00:15.140+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:00:15.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:00:15.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:00:15.165+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:00:15.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:00:15.175+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:00:15.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:00:15.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:00:45.671+0000] {processor.py:157} INFO - Started process (PID=38020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:00:45.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:00:45.685+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:00:45.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:00:45.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:00:45.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:00:45.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:00:45.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:00:45.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:00:45.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-21T08:16:46.448+0000] {processor.py:157} INFO - Started process (PID=38045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:16:46.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:16:46.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:16:46.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:16:46.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:16:46.500+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:16:46.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:16:46.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:16:46.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:16:46.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-21T08:17:17.096+0000] {processor.py:157} INFO - Started process (PID=38072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:17:17.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:17:17.099+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:17:17.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:17:17.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:17:17.132+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:17:17.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:17:17.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:17:17.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:17:17.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T08:17:47.540+0000] {processor.py:157} INFO - Started process (PID=38097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:17:47.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:17:47.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:17:47.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:17:47.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:17:47.567+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:17:47.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:17:47.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:17:47.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:17:47.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T08:18:17.961+0000] {processor.py:157} INFO - Started process (PID=38122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:18:17.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:18:17.964+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:18:17.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:18:17.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:18:17.989+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:18:17.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:18:18.001+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:18:18.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:18:18.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:18:48.389+0000] {processor.py:157} INFO - Started process (PID=38147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:18:48.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:18:48.392+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:18:48.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:18:48.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:18:48.418+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:18:48.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:18:48.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:18:48.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:18:48.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:19:18.811+0000] {processor.py:157} INFO - Started process (PID=38172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:19:18.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:19:18.815+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:19:18.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:19:18.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:19:18.839+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:19:18.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:19:18.851+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:19:18.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:19:18.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:19:49.247+0000] {processor.py:157} INFO - Started process (PID=38197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:19:49.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:19:49.252+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:19:49.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:19:49.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:19:49.278+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:19:49.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:19:49.287+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:19:49.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:19:49.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T08:20:19.694+0000] {processor.py:157} INFO - Started process (PID=38222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:20:19.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:20:19.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:20:19.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:20:19.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:20:19.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:20:19.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:20:19.740+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:20:19.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:20:19.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T08:20:50.127+0000] {processor.py:157} INFO - Started process (PID=38247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:20:50.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:20:50.130+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:20:50.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:20:50.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:20:50.156+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:20:50.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:20:50.168+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:20:50.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:20:50.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:21:20.561+0000] {processor.py:157} INFO - Started process (PID=38272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:21:20.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:21:20.565+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:21:20.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:21:20.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:21:20.594+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:21:20.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:21:20.604+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:21:20.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:21:20.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T08:21:50.985+0000] {processor.py:157} INFO - Started process (PID=38297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:21:50.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:21:50.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:21:50.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:21:51.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:21:51.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:21:51.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:21:51.029+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:21:51.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:21:51.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T08:22:21.475+0000] {processor.py:157} INFO - Started process (PID=38322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:22:21.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:22:21.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:22:21.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:22:21.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:22:21.517+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:22:21.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:22:21.530+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:22:21.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:22:21.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T08:22:52.022+0000] {processor.py:157} INFO - Started process (PID=38347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:22:52.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:22:52.025+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:22:52.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:22:52.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:22:52.055+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:22:52.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:22:52.064+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:22:52.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:22:52.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T08:23:22.434+0000] {processor.py:157} INFO - Started process (PID=38372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:23:22.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:23:22.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:23:22.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:23:22.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:23:22.466+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:23:22.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:23:22.477+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:23:22.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:23:22.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:23:52.891+0000] {processor.py:157} INFO - Started process (PID=38397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:23:52.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:23:52.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:23:52.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:23:52.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:23:52.923+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:23:52.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:23:52.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:23:52.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:23:52.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T08:24:23.352+0000] {processor.py:157} INFO - Started process (PID=38422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:24:23.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:24:23.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:24:23.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:24:23.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:24:23.382+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:24:23.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:24:23.393+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:24:23.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:24:23.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:24:53.839+0000] {processor.py:157} INFO - Started process (PID=38447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:24:53.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:24:53.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:24:53.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:24:53.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:24:53.868+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:24:53.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:24:53.878+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:24:53.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:24:53.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:25:24.273+0000] {processor.py:157} INFO - Started process (PID=38472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:25:24.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:25:24.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:25:24.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:25:24.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:25:24.300+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:25:24.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:25:24.310+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:25:24.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:25:24.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T08:25:54.759+0000] {processor.py:157} INFO - Started process (PID=38497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:25:54.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:25:54.763+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:25:54.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:25:54.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:25:54.786+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:25:54.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:25:54.796+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:25:54.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:25:54.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T08:26:25.232+0000] {processor.py:157} INFO - Started process (PID=38522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:26:25.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:26:25.235+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:26:25.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:26:25.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:26:25.262+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:26:25.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:26:25.274+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:26:25.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:26:25.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T08:26:55.644+0000] {processor.py:157} INFO - Started process (PID=38547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:26:55.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:26:55.647+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:26:55.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:26:55.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:26:55.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:26:55.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:26:55.683+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:26:55.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:26:55.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T08:27:26.123+0000] {processor.py:157} INFO - Started process (PID=38572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:27:26.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:27:26.127+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:27:26.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:27:26.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:27:26.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:27:26.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:27:26.160+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:27:26.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:27:26.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T08:27:56.589+0000] {processor.py:157} INFO - Started process (PID=38597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:27:56.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:27:56.593+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:27:56.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:27:56.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:27:56.625+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:27:56.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:27:56.635+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:27:56.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:27:56.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T08:28:27.071+0000] {processor.py:157} INFO - Started process (PID=38622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:28:27.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:28:27.073+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:28:27.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:28:27.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:28:27.101+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:28:27.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:28:27.113+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:28:27.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:28:27.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:28:57.473+0000] {processor.py:157} INFO - Started process (PID=38647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:28:57.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:28:57.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:28:57.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:28:57.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:28:57.499+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:28:57.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:28:57.509+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:28:57.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:28:57.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T08:29:27.867+0000] {processor.py:157} INFO - Started process (PID=38672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:29:27.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:29:27.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:29:27.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:29:27.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:29:27.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:29:27.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:29:27.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:29:27.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:29:27.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:29:58.384+0000] {processor.py:157} INFO - Started process (PID=38697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:29:58.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:29:58.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:29:58.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:29:58.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:29:58.418+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:29:58.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:29:58.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:29:58.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:29:58.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:30:28.891+0000] {processor.py:157} INFO - Started process (PID=38722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:30:28.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:30:28.895+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:30:28.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:30:28.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:30:28.927+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:30:28.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:30:28.938+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:30:28.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:30:28.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T08:30:59.375+0000] {processor.py:157} INFO - Started process (PID=38747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:30:59.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:30:59.379+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:30:59.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:30:59.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:30:59.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:30:59.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:30:59.420+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:30:59.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:30:59.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T08:31:29.850+0000] {processor.py:157} INFO - Started process (PID=38772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:31:29.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:31:29.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:31:29.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:31:29.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:31:29.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:31:29.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:31:29.892+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:31:29.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:31:29.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:32:00.146+0000] {processor.py:157} INFO - Started process (PID=38797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:32:00.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:32:00.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:32:00.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:32:00.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:32:00.185+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:32:00.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:32:00.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:32:00.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:32:00.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T08:32:30.594+0000] {processor.py:157} INFO - Started process (PID=38822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:32:30.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:32:30.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:32:30.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:32:30.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:32:30.624+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:32:30.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:32:30.636+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:32:30.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:32:30.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:33:01.093+0000] {processor.py:157} INFO - Started process (PID=38847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:33:01.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:33:01.097+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:33:01.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:33:01.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:33:01.124+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:33:01.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:33:01.136+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:33:01.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:33:01.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:33:31.514+0000] {processor.py:157} INFO - Started process (PID=38872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:33:31.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:33:31.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:33:31.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:33:31.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:33:31.550+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:33:31.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:33:31.562+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:33:31.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:33:31.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T08:34:01.939+0000] {processor.py:157} INFO - Started process (PID=38897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:34:01.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:34:01.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:34:01.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:34:01.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:34:01.969+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:34:01.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:34:01.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:34:01.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:34:01.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:34:32.381+0000] {processor.py:157} INFO - Started process (PID=38922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:34:32.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:34:32.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:34:32.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:34:32.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:34:32.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:34:32.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:34:32.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:34:32.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:34:32.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:35:02.760+0000] {processor.py:157} INFO - Started process (PID=38947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:35:02.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:35:02.764+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:35:02.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:35:02.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:35:02.791+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:35:02.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:35:02.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:35:02.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:35:02.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:35:33.257+0000] {processor.py:157} INFO - Started process (PID=38972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:35:33.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:35:33.260+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:35:33.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:35:33.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:35:33.285+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:35:33.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:35:33.295+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:35:33.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:35:33.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T08:36:03.669+0000] {processor.py:157} INFO - Started process (PID=38997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:36:03.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:36:03.671+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:36:03.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:36:03.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:36:03.700+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:36:03.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:36:03.712+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:36:03.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:36:03.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T08:36:34.163+0000] {processor.py:157} INFO - Started process (PID=39022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:36:34.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:36:34.166+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:36:34.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:36:34.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:36:34.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:36:34.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:36:34.208+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:36:34.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:36:34.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T08:37:04.614+0000] {processor.py:157} INFO - Started process (PID=39047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:37:04.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:37:04.616+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:37:04.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:37:04.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:37:04.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:37:04.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:37:04.646+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:37:04.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:37:04.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-21T08:37:35.081+0000] {processor.py:157} INFO - Started process (PID=39072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:37:35.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:37:35.085+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:37:35.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:37:35.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:37:35.112+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:37:35.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:37:35.124+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:37:35.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:37:35.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T08:38:05.534+0000] {processor.py:157} INFO - Started process (PID=39097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:38:05.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:38:05.538+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:38:05.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:38:05.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:38:05.567+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:38:05.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:38:05.576+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:38:05.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:38:05.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:38:35.922+0000] {processor.py:157} INFO - Started process (PID=39122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:38:35.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:38:35.926+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:38:35.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:38:35.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:38:35.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:38:35.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:38:35.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:38:35.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:38:35.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T08:39:06.395+0000] {processor.py:157} INFO - Started process (PID=39147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:39:06.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:39:06.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:39:06.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:39:06.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:39:06.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:39:06.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:39:06.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:39:06.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:39:06.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:39:36.879+0000] {processor.py:157} INFO - Started process (PID=39172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:39:36.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:39:36.882+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:39:36.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:39:36.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:39:36.911+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:39:36.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:39:36.920+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:39:36.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:39:36.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:40:07.315+0000] {processor.py:157} INFO - Started process (PID=39197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:40:07.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:40:07.317+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:40:07.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:40:07.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:40:07.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:40:07.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:40:07.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:40:07.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:40:07.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T08:40:37.801+0000] {processor.py:157} INFO - Started process (PID=39222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:40:37.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:40:37.807+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:40:37.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:40:37.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:40:37.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:40:37.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:40:37.854+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:40:37.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:40:37.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T08:41:08.310+0000] {processor.py:157} INFO - Started process (PID=39247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:41:08.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:41:08.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:41:08.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:41:08.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:41:08.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:41:08.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:41:08.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:41:08.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:41:08.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:41:38.800+0000] {processor.py:157} INFO - Started process (PID=39272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:41:38.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:41:38.804+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:41:38.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:41:38.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:41:38.831+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:41:38.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:41:38.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:41:38.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:41:38.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:42:09.309+0000] {processor.py:157} INFO - Started process (PID=39297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:42:09.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:42:09.314+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:42:09.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:42:09.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:42:09.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:42:09.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:42:09.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:42:09.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:42:09.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T08:42:39.745+0000] {processor.py:157} INFO - Started process (PID=39322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:42:39.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:42:39.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:42:39.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:42:39.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:42:39.774+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:42:39.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:42:39.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:42:39.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:42:39.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:43:10.173+0000] {processor.py:157} INFO - Started process (PID=39347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:43:10.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:43:10.176+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:43:10.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:43:10.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:43:10.205+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:43:10.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:43:10.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:43:10.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:43:10.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:43:40.606+0000] {processor.py:157} INFO - Started process (PID=39372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:43:40.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:43:40.610+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:43:40.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:43:40.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:43:40.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:43:40.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:43:40.650+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:43:40.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:43:40.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T08:44:11.107+0000] {processor.py:157} INFO - Started process (PID=39396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:44:11.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:44:11.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:44:11.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:44:11.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:44:11.132+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:44:11.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:44:11.141+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:44:11.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:44:11.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T08:44:41.534+0000] {processor.py:157} INFO - Started process (PID=39422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:44:41.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:44:41.536+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:44:41.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:44:41.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:44:41.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:44:41.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:44:41.573+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:44:41.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:44:41.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T08:45:11.999+0000] {processor.py:157} INFO - Started process (PID=39447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:45:11.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:45:12.001+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:45:12.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:45:12.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:45:12.033+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:45:12.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:45:12.042+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:45:12.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:45:12.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:45:42.425+0000] {processor.py:157} INFO - Started process (PID=39472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:45:42.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:45:42.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:45:42.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:45:42.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:45:42.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:45:42.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:45:42.464+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:45:42.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:45:42.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:46:12.831+0000] {processor.py:157} INFO - Started process (PID=39497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:46:12.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:46:12.834+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:46:12.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:46:12.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:46:12.861+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:46:12.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:46:12.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:46:12.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:46:12.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:46:43.230+0000] {processor.py:157} INFO - Started process (PID=39522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:46:43.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:46:43.232+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:46:43.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:46:43.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:46:43.263+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:46:43.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:46:43.273+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:46:43.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:46:43.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T08:47:13.740+0000] {processor.py:157} INFO - Started process (PID=39547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:47:13.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:47:13.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:47:13.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:47:13.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:47:13.769+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:47:13.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:47:13.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:47:13.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:47:13.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T08:47:44.168+0000] {processor.py:157} INFO - Started process (PID=39572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:47:44.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:47:44.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:47:44.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:47:44.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:47:44.191+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:47:44.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:47:44.201+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:47:44.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:47:44.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-21T08:48:14.710+0000] {processor.py:157} INFO - Started process (PID=39597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:48:14.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:48:14.713+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:48:14.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:48:14.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:48:14.740+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:48:14.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:48:14.749+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:48:14.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:48:14.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T08:48:45.143+0000] {processor.py:157} INFO - Started process (PID=39622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:48:45.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:48:45.146+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:48:45.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:48:45.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:48:45.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:48:45.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:48:45.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:48:45.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:48:45.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:49:15.534+0000] {processor.py:157} INFO - Started process (PID=39647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:49:15.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:49:15.541+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:49:15.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:49:15.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:49:15.578+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:49:15.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:49:15.591+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:49:15.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:49:15.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T08:49:46.016+0000] {processor.py:157} INFO - Started process (PID=39672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:49:46.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:49:46.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:49:46.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:49:46.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:49:46.046+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:49:46.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:49:46.057+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:49:46.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:49:46.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:50:16.480+0000] {processor.py:157} INFO - Started process (PID=39697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:50:16.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:50:16.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:50:16.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:50:16.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:50:16.505+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:50:16.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:50:16.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:50:16.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:50:16.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T08:50:46.935+0000] {processor.py:157} INFO - Started process (PID=39722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:50:46.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:50:46.938+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:50:46.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:50:46.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:50:46.964+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:50:46.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:50:46.974+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:50:46.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:50:46.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:51:17.340+0000] {processor.py:157} INFO - Started process (PID=39747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:51:17.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:51:17.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:51:17.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:51:17.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:51:17.370+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:51:17.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:51:17.383+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:51:17.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:51:17.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:51:47.772+0000] {processor.py:157} INFO - Started process (PID=39772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:51:47.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:51:47.774+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:51:47.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:51:47.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:51:47.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:51:47.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:51:47.811+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:51:47.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:51:47.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:52:18.229+0000] {processor.py:157} INFO - Started process (PID=39797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:52:18.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:52:18.233+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:52:18.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:52:18.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:52:18.258+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:52:18.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:52:18.268+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:52:18.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:52:18.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:52:48.703+0000] {processor.py:157} INFO - Started process (PID=39822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:52:48.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:52:48.707+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:52:48.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:52:48.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:52:48.734+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:52:48.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:52:48.746+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:52:48.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:52:48.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:53:19.178+0000] {processor.py:157} INFO - Started process (PID=39847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:53:19.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:53:19.182+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:53:19.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:53:19.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:53:19.207+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:53:19.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:53:19.217+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:53:19.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:53:19.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:53:49.544+0000] {processor.py:157} INFO - Started process (PID=39872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:53:49.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:53:49.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:53:49.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:53:49.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:53:49.574+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:53:49.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:53:49.586+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:53:49.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:53:49.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:54:19.974+0000] {processor.py:157} INFO - Started process (PID=39897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:54:19.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:54:19.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:54:19.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:54:19.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:54:20.006+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:54:20.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:54:20.017+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:54:20.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:54:20.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T08:54:50.448+0000] {processor.py:157} INFO - Started process (PID=39922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:54:50.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:54:50.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:54:50.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:54:50.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:54:50.477+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:54:50.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:54:50.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:54:50.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:54:50.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:55:20.888+0000] {processor.py:157} INFO - Started process (PID=39947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:55:20.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:55:20.890+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:55:20.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:55:20.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:55:20.918+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:55:20.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:55:20.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:55:20.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:55:20.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T08:55:51.337+0000] {processor.py:157} INFO - Started process (PID=39972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:55:51.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:55:51.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:55:51.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:55:51.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:55:51.365+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:55:51.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:55:51.375+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:55:51.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:55:51.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T08:56:21.763+0000] {processor.py:157} INFO - Started process (PID=39997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:56:21.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:56:21.769+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:56:21.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:56:21.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:56:21.794+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:56:21.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:56:21.805+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:56:21.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:56:21.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T08:56:52.211+0000] {processor.py:157} INFO - Started process (PID=40022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:56:52.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:56:52.214+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:56:52.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:56:52.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:56:52.238+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:56:52.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:56:52.248+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:56:52.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:56:52.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T08:57:22.686+0000] {processor.py:157} INFO - Started process (PID=40047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:57:22.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:57:22.691+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:57:22.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:57:22.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:57:22.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:57:22.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:57:22.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:57:22.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:57:22.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T08:57:53.168+0000] {processor.py:157} INFO - Started process (PID=40072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:57:53.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:57:53.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:57:53.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:57:53.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:57:53.200+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:57:53.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:57:53.213+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:57:53.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:57:53.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T08:58:23.651+0000] {processor.py:157} INFO - Started process (PID=40097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:58:23.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:58:23.654+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:58:23.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:58:23.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:58:23.682+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:58:23.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:58:23.693+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:58:23.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:58:23.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T08:58:54.069+0000] {processor.py:157} INFO - Started process (PID=40122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:58:54.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:58:54.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:58:54.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:58:54.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:58:54.099+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:58:54.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:58:54.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:58:54.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:58:54.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T08:59:24.465+0000] {processor.py:157} INFO - Started process (PID=40147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:59:24.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:59:24.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:59:24.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:59:24.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:59:24.501+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:59:24.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:59:24.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:59:24.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:59:24.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T08:59:54.923+0000] {processor.py:157} INFO - Started process (PID=40172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:59:54.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T08:59:54.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:59:54.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:59:54.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T08:59:54.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:59:54.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T08:59:54.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T08:59:54.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T08:59:54.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:00:25.401+0000] {processor.py:157} INFO - Started process (PID=40197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:00:25.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:00:25.403+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:00:25.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:00:25.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:00:25.430+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:00:25.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:00:25.439+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:00:25.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:00:25.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T09:00:55.848+0000] {processor.py:157} INFO - Started process (PID=40222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:00:55.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:00:55.857+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:00:55.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:00:55.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:00:55.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:00:55.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:00:55.892+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:00:55.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:00:55.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T09:01:26.316+0000] {processor.py:157} INFO - Started process (PID=40247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:01:26.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:01:26.319+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:01:26.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:01:26.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:01:26.349+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:01:26.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:01:26.362+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:01:26.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:01:26.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T09:01:56.769+0000] {processor.py:157} INFO - Started process (PID=40272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:01:56.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:01:56.772+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:01:56.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:01:56.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:01:56.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:01:56.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:01:56.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:01:56.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:01:56.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:02:27.199+0000] {processor.py:157} INFO - Started process (PID=40296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:02:27.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:02:27.206+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:02:27.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:02:27.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:02:27.227+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:02:27.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:02:27.236+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:02:27.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:02:27.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T09:02:57.659+0000] {processor.py:157} INFO - Started process (PID=40322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:02:57.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:02:57.669+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:02:57.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:02:57.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:02:57.690+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:02:57.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:02:57.700+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:02:57.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:02:57.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:03:28.161+0000] {processor.py:157} INFO - Started process (PID=40347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:03:28.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:03:28.164+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:03:28.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:03:28.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:03:28.194+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:03:28.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:03:28.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:03:28.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:03:28.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T09:03:58.552+0000] {processor.py:157} INFO - Started process (PID=40372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:03:58.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:03:58.554+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:03:58.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:03:58.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:03:58.580+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:03:58.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:03:58.590+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:03:58.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:03:58.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T09:04:29.008+0000] {processor.py:157} INFO - Started process (PID=40397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:04:29.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:04:29.011+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:04:29.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:04:29.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:04:29.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:04:29.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:04:29.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:04:29.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:04:29.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:04:59.446+0000] {processor.py:157} INFO - Started process (PID=40422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:04:59.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:04:59.450+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:04:59.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:04:59.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:04:59.479+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:04:59.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:04:59.489+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:04:59.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:04:59.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T09:05:29.890+0000] {processor.py:157} INFO - Started process (PID=40447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:05:29.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:05:29.895+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:05:29.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:05:29.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:05:29.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:05:29.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:05:29.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:05:29.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:05:29.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T09:06:00.309+0000] {processor.py:157} INFO - Started process (PID=40472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:06:00.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:06:00.314+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:06:00.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:06:00.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:06:00.340+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:06:00.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:06:00.350+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:06:00.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:06:00.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:06:30.756+0000] {processor.py:157} INFO - Started process (PID=40497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:06:30.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:06:30.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:06:30.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:06:30.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:06:30.787+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:06:30.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:06:30.798+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:06:30.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:06:30.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T09:07:01.240+0000] {processor.py:157} INFO - Started process (PID=40522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:07:01.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:07:01.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:07:01.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:07:01.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:07:01.270+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:07:01.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:07:01.280+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:07:01.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:07:01.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T09:07:31.663+0000] {processor.py:157} INFO - Started process (PID=40547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:07:31.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:07:31.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:07:31.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:07:31.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:07:31.693+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:07:31.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:07:31.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:07:31.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:07:31.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:08:02.070+0000] {processor.py:157} INFO - Started process (PID=40572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:08:02.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:08:02.073+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:08:02.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:08:02.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:08:02.100+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:08:02.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:08:02.109+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:08:02.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:08:02.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T09:08:32.493+0000] {processor.py:157} INFO - Started process (PID=40597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:08:32.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:08:32.495+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:08:32.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:08:32.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:08:32.517+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:08:32.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:08:32.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:08:32.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:08:32.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T09:09:02.953+0000] {processor.py:157} INFO - Started process (PID=40622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:09:02.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:09:02.956+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:09:02.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:09:02.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:09:02.982+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:09:02.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:09:02.995+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:09:02.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:09:03.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T09:09:33.437+0000] {processor.py:157} INFO - Started process (PID=40647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:09:33.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:09:33.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:09:33.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:09:33.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:09:33.469+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:09:33.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:09:33.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:09:33.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:09:33.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T09:10:03.874+0000] {processor.py:157} INFO - Started process (PID=40672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:10:03.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:10:03.878+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:10:03.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:10:03.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:10:03.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:10:03.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:10:03.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:10:03.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:10:03.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T09:10:34.310+0000] {processor.py:157} INFO - Started process (PID=40696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:10:34.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:10:34.312+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:10:34.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:10:34.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:10:34.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:10:34.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:10:34.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:10:34.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:10:34.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T09:11:04.715+0000] {processor.py:157} INFO - Started process (PID=40722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:11:04.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:11:04.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:11:04.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:11:04.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:11:04.746+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:11:04.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:11:04.756+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:11:04.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:11:04.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T09:11:35.141+0000] {processor.py:157} INFO - Started process (PID=40747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:11:35.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:11:35.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:11:35.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:11:35.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:11:35.172+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:11:35.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:11:35.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:11:35.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:11:35.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T09:12:05.609+0000] {processor.py:157} INFO - Started process (PID=40772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:12:05.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:12:05.611+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:12:05.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:12:05.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:12:05.641+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:12:05.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:12:05.653+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:12:05.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:12:05.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T09:12:36.127+0000] {processor.py:157} INFO - Started process (PID=40797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:12:36.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:12:36.130+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:12:36.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:12:36.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:12:36.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:12:36.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:12:36.165+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:12:36.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:12:36.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T09:13:06.518+0000] {processor.py:157} INFO - Started process (PID=40822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:13:06.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:13:06.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:13:06.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:13:06.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:13:06.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:13:06.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:13:06.554+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:13:06.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:13:06.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T09:13:36.910+0000] {processor.py:157} INFO - Started process (PID=40847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:13:36.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:13:36.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:13:36.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:13:36.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:13:36.937+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:13:36.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:13:36.946+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:13:36.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:13:36.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-21T09:14:07.348+0000] {processor.py:157} INFO - Started process (PID=40872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:14:07.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:14:07.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:14:07.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:14:07.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:14:07.379+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:14:07.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:14:07.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:14:07.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:14:07.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T09:14:37.775+0000] {processor.py:157} INFO - Started process (PID=40897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:14:37.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:14:37.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:14:37.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:14:37.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:14:37.806+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:14:37.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:14:37.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:14:37.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:14:37.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T09:15:08.185+0000] {processor.py:157} INFO - Started process (PID=40922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:15:08.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:15:08.188+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:15:08.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:15:08.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:15:08.215+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:15:08.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:15:08.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:15:08.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:15:08.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T09:15:38.656+0000] {processor.py:157} INFO - Started process (PID=40947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:15:38.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:15:38.659+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:15:38.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:15:38.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:15:38.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:15:38.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:15:38.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:15:38.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:15:38.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T09:16:09.083+0000] {processor.py:157} INFO - Started process (PID=40972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:16:09.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:16:09.085+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:16:09.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:16:09.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:16:09.111+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:16:09.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:16:09.121+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:16:09.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:16:09.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T09:16:39.622+0000] {processor.py:157} INFO - Started process (PID=40997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:16:39.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:16:39.627+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:16:39.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:16:39.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:16:39.682+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:16:39.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:16:39.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:16:39.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:16:39.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-21T09:32:11.424+0000] {processor.py:157} INFO - Started process (PID=41022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:32:11.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:32:11.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:32:11.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:32:11.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:32:11.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:32:11.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:32:11.463+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:32:11.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:32:11.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T09:32:41.925+0000] {processor.py:157} INFO - Started process (PID=41048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:32:41.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:32:41.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:32:41.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:32:41.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:32:41.967+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:32:41.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:32:41.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:32:41.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:32:41.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T09:33:12.385+0000] {processor.py:157} INFO - Started process (PID=41074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:33:12.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:33:12.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:33:12.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:33:12.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:33:12.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:33:12.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:33:12.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:33:12.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:33:12.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:33:42.830+0000] {processor.py:157} INFO - Started process (PID=41098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:33:42.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:33:42.836+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:33:42.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:33:42.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:33:42.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:33:42.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:33:42.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:33:42.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:33:42.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-21T09:34:13.274+0000] {processor.py:157} INFO - Started process (PID=41124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:34:13.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:34:13.278+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:34:13.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:34:13.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:34:13.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:34:13.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:34:13.318+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:34:13.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:34:13.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T09:34:43.686+0000] {processor.py:157} INFO - Started process (PID=41149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:34:43.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:34:43.694+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:34:43.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:34:43.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:34:43.726+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:34:43.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:34:43.737+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:34:43.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:34:43.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T09:50:31.623+0000] {processor.py:157} INFO - Started process (PID=41176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:50:31.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:50:31.626+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:50:31.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:50:31.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:50:31.673+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:50:31.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:50:31.685+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:50:31.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:50:31.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T09:51:02.067+0000] {processor.py:157} INFO - Started process (PID=41201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:51:02.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:51:02.069+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:51:02.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:51:02.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:51:02.098+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:51:02.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:51:02.108+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:51:02.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:51:02.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T09:51:32.498+0000] {processor.py:157} INFO - Started process (PID=41226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:51:32.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:51:32.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:51:32.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:51:32.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:51:32.549+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:51:32.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:51:32.562+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:51:32.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:51:32.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T09:52:02.975+0000] {processor.py:157} INFO - Started process (PID=41251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:52:02.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:52:02.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:52:02.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:52:02.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:52:03.007+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:52:03.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:52:03.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:52:03.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:52:03.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T09:52:33.408+0000] {processor.py:157} INFO - Started process (PID=41276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:52:33.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:52:33.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:52:33.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:52:33.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:52:33.438+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:52:33.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:52:33.447+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:52:33.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:52:33.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T09:53:03.872+0000] {processor.py:157} INFO - Started process (PID=41301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:53:03.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:53:03.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:53:03.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:53:03.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:53:03.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:53:03.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:53:03.915+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:53:03.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:53:03.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T09:53:34.306+0000] {processor.py:157} INFO - Started process (PID=41326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:53:34.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:53:34.311+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:53:34.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:53:34.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:53:34.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:53:34.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:53:34.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:53:34.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:53:34.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T09:54:04.721+0000] {processor.py:157} INFO - Started process (PID=41351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:54:04.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:54:04.724+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:54:04.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:54:04.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:54:04.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:54:04.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:54:04.771+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:54:04.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:54:04.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T09:54:35.207+0000] {processor.py:157} INFO - Started process (PID=41376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:54:35.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:54:35.209+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:54:35.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:54:35.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:54:35.237+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:54:35.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:54:35.247+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:54:35.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:54:35.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T09:55:05.673+0000] {processor.py:157} INFO - Started process (PID=41401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:55:05.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:55:05.676+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:55:05.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:55:05.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:55:05.708+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:55:05.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:55:05.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:55:05.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:55:05.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T09:55:36.188+0000] {processor.py:157} INFO - Started process (PID=41426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:55:36.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:55:36.191+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:55:36.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:55:36.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:55:36.218+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:55:36.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:55:36.230+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:55:36.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:55:36.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:56:06.651+0000] {processor.py:157} INFO - Started process (PID=41451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:56:06.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:56:06.656+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:56:06.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:56:06.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:56:06.684+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:56:06.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:56:06.693+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:56:06.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:56:06.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:56:37.154+0000] {processor.py:157} INFO - Started process (PID=41476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:56:37.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:56:37.158+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:56:37.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:56:37.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:56:37.189+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:56:37.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:56:37.202+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:56:37.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:56:37.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T09:57:07.549+0000] {processor.py:157} INFO - Started process (PID=41501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:57:07.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:57:07.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:57:07.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:57:07.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:57:07.578+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:57:07.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:57:07.590+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:57:07.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:57:07.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T09:57:38.009+0000] {processor.py:157} INFO - Started process (PID=41526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:57:38.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:57:38.012+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:57:38.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:57:38.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:57:38.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:57:38.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:57:38.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:57:38.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:57:38.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T09:58:08.465+0000] {processor.py:157} INFO - Started process (PID=41551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:58:08.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:58:08.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:58:08.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:58:08.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:58:08.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:58:08.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:58:08.499+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:58:08.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:58:08.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T09:58:38.945+0000] {processor.py:157} INFO - Started process (PID=41576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:58:38.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:58:38.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:58:38.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:58:38.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:58:38.987+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:58:38.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:58:39.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:58:39.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:58:39.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T09:59:09.437+0000] {processor.py:157} INFO - Started process (PID=41601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:59:09.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:59:09.439+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:59:09.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:59:09.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:59:09.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:59:09.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:59:09.477+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:59:09.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:59:09.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T09:59:39.837+0000] {processor.py:157} INFO - Started process (PID=41626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:59:39.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T09:59:39.839+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:59:39.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:59:39.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T09:59:39.867+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:59:39.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T09:59:39.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T09:59:39.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T09:59:39.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T10:00:10.228+0000] {processor.py:157} INFO - Started process (PID=41651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:00:10.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:00:10.232+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:00:10.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:00:10.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:00:10.260+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:00:10.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:00:10.270+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:00:10.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:00:10.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:00:40.696+0000] {processor.py:157} INFO - Started process (PID=41676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:00:40.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:00:40.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:00:40.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:00:40.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:00:40.726+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:00:40.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:00:40.735+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:00:40.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:00:40.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T10:01:11.179+0000] {processor.py:157} INFO - Started process (PID=41701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:01:11.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:01:11.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:01:11.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:01:11.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:01:11.211+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:01:11.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:01:11.222+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:01:11.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:01:11.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:01:41.630+0000] {processor.py:157} INFO - Started process (PID=41726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:01:41.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:01:41.632+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:01:41.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:01:41.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:01:41.653+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:01:41.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:01:41.662+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:01:41.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:01:41.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-21T10:02:12.061+0000] {processor.py:157} INFO - Started process (PID=41751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:02:12.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:02:12.064+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:02:12.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:02:12.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:02:12.093+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:02:12.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:02:12.106+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:02:12.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:02:12.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:02:42.518+0000] {processor.py:157} INFO - Started process (PID=41776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:02:42.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:02:42.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:02:42.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:02:42.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:02:42.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:02:42.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:02:42.565+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:02:42.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:02:42.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T10:03:12.931+0000] {processor.py:157} INFO - Started process (PID=41801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:03:12.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:03:12.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:03:12.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:03:12.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:03:12.968+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:03:12.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:03:12.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:03:12.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:03:12.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T10:03:43.412+0000] {processor.py:157} INFO - Started process (PID=41826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:03:43.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:03:43.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:03:43.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:03:43.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:03:43.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:03:43.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:03:43.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:03:43.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:03:43.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T10:04:13.819+0000] {processor.py:157} INFO - Started process (PID=41851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:04:13.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:04:13.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:04:13.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:04:13.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:04:13.860+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:04:13.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:04:13.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:04:13.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:04:13.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T10:04:44.339+0000] {processor.py:157} INFO - Started process (PID=41876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:04:44.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:04:44.343+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:04:44.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:04:44.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:04:44.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:04:44.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:04:44.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:04:44.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:04:44.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T10:05:14.769+0000] {processor.py:157} INFO - Started process (PID=41901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:05:14.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:05:14.772+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:05:14.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:05:14.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:05:14.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:05:14.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:05:14.809+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:05:14.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:05:14.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T10:05:45.256+0000] {processor.py:157} INFO - Started process (PID=41926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:05:45.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:05:45.258+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:05:45.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:05:45.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:05:45.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:05:45.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:05:45.298+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:05:45.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:05:45.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:06:15.695+0000] {processor.py:157} INFO - Started process (PID=41951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:06:15.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:06:15.698+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:06:15.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:06:15.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:06:15.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:06:15.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:06:15.742+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:06:15.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:06:15.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T10:06:46.118+0000] {processor.py:157} INFO - Started process (PID=41976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:06:46.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:06:46.123+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:06:46.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:06:46.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:06:46.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:06:46.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:06:46.162+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:06:46.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:06:46.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:07:16.563+0000] {processor.py:157} INFO - Started process (PID=42001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:07:16.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:07:16.566+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:07:16.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:07:16.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:07:16.594+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:07:16.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:07:16.606+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:07:16.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:07:16.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:07:46.983+0000] {processor.py:157} INFO - Started process (PID=42026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:07:46.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:07:46.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:07:46.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:07:46.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:07:47.012+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:07:47.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:07:47.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:07:47.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:07:47.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T10:08:17.392+0000] {processor.py:157} INFO - Started process (PID=42051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:08:17.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:08:17.396+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:08:17.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:08:17.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:08:17.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:08:17.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:08:17.433+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:08:17.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:08:17.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T10:08:47.851+0000] {processor.py:157} INFO - Started process (PID=42076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:08:47.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:08:47.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:08:47.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:08:47.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:08:47.882+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:08:47.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:08:47.892+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:08:47.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:08:47.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T10:09:18.302+0000] {processor.py:157} INFO - Started process (PID=42101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:09:18.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:09:18.304+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:09:18.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:09:18.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:09:18.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:09:18.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:09:18.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:09:18.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:09:18.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T10:09:48.730+0000] {processor.py:157} INFO - Started process (PID=42126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:09:48.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:09:48.732+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:09:48.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:09:48.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:09:48.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:09:48.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:09:48.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:09:48.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:09:48.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T10:10:19.159+0000] {processor.py:157} INFO - Started process (PID=42151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:10:19.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:10:19.162+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:10:19.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:10:19.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:10:19.188+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:10:19.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:10:19.198+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:10:19.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:10:19.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T10:10:49.683+0000] {processor.py:157} INFO - Started process (PID=42176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:10:49.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:10:49.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:10:49.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:10:49.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:10:49.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:10:49.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:10:49.724+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:10:49.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:10:49.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T10:11:20.124+0000] {processor.py:157} INFO - Started process (PID=42201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:11:20.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:11:20.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:11:20.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:11:20.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:11:20.157+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:11:20.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:11:20.169+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:11:20.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:11:20.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:11:50.594+0000] {processor.py:157} INFO - Started process (PID=42226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:11:50.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:11:50.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:11:50.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:11:50.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:11:50.635+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:11:50.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:11:50.647+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:11:50.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:11:50.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T10:12:21.076+0000] {processor.py:157} INFO - Started process (PID=42251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:12:21.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:12:21.078+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:12:21.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:12:21.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:12:21.108+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:12:21.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:12:21.119+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:12:21.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:12:21.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:12:51.542+0000] {processor.py:157} INFO - Started process (PID=42276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:12:51.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:12:51.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:12:51.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:12:51.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:12:51.572+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:12:51.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:12:51.585+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:12:51.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:12:51.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:13:22.012+0000] {processor.py:157} INFO - Started process (PID=42301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:13:22.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:13:22.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:13:22.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:13:22.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:13:22.041+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:13:22.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:13:22.051+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:13:22.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:13:22.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T10:13:52.374+0000] {processor.py:157} INFO - Started process (PID=42326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:13:52.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:13:52.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:13:52.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:13:52.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:13:52.406+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:13:52.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:13:52.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:13:52.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:13:52.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T10:14:22.827+0000] {processor.py:157} INFO - Started process (PID=42351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:14:22.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:14:22.831+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:14:22.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:14:22.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:14:22.861+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:14:22.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:14:22.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:14:22.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:14:22.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:14:53.257+0000] {processor.py:157} INFO - Started process (PID=42376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:14:53.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:14:53.260+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:14:53.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:14:53.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:14:53.287+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:14:53.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:14:53.297+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:14:53.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:14:53.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T10:15:23.674+0000] {processor.py:157} INFO - Started process (PID=42401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:15:23.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:15:23.676+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:15:23.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:15:23.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:15:23.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:15:23.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:15:23.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:15:23.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:15:23.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T10:15:54.196+0000] {processor.py:157} INFO - Started process (PID=42426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:15:54.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:15:54.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:15:54.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:15:54.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:15:54.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:15:54.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:15:54.234+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:15:54.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:15:54.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T10:16:24.627+0000] {processor.py:157} INFO - Started process (PID=42451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:16:24.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:16:24.630+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:16:24.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:16:24.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:16:24.656+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:16:24.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:16:24.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:16:24.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:16:24.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T10:16:55.109+0000] {processor.py:157} INFO - Started process (PID=42476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:16:55.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:16:55.114+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:16:55.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:16:55.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:16:55.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:16:55.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:16:55.153+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:16:55.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:16:55.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:17:25.565+0000] {processor.py:157} INFO - Started process (PID=42501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:17:25.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:17:25.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:17:25.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:17:25.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:17:25.603+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:17:25.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:17:25.614+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:17:25.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:17:25.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T10:17:55.983+0000] {processor.py:157} INFO - Started process (PID=42526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:17:55.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:17:55.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:17:55.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:17:56.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:17:56.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:17:56.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:17:56.034+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:17:56.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:17:56.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T10:18:26.458+0000] {processor.py:157} INFO - Started process (PID=42551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:18:26.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:18:26.461+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:18:26.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:18:26.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:18:26.488+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:18:26.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:18:26.498+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:18:26.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:18:26.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T10:18:56.894+0000] {processor.py:157} INFO - Started process (PID=42576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:18:56.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:18:56.897+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:18:56.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:18:56.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:18:56.925+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:18:56.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:18:56.937+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:18:56.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:18:56.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:19:27.304+0000] {processor.py:157} INFO - Started process (PID=42601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:19:27.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:19:27.308+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:19:27.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:19:27.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:19:27.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:19:27.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:19:27.346+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:19:27.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:19:27.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:19:57.717+0000] {processor.py:157} INFO - Started process (PID=42626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:19:57.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:19:57.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:19:57.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:19:57.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:19:57.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:19:57.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:19:57.763+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:19:57.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:19:57.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:20:28.233+0000] {processor.py:157} INFO - Started process (PID=42651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:20:28.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:20:28.236+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:20:28.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:20:28.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:20:28.268+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:20:28.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:20:28.276+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:20:28.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:20:28.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T10:20:58.742+0000] {processor.py:157} INFO - Started process (PID=42676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:20:58.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:20:58.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:20:58.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:20:58.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:20:58.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:20:58.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:20:58.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:20:58.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:20:58.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T10:21:29.246+0000] {processor.py:157} INFO - Started process (PID=42701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:21:29.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:21:29.249+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:21:29.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:21:29.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:21:29.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:21:29.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:21:29.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:21:29.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:21:29.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:21:59.707+0000] {processor.py:157} INFO - Started process (PID=42726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:21:59.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:21:59.712+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:21:59.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:21:59.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:21:59.741+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:21:59.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:21:59.753+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:21:59.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:21:59.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:22:30.112+0000] {processor.py:157} INFO - Started process (PID=42751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:22:30.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:22:30.115+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:22:30.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:22:30.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:22:30.152+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:22:30.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:22:30.164+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:22:30.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:22:30.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T10:23:00.609+0000] {processor.py:157} INFO - Started process (PID=42776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:23:00.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:23:00.612+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:23:00.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:23:00.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:23:00.642+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:23:00.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:23:00.654+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:23:00.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:23:00.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:23:31.091+0000] {processor.py:157} INFO - Started process (PID=42801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:23:31.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:23:31.093+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:23:31.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:23:31.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:23:31.124+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:23:31.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:23:31.136+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:23:31.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:23:31.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:24:01.591+0000] {processor.py:157} INFO - Started process (PID=42826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:24:01.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:24:01.595+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:24:01.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:24:01.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:24:01.624+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:24:01.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:24:01.634+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:24:01.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:24:01.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:24:31.997+0000] {processor.py:157} INFO - Started process (PID=42851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:24:31.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:24:32.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:24:32.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:24:32.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:24:32.028+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:24:32.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:24:32.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:24:32.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:24:32.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:25:02.415+0000] {processor.py:157} INFO - Started process (PID=42876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:25:02.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:25:02.418+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:25:02.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:25:02.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:25:02.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:25:02.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:25:02.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:25:02.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:25:02.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T10:25:32.861+0000] {processor.py:157} INFO - Started process (PID=42901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:25:32.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:25:32.865+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:25:32.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:25:32.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:25:32.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:25:32.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:25:32.911+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:25:32.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:25:32.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T10:26:03.341+0000] {processor.py:157} INFO - Started process (PID=42926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:26:03.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:26:03.344+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:26:03.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:26:03.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:26:03.376+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:26:03.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:26:03.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:26:03.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:26:03.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T10:26:33.844+0000] {processor.py:157} INFO - Started process (PID=42951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:26:33.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:26:33.847+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:26:33.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:26:33.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:26:33.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:26:33.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:26:33.886+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:26:33.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:26:33.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:27:04.322+0000] {processor.py:157} INFO - Started process (PID=42976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:27:04.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:27:04.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:27:04.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:27:04.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:27:04.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:27:04.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:27:04.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:27:04.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:27:04.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:27:34.787+0000] {processor.py:157} INFO - Started process (PID=43001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:27:34.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:27:34.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:27:34.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:27:34.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:27:34.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:27:34.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:27:34.832+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:27:34.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:27:34.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:28:05.188+0000] {processor.py:157} INFO - Started process (PID=43026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:28:05.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:28:05.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:28:05.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:28:05.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:28:05.231+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:28:05.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:28:05.245+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:28:05.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:28:05.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T10:28:35.706+0000] {processor.py:157} INFO - Started process (PID=43051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:28:35.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:28:35.711+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:28:35.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:28:35.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:28:35.740+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:28:35.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:28:35.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:28:35.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:28:35.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:29:06.127+0000] {processor.py:157} INFO - Started process (PID=43076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:29:06.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:29:06.130+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:29:06.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:29:06.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:29:06.162+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:29:06.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:29:06.173+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:29:06.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:29:06.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T10:29:36.566+0000] {processor.py:157} INFO - Started process (PID=43101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:29:36.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:29:36.569+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:29:36.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:29:36.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:29:36.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:29:36.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:29:36.610+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:29:36.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:29:36.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:30:06.980+0000] {processor.py:157} INFO - Started process (PID=43126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:30:06.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:30:06.982+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:30:06.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:30:06.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:30:07.009+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:30:07.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:30:07.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:30:07.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:30:07.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:30:37.399+0000] {processor.py:157} INFO - Started process (PID=43151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:30:37.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:30:37.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:30:37.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:30:37.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:30:37.432+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:30:37.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:30:37.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:30:37.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:30:37.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T10:31:07.843+0000] {processor.py:157} INFO - Started process (PID=43176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:31:07.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:31:07.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:31:07.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:31:07.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:31:07.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:31:07.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:31:07.884+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:31:07.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:31:07.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T10:31:38.275+0000] {processor.py:157} INFO - Started process (PID=43201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:31:38.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:31:38.278+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:31:38.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:31:38.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:31:38.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:31:38.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:31:38.318+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:31:38.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:31:38.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:32:08.727+0000] {processor.py:157} INFO - Started process (PID=43226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:32:08.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:32:08.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:32:08.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:32:08.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:32:08.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:32:08.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:32:08.770+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:32:08.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:32:08.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:32:39.166+0000] {processor.py:157} INFO - Started process (PID=43251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:32:39.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:32:39.169+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:32:39.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:32:39.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:32:39.197+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:32:39.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:32:39.208+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:32:39.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:32:39.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T10:33:09.589+0000] {processor.py:157} INFO - Started process (PID=43276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:33:09.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:33:09.591+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:33:09.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:33:09.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:33:09.625+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:33:09.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:33:09.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:33:09.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:33:09.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T10:33:40.086+0000] {processor.py:157} INFO - Started process (PID=43301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:33:40.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:33:40.090+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:33:40.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:33:40.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:33:40.120+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:33:40.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:33:40.132+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:33:40.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:33:40.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:34:10.512+0000] {processor.py:157} INFO - Started process (PID=43326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:34:10.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:34:10.517+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:34:10.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:34:10.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:34:10.551+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:34:10.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:34:10.564+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:34:10.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:34:10.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T10:34:40.970+0000] {processor.py:157} INFO - Started process (PID=43351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:34:40.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:34:40.974+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:34:40.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:34:40.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:34:41.004+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:34:41.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:34:41.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:34:41.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:34:41.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:35:11.381+0000] {processor.py:157} INFO - Started process (PID=43375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:35:11.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:35:11.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:35:11.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:35:11.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:35:11.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:35:11.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:35:11.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:35:11.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:35:11.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-21T10:35:41.929+0000] {processor.py:157} INFO - Started process (PID=43401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:35:41.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:35:41.933+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:35:41.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:35:41.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:35:41.963+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:35:41.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:35:41.972+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:35:41.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:35:41.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:36:12.383+0000] {processor.py:157} INFO - Started process (PID=43426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:36:12.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:36:12.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:36:12.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:36:12.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:36:12.412+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:36:12.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:36:12.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:36:12.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:36:12.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T10:36:42.858+0000] {processor.py:157} INFO - Started process (PID=43451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:36:42.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:36:42.862+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:36:42.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:36:42.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:36:42.891+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:36:42.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:36:42.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:36:42.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:36:42.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:37:13.353+0000] {processor.py:157} INFO - Started process (PID=43476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:37:13.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:37:13.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:37:13.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:37:13.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:37:13.382+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:37:13.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:37:13.392+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:37:13.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:37:13.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T10:37:43.833+0000] {processor.py:157} INFO - Started process (PID=43501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:37:43.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:37:43.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:37:43.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:37:43.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:37:43.864+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:37:43.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:37:43.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:37:43.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:37:43.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T10:38:14.301+0000] {processor.py:157} INFO - Started process (PID=43526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:38:14.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:38:14.306+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:38:14.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:38:14.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:38:14.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:38:14.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:38:14.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:38:14.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:38:14.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:38:44.684+0000] {processor.py:157} INFO - Started process (PID=43551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:38:44.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:38:44.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:38:44.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:38:44.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:38:44.717+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:38:44.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:38:44.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:38:44.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:38:44.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:39:15.117+0000] {processor.py:157} INFO - Started process (PID=43576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:39:15.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:39:15.120+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:39:15.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:39:15.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:39:15.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:39:15.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:39:15.159+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:39:15.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:39:15.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:39:45.555+0000] {processor.py:157} INFO - Started process (PID=43601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:39:45.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:39:45.558+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:39:45.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:39:45.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:39:45.584+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:39:45.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:39:45.595+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:39:45.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:39:45.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T10:40:16.046+0000] {processor.py:157} INFO - Started process (PID=43626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:40:16.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:40:16.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:40:16.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:40:16.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:40:16.078+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:40:16.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:40:16.087+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:40:16.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:40:16.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T10:40:46.523+0000] {processor.py:157} INFO - Started process (PID=43651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:40:46.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:40:46.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:40:46.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:40:46.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:40:46.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:40:46.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:40:46.567+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:40:46.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:40:46.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:41:16.952+0000] {processor.py:157} INFO - Started process (PID=43676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:41:16.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:41:16.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:41:16.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:41:16.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:41:16.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:41:16.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:41:16.996+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:41:16.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:41:17.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:41:47.412+0000] {processor.py:157} INFO - Started process (PID=43701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:41:47.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:41:47.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:41:47.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:41:47.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:41:47.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:41:47.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:41:47.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:41:47.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:41:47.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T10:42:17.836+0000] {processor.py:157} INFO - Started process (PID=43726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:42:17.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:42:17.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:42:17.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:42:17.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:42:17.869+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:42:17.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:42:17.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:42:17.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:42:17.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T10:42:48.321+0000] {processor.py:157} INFO - Started process (PID=43751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:42:48.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:42:48.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:42:48.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:42:48.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:42:48.357+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:42:48.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:42:48.367+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:42:48.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:42:48.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:43:18.802+0000] {processor.py:157} INFO - Started process (PID=43776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:43:18.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:43:18.807+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:43:18.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:43:18.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:43:18.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:43:18.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:43:18.848+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:43:18.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:43:18.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T10:43:49.211+0000] {processor.py:157} INFO - Started process (PID=43801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:43:49.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:43:49.214+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:43:49.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:43:49.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:43:49.242+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:43:49.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:43:49.254+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:43:49.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:43:49.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:44:19.621+0000] {processor.py:157} INFO - Started process (PID=43826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:44:19.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:44:19.624+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:44:19.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:44:19.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:44:19.652+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:44:19.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:44:19.662+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:44:19.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:44:19.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T10:44:50.015+0000] {processor.py:157} INFO - Started process (PID=43851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:44:50.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:44:50.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:44:50.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:44:50.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:44:50.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:44:50.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:44:50.058+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:44:50.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:44:50.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:45:20.472+0000] {processor.py:157} INFO - Started process (PID=43876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:45:20.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:45:20.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:45:20.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:45:20.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:45:20.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:45:20.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:45:20.518+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:45:20.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:45:20.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T10:45:50.919+0000] {processor.py:157} INFO - Started process (PID=43901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:45:50.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:45:50.923+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:45:50.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:45:50.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:45:50.949+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:45:50.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:45:50.961+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:45:50.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:45:50.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:46:21.369+0000] {processor.py:157} INFO - Started process (PID=43926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:46:21.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:46:21.373+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:46:21.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:46:21.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:46:21.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:46:21.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:46:21.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:46:21.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:46:21.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T10:46:51.862+0000] {processor.py:157} INFO - Started process (PID=43951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:46:51.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:46:51.867+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:46:51.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:46:51.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:46:51.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:46:51.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:46:51.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:46:51.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:46:51.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T10:47:22.345+0000] {processor.py:157} INFO - Started process (PID=43976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:47:22.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:47:22.350+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:47:22.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:47:22.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:47:22.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:47:22.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:47:22.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:47:22.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:47:22.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T10:47:52.799+0000] {processor.py:157} INFO - Started process (PID=44001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:47:52.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:47:52.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:47:52.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:47:52.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:47:52.833+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:47:52.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:47:52.844+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:47:52.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:47:52.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:48:23.261+0000] {processor.py:157} INFO - Started process (PID=44026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:48:23.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:48:23.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:48:23.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:48:23.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:48:23.294+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:48:23.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:48:23.305+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:48:23.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:48:23.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T10:48:53.724+0000] {processor.py:157} INFO - Started process (PID=44051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:48:53.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:48:53.727+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:48:53.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:48:53.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:48:53.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:48:53.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:48:53.766+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:48:53.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:48:53.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T10:49:24.183+0000] {processor.py:157} INFO - Started process (PID=44076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:49:24.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:49:24.187+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:49:24.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:49:24.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:49:24.217+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:49:24.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:49:24.228+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:49:24.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:49:24.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T10:49:54.572+0000] {processor.py:157} INFO - Started process (PID=44101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:49:54.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:49:54.576+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:49:54.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:49:54.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:49:54.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:49:54.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:49:54.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:49:54.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:49:54.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T10:50:25.047+0000] {processor.py:157} INFO - Started process (PID=44126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:50:25.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T10:50:25.053+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:50:25.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:50:25.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T10:50:25.103+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:50:25.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T10:50:25.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T10:50:25.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T10:50:25.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T11:01:38.954+0000] {processor.py:157} INFO - Started process (PID=44153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:01:38.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:01:38.961+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:01:38.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:01:38.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:01:39.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:01:39.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:01:39.045+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:01:39.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:01:39.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-21T11:02:09.583+0000] {processor.py:157} INFO - Started process (PID=44177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:02:09.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:02:09.589+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:02:09.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:02:09.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:02:09.627+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:02:09.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:02:09.640+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:02:09.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:02:09.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T11:17:39.303+0000] {processor.py:157} INFO - Started process (PID=44203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:17:39.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:17:39.305+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:17:39.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:17:39.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:17:39.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:17:39.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:17:39.344+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:17:39.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:17:39.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T11:18:09.859+0000] {processor.py:157} INFO - Started process (PID=44229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:18:09.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:18:09.865+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:18:09.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:18:09.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:18:09.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:18:09.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:18:09.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:18:09.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:18:09.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T11:18:45.831+0000] {processor.py:157} INFO - Started process (PID=44255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:18:45.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:18:45.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:18:45.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:18:45.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:18:45.867+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:18:45.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:18:45.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:18:45.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:18:45.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T11:19:16.352+0000] {processor.py:157} INFO - Started process (PID=44280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:19:16.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:19:16.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:19:16.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:19:16.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:19:16.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:19:16.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:19:16.398+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:19:16.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:19:16.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T11:19:46.902+0000] {processor.py:157} INFO - Started process (PID=44305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:19:46.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:19:46.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:19:46.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:19:46.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:19:46.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:19:46.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:19:46.946+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:19:46.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:19:46.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T11:20:17.489+0000] {processor.py:157} INFO - Started process (PID=44330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:20:17.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:20:17.492+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:20:17.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:20:17.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:20:17.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:20:17.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:20:17.531+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:20:17.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:20:17.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T11:20:47.972+0000] {processor.py:157} INFO - Started process (PID=44355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:20:47.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:20:47.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:20:47.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:20:47.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:20:48.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:20:48.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:20:48.012+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:20:48.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:20:48.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T11:21:18.369+0000] {processor.py:157} INFO - Started process (PID=44380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:21:18.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:21:18.372+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:21:18.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:21:18.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:21:18.400+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:21:18.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:21:18.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:21:18.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:21:18.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T11:21:48.891+0000] {processor.py:157} INFO - Started process (PID=44405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:21:48.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:21:48.899+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:21:48.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:21:48.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:21:48.927+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:21:48.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:21:48.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:21:48.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:21:48.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T11:22:19.474+0000] {processor.py:157} INFO - Started process (PID=44430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:22:19.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:22:19.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:22:19.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:22:19.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:22:19.503+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:22:19.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:22:19.513+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:22:19.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:22:19.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T11:22:49.909+0000] {processor.py:157} INFO - Started process (PID=44455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:22:49.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:22:49.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:22:49.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:22:49.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:22:49.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:22:49.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:22:49.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:22:49.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:22:49.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T11:23:20.403+0000] {processor.py:157} INFO - Started process (PID=44480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:23:20.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:23:20.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:23:20.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:23:20.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:23:20.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:23:20.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:23:20.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:23:20.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:23:20.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:23:50.856+0000] {processor.py:157} INFO - Started process (PID=44505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:23:50.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:23:50.862+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:23:50.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:23:50.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:23:50.885+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:23:50.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:23:50.895+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:23:50.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:23:50.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T11:24:21.383+0000] {processor.py:157} INFO - Started process (PID=44530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:24:21.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:24:21.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:24:21.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:24:21.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:24:21.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:24:21.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:24:21.425+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:24:21.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:24:21.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T11:24:51.868+0000] {processor.py:157} INFO - Started process (PID=44555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:24:51.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:24:51.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:24:51.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:24:51.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:24:51.897+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:24:51.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:24:51.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:24:51.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:24:51.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T11:25:22.385+0000] {processor.py:157} INFO - Started process (PID=44580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:25:22.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:25:22.392+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:25:22.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:25:22.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:25:22.412+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:25:22.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:25:22.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:25:22.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:25:22.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:25:52.777+0000] {processor.py:157} INFO - Started process (PID=44605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:25:52.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:25:52.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:25:52.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:25:52.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:25:52.809+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:25:52.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:25:52.821+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:25:52.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:25:52.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T11:26:23.340+0000] {processor.py:157} INFO - Started process (PID=44630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:26:23.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:26:23.348+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:26:23.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:26:23.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:26:23.368+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:26:23.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:26:23.377+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:26:23.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:26:23.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T11:26:53.888+0000] {processor.py:157} INFO - Started process (PID=44655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:26:53.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:26:53.890+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:26:53.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:26:53.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:26:53.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:26:53.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:26:53.926+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:26:53.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:26:53.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:27:24.380+0000] {processor.py:157} INFO - Started process (PID=44680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:27:24.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:27:24.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:27:24.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:27:24.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:27:24.414+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:27:24.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:27:24.424+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:27:24.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:27:24.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T11:27:54.850+0000] {processor.py:157} INFO - Started process (PID=44705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:27:54.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:27:54.852+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:27:54.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:27:54.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:27:54.888+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:27:54.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:27:54.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:27:54.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:27:54.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T11:28:25.438+0000] {processor.py:157} INFO - Started process (PID=44730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:28:25.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:28:25.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:28:25.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:28:25.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:28:25.472+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:28:25.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:28:25.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:28:25.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:28:25.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T11:28:56.006+0000] {processor.py:157} INFO - Started process (PID=44755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:28:56.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:28:56.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:28:56.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:28:56.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:28:56.033+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:28:56.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:28:56.044+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:28:56.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:28:56.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T11:29:26.490+0000] {processor.py:157} INFO - Started process (PID=44780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:29:26.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:29:26.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:29:26.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:29:26.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:29:26.518+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:29:26.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:29:26.528+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:29:26.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:29:26.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:29:56.921+0000] {processor.py:157} INFO - Started process (PID=44805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:29:56.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:29:56.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:29:56.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:29:56.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:29:56.959+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:29:56.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:29:56.970+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:29:56.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:29:56.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T11:30:27.390+0000] {processor.py:157} INFO - Started process (PID=44830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:30:27.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:30:27.396+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:30:27.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:30:27.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:30:27.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:30:27.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:30:27.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:30:27.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:30:27.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T11:30:57.904+0000] {processor.py:157} INFO - Started process (PID=44855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:30:57.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:30:57.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:30:57.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:30:57.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:30:57.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:30:57.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:30:57.946+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:30:57.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:30:57.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T11:31:28.426+0000] {processor.py:157} INFO - Started process (PID=44880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:31:28.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:31:28.430+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:31:28.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:31:28.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:31:28.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:31:28.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:31:28.462+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:31:28.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:31:28.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:31:58.988+0000] {processor.py:157} INFO - Started process (PID=44905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:31:58.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:31:58.992+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:31:58.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:31:59.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:31:59.027+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:31:59.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:31:59.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:31:59.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:31:59.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T11:32:29.544+0000] {processor.py:157} INFO - Started process (PID=44930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:32:29.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:32:29.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:32:29.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:32:29.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:32:29.572+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:32:29.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:32:29.582+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:32:29.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:32:29.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T11:33:00.088+0000] {processor.py:157} INFO - Started process (PID=44955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:33:00.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:33:00.097+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:33:00.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:33:00.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:33:00.120+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:33:00.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:33:00.129+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:33:00.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:33:00.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T11:33:30.665+0000] {processor.py:157} INFO - Started process (PID=44980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:33:30.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:33:30.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:33:30.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:33:30.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:33:30.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:33:30.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:33:30.708+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:33:30.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:33:30.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T11:34:01.074+0000] {processor.py:157} INFO - Started process (PID=45005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:34:01.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:34:01.079+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:34:01.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:34:01.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:34:01.106+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:34:01.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:34:01.116+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:34:01.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:34:01.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T11:34:31.492+0000] {processor.py:157} INFO - Started process (PID=45030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:34:31.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:34:31.495+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:34:31.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:34:31.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:34:31.530+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:34:31.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:34:31.540+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:34:31.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:34:31.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T11:35:02.074+0000] {processor.py:157} INFO - Started process (PID=45055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:35:02.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:35:02.077+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:35:02.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:35:02.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:35:02.115+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:35:02.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:35:02.127+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:35:02.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:35:02.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T11:35:32.607+0000] {processor.py:157} INFO - Started process (PID=45080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:35:32.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:35:32.612+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:35:32.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:35:32.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:35:32.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:35:32.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:35:32.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:35:32.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:35:32.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T11:36:03.140+0000] {processor.py:157} INFO - Started process (PID=45105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:36:03.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:36:03.146+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:36:03.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:36:03.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:36:03.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:36:03.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:36:03.180+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:36:03.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:36:03.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T11:36:33.576+0000] {processor.py:157} INFO - Started process (PID=45130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:36:33.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:36:33.579+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:36:33.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:36:33.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:36:33.608+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:36:33.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:36:33.620+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:36:33.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:36:33.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T11:37:04.027+0000] {processor.py:157} INFO - Started process (PID=45155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:37:04.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:37:04.029+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:37:04.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:37:04.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:37:04.055+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:37:04.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:37:04.065+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:37:04.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:37:04.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T11:37:34.443+0000] {processor.py:157} INFO - Started process (PID=45180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:37:34.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:37:34.446+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:37:34.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:37:34.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:37:34.474+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:37:34.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:37:34.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:37:34.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:37:34.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T11:38:04.938+0000] {processor.py:157} INFO - Started process (PID=45205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:38:04.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:38:04.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:38:04.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:38:04.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:38:04.974+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:38:04.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:38:04.985+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:38:04.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:38:04.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T11:38:35.421+0000] {processor.py:157} INFO - Started process (PID=45230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:38:35.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:38:35.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:38:35.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:38:35.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:38:35.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:38:35.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:38:35.463+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:38:35.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:38:35.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T11:39:05.870+0000] {processor.py:157} INFO - Started process (PID=45255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:39:05.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:39:05.877+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:39:05.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:39:05.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:39:05.900+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:39:05.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:39:05.910+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:39:05.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:39:05.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T11:39:36.300+0000] {processor.py:157} INFO - Started process (PID=45280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:39:36.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:39:36.303+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:39:36.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:39:36.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:39:36.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:39:36.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:39:36.349+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:39:36.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:39:36.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T11:40:06.799+0000] {processor.py:157} INFO - Started process (PID=45305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:40:06.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:40:06.802+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:40:06.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:40:06.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:40:06.831+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:40:06.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:40:06.844+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:40:06.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:40:06.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T11:40:37.234+0000] {processor.py:157} INFO - Started process (PID=45330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:40:37.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:40:37.237+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:40:37.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:40:37.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:40:37.266+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:40:37.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:40:37.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:40:37.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:40:37.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T11:41:07.787+0000] {processor.py:157} INFO - Started process (PID=45355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:41:07.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:41:07.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:41:07.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:41:07.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:41:07.817+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:41:07.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:41:07.827+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:41:07.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:41:07.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T11:41:38.312+0000] {processor.py:157} INFO - Started process (PID=45380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:41:38.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:41:38.316+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:41:38.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:41:38.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:41:38.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:41:38.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:41:38.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:41:38.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:41:38.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T11:42:08.792+0000] {processor.py:157} INFO - Started process (PID=45405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:42:08.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:42:08.795+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:42:08.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:42:08.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:42:08.823+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:42:08.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:42:08.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:42:08.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:42:08.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T11:42:39.294+0000] {processor.py:157} INFO - Started process (PID=45430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:42:39.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:42:39.301+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:42:39.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:42:39.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:42:39.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:42:39.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:42:39.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:42:39.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:42:39.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T11:43:09.733+0000] {processor.py:157} INFO - Started process (PID=45455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:43:09.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:43:09.736+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:43:09.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:43:09.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:43:09.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:43:09.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:43:09.778+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:43:09.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:43:09.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T11:43:40.245+0000] {processor.py:157} INFO - Started process (PID=45480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:43:40.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:43:40.248+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:43:40.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:43:40.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:43:40.281+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:43:40.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:43:40.291+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:43:40.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:43:40.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T11:44:10.770+0000] {processor.py:157} INFO - Started process (PID=45505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:44:10.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:44:10.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:44:10.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:44:10.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:44:10.799+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:44:10.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:44:10.809+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:44:10.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:44:10.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T11:44:41.190+0000] {processor.py:157} INFO - Started process (PID=45530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:44:41.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:44:41.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:44:41.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:44:41.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:44:41.221+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:44:41.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:44:41.231+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:44:41.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:44:41.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T11:45:11.727+0000] {processor.py:157} INFO - Started process (PID=45555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:45:11.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:45:11.732+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:45:11.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:45:11.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:45:11.757+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:45:11.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:45:11.771+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:45:11.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:45:11.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T11:45:42.140+0000] {processor.py:157} INFO - Started process (PID=45580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:45:42.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:45:42.144+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:45:42.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:45:42.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:45:42.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:45:42.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:45:42.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:45:42.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:45:42.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T11:46:12.725+0000] {processor.py:157} INFO - Started process (PID=45605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:46:12.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:46:12.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:46:12.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:46:12.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:46:12.756+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:46:12.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:46:12.770+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:46:12.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:46:12.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T11:46:43.148+0000] {processor.py:157} INFO - Started process (PID=45630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:46:43.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:46:43.152+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:46:43.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:46:43.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:46:43.179+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:46:43.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:46:43.188+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:46:43.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:46:43.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T11:47:13.706+0000] {processor.py:157} INFO - Started process (PID=45655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:47:13.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:47:13.709+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:47:13.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:47:13.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:47:13.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:47:13.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:47:13.756+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:47:13.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:47:13.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T11:47:44.225+0000] {processor.py:157} INFO - Started process (PID=45680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:47:44.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:47:44.229+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:47:44.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:47:44.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:47:44.269+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:47:44.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:47:44.284+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:47:44.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:47:44.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T11:48:14.695+0000] {processor.py:157} INFO - Started process (PID=45705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:48:14.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:48:14.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:48:14.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:48:14.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:48:14.727+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:48:14.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:48:14.737+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:48:14.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:48:14.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T11:48:45.275+0000] {processor.py:157} INFO - Started process (PID=45730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:48:45.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:48:45.278+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:48:45.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:48:45.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:48:45.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:48:45.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:48:45.320+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:48:45.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:48:45.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T11:49:15.800+0000] {processor.py:157} INFO - Started process (PID=45755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:49:15.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:49:15.803+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:49:15.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:49:15.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:49:15.830+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:49:15.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:49:15.839+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:49:15.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:49:15.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T11:49:46.210+0000] {processor.py:157} INFO - Started process (PID=45780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:49:46.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:49:46.213+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:49:46.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:49:46.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:49:46.241+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:49:46.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:49:46.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:49:46.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:49:46.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T11:50:16.694+0000] {processor.py:157} INFO - Started process (PID=45805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:50:16.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:50:16.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:50:16.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:50:16.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:50:16.721+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:50:16.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:50:16.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:50:16.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:50:16.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:50:47.168+0000] {processor.py:157} INFO - Started process (PID=45830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:50:47.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:50:47.172+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:50:47.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:50:47.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:50:47.207+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:50:47.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:50:47.218+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:50:47.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:50:47.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T11:51:17.661+0000] {processor.py:157} INFO - Started process (PID=45855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:51:17.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:51:17.663+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:51:17.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:51:17.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:51:17.692+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:51:17.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:51:17.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:51:17.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:51:17.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-21T11:51:48.117+0000] {processor.py:157} INFO - Started process (PID=45880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:51:48.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:51:48.120+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:51:48.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:51:48.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:51:48.144+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:51:48.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:51:48.153+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:51:48.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:51:48.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T11:52:18.630+0000] {processor.py:157} INFO - Started process (PID=45905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:52:18.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:52:18.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:52:18.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:52:18.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:52:18.659+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:52:18.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:52:18.669+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:52:18.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:52:18.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T11:52:49.038+0000] {processor.py:157} INFO - Started process (PID=45930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:52:49.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:52:49.040+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:52:49.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:52:49.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:52:49.064+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:52:49.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:52:49.074+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:52:49.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:52:49.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:53:19.453+0000] {processor.py:157} INFO - Started process (PID=45955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:53:19.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:53:19.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:53:19.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:53:19.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:53:19.480+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:53:19.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:53:19.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:53:19.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:53:19.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:53:49.886+0000] {processor.py:157} INFO - Started process (PID=45980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:53:49.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:53:49.894+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:53:49.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:53:49.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:53:49.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:53:49.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:53:49.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:53:49.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:53:49.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T11:54:20.372+0000] {processor.py:157} INFO - Started process (PID=46005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:54:20.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:54:20.381+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:54:20.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:54:20.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:54:20.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:54:20.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:54:20.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:54:20.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:54:20.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T11:54:50.869+0000] {processor.py:157} INFO - Started process (PID=46030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:54:50.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:54:50.873+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:54:50.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:54:50.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:54:50.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:54:50.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:54:50.918+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:54:50.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:54:50.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T11:55:21.275+0000] {processor.py:157} INFO - Started process (PID=46055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:55:21.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:55:21.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:55:21.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:55:21.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:55:21.299+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:55:21.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:55:21.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:55:21.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:55:21.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T11:55:51.698+0000] {processor.py:157} INFO - Started process (PID=46080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:55:51.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:55:51.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:55:51.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:55:51.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:55:51.727+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:55:51.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:55:51.737+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:55:51.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:55:51.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T11:56:22.177+0000] {processor.py:157} INFO - Started process (PID=46105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:56:22.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:56:22.187+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:56:22.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:56:22.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:56:22.207+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:56:22.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:56:22.217+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:56:22.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:56:22.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T11:56:52.650+0000] {processor.py:157} INFO - Started process (PID=46130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:56:52.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:56:52.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:56:52.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:56:52.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:56:52.677+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:56:52.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:56:52.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:56:52.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:56:52.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:57:23.144+0000] {processor.py:157} INFO - Started process (PID=46155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:57:23.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:57:23.146+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:57:23.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:57:23.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:57:23.170+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:57:23.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:57:23.182+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:57:23.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:57:23.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T11:57:53.640+0000] {processor.py:157} INFO - Started process (PID=46180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:57:53.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:57:53.644+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:57:53.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:57:53.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:57:53.680+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:57:53.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:57:53.693+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:57:53.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:57:53.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T11:58:24.148+0000] {processor.py:157} INFO - Started process (PID=46205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:58:24.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:58:24.151+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:58:24.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:58:24.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:58:24.179+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:58:24.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:58:24.190+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:58:24.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:58:24.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T11:58:54.540+0000] {processor.py:157} INFO - Started process (PID=46230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:58:54.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:58:54.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:58:54.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:58:54.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:58:54.567+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:58:54.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:58:54.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:58:54.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:58:54.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T11:59:25.027+0000] {processor.py:157} INFO - Started process (PID=46255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:59:25.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:59:25.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:59:25.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:59:25.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:59:25.058+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:59:25.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:59:25.068+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:59:25.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:59:25.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T11:59:55.500+0000] {processor.py:157} INFO - Started process (PID=46280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:59:55.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T11:59:55.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:59:55.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:59:55.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T11:59:55.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:59:55.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T11:59:55.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T11:59:55.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T11:59:55.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T12:00:25.929+0000] {processor.py:157} INFO - Started process (PID=46305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:00:25.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:00:25.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:00:25.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:00:25.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:00:25.958+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:00:25.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:00:25.967+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:00:25.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:00:25.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:00:56.350+0000] {processor.py:157} INFO - Started process (PID=46330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:00:56.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:00:56.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:00:56.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:00:56.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:00:56.377+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:00:56.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:00:56.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:00:56.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:00:56.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T12:01:26.895+0000] {processor.py:157} INFO - Started process (PID=46355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:01:26.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:01:26.901+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:01:26.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:01:26.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:01:26.924+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:01:26.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:01:26.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:01:26.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:01:26.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:01:57.334+0000] {processor.py:157} INFO - Started process (PID=46380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:01:57.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:01:57.339+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:01:57.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:01:57.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:01:57.368+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:01:57.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:01:57.381+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:01:57.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:01:57.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T12:02:27.744+0000] {processor.py:157} INFO - Started process (PID=46405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:02:27.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:02:27.747+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:02:27.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:02:27.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:02:27.774+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:02:27.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:02:27.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:02:27.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:02:27.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:02:58.221+0000] {processor.py:157} INFO - Started process (PID=46430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:02:58.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:02:58.224+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:02:58.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:02:58.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:02:58.257+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:02:58.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:02:58.268+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:02:58.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:02:58.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T12:03:28.736+0000] {processor.py:157} INFO - Started process (PID=46455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:03:28.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:03:28.741+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:03:28.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:03:28.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:03:28.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:03:28.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:03:28.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:03:28.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:03:28.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T12:03:59.214+0000] {processor.py:157} INFO - Started process (PID=46480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:03:59.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:03:59.222+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:03:59.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:03:59.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:03:59.242+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:03:59.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:03:59.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:03:59.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:03:59.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T12:04:29.792+0000] {processor.py:157} INFO - Started process (PID=46505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:04:29.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:04:29.795+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:04:29.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:04:29.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:04:29.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:04:29.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:04:29.832+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:04:29.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:04:29.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T12:05:00.262+0000] {processor.py:157} INFO - Started process (PID=46530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:05:00.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:05:00.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:05:00.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:05:00.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:05:00.289+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:05:00.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:05:00.299+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:05:00.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:05:00.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T12:05:30.715+0000] {processor.py:157} INFO - Started process (PID=46555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:05:30.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:05:30.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:05:30.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:05:30.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:05:30.753+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:05:30.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:05:30.763+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:05:30.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:05:30.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T12:06:01.150+0000] {processor.py:157} INFO - Started process (PID=46580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:06:01.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:06:01.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:06:01.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:06:01.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:06:01.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:06:01.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:06:01.190+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:06:01.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:06:01.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T12:06:31.674+0000] {processor.py:157} INFO - Started process (PID=46605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:06:31.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:06:31.676+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:06:31.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:06:31.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:06:31.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:06:31.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:06:31.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:06:31.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:06:31.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:07:02.184+0000] {processor.py:157} INFO - Started process (PID=46630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:07:02.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:07:02.188+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:07:02.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:07:02.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:07:02.214+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:07:02.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:07:02.226+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:07:02.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:07:02.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:07:32.679+0000] {processor.py:157} INFO - Started process (PID=46655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:07:32.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:07:32.683+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:07:32.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:07:32.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:07:32.709+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:07:32.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:07:32.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:07:32.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:07:32.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:08:03.055+0000] {processor.py:157} INFO - Started process (PID=46680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:08:03.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:08:03.058+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:08:03.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:08:03.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:08:03.085+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:08:03.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:08:03.098+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:08:03.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:08:03.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T12:08:33.632+0000] {processor.py:157} INFO - Started process (PID=46705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:08:33.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:08:33.635+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:08:33.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:08:33.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:08:33.663+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:08:33.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:08:33.673+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:08:33.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:08:33.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T12:09:04.086+0000] {processor.py:157} INFO - Started process (PID=46730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:09:04.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:09:04.093+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:09:04.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:09:04.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:09:04.120+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:09:04.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:09:04.130+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:09:04.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:09:04.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T12:09:34.585+0000] {processor.py:157} INFO - Started process (PID=46755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:09:34.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:09:34.589+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:09:34.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:09:34.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:09:34.614+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:09:34.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:09:34.626+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:09:34.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:09:34.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:10:05.061+0000] {processor.py:157} INFO - Started process (PID=46780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:10:05.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:10:05.063+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:10:05.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:10:05.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:10:05.090+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:10:05.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:10:05.102+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:10:05.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:10:05.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:10:35.623+0000] {processor.py:157} INFO - Started process (PID=46805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:10:35.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:10:35.627+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:10:35.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:10:35.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:10:35.660+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:10:35.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:10:35.671+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:10:35.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:10:35.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T12:11:06.107+0000] {processor.py:157} INFO - Started process (PID=46830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:11:06.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:11:06.112+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:11:06.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:11:06.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:11:06.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:11:06.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:11:06.156+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:11:06.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:11:06.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T12:11:36.701+0000] {processor.py:157} INFO - Started process (PID=46855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:11:36.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:11:36.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:11:36.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:11:36.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:11:36.733+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:11:36.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:11:36.742+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:11:36.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:11:36.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:12:07.168+0000] {processor.py:157} INFO - Started process (PID=46880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:12:07.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:12:07.175+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:12:07.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:12:07.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:12:07.192+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:12:07.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:12:07.200+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:12:07.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:12:07.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-21T12:12:37.693+0000] {processor.py:157} INFO - Started process (PID=46905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:12:37.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:12:37.701+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:12:37.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:12:37.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:12:37.721+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:12:37.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:12:37.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:12:37.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:12:37.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:13:08.135+0000] {processor.py:157} INFO - Started process (PID=46930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:13:08.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:13:08.140+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:13:08.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:13:08.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:13:08.179+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:13:08.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:13:08.190+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:13:08.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:13:08.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T12:13:38.656+0000] {processor.py:157} INFO - Started process (PID=46955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:13:38.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:13:38.663+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:13:38.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:13:38.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:13:38.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:13:38.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:13:38.697+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:13:38.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:13:38.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T12:14:09.172+0000] {processor.py:157} INFO - Started process (PID=46980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:14:09.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:14:09.180+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:14:09.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:14:09.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:14:09.221+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:14:09.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:14:09.249+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:14:09.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:14:09.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-21T12:14:39.761+0000] {processor.py:157} INFO - Started process (PID=47005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:14:39.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:14:39.764+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:14:39.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:14:39.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:14:39.791+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:14:39.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:14:39.800+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:14:39.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:14:39.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T12:15:10.253+0000] {processor.py:157} INFO - Started process (PID=47030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:15:10.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:15:10.261+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:15:10.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:15:10.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:15:10.283+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:15:10.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:15:10.293+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:15:10.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:15:10.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:15:40.807+0000] {processor.py:157} INFO - Started process (PID=47055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:15:40.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:15:40.811+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:15:40.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:15:40.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:15:40.847+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:15:40.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:15:40.859+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:15:40.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:15:40.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T12:16:11.263+0000] {processor.py:157} INFO - Started process (PID=47080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:16:11.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:16:11.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:16:11.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:16:11.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:16:11.289+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:16:11.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:16:11.299+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:16:11.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:16:11.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T12:16:41.735+0000] {processor.py:157} INFO - Started process (PID=47105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:16:41.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:16:41.738+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:16:41.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:16:41.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:16:41.770+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:16:41.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:16:41.781+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:16:41.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:16:41.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T12:17:12.303+0000] {processor.py:157} INFO - Started process (PID=47130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:17:12.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:17:12.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:17:12.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:17:12.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:17:12.344+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:17:12.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:17:12.356+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:17:12.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:17:12.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T12:17:42.905+0000] {processor.py:157} INFO - Started process (PID=47155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:17:42.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:17:42.911+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:17:42.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:17:42.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:17:42.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:17:42.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:17:42.952+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:17:42.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:17:42.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T12:18:13.339+0000] {processor.py:157} INFO - Started process (PID=47180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:18:13.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:18:13.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:18:13.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:18:13.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:18:13.365+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:18:13.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:18:13.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:18:13.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:18:13.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T12:18:43.867+0000] {processor.py:157} INFO - Started process (PID=47205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:18:43.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:18:43.875+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:18:43.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:18:43.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:18:43.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:18:43.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:18:43.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:18:43.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:18:43.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T12:19:14.392+0000] {processor.py:157} INFO - Started process (PID=47230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:19:14.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:19:14.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:19:14.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:19:14.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:19:14.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:19:14.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:19:14.433+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:19:14.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:19:14.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:19:44.910+0000] {processor.py:157} INFO - Started process (PID=47255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:19:44.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:19:44.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:19:44.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:19:44.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:19:44.937+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:19:44.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:19:44.947+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:19:44.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:19:44.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T12:20:15.926+0000] {processor.py:157} INFO - Started process (PID=47280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:20:15.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:20:15.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:20:15.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:20:15.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:20:15.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:20:15.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:20:15.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:20:15.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:20:16.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-21T12:21:33.494+0000] {processor.py:157} INFO - Started process (PID=47307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:21:33.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:21:33.496+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:21:33.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:21:33.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:21:33.531+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:21:33.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:21:33.543+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:21:33.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:21:33.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T12:22:03.987+0000] {processor.py:157} INFO - Started process (PID=47332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:22:03.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:22:03.991+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:22:03.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:22:04.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:22:04.021+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:22:04.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:22:04.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:22:04.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:22:04.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T12:22:34.445+0000] {processor.py:157} INFO - Started process (PID=47356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:22:34.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:22:34.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:22:34.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:22:34.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:22:34.502+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:22:34.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:22:34.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:22:34.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:22:34.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-21T12:23:04.954+0000] {processor.py:157} INFO - Started process (PID=47382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:23:04.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:23:04.957+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:23:04.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:23:04.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:23:04.985+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:23:04.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:23:04.997+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:23:04.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:23:05.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T12:23:35.397+0000] {processor.py:157} INFO - Started process (PID=47407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:23:35.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:23:35.400+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:23:35.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:23:35.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:23:35.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:23:35.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:23:35.438+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:23:35.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:23:35.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T12:24:05.840+0000] {processor.py:157} INFO - Started process (PID=47432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:24:05.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:24:05.843+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:24:05.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:24:05.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:24:05.875+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:24:05.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:24:05.884+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:24:05.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:24:05.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T12:24:36.287+0000] {processor.py:157} INFO - Started process (PID=47457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:24:36.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:24:36.326+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:24:36.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:24:36.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:24:36.410+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:24:36.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:24:36.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:24:36.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:24:36.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-21T12:25:06.802+0000] {processor.py:157} INFO - Started process (PID=47482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:25:06.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:25:06.805+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:25:06.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:25:06.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:25:06.831+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:25:06.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:25:06.842+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:25:06.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:25:06.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T12:25:37.243+0000] {processor.py:157} INFO - Started process (PID=47507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:25:37.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:25:37.247+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:25:37.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:25:37.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:25:37.276+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:25:37.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:25:37.286+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:25:37.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:25:37.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:26:07.789+0000] {processor.py:157} INFO - Started process (PID=47532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:26:07.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:26:07.795+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:26:07.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:26:07.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:26:07.828+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:26:07.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:26:07.839+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:26:07.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:26:07.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T12:26:38.259+0000] {processor.py:157} INFO - Started process (PID=47557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:26:38.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:26:38.263+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:26:38.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:26:38.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:26:38.293+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:26:38.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:26:38.307+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:26:38.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:26:38.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T12:27:08.778+0000] {processor.py:157} INFO - Started process (PID=47582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:27:08.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:27:08.781+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:27:08.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:27:08.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:27:08.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:27:08.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:27:08.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:27:08.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:27:08.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T12:27:39.189+0000] {processor.py:157} INFO - Started process (PID=47607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:27:39.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:27:39.192+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:27:39.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:27:39.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:27:39.217+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:27:39.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:27:39.229+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:27:39.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:27:39.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T12:28:09.605+0000] {processor.py:157} INFO - Started process (PID=47632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:28:09.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:28:09.608+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:28:09.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:28:09.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:28:09.636+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:28:09.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:28:09.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:28:09.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:28:09.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:28:40.123+0000] {processor.py:157} INFO - Started process (PID=47657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:28:40.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:28:40.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:28:40.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:28:40.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:28:40.157+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:28:40.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:28:40.166+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:28:40.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:28:40.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T12:29:10.514+0000] {processor.py:157} INFO - Started process (PID=47682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:29:10.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:29:10.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:29:10.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:29:10.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:29:10.546+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:29:10.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:29:10.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:29:10.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:29:10.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:29:41.027+0000] {processor.py:157} INFO - Started process (PID=47707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:29:41.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:29:41.034+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:29:41.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:29:41.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:29:41.084+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:29:41.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:29:41.103+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:29:41.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:29:41.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-21T12:30:11.504+0000] {processor.py:157} INFO - Started process (PID=47732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:30:11.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:30:11.508+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:30:11.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:30:11.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:30:11.536+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:30:11.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:30:11.548+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:30:11.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:30:11.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T12:30:42.005+0000] {processor.py:157} INFO - Started process (PID=47757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:30:42.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:30:42.013+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:30:42.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:30:42.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:30:42.063+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:30:42.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:30:42.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:30:42.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:30:42.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-21T12:31:12.467+0000] {processor.py:157} INFO - Started process (PID=47782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:31:12.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:31:12.470+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:31:12.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:31:12.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:31:12.498+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:31:12.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:31:12.507+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:31:12.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:31:12.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:31:43.029+0000] {processor.py:157} INFO - Started process (PID=47807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:31:43.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:31:43.037+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:31:43.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:31:43.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:31:43.092+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:31:43.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:31:43.104+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:31:43.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:31:43.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-21T12:32:13.549+0000] {processor.py:157} INFO - Started process (PID=47832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:32:13.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:32:13.553+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:32:13.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:32:13.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:32:13.608+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:32:13.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:32:13.624+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:32:13.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:32:13.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-21T12:32:44.089+0000] {processor.py:157} INFO - Started process (PID=47857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:32:44.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:32:44.096+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:32:44.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:32:44.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:32:44.135+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:32:44.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:32:44.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:32:44.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:32:44.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T12:33:14.493+0000] {processor.py:157} INFO - Started process (PID=47882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:33:14.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:33:14.496+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:33:14.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:33:14.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:33:14.524+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:33:14.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:33:14.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:33:14.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:33:14.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:33:45.021+0000] {processor.py:157} INFO - Started process (PID=47907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:33:45.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:33:45.028+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:33:45.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:33:45.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:33:45.069+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:33:45.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:33:45.083+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:33:45.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:33:45.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-21T12:34:15.456+0000] {processor.py:157} INFO - Started process (PID=47932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:34:15.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:34:15.460+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:34:15.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:34:15.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:34:15.485+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:34:15.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:34:15.494+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:34:15.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:34:15.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T12:34:45.916+0000] {processor.py:157} INFO - Started process (PID=47956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:34:45.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:34:45.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:34:45.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:34:45.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:34:45.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:34:45.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:34:45.978+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:34:45.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:34:45.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T12:35:16.462+0000] {processor.py:157} INFO - Started process (PID=47982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:35:16.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:35:16.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:35:16.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:35:16.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:35:16.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:35:16.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:35:16.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:35:16.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:35:16.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T12:35:46.872+0000] {processor.py:157} INFO - Started process (PID=48007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:35:46.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:35:46.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:35:46.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:35:46.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:35:47.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:35:47.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:35:47.035+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:35:47.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:35:47.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-21T12:36:17.556+0000] {processor.py:157} INFO - Started process (PID=48032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:36:17.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:36:17.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:36:17.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:36:17.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:36:17.654+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:36:17.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:36:17.701+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:36:17.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:36:17.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-21T12:36:48.042+0000] {processor.py:157} INFO - Started process (PID=48057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:36:48.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:36:48.046+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:36:48.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:36:48.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:36:48.076+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:36:48.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:36:48.087+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:36:48.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:36:48.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T12:37:18.469+0000] {processor.py:157} INFO - Started process (PID=48082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:37:18.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:37:18.474+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:37:18.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:37:18.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:37:18.507+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:37:18.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:37:18.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:37:18.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:37:18.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T12:37:48.992+0000] {processor.py:157} INFO - Started process (PID=48107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:37:48.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:37:48.999+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:37:48.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:37:49.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:37:49.032+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:37:49.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:37:49.044+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:37:49.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:37:49.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T12:38:19.515+0000] {processor.py:157} INFO - Started process (PID=48132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:38:19.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:38:19.523+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:38:19.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:38:19.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:38:19.587+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:38:19.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:38:19.607+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:38:19.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:38:19.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-21T12:38:49.972+0000] {processor.py:157} INFO - Started process (PID=48157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:38:49.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:38:49.973+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:38:49.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:38:49.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:38:50.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:38:49.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:38:50.009+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:38:50.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:38:50.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T12:39:20.520+0000] {processor.py:157} INFO - Started process (PID=48181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:39:20.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:39:20.526+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:39:20.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:39:20.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:39:20.568+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:39:20.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:39:20.594+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:39:20.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:39:20.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-21T12:39:51.010+0000] {processor.py:157} INFO - Started process (PID=48207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:39:51.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:39:51.018+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:39:51.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:39:51.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:39:51.057+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:39:51.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:39:51.071+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:39:51.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:39:51.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T12:40:21.539+0000] {processor.py:157} INFO - Started process (PID=48232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:40:21.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:40:21.544+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:40:21.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:40:21.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:40:21.575+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:40:21.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:40:21.586+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:40:21.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:40:21.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T12:40:52.039+0000] {processor.py:157} INFO - Started process (PID=48257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:40:52.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:40:52.052+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:40:52.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:40:52.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:40:52.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:40:52.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:40:52.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:40:52.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:40:52.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-21T12:41:22.689+0000] {processor.py:157} INFO - Started process (PID=48282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:41:22.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:41:22.707+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:41:22.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:41:22.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:41:22.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:41:22.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:41:22.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:41:22.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:41:22.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-21T12:41:53.156+0000] {processor.py:157} INFO - Started process (PID=48307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:41:53.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:41:53.158+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:41:53.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:41:53.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:41:53.191+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:41:53.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:41:53.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:41:53.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:41:53.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T12:42:23.549+0000] {processor.py:157} INFO - Started process (PID=48332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:42:23.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:42:23.551+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:42:23.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:42:23.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:42:23.582+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:42:23.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:42:23.594+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:42:23.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:42:23.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T12:42:53.927+0000] {processor.py:157} INFO - Started process (PID=48357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:42:53.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:42:53.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:42:53.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:42:53.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:42:53.959+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:42:53.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:42:53.969+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:42:53.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:42:53.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T12:43:24.416+0000] {processor.py:157} INFO - Started process (PID=48382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:43:24.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:43:24.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:43:24.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:43:24.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:43:24.458+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:43:24.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:43:24.471+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:43:24.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:43:24.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T12:43:55.077+0000] {processor.py:157} INFO - Started process (PID=48407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:43:55.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:43:55.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:43:55.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:43:55.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:43:55.112+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:43:55.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:43:55.124+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:43:55.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:43:55.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T12:44:25.557+0000] {processor.py:157} INFO - Started process (PID=48432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:44:25.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:44:25.562+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:44:25.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:44:25.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:44:25.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:44:25.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:44:25.610+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:44:25.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:44:25.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T12:44:55.958+0000] {processor.py:157} INFO - Started process (PID=48457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:44:55.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:44:55.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:44:55.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:44:55.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:44:55.989+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:44:55.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:44:55.999+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:44:55.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:44:56.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:45:26.447+0000] {processor.py:157} INFO - Started process (PID=48482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:45:26.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:45:26.452+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:45:26.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:45:26.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:45:26.494+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:45:26.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:45:26.507+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:45:26.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:45:26.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-21T12:45:56.904+0000] {processor.py:157} INFO - Started process (PID=48507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:45:56.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:45:56.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:45:56.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:45:56.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:45:56.941+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:45:56.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:45:56.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:45:56.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:45:56.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T12:46:27.314+0000] {processor.py:157} INFO - Started process (PID=48532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:46:27.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:46:27.320+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:46:27.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:46:27.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:46:27.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:46:27.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:46:27.396+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:46:27.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:46:27.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-21T12:46:57.830+0000] {processor.py:157} INFO - Started process (PID=48557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:46:57.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:46:57.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:46:57.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:46:57.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:46:57.868+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:46:57.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:46:57.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:46:57.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:46:57.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T12:47:28.279+0000] {processor.py:157} INFO - Started process (PID=48581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:47:28.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:47:28.285+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:47:28.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:47:28.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:47:28.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:47:28.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:47:28.344+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:47:28.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:47:28.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T12:47:58.767+0000] {processor.py:157} INFO - Started process (PID=48607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:47:58.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:47:58.772+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:47:58.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:47:58.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:47:58.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:47:58.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:47:58.814+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:47:58.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:47:58.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T12:48:29.130+0000] {processor.py:157} INFO - Started process (PID=48632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:48:29.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:48:29.135+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:48:29.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:48:29.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:48:29.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:48:29.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:48:29.184+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:48:29.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:48:29.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T12:48:59.648+0000] {processor.py:157} INFO - Started process (PID=48656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:48:59.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:48:59.652+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:48:59.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:48:59.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:48:59.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:48:59.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:48:59.709+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:48:59.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:48:59.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T12:49:30.072+0000] {processor.py:157} INFO - Started process (PID=48682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:49:30.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:49:30.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:49:30.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:49:30.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:49:30.104+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:49:30.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:49:30.116+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:49:30.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:49:30.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T12:50:00.446+0000] {processor.py:157} INFO - Started process (PID=48707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:50:00.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:50:00.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:50:00.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:50:00.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:50:00.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:50:00.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:50:00.494+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:50:00.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:50:00.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T12:50:30.922+0000] {processor.py:157} INFO - Started process (PID=48732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:50:30.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:50:30.928+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:50:30.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:50:30.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:50:30.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:50:30.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:50:31.002+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:50:31.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:50:31.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-21T12:51:01.413+0000] {processor.py:157} INFO - Started process (PID=48757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:51:01.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:51:01.416+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:51:01.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:51:01.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:51:01.446+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:51:01.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:51:01.457+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:51:01.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:51:01.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T12:51:31.816+0000] {processor.py:157} INFO - Started process (PID=48782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:51:31.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:51:31.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:51:31.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:51:31.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:51:31.861+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:51:31.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:51:31.875+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:51:31.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:51:31.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T12:52:02.200+0000] {processor.py:157} INFO - Started process (PID=48807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:52:02.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:52:02.206+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:52:02.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:52:02.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:52:02.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:52:02.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:52:02.258+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:52:02.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:52:02.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T12:52:32.666+0000] {processor.py:157} INFO - Started process (PID=48832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:52:32.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:52:32.671+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:52:32.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:52:32.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:52:32.708+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:52:32.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:52:32.722+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:52:32.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:52:32.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T12:53:03.132+0000] {processor.py:157} INFO - Started process (PID=48857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:53:03.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:53:03.135+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:53:03.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:53:03.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:53:03.173+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:53:03.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:53:03.187+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:53:03.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:53:03.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T12:53:33.659+0000] {processor.py:157} INFO - Started process (PID=48882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:53:33.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:53:33.662+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:53:33.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:53:33.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:53:33.690+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:53:33.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:53:33.700+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:53:33.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:53:33.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T12:54:04.150+0000] {processor.py:157} INFO - Started process (PID=48907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:54:04.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:54:04.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:54:04.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:54:04.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:54:04.190+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:54:04.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:54:04.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:54:04.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:54:04.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T12:54:34.625+0000] {processor.py:157} INFO - Started process (PID=48932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:54:34.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:54:34.629+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:54:34.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:54:34.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:54:34.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:54:34.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:54:34.665+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:54:34.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:54:34.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T12:55:05.105+0000] {processor.py:157} INFO - Started process (PID=48957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:55:05.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:55:05.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:55:05.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:55:05.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:55:05.136+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:55:05.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:55:05.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:55:05.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:55:05.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T12:55:35.678+0000] {processor.py:157} INFO - Started process (PID=48982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:55:35.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:55:35.692+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:55:35.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:55:35.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:55:35.783+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:55:35.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:55:35.802+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:55:35.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:55:35.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-21T12:56:06.320+0000] {processor.py:157} INFO - Started process (PID=49007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:56:06.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:56:06.326+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:56:06.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:56:06.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:56:06.376+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:56:06.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:56:06.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:56:06.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:56:06.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-21T12:56:36.835+0000] {processor.py:157} INFO - Started process (PID=49032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:56:36.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:56:36.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:56:36.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:56:36.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:56:36.864+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:56:36.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:56:36.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:56:36.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:56:36.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T12:57:07.297+0000] {processor.py:157} INFO - Started process (PID=49057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:57:07.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:57:07.299+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:57:07.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:57:07.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:57:07.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:57:07.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:57:07.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:57:07.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:57:07.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T12:57:37.744+0000] {processor.py:157} INFO - Started process (PID=49082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:57:37.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:57:37.747+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:57:37.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:57:37.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:57:37.776+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:57:37.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:57:37.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:57:37.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:57:37.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T12:58:08.217+0000] {processor.py:157} INFO - Started process (PID=49107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:58:08.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:58:08.222+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:58:08.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:58:08.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:58:08.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:58:08.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:58:08.261+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:58:08.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:58:08.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T12:58:38.622+0000] {processor.py:157} INFO - Started process (PID=49132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:58:38.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:58:38.625+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:58:38.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:58:38.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:58:38.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:58:38.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:58:38.829+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:58:38.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:58:38.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-07-21T12:59:09.220+0000] {processor.py:157} INFO - Started process (PID=49157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:59:09.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:59:09.226+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:59:09.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:59:09.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:59:09.269+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:59:09.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:59:09.282+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:59:09.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:59:09.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-21T12:59:39.658+0000] {processor.py:157} INFO - Started process (PID=49182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:59:39.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T12:59:39.660+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:59:39.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:59:39.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T12:59:39.691+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:59:39.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T12:59:39.701+0000] {logging_mixin.py:151} INFO - [2024-07-21T12:59:39.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T12:59:39.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:00:10.139+0000] {processor.py:157} INFO - Started process (PID=49207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:00:10.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:00:10.142+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:00:10.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:00:10.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:00:10.172+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:00:10.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:00:10.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:00:10.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:00:10.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:00:40.550+0000] {processor.py:157} INFO - Started process (PID=49232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:00:40.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:00:40.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:00:40.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:00:40.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:00:40.584+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:00:40.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:00:40.595+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:00:40.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:00:40.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:01:11.052+0000] {processor.py:157} INFO - Started process (PID=49257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:01:11.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:01:11.055+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:01:11.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:01:11.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:01:11.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:01:11.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:01:11.106+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:01:11.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:01:11.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T13:01:41.547+0000] {processor.py:157} INFO - Started process (PID=49282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:01:41.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:01:41.554+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:01:41.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:01:41.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:01:41.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:01:41.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:01:41.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:01:41.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:01:41.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T13:02:12.076+0000] {processor.py:157} INFO - Started process (PID=49307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:02:12.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:02:12.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:02:12.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:02:12.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:02:12.109+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:02:12.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:02:12.120+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:02:12.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:02:12.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:02:42.450+0000] {processor.py:157} INFO - Started process (PID=49332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:02:42.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:02:42.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:02:42.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:02:42.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:02:42.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:02:42.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:02:42.491+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:02:42.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:02:42.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:03:12.948+0000] {processor.py:157} INFO - Started process (PID=49357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:03:12.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:03:12.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:03:12.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:03:12.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:03:12.978+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:03:12.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:03:12.989+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:03:12.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:03:12.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:03:43.397+0000] {processor.py:157} INFO - Started process (PID=49382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:03:43.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:03:43.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:03:43.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:03:43.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:03:43.433+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:03:43.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:03:43.446+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:03:43.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:03:43.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T13:04:13.912+0000] {processor.py:157} INFO - Started process (PID=49407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:04:13.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:04:13.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:04:13.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:04:13.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:04:13.938+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:04:13.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:04:13.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:04:13.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:04:13.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T13:04:44.398+0000] {processor.py:157} INFO - Started process (PID=49432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:04:44.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:04:44.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:04:44.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:04:44.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:04:44.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:04:44.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:04:44.442+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:04:44.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:04:44.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:05:14.865+0000] {processor.py:157} INFO - Started process (PID=49457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:05:14.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:05:14.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:05:14.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:05:14.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:05:14.901+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:05:14.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:05:14.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:05:14.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:05:14.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T13:05:45.352+0000] {processor.py:157} INFO - Started process (PID=49482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:05:45.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:05:45.356+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:05:45.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:05:45.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:05:45.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:05:45.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:05:45.397+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:05:45.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:05:45.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:06:15.799+0000] {processor.py:157} INFO - Started process (PID=49507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:06:15.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:06:15.807+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:06:15.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:06:15.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:06:15.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:06:15.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:06:15.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:06:15.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:06:15.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-21T13:06:46.227+0000] {processor.py:157} INFO - Started process (PID=49532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:06:46.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:06:46.230+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:06:46.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:06:46.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:06:46.255+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:06:46.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:06:46.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:06:46.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:06:46.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T13:07:16.652+0000] {processor.py:157} INFO - Started process (PID=49557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:07:16.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:07:16.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:07:16.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:07:16.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:07:16.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:07:16.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:07:16.698+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:07:16.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:07:16.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T13:07:47.014+0000] {processor.py:157} INFO - Started process (PID=49582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:07:47.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:07:47.016+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:07:47.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:07:47.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:07:47.042+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:07:47.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:07:47.051+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:07:47.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:07:47.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:08:17.488+0000] {processor.py:157} INFO - Started process (PID=49607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:08:17.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:08:17.492+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:08:17.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:08:17.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:08:17.519+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:08:17.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:08:17.528+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:08:17.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:08:17.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T13:08:47.936+0000] {processor.py:157} INFO - Started process (PID=49632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:08:47.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:08:47.941+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:08:47.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:08:47.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:08:47.967+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:08:47.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:08:47.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:08:47.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:08:47.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:09:18.422+0000] {processor.py:157} INFO - Started process (PID=49657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:09:18.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:09:18.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:09:18.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:09:18.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:09:18.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:09:18.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:09:18.464+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:09:18.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:09:18.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:09:48.888+0000] {processor.py:157} INFO - Started process (PID=49682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:09:48.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:09:48.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:09:48.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:09:48.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:09:48.922+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:09:48.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:09:48.932+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:09:48.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:09:48.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:10:19.239+0000] {processor.py:157} INFO - Started process (PID=49707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:10:19.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:10:19.241+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:10:19.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:10:19.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:10:19.268+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:10:19.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:10:19.279+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:10:19.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:10:19.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:10:49.655+0000] {processor.py:157} INFO - Started process (PID=49732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:10:49.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:10:49.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:10:49.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:10:49.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:10:49.678+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:10:49.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:10:49.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:10:49.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:10:49.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T13:11:20.152+0000] {processor.py:157} INFO - Started process (PID=49757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:11:20.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:11:20.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:11:20.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:11:20.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:11:20.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:11:20.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:11:20.192+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:11:20.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:11:20.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:11:50.558+0000] {processor.py:157} INFO - Started process (PID=49782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:11:50.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:11:50.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:11:50.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:11:50.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:11:50.588+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:11:50.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:11:50.598+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:11:50.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:11:50.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:12:20.944+0000] {processor.py:157} INFO - Started process (PID=49807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:12:20.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:12:20.946+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:12:20.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:12:20.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:12:20.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:12:20.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:12:20.985+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:12:20.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:12:20.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:12:51.362+0000] {processor.py:157} INFO - Started process (PID=49832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:12:51.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:12:51.365+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:12:51.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:12:51.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:12:51.391+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:12:51.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:12:51.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:12:51.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:12:51.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:13:21.783+0000] {processor.py:157} INFO - Started process (PID=49857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:13:21.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:13:21.787+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:13:21.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:13:21.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:13:21.816+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:13:21.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:13:21.826+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:13:21.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:13:21.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:13:52.242+0000] {processor.py:157} INFO - Started process (PID=49882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:13:52.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:13:52.247+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:13:52.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:13:52.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:13:52.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:13:52.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:13:52.285+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:13:52.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:13:52.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:14:22.728+0000] {processor.py:157} INFO - Started process (PID=49907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:14:22.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:14:22.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:14:22.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:14:22.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:14:22.757+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:14:22.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:14:22.767+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:14:22.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:14:22.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:14:53.156+0000] {processor.py:157} INFO - Started process (PID=49932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:14:53.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:14:53.159+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:14:53.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:14:53.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:14:53.189+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:14:53.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:14:53.198+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:14:53.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:14:53.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:15:23.673+0000] {processor.py:157} INFO - Started process (PID=49957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:15:23.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:15:23.676+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:15:23.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:15:23.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:15:23.703+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:15:23.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:15:23.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:15:23.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:15:23.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:15:54.016+0000] {processor.py:157} INFO - Started process (PID=49982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:15:54.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:15:54.021+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:15:54.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:15:54.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:15:54.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:15:54.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:15:54.059+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:15:54.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:15:54.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:16:24.409+0000] {processor.py:157} INFO - Started process (PID=50007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:16:24.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:16:24.412+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:16:24.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:16:24.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:16:24.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:16:24.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:16:24.450+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:16:24.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:16:24.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:16:54.833+0000] {processor.py:157} INFO - Started process (PID=50032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:16:54.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:16:54.836+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:16:54.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:16:54.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:16:54.861+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:16:54.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:16:54.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:16:54.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:16:54.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T13:17:25.281+0000] {processor.py:157} INFO - Started process (PID=50057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:17:25.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:17:25.286+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:17:25.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:17:25.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:17:25.314+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:17:25.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:17:25.326+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:17:25.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:17:25.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:17:55.774+0000] {processor.py:157} INFO - Started process (PID=50082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:17:55.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:17:55.777+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:17:55.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:17:55.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:17:55.806+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:17:55.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:17:55.816+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:17:55.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:17:55.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:18:26.322+0000] {processor.py:157} INFO - Started process (PID=50107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:18:26.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:18:26.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:18:26.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:18:26.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:18:26.354+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:18:26.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:18:26.363+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:18:26.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:18:26.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:18:56.837+0000] {processor.py:157} INFO - Started process (PID=50132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:18:56.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:18:56.842+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:18:56.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:18:56.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:18:56.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:18:56.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:18:56.891+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:18:56.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:18:56.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T13:19:27.350+0000] {processor.py:157} INFO - Started process (PID=50157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:19:27.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:19:27.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:19:27.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:19:27.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:19:27.380+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:19:27.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:19:27.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:19:27.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:19:27.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T13:19:57.813+0000] {processor.py:157} INFO - Started process (PID=50182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:19:57.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:19:57.815+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:19:57.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:19:57.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:19:57.844+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:19:57.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:19:57.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:19:57.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:19:57.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:20:28.197+0000] {processor.py:157} INFO - Started process (PID=50207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:20:28.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:20:28.200+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:20:28.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:20:28.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:20:28.227+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:20:28.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:20:28.239+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:20:28.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:20:28.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:20:58.668+0000] {processor.py:157} INFO - Started process (PID=50232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:20:58.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:20:58.672+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:20:58.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:20:58.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:20:58.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:20:58.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:20:58.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:20:58.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:20:58.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T13:21:29.077+0000] {processor.py:157} INFO - Started process (PID=50257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:21:29.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:21:29.079+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:21:29.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:21:29.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:21:29.103+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:21:29.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:21:29.112+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:21:29.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:21:29.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T13:21:59.478+0000] {processor.py:157} INFO - Started process (PID=50282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:21:59.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:21:59.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:21:59.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:21:59.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:21:59.509+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:21:59.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:21:59.519+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:21:59.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:21:59.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:22:29.981+0000] {processor.py:157} INFO - Started process (PID=50307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:22:29.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:22:29.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:22:29.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:22:29.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:22:30.011+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:22:30.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:22:30.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:22:30.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:22:30.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:23:00.404+0000] {processor.py:157} INFO - Started process (PID=50332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:23:00.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:23:00.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:23:00.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:23:00.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:23:00.435+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:23:00.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:23:00.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:23:00.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:23:00.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:23:30.913+0000] {processor.py:157} INFO - Started process (PID=50357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:23:30.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:23:30.915+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:23:30.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:23:30.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:23:30.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:23:30.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:23:30.953+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:23:30.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:23:30.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:24:01.386+0000] {processor.py:157} INFO - Started process (PID=50382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:24:01.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:24:01.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:24:01.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:24:01.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:24:01.414+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:24:01.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:24:01.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:24:01.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:24:01.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T13:24:31.803+0000] {processor.py:157} INFO - Started process (PID=50407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:24:31.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:24:31.806+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:24:31.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:24:31.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:24:31.833+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:24:31.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:24:31.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:24:31.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:24:31.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:25:02.253+0000] {processor.py:157} INFO - Started process (PID=50432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:25:02.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:25:02.256+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:25:02.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:25:02.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:25:02.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:25:02.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:25:02.297+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:25:02.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:25:02.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:25:32.769+0000] {processor.py:157} INFO - Started process (PID=50457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:25:32.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:25:32.771+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:25:32.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:25:32.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:25:32.795+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:25:32.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:25:32.803+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:25:32.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:25:32.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T13:26:03.156+0000] {processor.py:157} INFO - Started process (PID=50482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:26:03.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:26:03.159+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:26:03.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:26:03.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:26:03.189+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:26:03.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:26:03.200+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:26:03.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:26:03.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:26:33.516+0000] {processor.py:157} INFO - Started process (PID=50507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:26:33.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:26:33.519+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:26:33.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:26:33.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:26:33.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:26:33.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:26:33.555+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:26:33.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:26:33.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:27:04.031+0000] {processor.py:157} INFO - Started process (PID=50532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:27:04.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:27:04.035+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:27:04.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:27:04.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:27:04.068+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:27:04.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:27:04.078+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:27:04.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:27:04.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T13:27:34.490+0000] {processor.py:157} INFO - Started process (PID=50557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:27:34.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:27:34.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:27:34.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:27:34.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:27:34.519+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:27:34.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:27:34.529+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:27:34.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:27:34.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:28:04.934+0000] {processor.py:157} INFO - Started process (PID=50582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:28:04.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:28:04.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:28:04.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:28:04.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:28:04.968+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:28:04.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:28:04.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:28:04.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:28:04.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:28:35.392+0000] {processor.py:157} INFO - Started process (PID=50607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:28:35.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:28:35.395+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:28:35.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:28:35.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:28:35.424+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:28:35.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:28:35.435+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:28:35.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:28:35.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:29:05.823+0000] {processor.py:157} INFO - Started process (PID=50632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:29:05.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:29:05.829+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:29:05.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:29:05.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:29:05.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:29:05.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:29:05.866+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:29:05.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:29:05.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:29:36.303+0000] {processor.py:157} INFO - Started process (PID=50657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:29:36.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:29:36.305+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:29:36.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:29:36.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:29:36.333+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:29:36.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:29:36.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:29:36.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:29:36.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:30:06.717+0000] {processor.py:157} INFO - Started process (PID=50682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:30:06.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:30:06.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:30:06.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:30:06.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:30:06.750+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:30:06.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:30:06.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:30:06.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:30:06.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:30:37.236+0000] {processor.py:157} INFO - Started process (PID=50707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:30:37.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:30:37.239+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:30:37.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:30:37.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:30:37.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:30:37.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:30:37.279+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:30:37.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:30:37.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:31:07.607+0000] {processor.py:157} INFO - Started process (PID=50732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:31:07.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:31:07.610+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:31:07.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:31:07.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:31:07.636+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:31:07.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:31:07.645+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:31:07.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:31:07.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T13:31:38.007+0000] {processor.py:157} INFO - Started process (PID=50757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:31:38.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:31:38.010+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:31:38.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:31:38.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:31:38.036+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:31:38.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:31:38.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:31:38.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:31:38.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:32:08.528+0000] {processor.py:157} INFO - Started process (PID=50782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:32:08.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:32:08.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:32:08.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:32:08.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:32:08.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:32:08.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:32:08.573+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:32:08.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:32:08.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T13:32:38.936+0000] {processor.py:157} INFO - Started process (PID=50807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:32:38.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:32:38.945+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:32:38.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:32:38.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:32:38.972+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:32:38.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:32:38.982+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:32:38.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:32:38.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:33:09.434+0000] {processor.py:157} INFO - Started process (PID=50832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:33:09.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:33:09.436+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:33:09.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:33:09.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:33:09.464+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:33:09.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:33:09.472+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:33:09.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:33:09.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:33:39.958+0000] {processor.py:157} INFO - Started process (PID=50857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:33:39.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:33:39.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:33:39.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:33:39.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:33:40.003+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:33:40.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:33:40.013+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:33:40.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:33:40.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T13:34:10.478+0000] {processor.py:157} INFO - Started process (PID=50882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:34:10.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:34:10.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:34:10.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:34:10.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:34:10.513+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:34:10.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:34:10.528+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:34:10.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:34:10.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T13:34:40.879+0000] {processor.py:157} INFO - Started process (PID=50907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:34:40.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:34:40.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:34:40.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:34:40.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:34:40.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:34:40.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:34:40.925+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:34:40.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:34:40.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T13:35:11.300+0000] {processor.py:157} INFO - Started process (PID=50932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:35:11.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:35:11.302+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:35:11.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:35:11.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:35:11.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:35:11.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:35:11.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:35:11.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:35:11.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:35:41.705+0000] {processor.py:157} INFO - Started process (PID=50957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:35:41.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:35:41.708+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:35:41.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:35:41.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:35:41.738+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:35:41.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:35:41.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:35:41.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:35:41.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:36:12.161+0000] {processor.py:157} INFO - Started process (PID=50982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:36:12.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:36:12.165+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:36:12.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:36:12.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:36:12.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:36:12.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:36:12.206+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:36:12.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:36:12.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:36:42.618+0000] {processor.py:157} INFO - Started process (PID=51007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:36:42.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:36:42.622+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:36:42.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:36:42.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:36:42.650+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:36:42.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:36:42.660+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:36:42.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:36:42.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:37:13.038+0000] {processor.py:157} INFO - Started process (PID=51032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:37:13.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:37:13.040+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:37:13.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:37:13.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:37:13.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:37:13.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:37:13.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:37:13.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:37:13.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T13:37:43.457+0000] {processor.py:157} INFO - Started process (PID=51057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:37:43.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:37:43.459+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:37:43.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:37:43.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:37:43.489+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:37:43.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:37:43.501+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:37:43.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:37:43.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:38:13.915+0000] {processor.py:157} INFO - Started process (PID=51082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:38:13.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:38:13.918+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:38:13.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:38:13.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:38:13.949+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:38:13.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:38:13.960+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:38:13.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:38:13.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:38:44.378+0000] {processor.py:157} INFO - Started process (PID=51107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:38:44.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:38:44.382+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:38:44.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:38:44.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:38:44.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:38:44.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:38:44.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:38:44.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:38:44.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:39:14.893+0000] {processor.py:157} INFO - Started process (PID=51132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:39:14.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:39:14.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:39:14.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:39:14.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:39:14.922+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:39:14.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:39:14.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:39:14.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:39:14.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T13:39:45.488+0000] {processor.py:157} INFO - Started process (PID=51157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:39:45.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:39:45.494+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:39:45.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:39:45.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:39:45.529+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:39:45.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:39:45.541+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:39:45.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:39:45.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T13:40:16.018+0000] {processor.py:157} INFO - Started process (PID=51182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:40:16.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:40:16.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:40:16.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:40:16.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:40:16.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:40:16.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:40:16.061+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:40:16.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:40:16.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:40:46.441+0000] {processor.py:157} INFO - Started process (PID=51207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:40:46.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:40:46.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:40:46.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:40:46.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:40:46.473+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:40:46.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:40:46.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:40:46.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:40:46.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:41:16.904+0000] {processor.py:157} INFO - Started process (PID=51232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:41:16.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:41:16.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:41:16.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:41:16.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:41:16.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:41:16.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:41:16.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:41:16.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:41:16.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T13:41:47.310+0000] {processor.py:157} INFO - Started process (PID=51257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:41:47.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:41:47.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:41:47.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:41:47.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:41:47.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:41:47.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:41:47.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:41:47.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:41:47.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:42:17.746+0000] {processor.py:157} INFO - Started process (PID=51282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:42:17.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:42:17.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:42:17.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:42:17.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:42:17.776+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:42:17.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:42:17.786+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:42:17.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:42:17.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:42:48.227+0000] {processor.py:157} INFO - Started process (PID=51307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:42:48.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:42:48.229+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:42:48.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:42:48.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:42:48.253+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:42:48.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:42:48.266+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:42:48.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:42:48.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T13:43:18.660+0000] {processor.py:157} INFO - Started process (PID=51332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:43:18.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:43:18.663+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:43:18.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:43:18.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:43:18.688+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:43:18.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:43:18.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:43:18.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:43:18.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:43:49.202+0000] {processor.py:157} INFO - Started process (PID=51357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:43:49.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:43:49.206+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:43:49.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:43:49.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:43:49.234+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:43:49.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:43:49.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:43:49.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:43:49.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:44:19.713+0000] {processor.py:157} INFO - Started process (PID=51382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:44:19.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:44:19.716+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:44:19.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:44:19.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:44:19.743+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:44:19.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:44:19.753+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:44:19.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:44:19.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:44:50.234+0000] {processor.py:157} INFO - Started process (PID=51407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:44:50.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:44:50.238+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:44:50.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:44:50.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:44:50.264+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:44:50.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:44:50.273+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:44:50.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:44:50.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T13:45:20.635+0000] {processor.py:157} INFO - Started process (PID=51432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:45:20.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:45:20.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:45:20.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:45:20.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:45:20.670+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:45:20.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:45:20.679+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:45:20.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:45:20.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:45:51.104+0000] {processor.py:157} INFO - Started process (PID=51457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:45:51.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:45:51.106+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:45:51.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:45:51.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:45:51.131+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:45:51.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:45:51.141+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:45:51.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:45:51.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T13:46:21.506+0000] {processor.py:157} INFO - Started process (PID=51482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:46:21.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:46:21.509+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:46:21.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:46:21.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:46:21.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:46:21.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:46:21.541+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:46:21.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:46:21.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T13:46:51.976+0000] {processor.py:157} INFO - Started process (PID=51507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:46:51.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:46:51.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:46:51.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:46:51.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:46:52.012+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:46:52.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:46:52.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:46:52.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:46:52.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:47:22.415+0000] {processor.py:157} INFO - Started process (PID=51532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:47:22.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:47:22.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:47:22.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:47:22.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:47:22.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:47:22.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:47:22.460+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:47:22.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:47:22.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:47:52.984+0000] {processor.py:157} INFO - Started process (PID=51557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:47:52.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:47:52.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:47:52.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:47:53.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:47:53.017+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:47:53.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:47:53.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:47:53.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:47:53.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T13:48:23.427+0000] {processor.py:157} INFO - Started process (PID=51582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:48:23.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:48:23.430+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:48:23.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:48:23.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:48:23.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:48:23.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:48:23.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:48:23.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:48:23.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:48:53.869+0000] {processor.py:157} INFO - Started process (PID=51607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:48:53.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:48:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:48:53.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:48:53.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:48:53.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:48:53.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:48:53.916+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:48:53.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:48:53.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:49:24.272+0000] {processor.py:157} INFO - Started process (PID=51632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:49:24.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:49:24.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:49:24.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:49:24.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:49:24.303+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:49:24.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:49:24.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:49:24.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:49:24.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:49:54.722+0000] {processor.py:157} INFO - Started process (PID=51657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:49:54.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:49:54.725+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:49:54.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:49:54.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:49:54.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:49:54.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:49:54.762+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:49:54.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:49:54.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T13:50:25.228+0000] {processor.py:157} INFO - Started process (PID=51682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:50:25.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:50:25.233+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:50:25.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:50:25.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:50:25.264+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:50:25.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:50:25.272+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:50:25.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:50:25.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T13:50:55.677+0000] {processor.py:157} INFO - Started process (PID=51707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:50:55.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:50:55.682+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:50:55.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:50:55.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:50:55.708+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:50:55.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:50:55.717+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:50:55.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:50:55.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T13:51:26.120+0000] {processor.py:157} INFO - Started process (PID=51732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:51:26.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:51:26.124+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:51:26.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:51:26.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:51:26.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:51:26.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:51:26.167+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:51:26.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:51:26.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T13:51:56.629+0000] {processor.py:157} INFO - Started process (PID=51757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:51:56.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:51:56.631+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:51:56.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:51:56.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:51:56.659+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:51:56.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:51:56.669+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:51:56.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:51:56.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:52:27.147+0000] {processor.py:157} INFO - Started process (PID=51782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:52:27.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:52:27.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:52:27.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:52:27.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:52:27.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:52:27.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:52:27.192+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:52:27.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:52:27.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T13:52:57.713+0000] {processor.py:157} INFO - Started process (PID=51807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:52:57.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:52:57.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:52:57.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:52:57.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:52:57.738+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:52:57.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:52:57.747+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:52:57.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:52:57.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T13:53:28.107+0000] {processor.py:157} INFO - Started process (PID=51832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:53:28.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:53:28.111+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:53:28.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:53:28.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:53:28.136+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:53:28.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:53:28.146+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:53:28.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:53:28.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T13:53:58.628+0000] {processor.py:157} INFO - Started process (PID=51857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:53:58.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:53:58.631+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:53:58.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:53:58.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:53:58.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:53:58.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:53:58.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:53:58.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:53:58.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T13:54:29.066+0000] {processor.py:157} INFO - Started process (PID=51882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:54:29.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:54:29.070+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:54:29.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:54:29.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:54:29.097+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:54:29.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:54:29.109+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:54:29.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:54:29.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T13:54:59.550+0000] {processor.py:157} INFO - Started process (PID=51907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:54:59.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:54:59.554+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:54:59.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:54:59.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:54:59.583+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:54:59.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:54:59.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:54:59.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:54:59.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:55:29.976+0000] {processor.py:157} INFO - Started process (PID=51932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:55:29.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:55:29.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:55:29.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:55:29.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:55:30.007+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:55:30.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:55:30.017+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:55:30.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:55:30.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T13:56:00.543+0000] {processor.py:157} INFO - Started process (PID=51957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:56:00.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:56:00.546+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:56:00.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:56:00.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:56:00.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:56:00.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:56:00.587+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:56:00.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:56:00.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:56:31.018+0000] {processor.py:157} INFO - Started process (PID=51982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:56:31.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:56:31.020+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:56:31.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:56:31.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:56:31.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:56:31.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:56:31.058+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:56:31.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:56:31.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:57:01.521+0000] {processor.py:157} INFO - Started process (PID=52007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:57:01.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:57:01.524+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:57:01.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:57:01.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:57:01.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:57:01.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:57:01.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:57:01.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:57:01.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T13:57:31.982+0000] {processor.py:157} INFO - Started process (PID=52032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:57:31.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:57:31.985+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:57:31.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:57:32.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:57:32.017+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:57:32.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:57:32.027+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:57:32.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:57:32.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T13:58:02.472+0000] {processor.py:157} INFO - Started process (PID=52057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:58:02.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:58:02.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:58:02.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:58:02.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:58:02.501+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:58:02.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:58:02.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:58:02.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:58:02.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T13:58:32.911+0000] {processor.py:157} INFO - Started process (PID=52082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:58:32.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:58:32.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:58:32.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:58:32.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:58:32.940+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:58:32.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:58:32.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:58:32.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:58:32.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T13:59:03.387+0000] {processor.py:157} INFO - Started process (PID=52107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:59:03.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:59:03.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:59:03.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:59:03.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:59:03.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:59:03.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:59:03.424+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:59:03.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:59:03.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T13:59:33.778+0000] {processor.py:157} INFO - Started process (PID=52132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:59:33.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T13:59:33.781+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:59:33.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:59:33.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T13:59:33.806+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:59:33.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T13:59:33.818+0000] {logging_mixin.py:151} INFO - [2024-07-21T13:59:33.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T13:59:33.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:00:04.267+0000] {processor.py:157} INFO - Started process (PID=52157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:00:04.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:00:04.270+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:00:04.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:00:04.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:00:04.297+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:00:04.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:00:04.307+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:00:04.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:00:04.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T14:00:34.743+0000] {processor.py:157} INFO - Started process (PID=52182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:00:34.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:00:34.746+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:00:34.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:00:34.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:00:34.770+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:00:34.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:00:34.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:00:34.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:00:34.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T14:01:05.214+0000] {processor.py:157} INFO - Started process (PID=52207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:01:05.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:01:05.219+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:01:05.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:01:05.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:01:05.246+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:01:05.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:01:05.259+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:01:05.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:01:05.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:01:35.702+0000] {processor.py:157} INFO - Started process (PID=52232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:01:35.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:01:35.707+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:01:35.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:01:35.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:01:35.733+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:01:35.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:01:35.745+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:01:35.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:01:35.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:02:06.154+0000] {processor.py:157} INFO - Started process (PID=52257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:02:06.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:02:06.158+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:02:06.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:02:06.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:02:06.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:02:06.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:02:06.195+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:02:06.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:02:06.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:02:36.684+0000] {processor.py:157} INFO - Started process (PID=52282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:02:36.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:02:36.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:02:36.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:02:36.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:02:36.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:02:36.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:02:36.725+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:02:36.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:02:36.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:03:07.115+0000] {processor.py:157} INFO - Started process (PID=52307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:03:07.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:03:07.117+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:03:07.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:03:07.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:03:07.144+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:03:07.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:03:07.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:03:07.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:03:07.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:03:37.509+0000] {processor.py:157} INFO - Started process (PID=52332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:03:37.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:03:37.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:03:37.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:03:37.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:03:37.539+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:03:37.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:03:37.549+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:03:37.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:03:37.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:04:08.043+0000] {processor.py:157} INFO - Started process (PID=52357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:04:08.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:04:08.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:04:08.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:04:08.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:04:08.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:04:08.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:04:08.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:04:08.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:04:08.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T14:04:38.528+0000] {processor.py:157} INFO - Started process (PID=52382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:04:38.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:04:38.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:04:38.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:04:38.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:04:38.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:04:38.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:04:38.568+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:04:38.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:04:38.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T14:05:08.939+0000] {processor.py:157} INFO - Started process (PID=52407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:05:08.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:05:08.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:05:08.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:05:08.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:05:08.970+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:05:08.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:05:08.983+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:05:08.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:05:08.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:05:39.343+0000] {processor.py:157} INFO - Started process (PID=52432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:05:39.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:05:39.346+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:05:39.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:05:39.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:05:39.373+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:05:39.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:05:39.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:05:39.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:05:39.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:06:09.846+0000] {processor.py:157} INFO - Started process (PID=52457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:06:09.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:06:09.849+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:06:09.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:06:09.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:06:09.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:06:09.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:06:09.885+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:06:09.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:06:09.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:06:40.215+0000] {processor.py:157} INFO - Started process (PID=52482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:06:40.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:06:40.218+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:06:40.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:06:40.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:06:40.248+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:06:40.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:06:40.258+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:06:40.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:06:40.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:07:10.757+0000] {processor.py:157} INFO - Started process (PID=52507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:07:10.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:07:10.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:07:10.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:07:10.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:07:10.789+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:07:10.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:07:10.800+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:07:10.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:07:10.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:07:41.180+0000] {processor.py:157} INFO - Started process (PID=52532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:07:41.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:07:41.185+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:07:41.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:07:41.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:07:41.214+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:07:41.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:07:41.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:07:41.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:07:41.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T14:08:11.543+0000] {processor.py:157} INFO - Started process (PID=52557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:08:11.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:08:11.546+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:08:11.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:08:11.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:08:11.571+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:08:11.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:08:11.582+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:08:11.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:08:11.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T14:08:42.021+0000] {processor.py:157} INFO - Started process (PID=52582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:08:42.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:08:42.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:08:42.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:08:42.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:08:42.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:08:42.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:08:42.059+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:08:42.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:08:42.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:09:12.467+0000] {processor.py:157} INFO - Started process (PID=52607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:09:12.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:09:12.470+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:09:12.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:09:12.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:09:12.500+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:09:12.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:09:12.510+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:09:12.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:09:12.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:09:42.930+0000] {processor.py:157} INFO - Started process (PID=52632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:09:42.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:09:42.933+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:09:42.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:09:42.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:09:42.967+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:09:42.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:09:42.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:09:42.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:09:42.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T14:10:13.402+0000] {processor.py:157} INFO - Started process (PID=52657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:10:13.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:10:13.407+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:10:13.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:10:13.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:10:13.432+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:10:13.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:10:13.442+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:10:13.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:10:13.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:10:43.862+0000] {processor.py:157} INFO - Started process (PID=52682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:10:43.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:10:43.865+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:10:43.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:10:43.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:10:43.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:10:43.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:10:43.909+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:10:43.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:10:43.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T14:11:14.353+0000] {processor.py:157} INFO - Started process (PID=52707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:11:14.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:11:14.358+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:11:14.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:11:14.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:11:14.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:11:14.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:11:14.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:11:14.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:11:14.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:11:44.760+0000] {processor.py:157} INFO - Started process (PID=52732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:11:44.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:11:44.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:11:44.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:11:44.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:11:44.806+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:11:44.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:11:44.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:11:44.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:11:44.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T14:12:15.273+0000] {processor.py:157} INFO - Started process (PID=52757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:12:15.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:12:15.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:12:15.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:12:15.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:12:15.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:12:15.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:12:15.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:12:15.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:12:15.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T14:12:45.748+0000] {processor.py:157} INFO - Started process (PID=52782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:12:45.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:12:45.752+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:12:45.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:12:45.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:12:45.777+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:12:45.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:12:45.787+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:12:45.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:12:45.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T14:13:16.269+0000] {processor.py:157} INFO - Started process (PID=52807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:13:16.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:13:16.271+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:13:16.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:13:16.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:13:16.302+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:13:16.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:13:16.312+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:13:16.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:13:16.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T14:13:46.780+0000] {processor.py:157} INFO - Started process (PID=52832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:13:46.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:13:46.782+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:13:46.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:13:46.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:13:46.808+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:13:46.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:13:46.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:13:46.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:13:46.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T14:14:17.300+0000] {processor.py:157} INFO - Started process (PID=52857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:14:17.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:14:17.305+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:14:17.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:14:17.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:14:17.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:14:17.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:14:17.340+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:14:17.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:14:17.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:14:47.690+0000] {processor.py:157} INFO - Started process (PID=52882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:14:47.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:14:47.694+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:14:47.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:14:47.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:14:47.724+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:14:47.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:14:47.733+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:14:47.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:14:47.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:15:18.109+0000] {processor.py:157} INFO - Started process (PID=52907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:15:18.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:15:18.113+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:15:18.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:15:18.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:15:18.140+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:15:18.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:15:18.149+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:15:18.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:15:18.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:15:48.565+0000] {processor.py:157} INFO - Started process (PID=52932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:15:48.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:15:48.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:15:48.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:15:48.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:15:48.610+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:15:48.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:15:48.622+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:15:48.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:15:48.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-21T14:16:18.963+0000] {processor.py:157} INFO - Started process (PID=52957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:16:18.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:16:18.968+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:16:18.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:16:18.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:16:18.997+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:16:18.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:16:19.007+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:16:19.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:16:19.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T14:16:49.454+0000] {processor.py:157} INFO - Started process (PID=52982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:16:49.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:16:49.463+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:16:49.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:16:49.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:16:49.521+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:16:49.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:16:49.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:16:49.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:16:49.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-21T14:17:19.884+0000] {processor.py:157} INFO - Started process (PID=53007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:17:19.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:17:19.889+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:17:19.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:17:19.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:17:19.922+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:17:19.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:17:19.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:17:19.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:17:19.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T14:17:50.414+0000] {processor.py:157} INFO - Started process (PID=53032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:17:50.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:17:50.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:17:50.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:17:50.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:17:50.457+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:17:50.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:17:50.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:17:50.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:17:50.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-21T14:18:20.940+0000] {processor.py:157} INFO - Started process (PID=53057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:18:20.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:18:20.945+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:18:20.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:18:20.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:18:20.976+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:18:20.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:18:20.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:18:20.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:18:20.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T14:18:51.422+0000] {processor.py:157} INFO - Started process (PID=53082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:18:51.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:18:51.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:18:51.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:18:51.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:18:51.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:18:51.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:18:51.466+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:18:51.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:18:51.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:19:21.896+0000] {processor.py:157} INFO - Started process (PID=53107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:19:21.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:19:21.901+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:19:21.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:19:21.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:19:21.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:19:21.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:19:21.948+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:19:21.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:19:21.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T14:19:52.387+0000] {processor.py:157} INFO - Started process (PID=53132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:19:52.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:19:52.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:19:52.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:19:52.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:19:52.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:19:52.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:19:52.430+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:19:52.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:19:52.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T14:20:22.856+0000] {processor.py:157} INFO - Started process (PID=53157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:20:22.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:20:22.858+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:20:22.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:20:22.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:20:22.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:20:22.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:20:22.890+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:20:22.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:20:22.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T14:20:53.318+0000] {processor.py:157} INFO - Started process (PID=53182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:20:53.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:20:53.320+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:20:53.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:20:53.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:20:53.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:20:53.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:20:53.354+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:20:53.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:20:53.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T14:21:23.787+0000] {processor.py:157} INFO - Started process (PID=53207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:21:23.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:21:23.791+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:21:23.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:21:23.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:21:23.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:21:23.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:21:23.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:21:23.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:21:23.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-21T14:21:54.338+0000] {processor.py:157} INFO - Started process (PID=53232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:21:54.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:21:54.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:21:54.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:21:54.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:21:54.375+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:21:54.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:21:54.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:21:54.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:21:54.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T14:22:24.810+0000] {processor.py:157} INFO - Started process (PID=53257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:22:24.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:22:24.818+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:22:24.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:22:24.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:22:24.854+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:22:24.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:22:24.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:22:24.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:22:24.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T14:22:55.267+0000] {processor.py:157} INFO - Started process (PID=53282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:22:55.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:22:55.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:22:55.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:22:55.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:22:55.305+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:22:55.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:22:55.317+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:22:55.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:22:55.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T14:23:25.757+0000] {processor.py:157} INFO - Started process (PID=53307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:23:25.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:23:25.761+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:23:25.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:23:25.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:23:25.787+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:23:25.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:23:25.799+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:23:25.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:23:25.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:23:56.146+0000] {processor.py:157} INFO - Started process (PID=53332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:23:56.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:23:56.151+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:23:56.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:23:56.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:23:56.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:23:56.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:23:56.195+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:23:56.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:23:56.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T14:24:26.635+0000] {processor.py:157} INFO - Started process (PID=53357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:24:26.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:24:26.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:24:26.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:24:26.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:24:26.671+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:24:26.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:24:26.682+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:24:26.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:24:26.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T14:24:57.069+0000] {processor.py:157} INFO - Started process (PID=53382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:24:57.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:24:57.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:24:57.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:24:57.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:24:57.098+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:24:57.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:24:57.108+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:24:57.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:24:57.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T14:25:27.500+0000] {processor.py:157} INFO - Started process (PID=53407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:25:27.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:25:27.503+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:25:27.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:25:27.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:25:27.531+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:25:27.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:25:27.541+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:25:27.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:25:27.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:25:57.875+0000] {processor.py:157} INFO - Started process (PID=53432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:25:57.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:25:57.878+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:25:57.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:25:57.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:25:57.904+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:25:57.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:25:57.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:25:57.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:25:57.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:26:28.243+0000] {processor.py:157} INFO - Started process (PID=53457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:26:28.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:26:28.245+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:26:28.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:26:28.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:26:28.271+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:26:28.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:26:28.281+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:26:28.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:26:28.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T14:26:58.750+0000] {processor.py:157} INFO - Started process (PID=53482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:26:58.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:26:58.757+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:26:58.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:26:58.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:26:58.788+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:26:58.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:26:58.802+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:26:58.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:26:58.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T14:27:29.225+0000] {processor.py:157} INFO - Started process (PID=53507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:27:29.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:27:29.227+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:27:29.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:27:29.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:27:29.255+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:27:29.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:27:29.264+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:27:29.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:27:29.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:27:59.706+0000] {processor.py:157} INFO - Started process (PID=53532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:27:59.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:27:59.709+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:27:59.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:27:59.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:27:59.733+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:27:59.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:27:59.743+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:27:59.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:27:59.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T14:28:30.150+0000] {processor.py:157} INFO - Started process (PID=53557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:28:30.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:28:30.153+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:28:30.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:28:30.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:28:30.191+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:28:30.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:28:30.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:28:30.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:28:30.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T14:29:00.618+0000] {processor.py:157} INFO - Started process (PID=53582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:29:00.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:29:00.629+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:29:00.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:29:00.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:29:00.685+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:29:00.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:29:00.695+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:29:00.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:29:00.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-21T14:29:31.243+0000] {processor.py:157} INFO - Started process (PID=53607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:29:31.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:29:31.248+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:29:31.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:29:31.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:29:31.287+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:29:31.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:29:31.300+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:29:31.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:29:31.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T14:30:01.759+0000] {processor.py:157} INFO - Started process (PID=53632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:30:01.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:30:01.765+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:30:01.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:30:01.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:30:01.803+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:30:01.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:30:01.815+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:30:01.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:30:01.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T14:30:32.202+0000] {processor.py:157} INFO - Started process (PID=53657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:30:32.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:30:32.204+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:30:32.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:30:32.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:30:32.233+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:30:32.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:30:32.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:30:32.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:30:32.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:31:02.613+0000] {processor.py:157} INFO - Started process (PID=53682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:31:02.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:31:02.615+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:31:02.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:31:02.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:31:02.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:31:02.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:31:02.649+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:31:02.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:31:02.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T14:31:33.061+0000] {processor.py:157} INFO - Started process (PID=53707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:31:33.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:31:33.064+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:31:33.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:31:33.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:31:33.102+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:31:33.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:31:33.115+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:31:33.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:31:33.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T14:32:03.530+0000] {processor.py:157} INFO - Started process (PID=53732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:32:03.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:32:03.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:32:03.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:32:03.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:32:03.565+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:32:03.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:32:03.578+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:32:03.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:32:03.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T14:32:34.123+0000] {processor.py:157} INFO - Started process (PID=53757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:32:34.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:32:34.128+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:32:34.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:32:34.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:32:34.173+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:32:34.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:32:34.192+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:32:34.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:32:34.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-21T14:33:04.535+0000] {processor.py:157} INFO - Started process (PID=53782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:33:04.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:33:04.539+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:33:04.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:33:04.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:33:04.566+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:33:04.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:33:04.576+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:33:04.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:33:04.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:33:35.030+0000] {processor.py:157} INFO - Started process (PID=53807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:33:35.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:33:35.033+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:33:35.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:33:35.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:33:35.062+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:33:35.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:33:35.073+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:33:35.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:33:35.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:34:05.439+0000] {processor.py:157} INFO - Started process (PID=53832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:34:05.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:34:05.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:34:05.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:34:05.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:34:05.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:34:05.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:34:05.496+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:34:05.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:34:05.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T14:34:35.890+0000] {processor.py:157} INFO - Started process (PID=53857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:34:35.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:34:35.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:34:35.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:34:35.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:34:35.925+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:34:35.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:34:35.937+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:34:35.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:34:35.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T14:35:06.288+0000] {processor.py:157} INFO - Started process (PID=53882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:35:06.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:35:06.290+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:35:06.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:35:06.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:35:06.321+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:35:06.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:35:06.332+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:35:06.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:35:06.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T14:35:36.743+0000] {processor.py:157} INFO - Started process (PID=53907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:35:36.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:35:36.746+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:35:36.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:35:36.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:35:36.776+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:35:36.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:35:36.786+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:35:36.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:35:36.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T14:36:07.249+0000] {processor.py:157} INFO - Started process (PID=53932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:36:07.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:36:07.253+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:36:07.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:36:07.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:36:07.278+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:36:07.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:36:07.292+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:36:07.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:36:07.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:36:37.644+0000] {processor.py:157} INFO - Started process (PID=53957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:36:37.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:36:37.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:36:37.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:36:37.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:36:37.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:36:37.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:36:37.698+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:36:37.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:36:37.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T14:37:08.120+0000] {processor.py:157} INFO - Started process (PID=53982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:37:08.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:37:08.124+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:37:08.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:37:08.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:37:08.151+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:37:08.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:37:08.163+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:37:08.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:37:08.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:37:38.532+0000] {processor.py:157} INFO - Started process (PID=54007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:37:38.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:37:38.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:37:38.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:37:38.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:37:38.564+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:37:38.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:37:38.575+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:37:38.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:37:38.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:38:08.892+0000] {processor.py:157} INFO - Started process (PID=54032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:38:08.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:38:08.894+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:38:08.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:38:08.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:38:08.920+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:38:08.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:38:08.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:38:08.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:38:08.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T14:38:39.372+0000] {processor.py:157} INFO - Started process (PID=54057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:38:39.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:38:39.376+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:38:39.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:38:39.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:38:39.405+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:38:39.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:38:39.416+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:38:39.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:38:39.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:39:09.823+0000] {processor.py:157} INFO - Started process (PID=54082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:39:09.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:39:09.827+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:39:09.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:39:09.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:39:09.861+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:39:09.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:39:09.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:39:09.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:39:09.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T14:39:40.344+0000] {processor.py:157} INFO - Started process (PID=54107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:39:40.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:39:40.347+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:39:40.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:39:40.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:39:40.375+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:39:40.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:39:40.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:39:40.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:39:40.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:40:10.741+0000] {processor.py:157} INFO - Started process (PID=54132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:40:10.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:40:10.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:40:10.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:40:10.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:40:10.771+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:40:10.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:40:10.782+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:40:10.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:40:10.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T14:40:41.178+0000] {processor.py:157} INFO - Started process (PID=54157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:40:41.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:40:41.184+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:40:41.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:40:41.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:40:41.212+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:40:41.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:40:41.223+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:40:41.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:40:41.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T14:41:11.555+0000] {processor.py:157} INFO - Started process (PID=54182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:41:11.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:41:11.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:41:11.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:41:11.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:41:11.586+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:41:11.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:41:11.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:41:11.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:41:11.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:41:42.001+0000] {processor.py:157} INFO - Started process (PID=54207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:41:42.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:41:42.003+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:41:42.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:41:42.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:41:42.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:41:42.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:41:42.040+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:41:42.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:41:42.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:42:12.438+0000] {processor.py:157} INFO - Started process (PID=54232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:42:12.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:42:12.447+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:42:12.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:42:12.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:42:12.491+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:42:12.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:42:12.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:42:12.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:42:12.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T14:42:42.870+0000] {processor.py:157} INFO - Started process (PID=54257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:42:42.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:42:42.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:42:42.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:42:42.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:42:42.899+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:42:42.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:42:42.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:42:42.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:42:42.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:43:13.340+0000] {processor.py:157} INFO - Started process (PID=54282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:43:13.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:43:13.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:43:13.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:43:13.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:43:13.371+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:43:13.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:43:13.381+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:43:13.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:43:13.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:43:43.792+0000] {processor.py:157} INFO - Started process (PID=54307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:43:43.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:43:43.796+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:43:43.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:43:43.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:43:43.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:43:43.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:43:43.832+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:43:43.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:43:43.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:44:14.264+0000] {processor.py:157} INFO - Started process (PID=54332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:44:14.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:44:14.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:44:14.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:44:14.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:44:14.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:44:14.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:44:14.307+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:44:14.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:44:14.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:44:44.778+0000] {processor.py:157} INFO - Started process (PID=54357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:44:44.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:44:44.784+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:44:44.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:44:44.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:44:44.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:44:44.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:44:44.832+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:44:44.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:44:44.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T14:45:15.199+0000] {processor.py:157} INFO - Started process (PID=54382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:45:15.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:45:15.200+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:45:15.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:45:15.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:45:15.226+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:45:15.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:45:15.237+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:45:15.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:45:15.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:45:45.635+0000] {processor.py:157} INFO - Started process (PID=54407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:45:45.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:45:45.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:45:45.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:45:45.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:45:45.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:45:45.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:45:45.679+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:45:45.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:45:45.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T14:46:16.063+0000] {processor.py:157} INFO - Started process (PID=54432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:46:16.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:46:16.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:46:16.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:46:16.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:46:16.099+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:46:16.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:46:16.115+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:46:16.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:46:16.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T14:46:46.630+0000] {processor.py:157} INFO - Started process (PID=54457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:46:46.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:46:46.633+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:46:46.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:46:46.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:46:46.663+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:46:46.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:46:46.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:46:46.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:46:46.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T14:47:17.017+0000] {processor.py:157} INFO - Started process (PID=54482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:47:17.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:47:17.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:47:17.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:47:17.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:47:17.046+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:47:17.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:47:17.056+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:47:17.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:47:17.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T14:47:47.443+0000] {processor.py:157} INFO - Started process (PID=54507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:47:47.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:47:47.445+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:47:47.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:47:47.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:47:47.472+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:47:47.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:47:47.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:47:47.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:47:47.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:48:17.860+0000] {processor.py:157} INFO - Started process (PID=54532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:48:17.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:48:17.863+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:48:17.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:48:17.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:48:17.892+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:48:17.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:48:17.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:48:17.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:48:17.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:48:48.320+0000] {processor.py:157} INFO - Started process (PID=54557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:48:48.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:48:48.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:48:48.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:48:48.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:48:48.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:48:48.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:48:48.367+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:48:48.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:48:48.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T14:49:18.789+0000] {processor.py:157} INFO - Started process (PID=54582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:49:18.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:49:18.793+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:49:18.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:49:18.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:49:18.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:49:18.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:49:18.830+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:49:18.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:49:18.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:49:49.185+0000] {processor.py:157} INFO - Started process (PID=54607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:49:49.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:49:49.190+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:49:49.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:49:49.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:49:49.230+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:49:49.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:49:49.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:49:49.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:49:49.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T14:50:19.643+0000] {processor.py:157} INFO - Started process (PID=54632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:50:19.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:50:19.646+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:50:19.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:50:19.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:50:19.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:50:19.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:50:19.684+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:50:19.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:50:19.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:50:50.067+0000] {processor.py:157} INFO - Started process (PID=54657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:50:50.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:50:50.070+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:50:50.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:50:50.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:50:50.096+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:50:50.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:50:50.105+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:50:50.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:50:50.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T14:51:20.526+0000] {processor.py:157} INFO - Started process (PID=54682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:51:20.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:51:20.531+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:51:20.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:51:20.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:51:20.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:51:20.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:51:20.569+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:51:20.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:51:20.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:51:50.927+0000] {processor.py:157} INFO - Started process (PID=54707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:51:50.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:51:50.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:51:50.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:51:50.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:51:50.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:51:50.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:51:50.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:51:50.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:51:50.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T14:52:21.315+0000] {processor.py:157} INFO - Started process (PID=54732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:52:21.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:52:21.318+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:52:21.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:52:21.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:52:21.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:52:21.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:52:21.356+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:52:21.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:52:21.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:52:51.700+0000] {processor.py:157} INFO - Started process (PID=54757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:52:51.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:52:51.703+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:52:51.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:52:51.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:52:51.732+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:52:51.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:52:51.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:52:51.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:52:51.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T14:53:22.106+0000] {processor.py:157} INFO - Started process (PID=54782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:53:22.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:53:22.109+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:53:22.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:53:22.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:53:22.135+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:53:22.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:53:22.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:53:22.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:53:22.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:53:52.573+0000] {processor.py:157} INFO - Started process (PID=54807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:53:52.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:53:52.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:53:52.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:53:52.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:53:52.605+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:53:52.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:53:52.619+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:53:52.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:53:52.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T14:54:23.014+0000] {processor.py:157} INFO - Started process (PID=54832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:54:23.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:54:23.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:54:23.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:54:23.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:54:23.047+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:54:23.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:54:23.057+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:54:23.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:54:23.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T14:54:53.502+0000] {processor.py:157} INFO - Started process (PID=54857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:54:53.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:54:53.505+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:54:53.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:54:53.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:54:53.530+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:54:53.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:54:53.540+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:54:53.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:54:53.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T14:55:23.979+0000] {processor.py:157} INFO - Started process (PID=54882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:55:23.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:55:23.981+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:55:23.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:55:23.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:55:24.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:55:24.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:55:24.018+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:55:24.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:55:24.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:55:54.408+0000] {processor.py:157} INFO - Started process (PID=54907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:55:54.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:55:54.413+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:55:54.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:55:54.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:55:54.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:55:54.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:55:54.463+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:55:54.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:55:54.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T14:56:24.905+0000] {processor.py:157} INFO - Started process (PID=54932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:56:24.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:56:24.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:56:24.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:56:24.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:56:24.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:56:24.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:56:24.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:56:24.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:56:24.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T14:56:55.304+0000] {processor.py:157} INFO - Started process (PID=54957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:56:55.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:56:55.308+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:56:55.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:56:55.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:56:55.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:56:55.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:56:55.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:56:55.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:56:55.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:57:25.750+0000] {processor.py:157} INFO - Started process (PID=54982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:57:25.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:57:25.752+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:57:25.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:57:25.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:57:25.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:57:25.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:57:25.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:57:25.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:57:25.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T14:57:56.171+0000] {processor.py:157} INFO - Started process (PID=55007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:57:56.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:57:56.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:57:56.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:57:56.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:57:56.202+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:57:56.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:57:56.213+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:57:56.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:57:56.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T14:58:26.614+0000] {processor.py:157} INFO - Started process (PID=55032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:58:26.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:58:26.619+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:58:26.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:58:26.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:58:26.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:58:26.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:58:26.659+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:58:26.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:58:26.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T14:58:57.059+0000] {processor.py:157} INFO - Started process (PID=55057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:58:57.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:58:57.062+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:58:57.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:58:57.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:58:57.088+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:58:57.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:58:57.099+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:58:57.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:58:57.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T14:59:27.472+0000] {processor.py:157} INFO - Started process (PID=55082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:59:27.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:59:27.477+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:59:27.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:59:27.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:59:27.512+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:59:27.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:59:27.526+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:59:27.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:59:27.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T14:59:57.973+0000] {processor.py:157} INFO - Started process (PID=55107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:59:57.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T14:59:57.976+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:59:57.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:59:57.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T14:59:58.005+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:59:58.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T14:59:58.018+0000] {logging_mixin.py:151} INFO - [2024-07-21T14:59:58.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T14:59:58.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:00:28.391+0000] {processor.py:157} INFO - Started process (PID=55132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:00:28.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:00:28.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:00:28.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:00:28.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:00:28.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:00:28.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:00:28.433+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:00:28.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:00:28.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T15:00:58.894+0000] {processor.py:157} INFO - Started process (PID=55157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:00:58.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:00:58.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:00:58.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:00:58.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:00:58.924+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:00:58.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:00:58.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:00:58.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:00:58.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T15:01:29.349+0000] {processor.py:157} INFO - Started process (PID=55182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:01:29.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:01:29.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:01:29.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:01:29.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:01:29.380+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:01:29.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:01:29.391+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:01:29.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:01:29.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:01:59.817+0000] {processor.py:157} INFO - Started process (PID=55207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:01:59.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:01:59.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:01:59.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:01:59.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:01:59.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:01:59.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:01:59.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:01:59.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:01:59.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T15:02:30.388+0000] {processor.py:157} INFO - Started process (PID=55232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:02:30.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:02:30.391+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:02:30.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:02:30.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:02:30.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:02:30.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:02:30.433+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:02:30.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:02:30.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T15:03:00.966+0000] {processor.py:157} INFO - Started process (PID=55257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:03:00.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:03:00.971+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:03:00.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:03:00.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:03:00.999+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:03:00.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:03:01.011+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:03:01.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:03:01.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T15:03:31.419+0000] {processor.py:157} INFO - Started process (PID=55282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:03:31.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:03:31.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:03:31.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:03:31.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:03:31.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:03:31.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:03:31.462+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:03:31.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:03:31.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:04:01.969+0000] {processor.py:157} INFO - Started process (PID=55307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:04:01.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:04:01.974+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:04:01.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:04:01.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:04:02.012+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:04:02.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:04:02.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:04:02.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:04:02.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T15:04:32.468+0000] {processor.py:157} INFO - Started process (PID=55332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:04:32.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:04:32.471+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:04:32.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:04:32.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:04:32.498+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:04:32.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:04:32.508+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:04:32.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:04:32.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T15:05:02.848+0000] {processor.py:157} INFO - Started process (PID=55357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:05:02.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:05:02.851+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:05:02.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:05:02.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:05:02.880+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:05:02.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:05:02.889+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:05:02.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:05:02.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T15:05:33.226+0000] {processor.py:157} INFO - Started process (PID=55382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:05:33.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:05:33.228+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:05:33.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:05:33.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:05:33.253+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:05:33.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:05:33.264+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:05:33.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:05:33.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T15:06:03.678+0000] {processor.py:157} INFO - Started process (PID=55407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:06:03.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:06:03.681+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:06:03.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:06:03.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:06:03.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:06:03.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:06:03.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:06:03.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:06:03.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T15:06:34.209+0000] {processor.py:157} INFO - Started process (PID=55432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:06:34.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:06:34.212+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:06:34.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:06:34.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:06:34.241+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:06:34.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:06:34.250+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:06:34.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:06:34.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:07:04.751+0000] {processor.py:157} INFO - Started process (PID=55457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:07:04.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:07:04.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:07:04.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:07:04.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:07:04.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:07:04.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:07:04.796+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:07:04.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:07:04.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T15:07:35.222+0000] {processor.py:157} INFO - Started process (PID=55482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:07:35.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:07:35.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:07:35.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:07:35.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:07:35.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:07:35.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:07:35.260+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:07:35.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:07:35.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T15:08:05.682+0000] {processor.py:157} INFO - Started process (PID=55507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:08:05.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:08:05.685+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:08:05.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:08:05.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:08:05.710+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:08:05.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:08:05.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:08:05.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:08:05.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T15:08:36.188+0000] {processor.py:157} INFO - Started process (PID=55532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:08:36.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:08:36.192+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:08:36.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:08:36.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:08:36.228+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:08:36.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:08:36.240+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:08:36.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:08:36.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T15:09:06.745+0000] {processor.py:157} INFO - Started process (PID=55557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:09:06.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:09:06.749+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:09:06.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:09:06.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:09:06.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:09:06.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:09:06.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:09:06.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:09:06.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T15:09:37.225+0000] {processor.py:157} INFO - Started process (PID=55582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:09:37.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:09:37.228+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:09:37.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:09:37.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:09:37.253+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:09:37.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:09:37.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:09:37.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:09:37.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T15:10:07.642+0000] {processor.py:157} INFO - Started process (PID=55607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:10:07.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:10:07.646+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:10:07.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:10:07.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:10:07.671+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:10:07.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:10:07.681+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:10:07.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:10:07.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T15:10:38.000+0000] {processor.py:157} INFO - Started process (PID=55632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:10:38.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:10:38.002+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:10:38.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:10:38.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:10:38.029+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:10:38.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:10:38.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:10:38.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:10:38.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T15:11:08.483+0000] {processor.py:157} INFO - Started process (PID=55657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:11:08.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:11:08.487+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:11:08.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:11:08.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:11:08.512+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:11:08.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:11:08.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:11:08.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:11:08.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T15:11:38.983+0000] {processor.py:157} INFO - Started process (PID=55682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:11:38.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:11:38.991+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:11:38.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:11:39.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:11:39.015+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:11:39.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:11:39.025+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:11:39.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:11:39.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:12:09.424+0000] {processor.py:157} INFO - Started process (PID=55707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:12:09.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:12:09.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:12:09.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:12:09.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:12:09.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:12:09.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:12:09.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:12:09.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:12:09.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T15:12:39.933+0000] {processor.py:157} INFO - Started process (PID=55732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:12:39.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:12:39.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:12:39.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:12:39.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:12:39.964+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:12:39.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:12:39.973+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:12:39.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:12:39.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T15:13:10.410+0000] {processor.py:157} INFO - Started process (PID=55757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:13:10.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:13:10.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:13:10.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:13:10.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:13:10.441+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:13:10.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:13:10.452+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:13:10.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:13:10.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:13:40.832+0000] {processor.py:157} INFO - Started process (PID=55782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:13:40.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:13:40.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:13:40.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:13:40.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:13:40.872+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:13:40.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:13:40.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:13:40.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:13:40.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T15:14:11.331+0000] {processor.py:157} INFO - Started process (PID=55807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:14:11.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:14:11.338+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:14:11.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:14:11.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:14:11.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:14:11.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:14:11.375+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:14:11.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:14:11.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T15:14:41.827+0000] {processor.py:157} INFO - Started process (PID=55832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:14:41.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:14:41.830+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:14:41.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:14:41.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:14:41.864+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:14:41.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:14:41.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:14:41.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:14:41.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T15:15:12.283+0000] {processor.py:157} INFO - Started process (PID=55857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:15:12.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:15:12.285+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:15:12.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:15:12.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:15:12.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:15:12.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:15:12.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:15:12.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:15:12.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T15:15:42.680+0000] {processor.py:157} INFO - Started process (PID=55881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:15:42.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:15:42.683+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:15:42.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:15:42.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:15:42.713+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:15:42.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:15:42.725+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:15:42.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:15:42.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T15:16:13.126+0000] {processor.py:157} INFO - Started process (PID=55907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:16:13.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:16:13.131+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:16:13.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:16:13.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:16:13.169+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:16:13.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:16:13.182+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:16:13.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:16:13.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T15:16:43.606+0000] {processor.py:157} INFO - Started process (PID=55932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:16:43.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:16:43.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:16:43.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:16:43.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:16:43.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:16:43.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:16:43.650+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:16:43.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:16:43.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T15:17:14.039+0000] {processor.py:157} INFO - Started process (PID=55957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:17:14.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:17:14.042+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:17:14.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:17:14.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:17:14.074+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:17:14.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:17:14.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:17:14.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:17:14.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T15:17:44.406+0000] {processor.py:157} INFO - Started process (PID=55982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:17:44.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:17:44.409+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:17:44.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:17:44.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:17:44.438+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:17:44.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:17:44.448+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:17:44.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:17:44.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T15:18:14.898+0000] {processor.py:157} INFO - Started process (PID=56007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:18:14.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:18:14.900+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:18:14.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:18:14.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:18:14.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:18:14.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:18:14.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:18:14.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:18:14.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:18:45.281+0000] {processor.py:157} INFO - Started process (PID=56032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:18:45.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:18:45.291+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:18:45.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:18:45.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:18:45.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:18:45.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:18:45.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:18:45.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:18:45.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T15:19:15.714+0000] {processor.py:157} INFO - Started process (PID=56057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:19:15.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:19:15.721+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:19:15.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:19:15.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:19:15.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:19:15.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:19:15.795+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:19:15.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:19:15.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-21T15:19:46.164+0000] {processor.py:157} INFO - Started process (PID=56082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:19:46.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:19:46.167+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:19:46.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:19:46.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:19:46.196+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:19:46.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:19:46.208+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:19:46.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:19:46.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:20:16.627+0000] {processor.py:157} INFO - Started process (PID=56107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:20:16.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:20:16.630+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:20:16.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:20:16.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:20:16.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:20:16.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:20:16.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:20:16.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:20:16.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:20:47.113+0000] {processor.py:157} INFO - Started process (PID=56132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:20:47.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:20:47.116+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:20:47.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:20:47.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:20:47.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:20:47.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:20:47.167+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:20:47.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:20:47.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T15:21:17.583+0000] {processor.py:157} INFO - Started process (PID=56157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:21:17.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:21:17.592+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:21:17.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:21:17.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:21:17.672+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:21:17.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:21:17.717+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:21:17.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:21:17.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-21T15:21:48.537+0000] {processor.py:157} INFO - Started process (PID=56182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:21:48.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:21:48.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:21:48.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:21:48.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:21:48.601+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:21:48.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:21:48.613+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:21:48.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:21:48.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-21T15:22:19.028+0000] {processor.py:157} INFO - Started process (PID=56207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:22:19.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:22:19.031+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:22:19.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:22:19.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:22:19.061+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:22:19.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:22:19.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:22:19.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:22:19.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T15:22:49.478+0000] {processor.py:157} INFO - Started process (PID=56232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:22:49.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:22:49.481+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:22:49.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:22:49.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:22:49.502+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:22:49.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:22:49.513+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:22:49.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:22:49.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T15:23:19.904+0000] {processor.py:157} INFO - Started process (PID=56257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:23:19.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:23:19.909+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:23:19.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:23:19.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:23:19.944+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:23:19.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:23:19.957+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:23:19.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:23:19.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T15:23:50.401+0000] {processor.py:157} INFO - Started process (PID=56282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:23:50.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:23:50.404+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:23:50.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:23:50.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:23:50.429+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:23:50.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:23:50.438+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:23:50.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:23:50.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T15:24:20.854+0000] {processor.py:157} INFO - Started process (PID=56307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:24:20.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:24:20.877+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:24:20.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:24:20.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:24:20.922+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:24:20.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:24:20.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:24:20.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:24:20.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-21T15:24:51.371+0000] {processor.py:157} INFO - Started process (PID=56332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:24:51.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:24:51.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:24:51.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:24:51.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:24:51.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:24:51.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:24:51.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:24:51.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:24:51.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T15:25:21.798+0000] {processor.py:157} INFO - Started process (PID=56357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:25:21.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:25:21.802+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:25:21.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:25:21.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:25:21.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:25:21.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:25:21.849+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:25:21.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:25:21.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T15:25:52.240+0000] {processor.py:157} INFO - Started process (PID=56382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:25:52.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:25:52.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:25:52.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:25:52.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:25:52.273+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:25:52.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:25:52.284+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:25:52.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:25:52.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T15:26:22.609+0000] {processor.py:157} INFO - Started process (PID=56407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:26:22.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:26:22.613+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:26:22.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:26:22.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:26:22.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:26:22.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:26:22.649+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:26:22.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:26:22.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T15:26:53.065+0000] {processor.py:157} INFO - Started process (PID=56432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:26:53.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:26:53.068+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:26:53.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:26:53.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:26:53.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:26:53.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:26:53.104+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:26:53.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:26:53.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T15:27:23.493+0000] {processor.py:157} INFO - Started process (PID=56457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:27:23.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:27:23.497+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:27:23.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:27:23.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:27:23.530+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:27:23.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:27:23.541+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:27:23.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:27:23.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T15:27:53.919+0000] {processor.py:157} INFO - Started process (PID=56482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:27:53.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:27:53.923+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:27:53.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:27:53.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:27:53.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:27:53.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:27:53.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:27:53.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:27:53.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:28:24.421+0000] {processor.py:157} INFO - Started process (PID=56507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:28:24.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:28:24.425+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:28:24.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:28:24.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:28:24.452+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:28:24.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:28:24.463+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:28:24.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:28:24.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:28:54.821+0000] {processor.py:157} INFO - Started process (PID=56532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:28:54.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:28:54.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:28:54.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:28:54.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:28:54.853+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:28:54.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:28:54.865+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:28:54.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:28:54.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T15:29:25.333+0000] {processor.py:157} INFO - Started process (PID=56557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:29:25.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:29:25.338+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:29:25.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:29:25.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:29:25.375+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:29:25.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:29:25.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:29:25.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:29:25.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T15:29:55.802+0000] {processor.py:157} INFO - Started process (PID=56582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:29:55.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:29:55.804+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:29:55.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:29:55.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:29:55.831+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:29:55.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:29:55.840+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:29:55.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:29:55.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T15:30:26.240+0000] {processor.py:157} INFO - Started process (PID=56607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:30:26.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:30:26.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:30:26.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:30:26.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:30:26.270+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:30:26.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:30:26.281+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:30:26.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:30:26.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T15:30:56.681+0000] {processor.py:157} INFO - Started process (PID=56632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:30:56.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:30:56.684+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:30:56.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:30:56.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:30:56.710+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:30:56.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:30:56.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:30:56.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:30:56.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T15:31:27.168+0000] {processor.py:157} INFO - Started process (PID=56657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:31:27.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:31:27.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:31:27.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:31:27.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:31:27.201+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:31:27.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:31:27.212+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:31:27.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:31:27.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T15:31:57.595+0000] {processor.py:157} INFO - Started process (PID=56682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:31:57.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:31:57.598+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:31:57.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:31:57.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:31:57.625+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:31:57.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:31:57.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:31:57.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:31:57.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:32:28.027+0000] {processor.py:157} INFO - Started process (PID=56707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:32:28.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:32:28.032+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:32:28.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:32:28.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:32:28.060+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:32:28.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:32:28.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:32:28.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:32:28.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T15:32:58.436+0000] {processor.py:157} INFO - Started process (PID=56732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:32:58.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:32:58.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:32:58.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:32:58.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:32:58.468+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:32:58.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:32:58.478+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:32:58.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:32:58.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:33:28.867+0000] {processor.py:157} INFO - Started process (PID=56757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:33:28.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:33:28.869+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:33:28.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:33:28.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:33:28.897+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:33:28.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:33:28.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:33:28.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:33:28.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T15:33:59.246+0000] {processor.py:157} INFO - Started process (PID=56782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:33:59.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:33:59.250+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:33:59.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:33:59.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:33:59.279+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:33:59.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:33:59.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:33:59.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:33:59.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T15:34:29.629+0000] {processor.py:157} INFO - Started process (PID=56807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:34:29.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:34:29.634+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:34:29.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:34:29.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:34:29.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:34:29.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:34:29.698+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:34:29.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:34:29.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-21T15:35:00.101+0000] {processor.py:157} INFO - Started process (PID=56832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:35:00.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:35:00.107+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:35:00.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:35:00.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:35:00.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:35:00.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:35:00.150+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:35:00.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:35:00.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T15:35:30.596+0000] {processor.py:157} INFO - Started process (PID=56857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:35:30.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:35:30.603+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:35:30.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:35:30.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:35:30.641+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:35:30.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:35:30.654+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:35:30.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:35:30.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T15:36:01.075+0000] {processor.py:157} INFO - Started process (PID=56882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:36:01.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:36:01.079+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:36:01.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:36:01.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:36:01.108+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:36:01.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:36:01.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:36:01.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:36:01.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T15:36:31.493+0000] {processor.py:157} INFO - Started process (PID=56907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:36:31.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:36:31.498+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:36:31.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:36:31.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:36:31.524+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:36:31.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:36:31.534+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:36:31.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:36:31.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:37:01.908+0000] {processor.py:157} INFO - Started process (PID=56932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:37:01.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:37:01.911+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:37:01.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:37:01.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:37:01.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:37:01.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:37:01.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:37:01.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:37:01.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T15:37:32.350+0000] {processor.py:157} INFO - Started process (PID=56957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:37:32.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:37:32.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:37:32.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:37:32.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:37:32.380+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:37:32.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:37:32.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:37:32.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:37:32.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T15:38:02.841+0000] {processor.py:157} INFO - Started process (PID=56982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:38:02.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:38:02.844+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:38:02.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:38:02.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:38:02.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:38:02.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:38:02.886+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:38:02.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:38:02.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T15:38:33.297+0000] {processor.py:157} INFO - Started process (PID=57007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:38:33.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:38:33.300+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:38:33.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:38:33.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:38:33.328+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:38:33.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:38:33.337+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:38:33.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:38:33.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T15:39:03.943+0000] {processor.py:157} INFO - Started process (PID=57032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:39:03.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:39:03.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:39:03.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:39:03.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:39:03.992+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:39:03.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:39:04.004+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:39:04.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:39:04.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T15:39:34.424+0000] {processor.py:157} INFO - Started process (PID=57057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:39:34.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:39:34.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:39:34.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:39:34.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:39:34.457+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:39:34.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:39:34.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:39:34.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:39:34.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:40:04.844+0000] {processor.py:157} INFO - Started process (PID=57082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:40:04.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:40:04.849+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:40:04.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:40:04.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:40:04.887+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:40:04.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:40:04.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:40:04.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:40:04.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T15:40:35.401+0000] {processor.py:157} INFO - Started process (PID=57107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:40:35.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:40:35.410+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:40:35.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:40:35.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:40:35.466+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:40:35.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:40:35.480+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:40:35.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:40:35.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-21T15:41:05.915+0000] {processor.py:157} INFO - Started process (PID=57132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:41:05.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:41:05.919+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:41:05.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:41:05.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:41:05.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:41:05.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:41:05.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:41:05.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:41:05.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T15:41:36.473+0000] {processor.py:157} INFO - Started process (PID=57157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:41:36.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:41:36.479+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:41:36.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:41:36.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:41:36.521+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:41:36.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:41:36.536+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:41:36.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:41:36.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T15:42:06.981+0000] {processor.py:157} INFO - Started process (PID=57182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:42:06.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:42:06.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:42:06.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:42:06.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:42:07.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:42:07.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:42:07.026+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:42:07.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:42:07.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T15:42:37.473+0000] {processor.py:157} INFO - Started process (PID=57207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:42:37.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:42:37.477+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:42:37.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:42:37.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:42:37.508+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:42:37.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:42:37.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:42:37.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:42:37.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T15:43:07.965+0000] {processor.py:157} INFO - Started process (PID=57232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:43:07.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:43:07.970+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:43:07.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:43:07.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:43:08.006+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:43:08.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:43:08.019+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:43:08.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:43:08.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T15:43:38.410+0000] {processor.py:157} INFO - Started process (PID=57257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:43:38.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:43:38.413+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:43:38.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:43:38.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:43:38.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:43:38.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:43:38.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:43:38.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:43:38.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:44:08.906+0000] {processor.py:157} INFO - Started process (PID=57282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:44:08.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:44:08.909+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:44:08.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:44:08.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:44:08.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:44:08.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:44:08.949+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:44:08.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:44:08.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T15:44:39.371+0000] {processor.py:157} INFO - Started process (PID=57307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:44:39.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:44:39.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:44:39.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:44:39.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:44:39.400+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:44:39.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:44:39.410+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:44:39.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:44:39.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T15:45:09.806+0000] {processor.py:157} INFO - Started process (PID=57332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:45:09.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:45:09.813+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:45:09.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:45:09.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:45:09.863+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:45:09.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:45:09.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:45:09.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:45:09.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T15:45:40.297+0000] {processor.py:157} INFO - Started process (PID=57357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:45:40.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:45:40.300+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:45:40.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:45:40.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:45:40.328+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:45:40.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:45:40.339+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:45:40.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:45:40.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T15:46:10.766+0000] {processor.py:157} INFO - Started process (PID=57382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:46:10.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:46:10.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:46:10.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:46:10.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:46:10.821+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:46:10.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:46:10.842+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:46:10.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:46:10.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-21T15:46:41.288+0000] {processor.py:157} INFO - Started process (PID=57407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:46:41.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:46:41.299+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:46:41.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:46:41.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:46:41.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:46:41.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:46:41.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:46:41.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:46:41.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-21T15:47:11.748+0000] {processor.py:157} INFO - Started process (PID=57432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:47:11.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:47:11.752+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:47:11.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:47:11.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:47:11.781+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:47:11.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:47:11.791+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:47:11.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:47:11.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:47:42.234+0000] {processor.py:157} INFO - Started process (PID=57457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:47:42.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:47:42.236+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:47:42.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:47:42.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:47:42.263+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:47:42.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:47:42.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:47:42.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:47:42.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T15:48:12.692+0000] {processor.py:157} INFO - Started process (PID=57482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:48:12.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:48:12.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:48:12.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:48:12.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:48:12.732+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:48:12.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:48:12.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:48:12.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:48:12.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T15:48:43.199+0000] {processor.py:157} INFO - Started process (PID=57507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:48:43.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:48:43.202+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:48:43.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:48:43.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:48:43.231+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:48:43.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:48:43.242+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:48:43.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:48:43.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T15:49:13.645+0000] {processor.py:157} INFO - Started process (PID=57532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:49:13.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:49:13.649+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:49:13.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:49:13.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:49:13.676+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:49:13.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:49:13.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:49:13.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:49:13.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:49:44.049+0000] {processor.py:157} INFO - Started process (PID=57557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:49:44.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:49:44.053+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:49:44.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:49:44.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:49:44.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:49:44.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:49:44.099+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:49:44.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:49:44.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T15:50:14.512+0000] {processor.py:157} INFO - Started process (PID=57582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:50:14.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:50:14.521+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:50:14.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:50:14.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:50:14.564+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:50:14.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:50:14.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:50:14.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:50:14.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-21T15:50:44.955+0000] {processor.py:157} INFO - Started process (PID=57607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:50:44.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:50:44.957+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:50:44.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:50:44.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:50:44.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:50:44.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:50:44.995+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:50:44.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:50:45.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T15:51:15.494+0000] {processor.py:157} INFO - Started process (PID=57632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:51:15.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:51:15.503+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:51:15.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:51:15.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:51:15.574+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:51:15.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:51:15.591+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:51:15.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:51:15.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-21T15:51:46.075+0000] {processor.py:157} INFO - Started process (PID=57657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:51:46.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:51:46.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:51:46.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:51:46.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:51:46.116+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:51:46.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:51:46.128+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:51:46.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:51:46.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T15:52:16.447+0000] {processor.py:157} INFO - Started process (PID=57682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:52:16.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:52:16.450+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:52:16.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:52:16.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:52:16.479+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:52:16.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:52:16.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:52:16.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:52:16.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:52:46.935+0000] {processor.py:157} INFO - Started process (PID=57707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:52:46.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:52:46.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:52:46.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:52:46.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:52:46.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:52:46.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:52:46.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:52:46.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:52:46.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T15:53:17.419+0000] {processor.py:157} INFO - Started process (PID=57732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:53:17.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:53:17.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:53:17.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:53:17.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:53:17.445+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:53:17.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:53:17.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:53:17.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:53:17.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T15:53:47.855+0000] {processor.py:157} INFO - Started process (PID=57757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:53:47.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:53:47.857+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:53:47.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:53:47.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:53:47.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:53:47.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:53:47.891+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:53:47.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:53:47.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T15:54:18.302+0000] {processor.py:157} INFO - Started process (PID=57782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:54:18.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:54:18.306+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:54:18.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:54:18.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:54:18.333+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:54:18.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:54:18.344+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:54:18.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:54:18.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:54:48.851+0000] {processor.py:157} INFO - Started process (PID=57807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:54:48.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:54:48.857+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:54:48.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:54:48.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:54:48.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:54:48.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:54:48.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:54:48.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:54:48.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T15:55:19.318+0000] {processor.py:157} INFO - Started process (PID=57832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:55:19.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:55:19.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:55:19.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:55:19.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:55:19.350+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:55:19.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:55:19.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:55:19.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:55:19.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T15:55:49.703+0000] {processor.py:157} INFO - Started process (PID=57857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:55:49.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:55:49.708+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:55:49.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:55:49.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:55:49.743+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:55:49.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:55:49.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:55:49.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:55:49.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T15:56:20.264+0000] {processor.py:157} INFO - Started process (PID=57882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:56:20.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:56:20.272+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:56:20.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:56:20.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:56:20.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:56:20.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:56:20.321+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:56:20.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:56:20.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T15:56:50.696+0000] {processor.py:157} INFO - Started process (PID=57907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:56:50.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:56:50.703+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:56:50.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:56:50.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:56:50.732+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:56:50.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:56:50.742+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:56:50.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:56:50.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T15:57:21.115+0000] {processor.py:157} INFO - Started process (PID=57932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:57:21.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:57:21.117+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:57:21.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:57:21.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:57:21.142+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:57:21.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:57:21.152+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:57:21.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:57:21.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T15:57:51.625+0000] {processor.py:157} INFO - Started process (PID=57957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:57:51.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:57:51.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:57:51.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:57:51.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:57:51.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:57:51.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:57:51.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:57:51.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:57:51.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T15:58:22.199+0000] {processor.py:157} INFO - Started process (PID=57982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:58:22.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:58:22.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:58:22.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:58:22.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:58:22.247+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:58:22.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:58:22.264+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:58:22.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:58:22.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-21T15:58:52.631+0000] {processor.py:157} INFO - Started process (PID=58007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:58:52.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:58:52.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:58:52.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:58:52.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:58:52.678+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:58:52.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:58:52.688+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:58:52.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:58:52.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T15:59:23.118+0000] {processor.py:157} INFO - Started process (PID=58032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:59:23.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:59:23.122+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:59:23.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:59:23.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:59:23.160+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:59:23.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:59:23.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:59:23.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:59:23.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T15:59:53.552+0000] {processor.py:157} INFO - Started process (PID=58057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:59:53.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T15:59:53.555+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:59:53.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:59:53.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T15:59:53.583+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:59:53.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T15:59:53.595+0000] {logging_mixin.py:151} INFO - [2024-07-21T15:59:53.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T15:59:53.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T16:00:24.054+0000] {processor.py:157} INFO - Started process (PID=58082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:00:24.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:00:24.058+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:00:24.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:00:24.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:00:24.085+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:00:24.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:00:24.096+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:00:24.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:00:24.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T16:00:54.476+0000] {processor.py:157} INFO - Started process (PID=58107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:00:54.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:00:54.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:00:54.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:00:54.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:00:54.512+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:00:54.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:00:54.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:00:54.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:00:54.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T16:01:24.917+0000] {processor.py:157} INFO - Started process (PID=58132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:01:24.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:01:24.920+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:01:24.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:01:24.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:01:24.958+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:01:24.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:01:24.971+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:01:24.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:01:24.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T16:01:55.380+0000] {processor.py:157} INFO - Started process (PID=58157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:01:55.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:01:55.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:01:55.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:01:55.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:01:55.410+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:01:55.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:01:55.420+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:01:55.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:01:55.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:02:25.851+0000] {processor.py:157} INFO - Started process (PID=58182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:02:25.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:02:25.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:02:25.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:02:25.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:02:25.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:02:25.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:02:25.891+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:02:25.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:02:25.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:02:56.325+0000] {processor.py:157} INFO - Started process (PID=58207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:02:56.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:02:56.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:02:56.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:02:56.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:02:56.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:02:56.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:02:56.363+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:02:56.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:02:56.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T16:03:26.779+0000] {processor.py:157} INFO - Started process (PID=58232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:03:26.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:03:26.781+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:03:26.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:03:26.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:03:26.802+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:03:26.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:03:26.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:03:26.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:03:26.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-21T16:03:57.235+0000] {processor.py:157} INFO - Started process (PID=58257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:03:57.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:03:57.239+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:03:57.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:03:57.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:03:57.278+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:03:57.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:03:57.290+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:03:57.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:03:57.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T16:04:27.674+0000] {processor.py:157} INFO - Started process (PID=58282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:04:27.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:04:27.679+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:04:27.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:04:27.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:04:27.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:04:27.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:04:27.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:04:27.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:04:27.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T16:04:58.066+0000] {processor.py:157} INFO - Started process (PID=58307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:04:58.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:04:58.069+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:04:58.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:04:58.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:04:58.096+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:04:58.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:04:58.107+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:04:58.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:04:58.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T16:05:28.556+0000] {processor.py:157} INFO - Started process (PID=58332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:05:28.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:05:28.561+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:05:28.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:05:28.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:05:28.589+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:05:28.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:05:28.602+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:05:28.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:05:28.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T16:05:58.969+0000] {processor.py:157} INFO - Started process (PID=58357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:05:58.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:05:58.972+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:05:58.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:05:58.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:05:59.002+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:05:59.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:05:59.015+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:05:59.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:05:59.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T16:06:29.438+0000] {processor.py:157} INFO - Started process (PID=58382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:06:29.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:06:29.442+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:06:29.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:06:29.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:06:29.473+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:06:29.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:06:29.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:06:29.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:06:29.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T16:06:59.874+0000] {processor.py:157} INFO - Started process (PID=58406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:06:59.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:06:59.877+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:06:59.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:06:59.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:06:59.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:06:59.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:06:59.915+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:06:59.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:06:59.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:07:30.332+0000] {processor.py:157} INFO - Started process (PID=58432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:07:30.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:07:30.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:07:30.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:07:30.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:07:30.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:07:30.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:07:30.370+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:07:30.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:07:30.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T16:08:00.781+0000] {processor.py:157} INFO - Started process (PID=58457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:08:00.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:08:00.783+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:08:00.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:08:00.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:08:00.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:08:00.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:08:00.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:08:00.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:08:00.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:08:31.170+0000] {processor.py:157} INFO - Started process (PID=58482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:08:31.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:08:31.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:08:31.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:08:31.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:08:31.207+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:08:31.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:08:31.221+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:08:31.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:08:31.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T16:09:01.686+0000] {processor.py:157} INFO - Started process (PID=58507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:09:01.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:09:01.692+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:09:01.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:09:01.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:09:01.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:09:01.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:09:01.742+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:09:01.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:09:01.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T16:09:32.209+0000] {processor.py:157} INFO - Started process (PID=58532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:09:32.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:09:32.212+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:09:32.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:09:32.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:09:32.240+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:09:32.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:09:32.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:09:32.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:09:32.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:10:02.658+0000] {processor.py:157} INFO - Started process (PID=58557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:10:02.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:10:02.660+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:10:02.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:10:02.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:10:02.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:10:02.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:10:02.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:10:02.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:10:02.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:10:33.040+0000] {processor.py:157} INFO - Started process (PID=58582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:10:33.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:10:33.043+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:10:33.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:10:33.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:10:33.063+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:10:33.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:10:33.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:10:33.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:10:33.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-21T16:11:03.489+0000] {processor.py:157} INFO - Started process (PID=58607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:11:03.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:11:03.492+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:11:03.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:11:03.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:11:03.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:11:03.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:11:03.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:11:03.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:11:03.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:11:33.953+0000] {processor.py:157} INFO - Started process (PID=58632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:11:33.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:11:33.956+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:11:33.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:11:33.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:11:33.983+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:11:33.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:11:33.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:11:33.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:11:34.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:12:04.385+0000] {processor.py:157} INFO - Started process (PID=58657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:12:04.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:12:04.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:12:04.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:12:04.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:12:04.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:12:04.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:12:04.425+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:12:04.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:12:04.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:12:34.900+0000] {processor.py:157} INFO - Started process (PID=58682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:12:34.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:12:34.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:12:34.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:12:34.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:12:34.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:12:34.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:12:34.945+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:12:34.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:12:34.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T16:13:05.342+0000] {processor.py:157} INFO - Started process (PID=58707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:13:05.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:13:05.350+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:13:05.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:13:05.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:13:05.398+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:13:05.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:13:05.414+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:13:05.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:13:05.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-21T16:13:35.855+0000] {processor.py:157} INFO - Started process (PID=58732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:13:35.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:13:35.858+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:13:35.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:13:35.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:13:35.887+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:13:35.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:13:35.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:13:35.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:13:35.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T16:14:06.341+0000] {processor.py:157} INFO - Started process (PID=58757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:14:06.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:14:06.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:14:06.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:14:06.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:14:06.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:14:06.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:14:06.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:14:06.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:14:06.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-21T16:14:36.889+0000] {processor.py:157} INFO - Started process (PID=58782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:14:36.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:14:36.892+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:14:36.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:14:36.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:14:36.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:14:36.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:14:36.926+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:14:36.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:14:36.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:15:07.390+0000] {processor.py:157} INFO - Started process (PID=58807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:15:07.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:15:07.404+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:15:07.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:15:07.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:15:07.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:15:07.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:15:07.462+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:15:07.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:15:07.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-21T16:15:37.904+0000] {processor.py:157} INFO - Started process (PID=58832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:15:37.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:15:37.910+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:15:37.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:15:37.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:15:37.947+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:15:37.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:15:37.959+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:15:37.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:15:37.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T16:16:08.313+0000] {processor.py:157} INFO - Started process (PID=58857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:16:08.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:16:08.316+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:16:08.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:16:08.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:16:08.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:16:08.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:16:08.354+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:16:08.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:16:08.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:16:38.814+0000] {processor.py:157} INFO - Started process (PID=58882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:16:38.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:16:38.817+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:16:38.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:16:38.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:16:38.845+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:16:38.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:16:38.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:16:38.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:16:38.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:17:09.302+0000] {processor.py:157} INFO - Started process (PID=58907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:17:09.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:17:09.305+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:17:09.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:17:09.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:17:09.330+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:17:09.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:17:09.340+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:17:09.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:17:09.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T16:17:39.785+0000] {processor.py:157} INFO - Started process (PID=58932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:17:39.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:17:39.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:17:39.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:17:39.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:17:39.830+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:17:39.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:17:39.845+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:17:39.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:17:39.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-21T16:18:10.312+0000] {processor.py:157} INFO - Started process (PID=58957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:18:10.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:18:10.318+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:18:10.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:18:10.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:18:10.363+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:18:10.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:18:10.375+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:18:10.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:18:10.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T16:18:40.814+0000] {processor.py:157} INFO - Started process (PID=58982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:18:40.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:18:40.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:18:40.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:18:40.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:18:40.857+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:18:40.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:18:40.867+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:18:40.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:18:40.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T16:19:11.232+0000] {processor.py:157} INFO - Started process (PID=59007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:19:11.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:19:11.238+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:19:11.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:19:11.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:19:11.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:19:11.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:19:11.279+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:19:11.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:19:11.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T16:19:41.581+0000] {processor.py:157} INFO - Started process (PID=59032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:19:41.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:19:41.585+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:19:41.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:19:41.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:19:41.612+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:19:41.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:19:41.624+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:19:41.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:19:41.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:20:12.031+0000] {processor.py:157} INFO - Started process (PID=59057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:20:12.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:20:12.034+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:20:12.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:20:12.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:20:12.062+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:20:12.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:20:12.074+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:20:12.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:20:12.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:20:42.461+0000] {processor.py:157} INFO - Started process (PID=59082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:20:42.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:20:42.463+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:20:42.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:20:42.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:20:42.489+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:20:42.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:20:42.500+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:20:42.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:20:42.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:21:12.950+0000] {processor.py:157} INFO - Started process (PID=59107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:21:12.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:21:12.954+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:21:12.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:21:12.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:21:12.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:21:12.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:21:12.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:21:12.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:21:13.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T16:21:43.400+0000] {processor.py:157} INFO - Started process (PID=59132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:21:43.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:21:43.405+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:21:43.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:21:43.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:21:43.432+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:21:43.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:21:43.441+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:21:43.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:21:43.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T16:22:13.861+0000] {processor.py:157} INFO - Started process (PID=59157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:22:13.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:22:13.864+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:22:13.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:22:13.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:22:13.901+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:22:13.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:22:13.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:22:13.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:22:13.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T16:22:44.282+0000] {processor.py:157} INFO - Started process (PID=59182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:22:44.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:22:44.287+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:22:44.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:22:44.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:22:44.314+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:22:44.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:22:44.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:22:44.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:22:44.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T16:23:14.740+0000] {processor.py:157} INFO - Started process (PID=59207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:23:14.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:23:14.743+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:23:14.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:23:14.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:23:14.769+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:23:14.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:23:14.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:23:14.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:23:14.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:23:45.156+0000] {processor.py:157} INFO - Started process (PID=59232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:23:45.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:23:45.161+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:23:45.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:23:45.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:23:45.189+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:23:45.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:23:45.198+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:23:45.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:23:45.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:24:15.562+0000] {processor.py:157} INFO - Started process (PID=59257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:24:15.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:24:15.564+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:24:15.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:24:15.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:24:15.590+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:24:15.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:24:15.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:24:15.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:24:15.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T16:24:45.972+0000] {processor.py:157} INFO - Started process (PID=59282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:24:45.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:24:45.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:24:45.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:24:45.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:24:46.002+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:24:46.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:24:46.013+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:24:46.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:24:46.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:25:16.378+0000] {processor.py:157} INFO - Started process (PID=59307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:25:16.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:25:16.381+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:25:16.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:25:16.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:25:16.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:25:16.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:25:16.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:25:16.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:25:16.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T16:25:46.847+0000] {processor.py:157} INFO - Started process (PID=59332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:25:46.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:25:46.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:25:46.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:25:46.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:25:46.877+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:25:46.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:25:46.887+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:25:46.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:25:46.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:26:17.324+0000] {processor.py:157} INFO - Started process (PID=59357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:26:17.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:26:17.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:26:17.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:26:17.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:26:17.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:26:17.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:26:17.362+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:26:17.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:26:17.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T16:26:47.731+0000] {processor.py:157} INFO - Started process (PID=59382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:26:47.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:26:47.734+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:26:47.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:26:47.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:26:47.764+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:26:47.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:26:47.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:26:47.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:26:47.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:27:18.187+0000] {processor.py:157} INFO - Started process (PID=59407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:27:18.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:27:18.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:27:18.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:27:18.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:27:18.220+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:27:18.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:27:18.232+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:27:18.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:27:18.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T16:27:48.544+0000] {processor.py:157} INFO - Started process (PID=59432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:27:48.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:27:48.546+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:27:48.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:27:48.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:27:48.571+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:27:48.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:27:48.580+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:27:48.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:27:48.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T16:28:19.036+0000] {processor.py:157} INFO - Started process (PID=59457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:28:19.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:28:19.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:28:19.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:28:19.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:28:19.070+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:28:19.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:28:19.079+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:28:19.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:28:19.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:28:49.568+0000] {processor.py:157} INFO - Started process (PID=59482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:28:49.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:28:49.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:28:49.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:28:49.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:28:49.598+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:28:49.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:28:49.611+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:28:49.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:28:49.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:29:20.270+0000] {processor.py:157} INFO - Started process (PID=59507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:29:20.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:29:20.289+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:29:20.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:29:20.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:29:20.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:29:20.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:29:20.358+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:29:20.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:29:20.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-21T16:29:50.861+0000] {processor.py:157} INFO - Started process (PID=59532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:29:50.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:29:50.868+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:29:50.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:29:50.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:29:50.929+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:29:50.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:29:50.941+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:29:50.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:29:50.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-21T16:30:21.476+0000] {processor.py:157} INFO - Started process (PID=59557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:30:21.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:30:21.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:30:21.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:30:21.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:30:21.525+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:30:21.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:30:21.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:30:21.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:30:21.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-21T16:30:51.979+0000] {processor.py:157} INFO - Started process (PID=59582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:30:51.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:30:51.985+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:30:51.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:30:52.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:30:52.021+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:30:52.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:30:52.031+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:30:52.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:30:52.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T16:31:22.493+0000] {processor.py:157} INFO - Started process (PID=59607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:31:22.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:31:22.497+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:31:22.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:31:22.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:31:22.524+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:31:22.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:31:22.538+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:31:22.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:31:22.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T16:31:52.906+0000] {processor.py:157} INFO - Started process (PID=59632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:31:52.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:31:52.911+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:31:52.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:31:52.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:31:52.949+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:31:52.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:31:52.959+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:31:52.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:31:52.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T16:32:23.360+0000] {processor.py:157} INFO - Started process (PID=59657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:32:23.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:32:23.365+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:32:23.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:32:23.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:32:23.396+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:32:23.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:32:23.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:32:23.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:32:23.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T16:32:53.770+0000] {processor.py:157} INFO - Started process (PID=59682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:32:53.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:32:53.776+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:32:53.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:32:53.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:32:53.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:32:53.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:32:53.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:32:53.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:32:53.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T16:33:24.211+0000] {processor.py:157} INFO - Started process (PID=59707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:33:24.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:33:24.214+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:33:24.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:33:24.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:33:24.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:33:24.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:33:24.263+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:33:24.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:33:24.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T16:33:54.683+0000] {processor.py:157} INFO - Started process (PID=59732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:33:54.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:33:54.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:33:54.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:33:54.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:33:54.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:33:54.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:33:54.729+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:33:54.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:33:54.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T16:34:25.083+0000] {processor.py:157} INFO - Started process (PID=59757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:34:25.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:34:25.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:34:25.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:34:25.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:34:25.116+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:34:25.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:34:25.128+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:34:25.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:34:25.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T16:34:55.508+0000] {processor.py:157} INFO - Started process (PID=59782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:34:55.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:34:55.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:34:55.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:34:55.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:34:55.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:34:55.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:34:55.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:34:55.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:34:55.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T16:35:25.985+0000] {processor.py:157} INFO - Started process (PID=59807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:35:25.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:35:25.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:35:25.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:35:26.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:35:26.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:35:26.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:35:26.037+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:35:26.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:35:26.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T16:35:56.527+0000] {processor.py:157} INFO - Started process (PID=59832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:35:56.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:35:56.534+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:35:56.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:35:56.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:35:56.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:35:56.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:35:56.580+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:35:56.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:35:56.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T16:36:27.011+0000] {processor.py:157} INFO - Started process (PID=59857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:36:27.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:36:27.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:36:27.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:36:27.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:36:27.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:36:27.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:36:27.059+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:36:27.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:36:27.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T16:36:57.571+0000] {processor.py:157} INFO - Started process (PID=59882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:36:57.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:36:57.580+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:36:57.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:36:57.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:36:57.629+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:36:57.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:36:57.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:36:57.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:36:57.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-21T16:37:28.001+0000] {processor.py:157} INFO - Started process (PID=59907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:37:28.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:37:28.004+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:37:28.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:37:28.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:37:28.036+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:37:28.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:37:28.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:37:28.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:37:28.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T16:37:58.498+0000] {processor.py:157} INFO - Started process (PID=59932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:37:58.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:37:58.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:37:58.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:37:58.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:37:58.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:37:58.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:37:58.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:37:58.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:37:58.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T16:38:29.221+0000] {processor.py:157} INFO - Started process (PID=59957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:38:29.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:38:29.245+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:38:29.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:38:29.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:38:29.366+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:38:29.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:38:29.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:38:29.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:38:29.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-07-21T16:38:59.848+0000] {processor.py:157} INFO - Started process (PID=59982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:38:59.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:38:59.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:38:59.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:38:59.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:38:59.894+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:38:59.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:38:59.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:38:59.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:38:59.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T16:39:30.284+0000] {processor.py:157} INFO - Started process (PID=60007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:39:30.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:39:30.293+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:39:30.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:39:30.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:39:30.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:39:30.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:39:30.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:39:30.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:39:30.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-21T16:40:00.747+0000] {processor.py:157} INFO - Started process (PID=60032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:40:00.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:40:00.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:40:00.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:40:00.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:40:00.777+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:40:00.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:40:00.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:40:00.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:40:00.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:40:31.131+0000] {processor.py:157} INFO - Started process (PID=60057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:40:31.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:40:31.136+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:40:31.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:40:31.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:40:31.167+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:40:31.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:40:31.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:40:31.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:40:31.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T16:41:01.557+0000] {processor.py:157} INFO - Started process (PID=60082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:41:01.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:41:01.565+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:41:01.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:41:01.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:41:01.593+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:41:01.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:41:01.602+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:41:01.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:41:01.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T16:41:32.042+0000] {processor.py:157} INFO - Started process (PID=60107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:41:32.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:41:32.045+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:41:32.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:41:32.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:41:32.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:41:32.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:41:32.095+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:41:32.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:41:32.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T16:42:02.448+0000] {processor.py:157} INFO - Started process (PID=60132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:42:02.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:42:02.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:42:02.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:42:02.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:42:02.478+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:42:02.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:42:02.489+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:42:02.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:42:02.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:42:32.929+0000] {processor.py:157} INFO - Started process (PID=60157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:42:32.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:42:32.933+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:42:32.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:42:32.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:42:32.961+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:42:32.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:42:32.971+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:42:32.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:42:32.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:43:03.365+0000] {processor.py:157} INFO - Started process (PID=60182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:43:03.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:43:03.368+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:43:03.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:43:03.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:43:03.397+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:43:03.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:43:03.407+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:43:03.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:43:03.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:43:33.854+0000] {processor.py:157} INFO - Started process (PID=60207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:43:33.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:43:33.857+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:43:33.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:43:33.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:43:33.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:43:33.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:43:33.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:43:33.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:43:33.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T16:44:04.284+0000] {processor.py:157} INFO - Started process (PID=60232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:44:04.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:44:04.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:44:04.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:44:04.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:44:04.319+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:44:04.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:44:04.330+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:44:04.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:44:04.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T16:44:34.666+0000] {processor.py:157} INFO - Started process (PID=60257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:44:34.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:44:34.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:44:34.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:44:34.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:44:34.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:44:34.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:44:34.706+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:44:34.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:44:34.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:45:05.110+0000] {processor.py:157} INFO - Started process (PID=60282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:45:05.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:45:05.112+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:45:05.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:45:05.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:45:05.140+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:45:05.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:45:05.149+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:45:05.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:45:05.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:45:35.591+0000] {processor.py:157} INFO - Started process (PID=60307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:45:35.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:45:35.594+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:45:35.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:45:35.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:45:35.625+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:45:35.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:45:35.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:45:35.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:45:35.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T16:46:06.061+0000] {processor.py:157} INFO - Started process (PID=60332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:46:06.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:46:06.064+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:46:06.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:46:06.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:46:06.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:46:06.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:46:06.106+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:46:06.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:46:06.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T16:46:36.417+0000] {processor.py:157} INFO - Started process (PID=60357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:46:36.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:46:36.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:46:36.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:46:36.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:46:36.452+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:46:36.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:46:36.463+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:46:36.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:46:36.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T16:47:06.872+0000] {processor.py:157} INFO - Started process (PID=60382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:47:06.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:47:06.875+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:47:06.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:47:06.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:47:06.904+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:47:06.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:47:06.915+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:47:06.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:47:06.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T16:47:37.287+0000] {processor.py:157} INFO - Started process (PID=60407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:47:37.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:47:37.290+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:47:37.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:47:37.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:47:37.316+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:47:37.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:47:37.327+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:47:37.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:47:37.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:48:07.687+0000] {processor.py:157} INFO - Started process (PID=60432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:48:07.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:48:07.689+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:48:07.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:48:07.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:48:07.718+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:48:07.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:48:07.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:48:07.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:48:07.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:48:38.155+0000] {processor.py:157} INFO - Started process (PID=60457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:48:38.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:48:38.158+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:48:38.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:48:38.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:48:38.184+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:48:38.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:48:38.195+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:48:38.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:48:38.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:49:08.511+0000] {processor.py:157} INFO - Started process (PID=60482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:49:08.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:49:08.515+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:49:08.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:49:08.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:49:08.544+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:49:08.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:49:08.553+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:49:08.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:49:08.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T16:49:38.966+0000] {processor.py:157} INFO - Started process (PID=60507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:49:38.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:49:38.970+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:49:38.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:49:38.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:49:38.998+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:49:38.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:49:39.009+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:49:39.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:49:39.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:50:09.353+0000] {processor.py:157} INFO - Started process (PID=60532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:50:09.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:50:09.356+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:50:09.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:50:09.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:50:09.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:50:09.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:50:09.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:50:09.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:50:09.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:50:39.732+0000] {processor.py:157} INFO - Started process (PID=60557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:50:39.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:50:39.734+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:50:39.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:50:39.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:50:39.761+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:50:39.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:50:39.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:50:39.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:50:39.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T16:51:10.127+0000] {processor.py:157} INFO - Started process (PID=60582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:51:10.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:51:10.130+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:51:10.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:51:10.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:51:10.161+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:51:10.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:51:10.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:51:10.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:51:10.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T16:51:40.656+0000] {processor.py:157} INFO - Started process (PID=60607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:51:40.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:51:40.660+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:51:40.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:51:40.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:51:40.685+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:51:40.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:51:40.694+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:51:40.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:51:40.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T16:52:11.114+0000] {processor.py:157} INFO - Started process (PID=60632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:52:11.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:52:11.117+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:52:11.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:52:11.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:52:11.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:52:11.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:52:11.151+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:52:11.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:52:11.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T16:52:41.551+0000] {processor.py:157} INFO - Started process (PID=60657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:52:41.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:52:41.553+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:52:41.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:52:41.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:52:41.581+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:52:41.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:52:41.592+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:52:41.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:52:41.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:53:12.074+0000] {processor.py:157} INFO - Started process (PID=60682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:53:12.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:53:12.076+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:53:12.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:53:12.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:53:12.101+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:53:12.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:53:12.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:53:12.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:53:12.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T16:53:42.497+0000] {processor.py:157} INFO - Started process (PID=60707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:53:42.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:53:42.500+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:53:42.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:53:42.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:53:42.528+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:53:42.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:53:42.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:53:42.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:53:42.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:54:13.018+0000] {processor.py:157} INFO - Started process (PID=60732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:54:13.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:54:13.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:54:13.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:54:13.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:54:13.053+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:54:13.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:54:13.063+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:54:13.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:54:13.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T16:54:43.448+0000] {processor.py:157} INFO - Started process (PID=60757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:54:43.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:54:43.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:54:43.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:54:43.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:54:43.473+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:54:43.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:54:43.485+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:54:43.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:54:43.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T16:55:13.928+0000] {processor.py:157} INFO - Started process (PID=60782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:55:13.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:55:13.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:55:13.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:55:13.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:55:13.953+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:55:13.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:55:13.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:55:13.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:55:13.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T16:55:44.403+0000] {processor.py:157} INFO - Started process (PID=60807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:55:44.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:55:44.406+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:55:44.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:55:44.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:55:44.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:55:44.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:55:44.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:55:44.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:55:44.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T16:56:14.848+0000] {processor.py:157} INFO - Started process (PID=60832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:56:14.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:56:14.852+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:56:14.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:56:14.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:56:14.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:56:14.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:56:14.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:56:14.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:56:14.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T16:56:45.444+0000] {processor.py:157} INFO - Started process (PID=60857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:56:45.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:56:45.447+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:56:45.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:56:45.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:56:45.473+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:56:45.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:56:45.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:56:45.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:56:45.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:57:15.955+0000] {processor.py:157} INFO - Started process (PID=60882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:57:15.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:57:15.959+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:57:15.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:57:15.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:57:15.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:57:15.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:57:15.998+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:57:15.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:57:16.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T16:57:46.311+0000] {processor.py:157} INFO - Started process (PID=60907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:57:46.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:57:46.314+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:57:46.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:57:46.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:57:46.339+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:57:46.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:57:46.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:57:46.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:57:46.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T16:58:16.783+0000] {processor.py:157} INFO - Started process (PID=60932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:58:16.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:58:16.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:58:16.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:58:16.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:58:16.809+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:58:16.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:58:16.817+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:58:16.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:58:16.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T16:58:47.174+0000] {processor.py:157} INFO - Started process (PID=60957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:58:47.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:58:47.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:58:47.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:58:47.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:58:47.205+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:58:47.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:58:47.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:58:47.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:58:47.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T16:59:17.573+0000] {processor.py:157} INFO - Started process (PID=60982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:59:17.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:59:17.575+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:59:17.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:59:17.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:59:17.602+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:59:17.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:59:17.612+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:59:17.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:59:17.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T16:59:48.007+0000] {processor.py:157} INFO - Started process (PID=61007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:59:48.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T16:59:48.011+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:59:48.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:59:48.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T16:59:48.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:59:48.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T16:59:48.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T16:59:48.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T16:59:48.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:00:18.481+0000] {processor.py:157} INFO - Started process (PID=61032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:00:18.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:00:18.486+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:00:18.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:00:18.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:00:18.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:00:18.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:00:18.521+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:00:18.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:00:18.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T17:00:48.877+0000] {processor.py:157} INFO - Started process (PID=61057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:00:48.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:00:48.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:00:48.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:00:48.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:00:48.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:00:48.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:00:48.916+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:00:48.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:00:48.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:01:19.432+0000] {processor.py:157} INFO - Started process (PID=61082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:01:19.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:01:19.435+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:01:19.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:01:19.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:01:19.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:01:19.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:01:19.478+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:01:19.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:01:19.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T17:01:49.915+0000] {processor.py:157} INFO - Started process (PID=61107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:01:49.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:01:49.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:01:49.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:01:49.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:01:49.938+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:01:49.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:01:49.948+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:01:49.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:01:49.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-21T17:02:20.384+0000] {processor.py:157} INFO - Started process (PID=61132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:02:20.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:02:20.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:02:20.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:02:20.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:02:20.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:02:20.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:02:20.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:02:20.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:02:20.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:02:50.907+0000] {processor.py:157} INFO - Started process (PID=61156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:02:50.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:02:50.910+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:02:50.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:02:50.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:02:50.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:02:50.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:02:50.944+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:02:50.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:02:50.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:03:21.328+0000] {processor.py:157} INFO - Started process (PID=61182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:03:21.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:03:21.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:03:21.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:03:21.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:03:21.356+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:03:21.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:03:21.366+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:03:21.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:03:21.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T17:03:51.757+0000] {processor.py:157} INFO - Started process (PID=61207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:03:51.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:03:51.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:03:51.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:03:51.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:03:51.788+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:03:51.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:03:51.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:03:51.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:03:51.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:04:22.134+0000] {processor.py:157} INFO - Started process (PID=61232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:04:22.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:04:22.139+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:04:22.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:04:22.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:04:22.166+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:04:22.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:04:22.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:04:22.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:04:22.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:04:52.556+0000] {processor.py:157} INFO - Started process (PID=61257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:04:52.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:04:52.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:04:52.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:04:52.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:04:52.587+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:04:52.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:04:52.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:04:52.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:04:52.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:05:22.925+0000] {processor.py:157} INFO - Started process (PID=61282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:05:22.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:05:22.927+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:05:22.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:05:22.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:05:22.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:05:22.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:05:22.960+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:05:22.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:05:22.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T17:05:53.262+0000] {processor.py:157} INFO - Started process (PID=61307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:05:53.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:05:53.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:05:53.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:05:53.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:05:53.292+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:05:53.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:05:53.302+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:05:53.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:05:53.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T17:06:23.693+0000] {processor.py:157} INFO - Started process (PID=61332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:06:23.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:06:23.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:06:23.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:06:23.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:06:23.723+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:06:23.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:06:23.735+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:06:23.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:06:23.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:06:54.121+0000] {processor.py:157} INFO - Started process (PID=61357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:06:54.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:06:54.125+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:06:54.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:06:54.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:06:54.152+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:06:54.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:06:54.163+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:06:54.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:06:54.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:07:24.536+0000] {processor.py:157} INFO - Started process (PID=61382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:07:24.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:07:24.539+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:07:24.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:07:24.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:07:24.566+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:07:24.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:07:24.575+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:07:24.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:07:24.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T17:07:54.946+0000] {processor.py:157} INFO - Started process (PID=61407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:07:54.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:07:54.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:07:54.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:07:54.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:07:54.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:07:54.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:07:54.991+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:07:54.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:07:55.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T17:08:25.461+0000] {processor.py:157} INFO - Started process (PID=61432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:08:25.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:08:25.464+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:08:25.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:08:25.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:08:25.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:08:25.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:08:25.503+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:08:25.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:08:25.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:08:55.837+0000] {processor.py:157} INFO - Started process (PID=61457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:08:55.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:08:55.840+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:08:55.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:08:55.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:08:55.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:08:55.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:08:55.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:08:55.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:08:55.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T17:09:26.262+0000] {processor.py:157} INFO - Started process (PID=61482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:09:26.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:09:26.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:09:26.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:09:26.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:09:26.300+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:09:26.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:09:26.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:09:26.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:09:26.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T17:09:56.728+0000] {processor.py:157} INFO - Started process (PID=61507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:09:56.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:09:56.732+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:09:56.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:09:56.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:09:56.758+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:09:56.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:09:56.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:09:56.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:09:56.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:10:27.199+0000] {processor.py:157} INFO - Started process (PID=61532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:10:27.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:10:27.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:10:27.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:10:27.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:10:27.230+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:10:27.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:10:27.240+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:10:27.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:10:27.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:10:57.654+0000] {processor.py:157} INFO - Started process (PID=61557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:10:57.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:10:57.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:10:57.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:10:57.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:10:57.683+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:10:57.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:10:57.694+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:10:57.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:10:57.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:11:28.157+0000] {processor.py:157} INFO - Started process (PID=61582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:11:28.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:11:28.160+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:11:28.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:11:28.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:11:28.190+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:11:28.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:11:28.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:11:28.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:11:28.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T17:11:58.554+0000] {processor.py:157} INFO - Started process (PID=61607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:11:58.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:11:58.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:11:58.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:11:58.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:11:58.584+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:11:58.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:11:58.594+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:11:58.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:11:58.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:12:29.019+0000] {processor.py:157} INFO - Started process (PID=61632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:12:29.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:12:29.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:12:29.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:12:29.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:12:29.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:12:29.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:12:29.060+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:12:29.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:12:29.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:12:59.447+0000] {processor.py:157} INFO - Started process (PID=61657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:12:59.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:12:59.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:12:59.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:12:59.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:12:59.477+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:12:59.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:12:59.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:12:59.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:12:59.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:13:29.866+0000] {processor.py:157} INFO - Started process (PID=61682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:13:29.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:13:29.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:13:29.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:13:29.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:13:29.897+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:13:29.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:13:29.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:13:29.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:13:29.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:14:00.303+0000] {processor.py:157} INFO - Started process (PID=61707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:14:00.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:14:00.307+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:14:00.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:14:00.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:14:00.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:14:00.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:14:00.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:14:00.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:14:00.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T17:14:30.787+0000] {processor.py:157} INFO - Started process (PID=61732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:14:30.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:14:30.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:14:30.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:14:30.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:14:30.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:14:30.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:14:30.831+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:14:30.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:14:30.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:15:01.330+0000] {processor.py:157} INFO - Started process (PID=61757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:15:01.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:15:01.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:15:01.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:15:01.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:15:01.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:15:01.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:15:01.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:15:01.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:15:01.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T17:15:31.792+0000] {processor.py:157} INFO - Started process (PID=61782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:15:31.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:15:31.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:15:31.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:15:31.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:15:31.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:15:31.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:15:31.834+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:15:31.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:15:31.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:16:02.202+0000] {processor.py:157} INFO - Started process (PID=61807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:16:02.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:16:02.206+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:16:02.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:16:02.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:16:02.235+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:16:02.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:16:02.244+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:16:02.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:16:02.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:16:32.688+0000] {processor.py:157} INFO - Started process (PID=61832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:16:32.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:16:32.690+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:16:32.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:16:32.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:16:32.717+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:16:32.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:16:32.725+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:16:32.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:16:32.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T17:17:03.158+0000] {processor.py:157} INFO - Started process (PID=61857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:17:03.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:17:03.161+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:17:03.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:17:03.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:17:03.189+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:17:03.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:17:03.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:17:03.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:17:03.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:17:33.594+0000] {processor.py:157} INFO - Started process (PID=61882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:17:33.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:17:33.598+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:17:33.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:17:33.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:17:33.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:17:33.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:17:33.638+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:17:33.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:17:33.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:18:04.043+0000] {processor.py:157} INFO - Started process (PID=61907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:18:04.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:18:04.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:18:04.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:18:04.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:18:04.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:18:04.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:18:04.084+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:18:04.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:18:04.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T17:18:34.517+0000] {processor.py:157} INFO - Started process (PID=61932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:18:34.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:18:34.521+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:18:34.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:18:34.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:18:34.550+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:18:34.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:18:34.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:18:34.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:18:34.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:19:04.951+0000] {processor.py:157} INFO - Started process (PID=61957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:19:04.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:19:04.956+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:19:04.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:19:04.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:19:04.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:19:04.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:19:04.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:19:04.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:19:05.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:19:35.390+0000] {processor.py:157} INFO - Started process (PID=61982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:19:35.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:19:35.392+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:19:35.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:19:35.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:19:35.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:19:35.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:19:35.420+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:19:35.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:19:35.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.038 seconds
[2024-07-21T17:20:05.784+0000] {processor.py:157} INFO - Started process (PID=62007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:20:05.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:20:05.786+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:20:05.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:20:05.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:20:05.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:20:05.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:20:05.826+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:20:05.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:20:05.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:20:36.258+0000] {processor.py:157} INFO - Started process (PID=62032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:20:36.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:20:36.261+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:20:36.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:20:36.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:20:36.289+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:20:36.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:20:36.299+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:20:36.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:20:36.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:21:06.707+0000] {processor.py:157} INFO - Started process (PID=62057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:21:06.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:21:06.713+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:21:06.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:21:06.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:21:06.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:21:06.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:21:06.761+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:21:06.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:21:06.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T17:21:37.175+0000] {processor.py:157} INFO - Started process (PID=62082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:21:37.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:21:37.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:21:37.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:21:37.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:21:37.205+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:21:37.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:21:37.217+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:21:37.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:21:37.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:22:07.652+0000] {processor.py:157} INFO - Started process (PID=62107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:22:07.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:22:07.656+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:22:07.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:22:07.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:22:07.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:22:07.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:22:07.697+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:22:07.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:22:07.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T17:22:38.076+0000] {processor.py:157} INFO - Started process (PID=62132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:22:38.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:22:38.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:22:38.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:22:38.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:22:38.107+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:22:38.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:22:38.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:22:38.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:22:38.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:23:08.516+0000] {processor.py:157} INFO - Started process (PID=62157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:23:08.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:23:08.518+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:23:08.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:23:08.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:23:08.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:23:08.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:23:08.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:23:08.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:23:08.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.037 seconds
[2024-07-21T17:23:38.992+0000] {processor.py:157} INFO - Started process (PID=62182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:23:38.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:23:38.995+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:23:38.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:23:39.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:23:39.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:23:39.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:23:39.033+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:23:39.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:23:39.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:24:09.425+0000] {processor.py:157} INFO - Started process (PID=62207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:24:09.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:24:09.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:24:09.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:24:09.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:24:09.457+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:24:09.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:24:09.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:24:09.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:24:09.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:24:39.811+0000] {processor.py:157} INFO - Started process (PID=62232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:24:39.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:24:39.815+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:24:39.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:24:39.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:24:39.840+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:24:39.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:24:39.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:24:39.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:24:39.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:25:10.226+0000] {processor.py:157} INFO - Started process (PID=62257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:25:10.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:25:10.228+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:25:10.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:25:10.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:25:10.256+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:25:10.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:25:10.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:25:10.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:25:10.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:25:40.710+0000] {processor.py:157} INFO - Started process (PID=62282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:25:40.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:25:40.713+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:25:40.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:25:40.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:25:40.749+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:25:40.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:25:40.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:25:40.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:25:40.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T17:26:11.137+0000] {processor.py:157} INFO - Started process (PID=62307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:26:11.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:26:11.140+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:26:11.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:26:11.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:26:11.168+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:26:11.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:26:11.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:26:11.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:26:11.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:26:41.632+0000] {processor.py:157} INFO - Started process (PID=62332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:26:41.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:26:41.635+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:26:41.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:26:41.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:26:41.662+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:26:41.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:26:41.671+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:26:41.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:26:41.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T17:27:12.033+0000] {processor.py:157} INFO - Started process (PID=62357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:27:12.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:27:12.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:27:12.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:27:12.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:27:12.065+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:27:12.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:27:12.077+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:27:12.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:27:12.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:27:42.462+0000] {processor.py:157} INFO - Started process (PID=62382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:27:42.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:27:42.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:27:42.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:27:42.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:27:42.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:27:42.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:27:42.501+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:27:42.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:27:42.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:28:12.835+0000] {processor.py:157} INFO - Started process (PID=62407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:28:12.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:28:12.839+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:28:12.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:28:12.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:28:12.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:28:12.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:28:12.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:28:12.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:28:12.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T17:28:43.350+0000] {processor.py:157} INFO - Started process (PID=62432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:28:43.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:28:43.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:28:43.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:28:43.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:28:43.382+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:28:43.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:28:43.393+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:28:43.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:28:43.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:29:13.795+0000] {processor.py:157} INFO - Started process (PID=62457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:29:13.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:29:13.800+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:29:13.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:29:13.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:29:13.839+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:29:13.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:29:13.851+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:29:13.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:29:13.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T17:29:44.287+0000] {processor.py:157} INFO - Started process (PID=62482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:29:44.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:29:44.290+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:29:44.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:29:44.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:29:44.315+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:29:44.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:29:44.325+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:29:44.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:29:44.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T17:30:14.697+0000] {processor.py:157} INFO - Started process (PID=62507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:30:14.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:30:14.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:30:14.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:30:14.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:30:14.726+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:30:14.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:30:14.736+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:30:14.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:30:14.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:30:45.148+0000] {processor.py:157} INFO - Started process (PID=62532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:30:45.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:30:45.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:30:45.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:30:45.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:30:45.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:30:45.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:30:45.195+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:30:45.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:30:45.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T17:31:15.553+0000] {processor.py:157} INFO - Started process (PID=62557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:31:15.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:31:15.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:31:15.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:31:15.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:31:15.582+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:31:15.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:31:15.594+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:31:15.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:31:15.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T17:31:45.973+0000] {processor.py:157} INFO - Started process (PID=62582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:31:45.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:31:45.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:31:45.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:31:45.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:31:46.003+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:31:46.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:31:46.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:31:46.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:31:46.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T17:32:16.424+0000] {processor.py:157} INFO - Started process (PID=62607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:32:16.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:32:16.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:32:16.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:32:16.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:32:16.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:32:16.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:32:16.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:32:16.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:32:16.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T17:32:46.885+0000] {processor.py:157} INFO - Started process (PID=62632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:32:46.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:32:46.888+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:32:46.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:32:46.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:32:46.915+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:32:46.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:32:46.926+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:32:46.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:32:46.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:33:17.330+0000] {processor.py:157} INFO - Started process (PID=62657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:33:17.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:33:17.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:33:17.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:33:17.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:33:17.363+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:33:17.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:33:17.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:33:17.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:33:17.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:33:47.790+0000] {processor.py:157} INFO - Started process (PID=62682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:33:47.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:33:47.795+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:33:47.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:33:47.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:33:47.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:33:47.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:33:47.832+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:33:47.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:33:47.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T17:34:18.277+0000] {processor.py:157} INFO - Started process (PID=62707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:34:18.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:34:18.283+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:34:18.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:34:18.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:34:18.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:34:18.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:34:18.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:34:18.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:34:18.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-21T17:34:48.766+0000] {processor.py:157} INFO - Started process (PID=62732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:34:48.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:34:48.770+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:34:48.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:34:48.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:34:48.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:34:48.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:34:48.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:34:48.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:34:48.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:35:19.115+0000] {processor.py:157} INFO - Started process (PID=62757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:35:19.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:35:19.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:35:19.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:35:19.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:35:19.145+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:35:19.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:35:19.157+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:35:19.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:35:19.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:35:49.547+0000] {processor.py:157} INFO - Started process (PID=62782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:35:49.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:35:49.550+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:35:49.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:35:49.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:35:49.582+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:35:49.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:35:49.591+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:35:49.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:35:49.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:36:20.020+0000] {processor.py:157} INFO - Started process (PID=62807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:36:20.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:36:20.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:36:20.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:36:20.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:36:20.052+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:36:20.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:36:20.063+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:36:20.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:36:20.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:36:50.518+0000] {processor.py:157} INFO - Started process (PID=62832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:36:50.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:36:50.521+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:36:50.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:36:50.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:36:50.550+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:36:50.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:36:50.562+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:36:50.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:36:50.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:37:20.978+0000] {processor.py:157} INFO - Started process (PID=62857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:37:20.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:37:20.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:37:20.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:37:20.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:37:21.003+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:37:21.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:37:21.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:37:21.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:37:21.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T17:37:51.424+0000] {processor.py:157} INFO - Started process (PID=62882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:37:51.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:37:51.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:37:51.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:37:51.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:37:51.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:37:51.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:37:51.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:37:51.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:37:51.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:38:21.909+0000] {processor.py:157} INFO - Started process (PID=62907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:38:21.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:38:21.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:38:21.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:38:21.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:38:21.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:38:21.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:38:21.949+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:38:21.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:38:21.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:38:52.359+0000] {processor.py:157} INFO - Started process (PID=62932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:38:52.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:38:52.365+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:38:52.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:38:52.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:38:52.400+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:38:52.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:38:52.410+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:38:52.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:38:52.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T17:39:22.797+0000] {processor.py:157} INFO - Started process (PID=62957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:39:22.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:39:22.802+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:39:22.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:39:22.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:39:22.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:39:22.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:39:22.854+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:39:22.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:39:23.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.337 seconds
[2024-07-21T17:39:53.519+0000] {processor.py:157} INFO - Started process (PID=62982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:39:53.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:39:53.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:39:53.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:39:53.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:39:53.549+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:39:53.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:39:53.561+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:39:53.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:39:53.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T17:40:23.995+0000] {processor.py:157} INFO - Started process (PID=63007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:40:23.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:40:24.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:40:24.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:40:24.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:40:24.027+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:40:24.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:40:24.037+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:40:24.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:40:24.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:40:54.462+0000] {processor.py:157} INFO - Started process (PID=63032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:40:54.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:40:54.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:40:54.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:40:54.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:40:54.492+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:40:54.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:40:54.502+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:40:54.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:40:54.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:41:24.871+0000] {processor.py:157} INFO - Started process (PID=63057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:41:24.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:41:24.880+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:41:24.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:41:24.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:41:24.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:41:24.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:41:24.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:41:24.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:41:24.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T17:41:55.266+0000] {processor.py:157} INFO - Started process (PID=63082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:41:55.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:41:55.269+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:41:55.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:41:55.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:41:55.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:41:55.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:41:55.308+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:41:55.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:41:55.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:42:25.682+0000] {processor.py:157} INFO - Started process (PID=63107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:42:25.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:42:25.684+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:42:25.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:42:25.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:42:25.712+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:42:25.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:42:25.724+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:42:25.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:42:25.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-21T17:42:56.336+0000] {processor.py:157} INFO - Started process (PID=63132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:42:56.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:42:56.339+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:42:56.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:42:56.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:42:56.369+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:42:56.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:42:56.379+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:42:56.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:42:56.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:43:26.817+0000] {processor.py:157} INFO - Started process (PID=63157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:43:26.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:43:26.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:43:26.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:43:26.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:43:26.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:43:26.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:43:26.860+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:43:26.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:43:26.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:43:57.247+0000] {processor.py:157} INFO - Started process (PID=63182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:43:57.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:43:57.250+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:43:57.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:43:57.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:43:57.273+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:43:57.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:43:57.285+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:43:57.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:43:57.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T17:44:27.689+0000] {processor.py:157} INFO - Started process (PID=63207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:44:27.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:44:27.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:44:27.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:44:27.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:44:27.726+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:44:27.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:44:27.736+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:44:27.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:44:27.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T17:44:58.197+0000] {processor.py:157} INFO - Started process (PID=63232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:44:58.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:44:58.202+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:44:58.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:44:58.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:44:58.229+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:44:58.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:44:58.242+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:44:58.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:44:58.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T17:45:28.653+0000] {processor.py:157} INFO - Started process (PID=63257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:45:28.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:45:28.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:45:28.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:45:28.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:45:28.686+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:45:28.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:45:28.698+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:45:28.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:45:28.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T17:45:59.120+0000] {processor.py:157} INFO - Started process (PID=63282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:45:59.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:45:59.123+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:45:59.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:45:59.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:45:59.160+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:45:59.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:45:59.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:45:59.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:45:59.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T17:46:29.558+0000] {processor.py:157} INFO - Started process (PID=63307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:46:29.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:46:29.561+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:46:29.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:46:29.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:46:29.588+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:46:29.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:46:29.600+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:46:29.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:46:29.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:46:59.966+0000] {processor.py:157} INFO - Started process (PID=63332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:46:59.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:46:59.968+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:46:59.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:46:59.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:46:59.996+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:46:59.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:47:00.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:47:00.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:47:00.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:47:30.358+0000] {processor.py:157} INFO - Started process (PID=63357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:47:30.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:47:30.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:47:30.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:47:30.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:47:30.381+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:47:30.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:47:30.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:47:30.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:47:30.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-21T17:48:00.785+0000] {processor.py:157} INFO - Started process (PID=63382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:48:00.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:48:00.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:48:00.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:48:00.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:48:00.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:48:00.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:48:00.829+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:48:00.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:48:00.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-21T17:48:31.462+0000] {processor.py:157} INFO - Started process (PID=63407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:48:31.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:48:31.465+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:48:31.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:48:31.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:48:31.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:48:31.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:48:31.505+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:48:31.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:48:31.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T17:49:01.929+0000] {processor.py:157} INFO - Started process (PID=63432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:49:01.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:49:01.932+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:49:01.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:49:01.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:49:01.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:49:01.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:49:01.978+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:49:01.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:49:01.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T17:49:32.388+0000] {processor.py:157} INFO - Started process (PID=63457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:49:32.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:49:32.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:49:32.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:49:32.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:49:32.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:49:32.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:49:32.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:49:32.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:49:32.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T17:50:02.833+0000] {processor.py:157} INFO - Started process (PID=63482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:50:02.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:50:02.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:50:02.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:50:02.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:50:02.868+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:50:02.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:50:02.877+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:50:02.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:50:02.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T17:50:33.259+0000] {processor.py:157} INFO - Started process (PID=63507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:50:33.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:50:33.263+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:50:33.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:50:33.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:50:33.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:50:33.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:50:33.308+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:50:33.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:50:33.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T17:51:03.642+0000] {processor.py:157} INFO - Started process (PID=63532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:51:03.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:51:03.644+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:51:03.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:51:03.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:51:03.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:51:03.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:51:03.685+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:51:03.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:51:03.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-21T17:51:34.292+0000] {processor.py:157} INFO - Started process (PID=63557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:51:34.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:51:34.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:51:34.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:51:34.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:51:34.325+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:51:34.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:51:34.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:51:34.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:51:34.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:52:04.772+0000] {processor.py:157} INFO - Started process (PID=63582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:52:04.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:52:04.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:52:04.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:52:04.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:52:04.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:52:04.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:52:04.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:52:04.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:52:04.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T17:52:35.248+0000] {processor.py:157} INFO - Started process (PID=63607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:52:35.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:52:35.252+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:52:35.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:52:35.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:52:35.282+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:52:35.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:52:35.293+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:52:35.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:52:35.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T17:53:05.734+0000] {processor.py:157} INFO - Started process (PID=63632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:53:05.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:53:05.736+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:53:05.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:53:05.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:53:05.767+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:53:05.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:53:05.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:53:05.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:53:05.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:53:36.182+0000] {processor.py:157} INFO - Started process (PID=63657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:53:36.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:53:36.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:53:36.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:53:36.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:53:36.215+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:53:36.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:53:36.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:53:36.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:53:36.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-21T17:54:06.715+0000] {processor.py:157} INFO - Started process (PID=63682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:54:06.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:54:06.718+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:54:06.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:54:06.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:54:06.746+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:54:06.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:54:06.828+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:54:06.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:54:06.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-21T17:54:37.346+0000] {processor.py:157} INFO - Started process (PID=63707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:54:37.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:54:37.349+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:54:37.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:54:37.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:54:37.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:54:37.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:54:37.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:54:37.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:54:37.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:55:07.759+0000] {processor.py:157} INFO - Started process (PID=63732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:55:07.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:55:07.764+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:55:07.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:55:07.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:55:07.793+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:55:07.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:55:07.804+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:55:07.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:55:07.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T17:55:38.264+0000] {processor.py:157} INFO - Started process (PID=63757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:55:38.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:55:38.269+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:55:38.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:55:38.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:55:38.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:55:38.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:55:38.306+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:55:38.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:55:38.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:56:08.714+0000] {processor.py:157} INFO - Started process (PID=63782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:56:08.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:56:08.718+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:56:08.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:56:08.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:56:08.749+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:56:08.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:56:08.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:56:08.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:56:08.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T17:56:39.164+0000] {processor.py:157} INFO - Started process (PID=63807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:56:39.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:56:39.168+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:56:39.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:56:39.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:56:39.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:56:39.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:56:39.204+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:56:39.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:56:39.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-21T17:57:09.799+0000] {processor.py:157} INFO - Started process (PID=63832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:57:09.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:57:09.803+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:57:09.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:57:09.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:57:09.834+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:57:09.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:57:09.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:57:09.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:57:09.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T17:57:40.301+0000] {processor.py:157} INFO - Started process (PID=63857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:57:40.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:57:40.304+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:57:40.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:57:40.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:57:40.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:57:40.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:57:40.344+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:57:40.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:57:40.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T17:58:10.735+0000] {processor.py:157} INFO - Started process (PID=63882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:58:10.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:58:10.737+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:58:10.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:58:10.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:58:10.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:58:10.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:58:10.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:58:10.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:58:10.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T17:58:41.196+0000] {processor.py:157} INFO - Started process (PID=63907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:58:41.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:58:41.201+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:58:41.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:58:41.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:58:41.231+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:58:41.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:58:41.242+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:58:41.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:58:41.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T17:59:11.712+0000] {processor.py:157} INFO - Started process (PID=63932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:59:11.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:59:11.717+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:59:11.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:59:11.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:59:11.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:59:11.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:59:11.757+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:59:11.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:59:11.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T17:59:42.134+0000] {processor.py:157} INFO - Started process (PID=63957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:59:42.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T17:59:42.146+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:59:42.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:59:42.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T17:59:42.188+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:59:42.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T17:59:42.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T17:59:42.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T17:59:42.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-07-21T18:00:12.755+0000] {processor.py:157} INFO - Started process (PID=63981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:00:12.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:00:12.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:00:12.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:00:12.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:00:12.782+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:00:12.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:00:12.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:00:12.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:00:12.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T18:00:43.152+0000] {processor.py:157} INFO - Started process (PID=64007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:00:43.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:00:43.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:00:43.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:00:43.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:00:43.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:00:43.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:00:43.194+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:00:43.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:00:43.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T18:01:13.549+0000] {processor.py:157} INFO - Started process (PID=64032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:01:13.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:01:13.552+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:01:13.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:01:13.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:01:13.581+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:01:13.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:01:13.592+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:01:13.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:01:13.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T18:01:44.051+0000] {processor.py:157} INFO - Started process (PID=64057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:01:44.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:01:44.062+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:01:44.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:01:44.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:01:44.113+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:01:44.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:01:44.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:01:44.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:01:44.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-21T18:02:14.635+0000] {processor.py:157} INFO - Started process (PID=64082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:02:14.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:02:14.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:02:14.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:02:14.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:02:14.665+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:02:14.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:02:14.675+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:02:14.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:02:14.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-07-21T18:02:45.250+0000] {processor.py:157} INFO - Started process (PID=64107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:02:45.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:02:45.256+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:02:45.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:02:45.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:02:45.289+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:02:45.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:02:45.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:02:45.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:02:45.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-07-21T18:03:15.867+0000] {processor.py:157} INFO - Started process (PID=64132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:03:15.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:03:15.887+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:03:15.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:03:15.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:03:15.933+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:03:15.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:03:15.946+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:03:15.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:03:15.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-21T18:03:46.388+0000] {processor.py:157} INFO - Started process (PID=64157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:03:46.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:03:46.391+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:03:46.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:03:46.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:03:46.421+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:03:46.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:03:46.433+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:03:46.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:03:46.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T18:04:16.847+0000] {processor.py:157} INFO - Started process (PID=64182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:04:16.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:04:16.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:04:16.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:04:16.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:04:16.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:04:16.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:04:16.891+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:04:16.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:04:16.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T18:04:47.317+0000] {processor.py:157} INFO - Started process (PID=64207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:04:47.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:04:47.320+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:04:47.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:04:47.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:04:47.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:04:47.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:04:47.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:04:47.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:04:47.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T18:05:17.748+0000] {processor.py:157} INFO - Started process (PID=64232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:05:17.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:05:17.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:05:17.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:05:17.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:05:17.781+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:05:17.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:05:17.793+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:05:17.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:05:17.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-07-21T18:05:48.504+0000] {processor.py:157} INFO - Started process (PID=64257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:05:48.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:05:48.509+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:05:48.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:05:48.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:05:48.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:05:48.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:05:48.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:05:48.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:05:48.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T18:06:18.962+0000] {processor.py:157} INFO - Started process (PID=64282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:06:18.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:06:18.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:06:18.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:06:18.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:06:18.989+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:06:18.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:06:19.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:06:19.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:06:19.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T18:06:49.360+0000] {processor.py:157} INFO - Started process (PID=64307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:06:49.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:06:49.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:06:49.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:06:49.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:06:49.393+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:06:49.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:06:49.403+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:06:49.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:06:49.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T18:07:19.806+0000] {processor.py:157} INFO - Started process (PID=64332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:07:19.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:07:19.811+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:07:19.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:07:19.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:07:19.837+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:07:19.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:07:19.847+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:07:19.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:07:19.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T18:07:50.169+0000] {processor.py:157} INFO - Started process (PID=64357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:07:50.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:07:50.172+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:07:50.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:07:50.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:07:50.212+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:07:50.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:07:50.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:07:50.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:07:50.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-07-21T18:08:20.880+0000] {processor.py:157} INFO - Started process (PID=64382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:08:20.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:08:20.888+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:08:20.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:08:20.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:08:20.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:08:20.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:08:21.069+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:08:21.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:08:21.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-07-21T18:08:51.494+0000] {processor.py:157} INFO - Started process (PID=64407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:08:51.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:08:51.497+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:08:51.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:08:51.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:08:51.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:08:51.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:08:51.537+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:08:51.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:08:51.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T18:09:21.902+0000] {processor.py:157} INFO - Started process (PID=64432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:09:21.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:09:21.908+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:09:21.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:09:21.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:09:21.946+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:09:21.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:09:21.959+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:09:21.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:09:21.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T18:09:52.373+0000] {processor.py:157} INFO - Started process (PID=64457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:09:52.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:09:52.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:09:52.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:09:52.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:09:52.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:09:52.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:09:52.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:09:52.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:09:52.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T18:10:22.866+0000] {processor.py:157} INFO - Started process (PID=64482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:10:22.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:10:22.868+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:10:22.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:10:22.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:10:22.892+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:10:22.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:10:22.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:10:22.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:10:22.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T18:10:53.306+0000] {processor.py:157} INFO - Started process (PID=64507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:10:53.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:10:53.310+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:10:53.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:10:53.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:10:53.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:10:53.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:10:53.346+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:10:53.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:10:53.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-07-21T18:11:24.036+0000] {processor.py:157} INFO - Started process (PID=64532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:11:24.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:11:24.040+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:11:24.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:11:24.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:11:24.069+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:11:24.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:11:24.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:11:24.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:11:24.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-21T18:11:54.523+0000] {processor.py:157} INFO - Started process (PID=64557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:11:54.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:11:54.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:11:54.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:11:54.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:11:54.558+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:11:54.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:11:54.571+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:11:54.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:11:54.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T18:12:24.973+0000] {processor.py:157} INFO - Started process (PID=64582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:12:24.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:12:24.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:12:24.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:12:24.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:12:25.013+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:12:25.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:12:25.025+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:12:25.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:12:25.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T18:12:55.455+0000] {processor.py:157} INFO - Started process (PID=64607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:12:55.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:12:55.459+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:12:55.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:12:55.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:12:55.485+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:12:55.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:12:55.495+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:12:55.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:12:55.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T18:13:25.934+0000] {processor.py:157} INFO - Started process (PID=64632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:13:25.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:13:25.938+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:13:25.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:13:25.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:13:25.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:13:25.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:13:25.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:13:25.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:13:25.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T18:13:56.352+0000] {processor.py:157} INFO - Started process (PID=64657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:13:56.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:13:56.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:13:56.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:13:56.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:13:56.381+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:13:56.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:13:56.548+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:13:56.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:13:56.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-07-21T18:14:26.995+0000] {processor.py:157} INFO - Started process (PID=64682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:14:26.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:14:27.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:14:27.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:14:27.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:14:27.029+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:14:27.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:14:27.108+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:14:27.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:14:27.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-21T18:14:57.508+0000] {processor.py:157} INFO - Started process (PID=64707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:14:57.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:14:57.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:14:57.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:14:57.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:14:57.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:14:57.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:14:57.554+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:14:57.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:14:57.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T18:15:27.935+0000] {processor.py:157} INFO - Started process (PID=64732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:15:27.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:15:27.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:15:27.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:15:27.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:15:27.974+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:15:27.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:15:27.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:15:27.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:15:27.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T18:15:58.379+0000] {processor.py:157} INFO - Started process (PID=64757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:15:58.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:15:58.381+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:15:58.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:15:58.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:15:58.406+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:15:58.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:15:58.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:15:58.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:15:58.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T18:16:28.866+0000] {processor.py:157} INFO - Started process (PID=64782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:16:28.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:16:28.869+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:16:28.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:16:28.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:16:28.899+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:16:28.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:16:28.909+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:16:28.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:16:28.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-21T18:16:59.433+0000] {processor.py:157} INFO - Started process (PID=64807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:16:59.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:16:59.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:16:59.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:16:59.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:16:59.468+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:16:59.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:16:59.549+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:16:59.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:16:59.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-21T18:17:30.053+0000] {processor.py:157} INFO - Started process (PID=64832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:17:30.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:17:30.062+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:17:30.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:17:30.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:17:30.103+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:17:30.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:17:30.115+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:17:30.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:17:30.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T18:18:00.534+0000] {processor.py:157} INFO - Started process (PID=64857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:18:00.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:18:00.543+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:18:00.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:18:00.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:18:00.573+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:18:00.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:18:00.583+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:18:00.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:18:00.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T18:18:31.023+0000] {processor.py:157} INFO - Started process (PID=64882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:18:31.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:18:31.026+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:18:31.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:18:31.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:18:31.059+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:18:31.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:18:31.068+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:18:31.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:18:31.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T18:19:01.443+0000] {processor.py:157} INFO - Started process (PID=64907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:19:01.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:19:01.445+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:19:01.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:19:01.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:19:01.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:19:01.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:19:01.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:19:01.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:19:01.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T18:19:31.902+0000] {processor.py:157} INFO - Started process (PID=64932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:19:31.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:19:31.906+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:19:31.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:19:31.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:19:31.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:19:31.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:19:31.948+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:19:31.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:19:32.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-07-21T18:20:02.515+0000] {processor.py:157} INFO - Started process (PID=64957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:20:02.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:20:02.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:20:02.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:20:02.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:20:02.548+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:20:02.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:20:02.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:20:02.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:20:02.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-21T18:20:33.039+0000] {processor.py:157} INFO - Started process (PID=64982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:20:33.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:20:33.045+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:20:33.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:20:33.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:20:33.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:20:33.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:20:33.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:20:33.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:20:33.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T18:21:03.493+0000] {processor.py:157} INFO - Started process (PID=65007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:21:03.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:21:03.496+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:21:03.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:21:03.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:21:03.523+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:21:03.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:21:03.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:21:03.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:21:03.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T18:21:34.001+0000] {processor.py:157} INFO - Started process (PID=65032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:21:34.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:21:34.007+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:21:34.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:21:34.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:21:34.044+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:21:34.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:21:34.057+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:21:34.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:21:34.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T18:22:04.450+0000] {processor.py:157} INFO - Started process (PID=65057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:22:04.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:22:04.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:22:04.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:22:04.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:22:04.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:22:04.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:22:04.485+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:22:04.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:22:04.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T18:22:34.893+0000] {processor.py:157} INFO - Started process (PID=65082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:22:34.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:22:34.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:22:34.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:22:34.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:22:34.925+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:22:34.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:22:35.002+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:22:35.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:22:35.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-21T18:23:05.387+0000] {processor.py:157} INFO - Started process (PID=65107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:23:05.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:23:05.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:23:05.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:23:05.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:23:05.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:23:05.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:23:05.491+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:23:05.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:23:05.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-21T18:23:36.078+0000] {processor.py:157} INFO - Started process (PID=65132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:23:36.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:23:36.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:23:36.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:23:36.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:23:36.109+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:23:36.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:23:36.120+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:23:36.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:23:36.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T18:24:06.527+0000] {processor.py:157} INFO - Started process (PID=65157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:24:06.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:24:06.530+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:24:06.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:24:06.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:24:06.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:24:06.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:24:06.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:24:06.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:24:06.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T18:24:37.014+0000] {processor.py:157} INFO - Started process (PID=65182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:24:37.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:24:37.018+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:24:37.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:24:37.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:24:37.045+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:24:37.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:24:37.054+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:24:37.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:24:37.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T18:25:07.362+0000] {processor.py:157} INFO - Started process (PID=65207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:25:07.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:25:07.365+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:25:07.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:25:07.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:25:07.392+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:25:07.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:25:07.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:25:07.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:25:07.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-07-21T18:25:38.016+0000] {processor.py:157} INFO - Started process (PID=65232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:25:38.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:25:38.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:25:38.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:25:38.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:25:38.061+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:25:38.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:25:38.140+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:25:38.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:25:38.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-21T18:26:08.633+0000] {processor.py:157} INFO - Started process (PID=65257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:26:08.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:26:08.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:26:08.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:26:08.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:26:08.665+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:26:08.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:26:08.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:26:08.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:26:08.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-21T18:26:39.313+0000] {processor.py:157} INFO - Started process (PID=65282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:26:39.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:26:39.317+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:26:39.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:26:39.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:26:39.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:26:39.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:26:39.356+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:26:39.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:26:39.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T18:27:09.719+0000] {processor.py:157} INFO - Started process (PID=65307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:27:09.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:27:09.723+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:27:09.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:27:09.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:27:09.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:27:09.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:27:09.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:27:09.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:27:09.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T18:27:40.135+0000] {processor.py:157} INFO - Started process (PID=65332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:27:40.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:27:40.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:27:40.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:27:40.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:27:40.165+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:27:40.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:27:40.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:27:40.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:27:40.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T18:28:10.553+0000] {processor.py:157} INFO - Started process (PID=65357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:28:10.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:28:10.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:28:10.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:28:10.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:28:10.587+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:28:10.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:28:10.598+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:28:10.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:28:10.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-21T18:28:41.086+0000] {processor.py:157} INFO - Started process (PID=65382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:28:41.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:28:41.090+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:28:41.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:28:41.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:28:41.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:28:41.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:28:41.194+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:28:41.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:28:41.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-21T18:29:11.634+0000] {processor.py:157} INFO - Started process (PID=65407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:29:11.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:29:11.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:29:11.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:29:11.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:29:11.665+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:29:11.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:29:11.675+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:29:11.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:29:11.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T18:29:42.070+0000] {processor.py:157} INFO - Started process (PID=65432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:29:42.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:29:42.078+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:29:42.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:29:42.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:29:42.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:29:42.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:29:42.122+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:29:42.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:29:42.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T18:30:12.516+0000] {processor.py:157} INFO - Started process (PID=65457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:30:12.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:30:12.519+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:30:12.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:30:12.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:30:12.546+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:30:12.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:30:12.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:30:12.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:30:12.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T18:30:42.981+0000] {processor.py:157} INFO - Started process (PID=65482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:30:42.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:30:42.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:30:42.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:30:42.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:30:43.011+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:30:43.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:30:43.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:30:43.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:30:43.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-21T18:31:13.625+0000] {processor.py:157} INFO - Started process (PID=65507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:31:13.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:31:13.627+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:31:13.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:31:13.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:31:13.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:31:13.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:31:13.735+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:31:13.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:31:13.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-21T18:31:44.121+0000] {processor.py:157} INFO - Started process (PID=65532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:31:44.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:31:44.125+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:31:44.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:31:44.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:31:44.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:31:44.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:31:44.235+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:31:44.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:31:44.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-21T18:32:14.667+0000] {processor.py:157} INFO - Started process (PID=65557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:32:14.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:32:14.673+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:32:14.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:32:14.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:32:14.712+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:32:14.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:32:14.724+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:32:14.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:32:14.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T18:32:45.105+0000] {processor.py:157} INFO - Started process (PID=65582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:32:45.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:32:45.109+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:32:45.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:32:45.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:32:45.137+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:32:45.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:32:45.148+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:32:45.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:32:45.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T18:33:15.448+0000] {processor.py:157} INFO - Started process (PID=65607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:33:15.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:33:15.450+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:33:15.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:33:15.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:33:15.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:33:15.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:33:15.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:33:15.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:33:15.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T18:33:45.872+0000] {processor.py:157} INFO - Started process (PID=65632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:33:45.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:33:45.876+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:33:45.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:33:45.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:33:45.900+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:33:45.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:33:45.910+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:33:45.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:33:46.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-07-21T18:34:16.577+0000] {processor.py:157} INFO - Started process (PID=65657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:34:16.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:34:16.581+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:34:16.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:34:16.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:34:16.611+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:34:16.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:34:16.694+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:34:16.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:34:16.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-21T18:34:47.170+0000] {processor.py:157} INFO - Started process (PID=65682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:34:47.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:34:47.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:34:47.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:34:47.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:34:47.227+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:34:47.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:34:47.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:34:47.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:34:47.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-07-21T18:35:17.976+0000] {processor.py:157} INFO - Started process (PID=65707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:35:17.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:35:17.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:35:17.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:35:17.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:35:18.010+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:35:18.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:35:18.020+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:35:18.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:35:18.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T18:35:48.388+0000] {processor.py:157} INFO - Started process (PID=65732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:35:48.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:35:48.391+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:35:48.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:35:48.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:35:48.420+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:35:48.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:35:48.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:35:48.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:35:48.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T18:36:18.826+0000] {processor.py:157} INFO - Started process (PID=65757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:36:18.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:36:18.830+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:36:18.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:36:18.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:36:18.869+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:36:18.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:36:18.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:36:18.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:36:18.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T18:36:49.241+0000] {processor.py:157} INFO - Started process (PID=65782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:36:49.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:36:49.244+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:36:49.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:36:49.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:36:49.269+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:36:49.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:36:49.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:36:49.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:36:49.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-21T18:37:19.921+0000] {processor.py:157} INFO - Started process (PID=65807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:37:19.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:37:19.924+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:37:19.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:37:19.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:37:19.954+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:37:19.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:37:20.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:37:20.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:37:20.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-21T18:37:50.584+0000] {processor.py:157} INFO - Started process (PID=65832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:37:50.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:37:50.589+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:37:50.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:37:50.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:37:50.685+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:37:50.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:37:50.693+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:37:50.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:37:50.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-21T18:38:21.143+0000] {processor.py:157} INFO - Started process (PID=65857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:38:21.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:38:21.145+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:38:21.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:38:21.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:38:21.175+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:38:21.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:38:21.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:38:21.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:38:21.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T18:38:51.605+0000] {processor.py:157} INFO - Started process (PID=65882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:38:51.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:38:51.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:38:51.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:38:51.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:38:51.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:38:51.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:38:51.649+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:38:51.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:38:51.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T18:39:22.109+0000] {processor.py:157} INFO - Started process (PID=65907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:39:22.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:39:22.112+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:39:22.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:39:22.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:39:22.141+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:39:22.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:39:22.153+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:39:22.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:39:22.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-21T18:39:52.748+0000] {processor.py:157} INFO - Started process (PID=65932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:39:52.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:39:52.753+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:39:52.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:39:52.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:39:52.807+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:39:52.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:39:52.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:39:52.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:39:52.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-07-21T18:40:23.329+0000] {processor.py:157} INFO - Started process (PID=65957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:40:23.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:40:23.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:40:23.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:40:23.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:40:23.356+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:40:23.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:40:23.436+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:40:23.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:40:23.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-21T18:40:53.867+0000] {processor.py:157} INFO - Started process (PID=65982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:40:53.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:40:53.871+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:40:53.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:40:53.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:40:53.901+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:40:53.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:40:53.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:40:53.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:40:53.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T18:41:24.293+0000] {processor.py:157} INFO - Started process (PID=66007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:41:24.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:41:24.295+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:41:24.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:41:24.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:41:24.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:41:24.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:41:24.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:41:24.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:41:24.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T18:41:54.733+0000] {processor.py:157} INFO - Started process (PID=66032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:41:54.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:41:54.735+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:41:54.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:41:54.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:41:54.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:41:54.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:41:54.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:41:54.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:41:54.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T18:42:25.124+0000] {processor.py:157} INFO - Started process (PID=66057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:42:25.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:42:25.129+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:42:25.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:42:25.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:42:25.166+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:42:25.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:42:25.179+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:42:25.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:42:25.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-21T18:42:55.827+0000] {processor.py:157} INFO - Started process (PID=66082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:42:55.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:42:55.830+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:42:55.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:42:55.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:42:55.859+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:42:55.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:42:55.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:42:55.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:42:55.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-21T18:43:26.395+0000] {processor.py:157} INFO - Started process (PID=66107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:43:26.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:43:26.398+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:43:26.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:43:26.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:43:26.500+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:43:26.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:43:26.508+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:43:26.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:43:26.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-21T18:43:57.034+0000] {processor.py:157} INFO - Started process (PID=66132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:43:57.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:43:57.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:43:57.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:43:57.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:43:57.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:43:57.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:43:57.076+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:43:57.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:43:57.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T18:44:27.427+0000] {processor.py:157} INFO - Started process (PID=66157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:44:27.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:44:27.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:44:27.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:44:27.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:44:27.462+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:44:27.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:44:27.471+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:44:27.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:44:27.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T18:44:57.837+0000] {processor.py:157} INFO - Started process (PID=66182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:44:57.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:44:57.840+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:44:57.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:44:57.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:44:57.868+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:44:57.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:44:57.878+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:44:57.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:44:57.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T18:45:28.326+0000] {processor.py:157} INFO - Started process (PID=66207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:45:28.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:45:28.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:45:28.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:45:28.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:45:28.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:45:28.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:45:28.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:45:28.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:45:28.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-21T18:45:58.846+0000] {processor.py:157} INFO - Started process (PID=66232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:45:58.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:45:58.848+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:45:58.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:45:58.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:45:58.875+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:45:58.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:45:58.954+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:45:58.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:45:58.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-21T18:46:29.520+0000] {processor.py:157} INFO - Started process (PID=66257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:46:29.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:46:29.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:46:29.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:46:29.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:46:29.621+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:46:29.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:46:29.629+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:46:29.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:46:29.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-21T18:47:00.053+0000] {processor.py:157} INFO - Started process (PID=66282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:47:00.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:47:00.057+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:47:00.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:47:00.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:47:00.083+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:47:00.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:47:00.096+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:47:00.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:47:00.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T18:47:30.470+0000] {processor.py:157} INFO - Started process (PID=66307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:47:30.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:47:30.473+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:47:30.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:47:30.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:47:30.500+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:47:30.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:47:30.510+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:47:30.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:47:30.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T18:48:00.949+0000] {processor.py:157} INFO - Started process (PID=66332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:48:00.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:48:00.952+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:48:00.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:48:00.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:48:00.978+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:48:00.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:48:00.992+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:48:00.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:48:01.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-21T18:48:31.605+0000] {processor.py:157} INFO - Started process (PID=66357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:48:31.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:48:31.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:48:31.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:48:31.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:48:31.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:48:31.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:48:31.716+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:48:31.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:48:31.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-21T18:49:02.158+0000] {processor.py:157} INFO - Started process (PID=66382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:49:02.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:49:02.163+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:49:02.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:49:02.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:49:02.196+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:49:02.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:49:02.297+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:49:02.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:49:02.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-21T18:49:32.749+0000] {processor.py:157} INFO - Started process (PID=66407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:49:32.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:49:32.754+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:49:32.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:49:32.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:49:32.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:49:32.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:49:32.804+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:49:32.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:49:32.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T18:50:03.280+0000] {processor.py:157} INFO - Started process (PID=66432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:50:03.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:50:03.282+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:50:03.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:50:03.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:50:03.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:50:03.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:50:03.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:50:03.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:50:03.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T18:50:33.748+0000] {processor.py:157} INFO - Started process (PID=66457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:50:33.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:50:33.751+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:50:33.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:50:33.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:50:33.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:50:33.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:50:33.789+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:50:33.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:50:33.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T18:51:04.112+0000] {processor.py:157} INFO - Started process (PID=66482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:51:04.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:51:04.114+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:51:04.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:51:04.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:51:04.141+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:51:04.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:51:04.257+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:51:04.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:51:04.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-21T18:51:34.793+0000] {processor.py:157} INFO - Started process (PID=66507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:51:34.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:51:34.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:51:34.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:51:34.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:51:34.824+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:51:34.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:51:34.904+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:51:34.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:51:34.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-21T18:52:05.322+0000] {processor.py:157} INFO - Started process (PID=66532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:52:05.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:52:05.326+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:52:05.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:52:05.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:52:05.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:52:05.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:52:05.451+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:52:05.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:52:05.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-21T18:52:36.042+0000] {processor.py:157} INFO - Started process (PID=66557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:52:36.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:52:36.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:52:36.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:52:36.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:52:36.085+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:52:36.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:52:36.097+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:52:36.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:52:36.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T18:53:06.566+0000] {processor.py:157} INFO - Started process (PID=66582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:53:06.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:53:06.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:53:06.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:53:06.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:53:06.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:53:06.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:53:06.607+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:53:06.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:53:06.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T18:53:37.020+0000] {processor.py:157} INFO - Started process (PID=66607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:53:37.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:53:37.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:53:37.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:53:37.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:53:37.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:53:37.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:53:37.059+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:53:37.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:53:37.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-07-21T18:54:07.624+0000] {processor.py:157} INFO - Started process (PID=66632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:54:07.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:54:07.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:54:07.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:54:07.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:54:07.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:54:07.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:54:07.736+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:54:07.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:54:07.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-21T18:54:38.332+0000] {processor.py:157} INFO - Started process (PID=66657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:54:38.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:54:38.336+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:54:38.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:54:38.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:54:38.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:54:38.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:54:38.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:54:38.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:54:38.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-21T18:55:08.856+0000] {processor.py:157} INFO - Started process (PID=66682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:55:08.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:55:08.863+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:55:08.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:55:08.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:55:08.959+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:55:08.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:55:08.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:55:08.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:55:08.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-21T18:55:39.561+0000] {processor.py:157} INFO - Started process (PID=66707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:55:39.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:55:39.566+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:55:39.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:55:39.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:55:39.602+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:55:39.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:55:39.615+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:55:39.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:55:39.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T18:56:10.048+0000] {processor.py:157} INFO - Started process (PID=66732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:56:10.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:56:10.054+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:56:10.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:56:10.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:56:10.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:56:10.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:56:10.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:56:10.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:56:10.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T18:56:40.527+0000] {processor.py:157} INFO - Started process (PID=66757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:56:40.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:56:40.530+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:56:40.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:56:40.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:56:40.558+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:56:40.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:56:40.572+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:56:40.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:56:40.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-21T18:57:11.092+0000] {processor.py:157} INFO - Started process (PID=66782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:57:11.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:57:11.097+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:57:11.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:57:11.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:57:11.125+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:57:11.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:57:11.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:57:11.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:57:11.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-21T18:57:41.606+0000] {processor.py:157} INFO - Started process (PID=66807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:57:41.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:57:41.610+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:57:41.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:57:41.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:57:41.641+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:57:41.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:57:41.721+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:57:41.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:57:41.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-21T18:58:12.137+0000] {processor.py:157} INFO - Started process (PID=66832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:58:12.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:58:12.139+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:58:12.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:58:12.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:58:12.254+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:58:12.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:58:12.261+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:58:12.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:58:12.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-21T18:58:42.745+0000] {processor.py:157} INFO - Started process (PID=66857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:58:42.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:58:42.748+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:58:42.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:58:42.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:58:42.777+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:58:42.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:58:42.788+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:58:42.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:58:42.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T18:59:13.253+0000] {processor.py:157} INFO - Started process (PID=66882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:59:13.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:59:13.262+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:59:13.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:59:13.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:59:13.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:59:13.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:59:13.337+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:59:13.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:59:13.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-21T18:59:43.769+0000] {processor.py:157} INFO - Started process (PID=66907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:59:43.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T18:59:43.774+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:59:43.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:59:43.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T18:59:43.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:59:43.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T18:59:44.060+0000] {logging_mixin.py:151} INFO - [2024-07-21T18:59:44.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T18:59:44.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.304 seconds
[2024-07-21T19:00:14.640+0000] {processor.py:157} INFO - Started process (PID=66932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:00:14.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:00:14.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:00:14.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:00:14.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:00:14.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:00:14.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:00:14.814+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:00:14.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:00:14.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-07-21T19:00:45.385+0000] {processor.py:157} INFO - Started process (PID=66957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:00:45.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:00:45.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:00:45.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:00:45.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:00:45.549+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:00:45.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:00:45.558+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:00:45.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:00:45.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-21T19:01:16.166+0000] {processor.py:157} INFO - Started process (PID=66982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:01:16.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:01:16.169+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:01:16.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:01:16.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:01:16.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:01:16.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:01:16.213+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:01:16.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:01:16.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T19:01:46.585+0000] {processor.py:157} INFO - Started process (PID=67007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:01:46.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:01:46.588+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:01:46.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:01:46.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:01:46.618+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:01:46.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:01:46.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:01:46.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:01:46.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T19:02:17.293+0000] {processor.py:157} INFO - Started process (PID=67031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:02:17.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:02:17.300+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:02:17.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:02:17.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:02:17.359+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:02:17.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:02:17.374+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:02:17.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:02:17.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.241 seconds
[2024-07-21T19:02:47.971+0000] {processor.py:157} INFO - Started process (PID=67057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:02:47.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:02:47.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:02:47.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:02:47.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:02:48.001+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:02:48.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:02:48.084+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:02:48.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:02:48.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-21T19:03:18.609+0000] {processor.py:157} INFO - Started process (PID=67082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:03:18.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:03:18.615+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:03:18.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:03:18.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:03:18.658+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:03:18.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:03:18.807+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:03:18.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:03:18.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-07-21T19:03:49.467+0000] {processor.py:157} INFO - Started process (PID=67107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:03:49.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:03:49.474+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:03:49.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:03:49.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:03:49.695+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:03:49.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:03:49.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:03:49.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:03:49.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.260 seconds
[2024-07-21T19:04:20.380+0000] {processor.py:157} INFO - Started process (PID=67132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:04:20.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:04:20.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:04:20.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:04:20.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:04:20.446+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:04:20.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:04:20.459+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:04:20.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:04:20.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-21T19:04:50.907+0000] {processor.py:157} INFO - Started process (PID=67157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:04:50.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:04:50.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:04:50.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:04:50.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:04:50.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:04:50.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:04:50.953+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:04:50.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:04:50.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T19:05:21.326+0000] {processor.py:157} INFO - Started process (PID=67182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:05:21.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:05:21.330+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:05:21.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:05:21.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:05:21.370+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:05:21.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:05:21.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:05:21.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:05:21.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-07-21T19:05:52.156+0000] {processor.py:157} INFO - Started process (PID=67207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:05:52.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:05:52.161+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:05:52.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:05:52.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:05:52.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:05:52.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:05:52.368+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:05:52.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:05:52.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-07-21T19:06:22.816+0000] {processor.py:157} INFO - Started process (PID=67232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:06:22.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:06:22.821+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:06:22.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:06:22.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:06:22.961+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:06:22.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:06:22.969+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:06:22.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:06:22.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-07-21T19:06:53.403+0000] {processor.py:157} INFO - Started process (PID=67257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:06:53.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:06:53.408+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:06:53.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:06:53.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:06:53.513+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:06:53.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:06:53.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:06:53.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:06:53.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-21T19:07:24.028+0000] {processor.py:157} INFO - Started process (PID=67282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:07:24.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:07:24.032+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:07:24.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:07:24.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:07:24.071+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:07:24.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:07:24.084+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:07:24.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:07:24.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T19:07:54.518+0000] {processor.py:157} INFO - Started process (PID=67307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:07:54.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:07:54.523+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:07:54.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:07:54.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:07:54.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:07:54.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:07:54.566+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:07:54.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:07:54.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T19:08:24.994+0000] {processor.py:157} INFO - Started process (PID=67332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:08:24.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:08:24.999+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:08:24.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:08:25.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:08:25.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:08:25.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:08:25.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:08:25.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:08:25.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-07-21T19:08:55.721+0000] {processor.py:157} INFO - Started process (PID=67357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:08:55.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:08:55.724+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:08:55.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:08:55.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:08:55.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:08:55.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:08:55.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:08:55.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:08:55.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-21T19:09:26.220+0000] {processor.py:157} INFO - Started process (PID=67382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:09:26.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:09:26.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:09:26.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:09:26.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:09:26.354+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:09:26.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:09:26.362+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:09:26.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:09:26.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-21T19:09:56.863+0000] {processor.py:157} INFO - Started process (PID=67407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:09:56.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:09:56.868+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:09:56.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:09:56.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:09:56.909+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:09:56.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:09:56.922+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:09:56.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:09:56.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T19:10:27.344+0000] {processor.py:157} INFO - Started process (PID=67432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:10:27.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:10:27.347+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:10:27.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:10:27.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:10:27.372+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:10:27.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:10:27.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:10:27.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:10:27.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T19:10:57.767+0000] {processor.py:157} INFO - Started process (PID=67457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:10:57.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:10:57.771+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:10:57.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:10:57.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:10:57.800+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:10:57.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:10:57.811+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:10:57.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:10:57.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-07-21T19:11:28.339+0000] {processor.py:157} INFO - Started process (PID=67482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:11:28.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:11:28.348+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:11:28.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:11:28.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:11:28.388+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:11:28.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:11:28.471+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:11:28.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:11:28.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-07-21T19:11:59.054+0000] {processor.py:157} INFO - Started process (PID=67507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:11:59.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:11:59.059+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:11:59.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:11:59.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:11:59.084+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:11:59.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:11:59.239+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:11:59.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:11:59.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-07-21T19:12:29.827+0000] {processor.py:157} INFO - Started process (PID=67532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:12:29.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:12:29.833+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:12:29.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:12:29.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:12:30.036+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:12:30.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:12:30.046+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:12:30.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:12:30.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-07-21T19:13:00.475+0000] {processor.py:157} INFO - Started process (PID=67557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:13:00.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:13:00.478+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:13:00.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:13:00.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:13:00.506+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:13:00.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:13:00.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:13:00.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:13:00.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T19:13:30.969+0000] {processor.py:157} INFO - Started process (PID=67582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:13:30.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:13:30.973+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:13:30.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:13:30.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:13:31.010+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:13:31.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:13:31.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:13:31.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:13:31.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T19:14:01.421+0000] {processor.py:157} INFO - Started process (PID=67607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:14:01.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:14:01.427+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:14:01.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:14:01.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:14:01.458+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:14:01.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:14:01.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:14:01.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:14:01.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.231 seconds
[2024-07-21T19:14:32.246+0000] {processor.py:157} INFO - Started process (PID=67632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:14:32.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:14:32.254+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:14:32.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:14:32.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:14:32.289+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:14:32.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:14:32.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:14:32.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:14:32.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-21T19:15:03.014+0000] {processor.py:157} INFO - Started process (PID=67657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:15:03.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:15:03.017+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:15:03.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:15:03.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:15:03.166+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:15:03.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:15:03.174+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:15:03.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:15:03.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-07-21T19:15:33.621+0000] {processor.py:157} INFO - Started process (PID=67682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:15:33.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:15:33.626+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:15:33.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:15:33.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:15:33.736+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:15:33.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:15:33.743+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:15:33.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:15:33.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-21T19:16:04.253+0000] {processor.py:157} INFO - Started process (PID=67706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:16:04.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:16:04.257+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:16:04.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:16:04.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:16:04.283+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:16:04.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:16:04.294+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:16:04.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:16:04.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:16:34.812+0000] {processor.py:157} INFO - Started process (PID=67732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:16:34.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:16:34.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:16:34.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:16:34.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:16:34.886+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:16:34.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:16:34.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:16:34.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:16:35.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-07-21T19:17:05.607+0000] {processor.py:157} INFO - Started process (PID=67756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:17:05.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:17:05.613+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:17:05.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:17:05.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:17:05.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:17:05.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:17:05.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:17:05.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:17:05.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.226 seconds
[2024-07-21T19:32:34.901+0000] {processor.py:157} INFO - Started process (PID=67782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:32:34.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:32:34.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:32:34.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:32:34.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:32:35.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:32:35.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:32:35.366+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:32:35.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:32:35.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.486 seconds
[2024-07-21T19:33:06.046+0000] {processor.py:157} INFO - Started process (PID=67809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:33:06.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:33:06.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:33:06.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:33:06.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:33:06.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:33:06.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:33:06.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:33:06.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:33:06.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-07-21T19:33:36.804+0000] {processor.py:157} INFO - Started process (PID=67834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:33:36.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:33:36.815+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:33:36.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:33:37.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:33:37.188+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:33:37.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:33:37.197+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:33:37.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:33:37.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.408 seconds
[2024-07-21T19:34:07.967+0000] {processor.py:157} INFO - Started process (PID=67859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:34:07.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:34:07.970+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:34:07.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:34:07.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:34:07.997+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:34:07.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:34:08.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:34:08.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:34:08.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:34:38.485+0000] {processor.py:157} INFO - Started process (PID=67884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:34:38.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:34:38.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:34:38.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:34:38.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:34:38.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:34:38.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:34:38.533+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:34:38.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:34:38.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T19:35:08.984+0000] {processor.py:157} INFO - Started process (PID=67909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:35:08.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:35:08.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:35:08.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:35:09.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:35:09.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:35:09.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:35:09.035+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:35:09.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:35:09.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T19:35:39.446+0000] {processor.py:157} INFO - Started process (PID=67934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:35:39.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:35:39.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:35:39.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:35:39.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:35:39.479+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:35:39.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:35:39.487+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:35:39.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:35:39.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:36:09.888+0000] {processor.py:157} INFO - Started process (PID=67959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:36:09.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:36:09.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:36:09.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:36:09.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:36:09.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:36:09.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:36:09.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:36:09.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:36:09.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T19:36:40.460+0000] {processor.py:157} INFO - Started process (PID=67984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:36:40.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:36:40.463+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:36:40.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:36:40.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:36:40.489+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:36:40.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:36:40.499+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:36:40.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:36:40.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T19:37:10.957+0000] {processor.py:157} INFO - Started process (PID=68009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:37:10.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:37:10.960+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:37:10.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:37:10.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:37:10.994+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:37:10.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:37:11.004+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:37:11.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:37:11.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T19:37:41.508+0000] {processor.py:157} INFO - Started process (PID=68034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:37:41.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:37:41.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:37:41.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:37:41.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:37:41.544+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:37:41.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:37:41.556+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:37:41.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:37:41.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T19:38:11.958+0000] {processor.py:157} INFO - Started process (PID=68059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:38:11.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:38:11.959+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:38:11.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:38:11.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:38:11.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:38:11.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:38:11.998+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:38:11.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:38:12.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T19:38:42.396+0000] {processor.py:157} INFO - Started process (PID=68084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:38:42.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:38:42.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:38:42.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:38:42.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:38:42.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:38:42.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:38:42.436+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:38:42.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:38:42.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T19:39:12.881+0000] {processor.py:157} INFO - Started process (PID=68109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:39:12.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:39:12.886+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:39:12.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:39:12.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:39:12.922+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:39:12.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:39:12.934+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:39:12.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:39:12.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T19:39:43.355+0000] {processor.py:157} INFO - Started process (PID=68134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:39:43.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:39:43.358+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:39:43.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:39:43.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:39:43.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:39:43.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:39:43.397+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:39:43.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:39:43.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T19:40:13.822+0000] {processor.py:157} INFO - Started process (PID=68159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:40:13.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:40:13.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:40:13.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:40:13.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:40:13.850+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:40:13.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:40:13.860+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:40:13.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:40:13.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T19:40:44.257+0000] {processor.py:157} INFO - Started process (PID=68184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:40:44.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:40:44.265+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:40:44.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:40:44.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:40:44.287+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:40:44.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:40:44.299+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:40:44.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:40:44.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T19:41:14.736+0000] {processor.py:157} INFO - Started process (PID=68209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:41:14.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:41:14.738+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:41:14.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:41:14.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:41:14.767+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:41:14.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:41:14.778+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:41:14.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:41:14.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:41:45.149+0000] {processor.py:157} INFO - Started process (PID=68234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:41:45.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:41:45.151+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:41:45.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:41:45.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:41:45.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:41:45.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:41:45.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:41:45.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:41:45.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T19:42:15.616+0000] {processor.py:157} INFO - Started process (PID=68259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:42:15.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:42:15.619+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:42:15.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:42:15.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:42:15.649+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:42:15.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:42:15.658+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:42:15.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:42:15.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T19:42:46.132+0000] {processor.py:157} INFO - Started process (PID=68284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:42:46.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:42:46.135+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:42:46.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:42:46.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:42:46.163+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:42:46.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:42:46.173+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:42:46.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:42:46.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T19:43:16.522+0000] {processor.py:157} INFO - Started process (PID=68309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:43:16.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:43:16.525+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:43:16.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:43:16.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:43:16.551+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:43:16.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:43:16.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:43:16.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:43:16.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T19:43:47.007+0000] {processor.py:157} INFO - Started process (PID=68334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:43:47.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:43:47.010+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:43:47.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:43:47.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:43:47.036+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:43:47.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:43:47.046+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:43:47.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:43:47.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:44:17.483+0000] {processor.py:157} INFO - Started process (PID=68359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:44:17.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:44:17.487+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:44:17.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:44:17.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:44:17.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:44:17.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:44:17.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:44:17.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:44:17.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T19:44:47.999+0000] {processor.py:157} INFO - Started process (PID=68384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:44:48.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:44:48.002+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:44:48.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:44:48.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:44:48.034+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:44:48.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:44:48.045+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:44:48.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:44:48.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T19:45:18.451+0000] {processor.py:157} INFO - Started process (PID=68409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:45:18.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:45:18.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:45:18.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:45:18.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:45:18.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:45:18.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:45:18.495+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:45:18.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:45:18.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T19:45:48.914+0000] {processor.py:157} INFO - Started process (PID=68434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:45:48.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:45:48.916+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:45:48.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:45:48.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:45:48.941+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:45:48.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:45:48.950+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:45:48.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:45:48.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T19:46:19.437+0000] {processor.py:157} INFO - Started process (PID=68459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:46:19.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:46:19.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:46:19.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:46:19.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:46:19.470+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:46:19.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:46:19.482+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:46:19.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:46:19.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T19:46:49.860+0000] {processor.py:157} INFO - Started process (PID=68484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:46:49.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:46:49.864+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:46:49.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:46:49.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:46:49.895+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:46:49.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:46:49.907+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:46:49.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:46:49.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T19:47:20.352+0000] {processor.py:157} INFO - Started process (PID=68509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:47:20.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:47:20.356+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:47:20.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:47:20.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:47:20.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:47:20.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:47:20.397+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:47:20.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:47:20.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T19:47:50.779+0000] {processor.py:157} INFO - Started process (PID=68534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:47:50.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:47:50.782+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:47:50.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:47:50.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:47:50.805+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:47:50.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:47:50.814+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:47:50.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:47:50.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T19:48:21.227+0000] {processor.py:157} INFO - Started process (PID=68559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:48:21.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:48:21.230+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:48:21.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:48:21.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:48:21.261+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:48:21.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:48:21.272+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:48:21.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:48:21.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T19:48:51.673+0000] {processor.py:157} INFO - Started process (PID=68584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:48:51.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:48:51.680+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:48:51.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:48:51.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:48:51.705+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:48:51.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:48:51.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:48:51.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:48:51.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:49:22.176+0000] {processor.py:157} INFO - Started process (PID=68609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:49:22.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:49:22.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:49:22.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:49:22.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:49:22.209+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:49:22.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:49:22.219+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:49:22.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:49:22.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:49:52.740+0000] {processor.py:157} INFO - Started process (PID=68633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:49:52.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:49:52.744+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:49:52.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:49:52.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:49:52.777+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:49:52.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:49:52.786+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:49:52.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:49:52.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T19:50:23.257+0000] {processor.py:157} INFO - Started process (PID=68659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:50:23.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:50:23.260+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:50:23.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:50:23.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:50:23.294+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:50:23.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:50:23.306+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:50:23.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:50:23.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T19:50:53.671+0000] {processor.py:157} INFO - Started process (PID=68684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:50:53.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:50:53.674+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:50:53.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:50:53.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:50:53.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:50:53.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:50:53.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:50:53.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:50:53.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:51:24.051+0000] {processor.py:157} INFO - Started process (PID=68709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:51:24.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:51:24.053+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:51:24.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:51:24.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:51:24.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:51:24.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:51:24.093+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:51:24.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:51:24.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T19:51:54.572+0000] {processor.py:157} INFO - Started process (PID=68734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:51:54.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:51:54.574+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:51:54.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:51:54.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:51:54.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:51:54.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:51:54.611+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:51:54.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:51:54.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T19:52:25.086+0000] {processor.py:157} INFO - Started process (PID=68759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:52:25.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:52:25.089+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:52:25.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:52:25.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:52:25.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:52:25.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:52:25.128+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:52:25.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:52:25.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T19:52:55.632+0000] {processor.py:157} INFO - Started process (PID=68784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:52:55.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:52:55.635+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:52:55.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:52:55.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:52:55.661+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:52:55.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:52:55.671+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:52:55.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:52:55.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T19:53:26.162+0000] {processor.py:157} INFO - Started process (PID=68809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:53:26.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:53:26.167+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:53:26.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:53:26.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:53:26.196+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:53:26.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:53:26.205+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:53:26.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:53:26.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T19:53:56.630+0000] {processor.py:157} INFO - Started process (PID=68834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:53:56.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:53:56.636+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:53:56.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:53:56.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:53:56.672+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:53:56.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:53:56.683+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:53:56.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:53:56.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T19:54:27.073+0000] {processor.py:157} INFO - Started process (PID=68859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:54:27.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:54:27.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:54:27.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:54:27.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:54:27.100+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:54:27.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:54:27.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:54:27.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:54:27.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T19:54:57.539+0000] {processor.py:157} INFO - Started process (PID=68884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:54:57.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:54:57.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:54:57.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:54:57.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:54:57.570+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:54:57.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:54:57.584+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:54:57.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:54:57.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T19:55:27.978+0000] {processor.py:157} INFO - Started process (PID=68909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:55:27.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:55:27.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:55:27.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:55:27.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:55:28.005+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:55:28.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:55:28.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:55:28.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:55:28.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T19:55:58.491+0000] {processor.py:157} INFO - Started process (PID=68934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:55:58.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:55:58.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:55:58.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:55:58.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:55:58.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:55:58.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:55:58.532+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:55:58.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:55:58.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T19:56:28.943+0000] {processor.py:157} INFO - Started process (PID=68959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:56:28.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:56:28.946+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:56:28.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:56:28.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:56:28.978+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:56:28.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:56:28.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:56:28.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:56:28.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T19:56:59.446+0000] {processor.py:157} INFO - Started process (PID=68984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:56:59.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:56:59.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:56:59.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:56:59.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:56:59.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:56:59.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:56:59.487+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:56:59.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:56:59.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T19:57:29.897+0000] {processor.py:157} INFO - Started process (PID=69009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:57:29.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:57:29.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:57:29.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:57:29.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:57:29.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:57:29.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:57:29.948+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:57:29.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:57:29.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T19:58:00.299+0000] {processor.py:157} INFO - Started process (PID=69034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:58:00.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:58:00.301+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:58:00.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:58:00.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:58:00.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:58:00.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:58:00.343+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:58:00.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:58:00.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T19:58:30.763+0000] {processor.py:157} INFO - Started process (PID=69059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:58:30.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:58:30.767+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:58:30.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:58:30.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:58:30.795+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:58:30.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:58:30.808+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:58:30.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:58:30.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T19:59:01.230+0000] {processor.py:157} INFO - Started process (PID=69084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:59:01.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:59:01.234+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:59:01.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:59:01.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:59:01.262+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:59:01.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:59:01.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:59:01.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:59:01.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T19:59:31.663+0000] {processor.py:157} INFO - Started process (PID=69109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:59:31.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T19:59:31.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:59:31.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:59:31.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T19:59:31.692+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:59:31.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T19:59:31.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T19:59:31.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T19:59:31.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T20:00:02.086+0000] {processor.py:157} INFO - Started process (PID=69134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:00:02.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:00:02.093+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:00:02.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:00:02.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:00:02.117+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:00:02.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:00:02.127+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:00:02.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:00:02.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T20:00:32.551+0000] {processor.py:157} INFO - Started process (PID=69159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:00:32.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:00:32.554+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:00:32.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:00:32.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:00:32.579+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:00:32.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:00:32.589+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:00:32.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:00:32.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T20:01:03.071+0000] {processor.py:157} INFO - Started process (PID=69184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:01:03.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:01:03.074+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:01:03.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:01:03.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:01:03.100+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:01:03.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:01:03.111+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:01:03.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:01:03.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T20:01:33.605+0000] {processor.py:157} INFO - Started process (PID=69209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:01:33.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:01:33.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:01:33.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:01:33.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:01:33.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:01:33.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:01:33.646+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:01:33.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:01:33.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T20:02:04.042+0000] {processor.py:157} INFO - Started process (PID=69234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:02:04.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:02:04.045+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:02:04.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:02:04.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:02:04.073+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:02:04.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:02:04.083+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:02:04.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:02:04.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:02:34.537+0000] {processor.py:157} INFO - Started process (PID=69259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:02:34.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:02:34.541+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:02:34.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:02:34.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:02:34.578+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:02:34.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:02:34.590+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:02:34.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:02:34.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T20:03:04.977+0000] {processor.py:157} INFO - Started process (PID=69284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:03:04.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:03:04.981+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:03:04.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:03:04.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:03:05.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:03:05.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:03:05.020+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:03:05.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:03:05.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T20:03:35.517+0000] {processor.py:157} INFO - Started process (PID=69309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:03:35.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:03:35.520+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:03:35.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:03:35.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:03:35.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:03:35.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:03:35.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:03:35.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:03:35.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T20:04:05.983+0000] {processor.py:157} INFO - Started process (PID=69334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:04:05.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:04:05.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:04:05.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:04:05.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:04:06.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:04:06.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:04:06.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:04:06.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:04:06.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:04:36.482+0000] {processor.py:157} INFO - Started process (PID=69359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:04:36.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:04:36.485+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:04:36.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:04:36.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:04:36.515+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:04:36.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:04:36.524+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:04:36.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:04:36.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T20:05:06.891+0000] {processor.py:157} INFO - Started process (PID=69384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:05:06.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:05:06.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:05:06.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:05:06.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:05:06.918+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:05:06.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:05:06.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:05:06.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:05:06.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T20:05:37.397+0000] {processor.py:157} INFO - Started process (PID=69409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:05:37.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:05:37.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:05:37.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:05:37.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:05:37.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:05:37.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:05:37.432+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:05:37.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:05:37.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-21T20:06:07.835+0000] {processor.py:157} INFO - Started process (PID=69433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:06:07.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:06:07.840+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:06:07.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:06:07.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:06:07.878+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:06:07.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:06:07.891+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:06:07.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:06:07.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-21T20:06:38.414+0000] {processor.py:157} INFO - Started process (PID=69459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:06:38.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:06:38.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:06:38.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:06:38.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:06:38.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:06:38.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:06:38.460+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:06:38.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:06:38.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T20:07:08.915+0000] {processor.py:157} INFO - Started process (PID=69484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:07:08.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:07:08.918+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:07:08.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:07:08.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:07:08.945+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:07:08.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:07:08.954+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:07:08.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:07:08.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T20:07:39.423+0000] {processor.py:157} INFO - Started process (PID=69509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:07:39.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:07:39.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:07:39.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:07:39.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:07:39.450+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:07:39.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:07:39.460+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:07:39.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:07:39.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T20:08:09.837+0000] {processor.py:157} INFO - Started process (PID=69534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:08:09.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:08:09.844+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:08:09.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:08:09.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:08:09.879+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:08:09.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:08:09.890+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:08:09.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:08:09.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-21T20:08:40.288+0000] {processor.py:157} INFO - Started process (PID=69559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:08:40.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:08:40.291+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:08:40.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:08:40.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:08:40.319+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:08:40.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:08:40.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:08:40.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:08:40.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T20:09:10.808+0000] {processor.py:157} INFO - Started process (PID=69584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:09:10.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:09:10.812+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:09:10.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:09:10.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:09:10.845+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:09:10.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:09:10.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:09:10.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:09:10.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T20:09:41.317+0000] {processor.py:157} INFO - Started process (PID=69609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:09:41.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:09:41.319+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:09:41.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:09:41.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:09:41.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:09:41.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:09:41.360+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:09:41.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:09:41.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T20:10:11.825+0000] {processor.py:157} INFO - Started process (PID=69634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:10:11.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:10:11.826+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:10:11.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:10:11.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:10:11.849+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:10:11.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:10:11.859+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:10:11.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:10:11.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T20:10:42.237+0000] {processor.py:157} INFO - Started process (PID=69659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:10:42.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:10:42.243+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:10:42.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:10:42.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:10:42.266+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:10:42.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:10:42.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:10:42.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:10:42.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T20:11:12.731+0000] {processor.py:157} INFO - Started process (PID=69684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:11:12.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:11:12.734+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:11:12.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:11:12.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:11:12.762+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:11:12.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:11:12.772+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:11:12.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:11:12.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:11:43.257+0000] {processor.py:157} INFO - Started process (PID=69709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:11:43.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:11:43.260+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:11:43.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:11:43.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:11:43.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:11:43.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:11:43.300+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:11:43.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:11:43.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T20:12:13.652+0000] {processor.py:157} INFO - Started process (PID=69734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:12:13.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:12:13.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:12:13.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:12:13.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:12:13.681+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:12:13.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:12:13.691+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:12:13.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:12:13.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T20:12:44.064+0000] {processor.py:157} INFO - Started process (PID=69759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:12:44.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:12:44.067+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:12:44.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:12:44.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:12:44.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:12:44.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:12:44.103+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:12:44.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:12:44.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T20:13:14.586+0000] {processor.py:157} INFO - Started process (PID=69784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:13:14.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:13:14.594+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:13:14.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:13:14.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:13:14.616+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:13:14.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:13:14.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:13:14.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:13:14.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T20:13:45.025+0000] {processor.py:157} INFO - Started process (PID=69809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:13:45.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:13:45.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:13:45.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:13:45.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:13:45.062+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:13:45.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:13:45.074+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:13:45.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:13:45.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T20:14:15.531+0000] {processor.py:157} INFO - Started process (PID=69834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:14:15.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:14:15.535+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:14:15.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:14:15.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:14:15.564+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:14:15.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:14:15.576+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:14:15.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:14:15.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T20:14:45.934+0000] {processor.py:157} INFO - Started process (PID=69859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:14:45.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:14:45.937+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:14:45.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:14:45.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:14:45.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:14:45.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:14:45.976+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:14:45.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:14:45.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T20:15:16.281+0000] {processor.py:157} INFO - Started process (PID=69884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:15:16.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:15:16.283+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:15:16.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:15:16.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:15:16.312+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:15:16.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:15:16.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:15:16.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:15:16.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T20:15:46.714+0000] {processor.py:157} INFO - Started process (PID=69909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:15:46.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:15:46.717+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:15:46.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:15:46.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:15:46.743+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:15:46.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:15:46.753+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:15:46.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:15:46.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T20:16:17.149+0000] {processor.py:157} INFO - Started process (PID=69934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:16:17.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:16:17.151+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:16:17.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:16:17.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:16:17.175+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:16:17.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:16:17.187+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:16:17.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:16:17.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T20:16:47.597+0000] {processor.py:157} INFO - Started process (PID=69959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:16:47.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:16:47.601+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:16:47.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:16:47.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:16:47.634+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:16:47.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:16:47.645+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:16:47.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:16:47.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T20:17:18.042+0000] {processor.py:157} INFO - Started process (PID=69984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:17:18.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:17:18.045+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:17:18.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:17:18.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:17:18.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:17:18.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:17:18.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:17:18.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:17:18.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:17:48.581+0000] {processor.py:157} INFO - Started process (PID=70009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:17:48.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:17:48.585+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:17:48.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:17:48.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:17:48.612+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:17:48.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:17:48.622+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:17:48.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:17:48.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T20:18:19.155+0000] {processor.py:157} INFO - Started process (PID=70034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:18:19.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:18:19.163+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:18:19.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:18:19.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:18:19.186+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:18:19.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:18:19.194+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:18:19.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:18:19.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T20:18:49.692+0000] {processor.py:157} INFO - Started process (PID=70059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:18:49.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:18:49.695+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:18:49.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:18:49.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:18:49.723+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:18:49.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:18:49.734+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:18:49.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:18:49.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T20:19:20.236+0000] {processor.py:157} INFO - Started process (PID=70084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:19:20.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:19:20.239+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:19:20.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:19:20.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:19:20.269+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:19:20.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:19:20.280+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:19:20.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:19:20.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T20:19:50.642+0000] {processor.py:157} INFO - Started process (PID=70109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:19:50.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:19:50.644+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:19:50.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:19:50.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:19:50.675+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:19:50.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:19:50.687+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:19:50.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:19:50.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T20:20:21.084+0000] {processor.py:157} INFO - Started process (PID=70134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:20:21.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:20:21.087+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:20:21.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:20:21.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:20:21.113+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:20:21.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:20:21.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:20:21.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:20:21.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:20:51.525+0000] {processor.py:157} INFO - Started process (PID=70159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:20:51.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:20:51.531+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:20:51.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:20:51.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:20:51.569+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:20:51.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:20:51.582+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:20:51.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:20:51.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T20:21:22.032+0000] {processor.py:157} INFO - Started process (PID=70184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:21:22.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:21:22.036+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:21:22.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:21:22.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:21:22.065+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:21:22.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:21:22.077+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:21:22.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:21:22.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T20:21:52.434+0000] {processor.py:157} INFO - Started process (PID=70209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:21:52.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:21:52.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:21:52.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:21:52.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:21:52.461+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:21:52.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:21:52.471+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:21:52.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:21:52.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T20:22:22.870+0000] {processor.py:157} INFO - Started process (PID=70234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:22:22.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:22:22.873+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:22:22.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:22:22.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:22:22.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:22:22.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:22:22.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:22:22.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:22:22.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:22:53.433+0000] {processor.py:157} INFO - Started process (PID=70259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:22:53.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:22:53.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:22:53.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:22:53.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:22:53.470+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:22:53.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:22:53.481+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:22:53.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:22:53.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T20:23:23.981+0000] {processor.py:157} INFO - Started process (PID=70284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:23:23.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:23:23.984+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:23:23.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:23:23.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:23:24.009+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:23:24.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:23:24.021+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:23:24.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:23:24.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T20:23:54.492+0000] {processor.py:157} INFO - Started process (PID=70309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:23:54.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:23:54.494+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:23:54.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:23:54.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:23:54.523+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:23:54.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:23:54.533+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:23:54.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:23:54.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:24:24.858+0000] {processor.py:157} INFO - Started process (PID=70334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:24:24.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:24:24.862+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:24:24.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:24:24.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:24:24.888+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:24:24.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:24:24.899+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:24:24.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:24:24.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T20:24:55.429+0000] {processor.py:157} INFO - Started process (PID=70359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:24:55.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:24:55.434+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:24:55.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:24:55.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:24:55.462+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:24:55.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:24:55.474+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:24:55.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:24:55.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T20:25:25.890+0000] {processor.py:157} INFO - Started process (PID=70384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:25:25.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:25:25.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:25:25.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:25:25.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:25:25.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:25:25.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:25:25.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:25:25.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:25:25.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:25:56.370+0000] {processor.py:157} INFO - Started process (PID=70409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:25:56.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:25:56.376+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:25:56.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:25:56.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:25:56.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:25:56.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:25:56.424+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:25:56.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:25:56.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T20:26:26.852+0000] {processor.py:157} INFO - Started process (PID=70434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:26:26.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:26:26.856+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:26:26.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:26:26.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:26:26.891+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:26:26.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:26:26.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:26:26.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:26:26.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T20:26:57.329+0000] {processor.py:157} INFO - Started process (PID=70459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:26:57.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:26:57.333+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:26:57.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:26:57.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:26:57.361+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:26:57.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:26:57.373+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:26:57.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:26:57.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T20:27:27.788+0000] {processor.py:157} INFO - Started process (PID=70484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:27:27.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:27:27.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:27:27.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:27:27.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:27:27.819+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:27:27.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:27:27.829+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:27:27.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:27:27.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T20:27:58.242+0000] {processor.py:157} INFO - Started process (PID=70509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:27:58.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:27:58.250+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:27:58.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:27:58.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:27:58.273+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:27:58.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:27:58.283+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:27:58.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:27:58.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T20:28:28.698+0000] {processor.py:157} INFO - Started process (PID=70534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:28:28.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:28:28.704+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:28:28.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:28:28.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:28:28.726+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:28:28.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:28:28.736+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:28:28.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:28:28.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T20:28:59.141+0000] {processor.py:157} INFO - Started process (PID=70559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:28:59.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:28:59.146+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:28:59.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:28:59.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:28:59.180+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:28:59.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:28:59.193+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:28:59.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:28:59.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T20:29:29.613+0000] {processor.py:157} INFO - Started process (PID=70584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:29:29.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:29:29.616+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:29:29.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:29:29.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:29:29.646+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:29:29.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:29:29.656+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:29:29.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:29:29.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T20:30:00.116+0000] {processor.py:157} INFO - Started process (PID=70609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:30:00.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:30:00.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:30:00.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:30:00.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:30:00.146+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:30:00.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:30:00.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:30:00.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:30:00.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T20:30:30.560+0000] {processor.py:157} INFO - Started process (PID=70634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:30:30.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:30:30.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:30:30.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:30:30.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:30:30.589+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:30:30.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:30:30.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:30:30.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:30:30.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T20:31:01.006+0000] {processor.py:157} INFO - Started process (PID=70659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:31:01.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:31:01.008+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:31:01.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:31:01.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:31:01.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:31:01.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:31:01.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:31:01.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:31:01.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T20:31:31.483+0000] {processor.py:157} INFO - Started process (PID=70684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:31:31.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:31:31.486+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:31:31.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:31:31.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:31:31.513+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:31:31.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:31:31.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:31:31.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:31:31.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T20:32:01.886+0000] {processor.py:157} INFO - Started process (PID=70708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:32:01.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:32:01.890+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:32:01.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:32:01.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:32:01.922+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:32:01.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:32:01.933+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:32:01.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:32:01.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T20:32:32.451+0000] {processor.py:157} INFO - Started process (PID=70734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:32:32.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:32:32.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:32:32.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:32:32.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:32:32.481+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:32:32.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:32:32.491+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:32:32.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:32:32.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T20:33:02.933+0000] {processor.py:157} INFO - Started process (PID=70759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:33:02.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:33:02.937+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:33:02.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:33:02.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:33:02.967+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:33:02.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:33:02.980+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:33:02.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:33:02.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T20:33:33.397+0000] {processor.py:157} INFO - Started process (PID=70784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:33:33.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:33:33.402+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:33:33.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:33:33.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:33:33.428+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:33:33.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:33:33.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:33:33.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:33:33.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T20:34:04.125+0000] {processor.py:157} INFO - Started process (PID=70809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:34:04.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:34:04.133+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:34:04.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:34:04.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:34:04.200+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:34:04.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:34:04.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:34:04.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:34:04.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-21T20:49:17.899+0000] {processor.py:157} INFO - Started process (PID=70834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:49:17.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:49:17.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:49:17.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:49:17.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:49:17.927+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:49:17.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:49:17.938+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:49:17.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:49:17.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T20:49:48.432+0000] {processor.py:157} INFO - Started process (PID=70861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:49:48.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T20:49:48.439+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:49:48.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:49:48.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T20:49:48.480+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:49:48.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T20:49:48.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T20:49:48.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T20:49:48.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-21T21:06:42.378+0000] {processor.py:157} INFO - Started process (PID=70887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:06:42.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:06:42.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:06:42.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:06:42.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:06:42.430+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:06:42.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:06:42.458+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:06:42.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:06:42.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-21T21:07:13.027+0000] {processor.py:157} INFO - Started process (PID=70913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:07:13.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:07:13.031+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:07:13.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:07:13.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:07:13.089+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:07:13.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:07:13.102+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:07:13.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:07:13.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-21T21:07:43.543+0000] {processor.py:157} INFO - Started process (PID=70938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:07:43.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:07:43.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:07:43.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:07:43.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:07:43.572+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:07:43.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:07:43.582+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:07:43.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:07:43.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:08:13.995+0000] {processor.py:157} INFO - Started process (PID=70963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:08:13.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:08:13.997+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:08:13.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:08:14.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:08:14.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:08:14.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:08:14.033+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:08:14.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:08:14.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T21:08:44.403+0000] {processor.py:157} INFO - Started process (PID=70988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:08:44.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:08:44.406+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:08:44.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:08:44.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:08:44.436+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:08:44.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:08:44.448+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:08:44.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:08:44.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T21:17:43.080+0000] {processor.py:157} INFO - Started process (PID=71014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:17:43.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:17:43.086+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:17:43.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:17:43.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:17:43.137+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:17:43.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:17:43.155+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:17:43.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:17:43.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-21T21:18:13.788+0000] {processor.py:157} INFO - Started process (PID=71040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:18:13.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:18:13.794+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:18:13.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:18:13.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:18:13.827+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:18:13.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:18:13.838+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:18:13.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:18:13.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T21:18:44.254+0000] {processor.py:157} INFO - Started process (PID=71065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:18:44.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:18:44.257+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:18:44.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:18:44.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:18:44.284+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:18:44.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:18:44.295+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:18:44.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:18:44.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T21:19:14.760+0000] {processor.py:157} INFO - Started process (PID=71090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:19:14.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:19:14.764+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:19:14.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:19:14.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:19:14.798+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:19:14.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:19:14.814+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:19:14.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:19:14.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T21:19:45.222+0000] {processor.py:157} INFO - Started process (PID=71115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:19:45.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:19:45.224+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:19:45.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:19:45.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:19:45.249+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:19:45.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:19:45.259+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:19:45.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:19:45.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T21:20:15.630+0000] {processor.py:157} INFO - Started process (PID=71140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:20:15.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:20:15.631+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:20:15.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:20:15.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:20:15.653+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:20:15.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:20:15.665+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:20:15.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:20:15.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-21T21:20:46.088+0000] {processor.py:157} INFO - Started process (PID=71165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:20:46.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:20:46.091+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:20:46.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:20:46.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:20:46.120+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:20:46.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:20:46.132+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:20:46.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:20:46.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T21:21:16.563+0000] {processor.py:157} INFO - Started process (PID=71190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:21:16.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:21:16.567+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:21:16.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:21:16.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:21:16.592+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:21:16.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:21:16.602+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:21:16.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:21:16.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T21:21:46.936+0000] {processor.py:157} INFO - Started process (PID=71215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:21:46.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:21:46.940+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:21:46.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:21:46.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:21:46.968+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:21:46.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:21:46.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:21:46.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:21:46.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T21:22:17.413+0000] {processor.py:157} INFO - Started process (PID=71240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:22:17.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:22:17.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:22:17.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:22:17.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:22:17.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:22:17.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:22:17.453+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:22:17.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:22:17.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T21:22:47.935+0000] {processor.py:157} INFO - Started process (PID=71265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:22:47.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:22:47.939+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:22:47.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:22:47.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:22:47.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:22:47.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:22:47.976+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:22:47.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:22:47.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T21:23:18.484+0000] {processor.py:157} INFO - Started process (PID=71290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:23:18.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:23:18.486+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:23:18.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:23:18.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:23:18.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:23:18.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:23:18.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:23:18.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:23:18.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T21:23:48.971+0000] {processor.py:157} INFO - Started process (PID=71314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:23:48.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:23:48.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:23:48.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:23:48.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:23:49.003+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:23:49.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:23:49.013+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:23:49.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:23:49.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:24:19.510+0000] {processor.py:157} INFO - Started process (PID=71339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:24:19.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:24:19.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:24:19.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:24:19.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:24:19.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:24:19.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:24:19.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:24:19.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:24:19.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T21:24:50.036+0000] {processor.py:157} INFO - Started process (PID=71365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:24:50.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:24:50.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:24:50.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:24:50.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:24:50.065+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:24:50.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:24:50.075+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:24:50.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:24:50.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T21:25:20.554+0000] {processor.py:157} INFO - Started process (PID=71390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:25:20.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:25:20.558+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:25:20.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:25:20.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:25:20.587+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:25:20.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:25:20.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:25:20.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:25:20.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T21:25:51.023+0000] {processor.py:157} INFO - Started process (PID=71415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:25:51.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:25:51.025+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:25:51.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:25:51.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:25:51.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:25:51.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:25:51.061+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:25:51.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:25:51.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T21:26:21.499+0000] {processor.py:157} INFO - Started process (PID=71440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:26:21.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:26:21.503+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:26:21.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:26:21.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:26:21.533+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:26:21.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:26:21.543+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:26:21.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:26:21.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T21:26:51.991+0000] {processor.py:157} INFO - Started process (PID=71465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:26:51.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:26:51.995+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:26:51.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:26:52.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:26:52.021+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:26:52.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:26:52.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:26:52.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:26:52.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T21:27:22.423+0000] {processor.py:157} INFO - Started process (PID=71490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:27:22.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:27:22.425+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:27:22.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:27:22.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:27:22.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:27:22.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:27:22.458+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:27:22.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:27:22.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T21:27:52.852+0000] {processor.py:157} INFO - Started process (PID=71515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:27:52.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:27:52.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:27:52.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:27:52.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:27:52.884+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:27:52.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:27:52.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:27:52.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:27:52.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T21:28:23.338+0000] {processor.py:157} INFO - Started process (PID=71539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:28:23.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:28:23.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:28:23.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:28:23.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:28:23.366+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:28:23.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:28:23.377+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:28:23.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:28:23.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T21:28:53.763+0000] {processor.py:157} INFO - Started process (PID=71565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:28:53.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:28:53.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:28:53.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:28:53.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:28:53.803+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:28:53.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:28:53.817+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:28:53.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:28:53.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T21:29:24.330+0000] {processor.py:157} INFO - Started process (PID=71590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:29:24.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:29:24.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:29:24.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:29:24.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:29:24.371+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:29:24.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:29:24.384+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:29:24.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:29:24.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T21:29:54.834+0000] {processor.py:157} INFO - Started process (PID=71615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:29:54.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:29:54.836+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:29:54.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:29:54.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:29:54.857+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:29:54.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:29:54.865+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:29:54.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:29:54.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-21T21:30:25.383+0000] {processor.py:157} INFO - Started process (PID=71640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:30:25.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:30:25.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:30:25.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:30:25.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:30:25.414+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:30:25.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:30:25.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:30:25.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:30:25.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:30:55.845+0000] {processor.py:157} INFO - Started process (PID=71665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:30:55.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:30:55.847+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:30:55.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:30:55.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:30:55.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:30:55.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:30:55.885+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:30:55.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:30:55.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:31:26.315+0000] {processor.py:157} INFO - Started process (PID=71690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:31:26.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:31:26.318+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:31:26.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:31:26.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:31:26.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:31:26.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:31:26.354+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:31:26.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:31:26.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T21:31:56.855+0000] {processor.py:157} INFO - Started process (PID=71715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:31:56.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:31:56.859+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:31:56.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:31:56.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:31:56.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:31:56.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:31:56.905+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:31:56.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:31:56.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T21:32:27.310+0000] {processor.py:157} INFO - Started process (PID=71740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:32:27.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:32:27.319+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:32:27.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:32:27.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:32:27.346+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:32:27.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:32:27.357+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:32:27.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:32:27.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T21:32:57.782+0000] {processor.py:157} INFO - Started process (PID=71765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:32:57.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:32:57.786+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:32:57.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:32:57.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:32:57.813+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:32:57.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:32:57.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:32:57.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:32:57.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T21:33:28.280+0000] {processor.py:157} INFO - Started process (PID=71790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:33:28.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:33:28.284+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:33:28.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:33:28.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:33:28.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:33:28.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:33:28.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:33:28.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:33:28.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T21:33:58.792+0000] {processor.py:157} INFO - Started process (PID=71815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:33:58.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:33:58.798+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:33:58.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:33:58.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:33:58.832+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:33:58.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:33:58.846+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:33:58.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:33:58.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T21:34:29.258+0000] {processor.py:157} INFO - Started process (PID=71840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:34:29.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:34:29.262+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:34:29.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:34:29.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:34:29.292+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:34:29.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:34:29.302+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:34:29.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:34:29.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T21:34:59.807+0000] {processor.py:157} INFO - Started process (PID=71865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:34:59.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:34:59.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:34:59.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:34:59.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:34:59.839+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:34:59.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:34:59.851+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:34:59.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:34:59.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T21:35:30.240+0000] {processor.py:157} INFO - Started process (PID=71890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:35:30.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:35:30.247+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:35:30.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:35:30.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:35:30.268+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:35:30.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:35:30.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:35:30.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:35:30.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T21:36:00.753+0000] {processor.py:157} INFO - Started process (PID=71915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:36:00.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:36:00.756+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:36:00.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:36:00.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:36:00.786+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:36:00.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:36:00.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:36:00.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:36:00.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T21:36:31.134+0000] {processor.py:157} INFO - Started process (PID=71940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:36:31.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:36:31.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:36:31.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:36:31.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:36:31.165+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:36:31.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:36:31.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:36:31.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:36:31.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T21:37:01.665+0000] {processor.py:157} INFO - Started process (PID=71965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:37:01.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:37:01.669+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:37:01.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:37:01.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:37:01.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:37:01.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:37:01.713+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:37:01.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:37:01.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T21:37:32.241+0000] {processor.py:157} INFO - Started process (PID=71990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:37:32.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:37:32.246+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:37:32.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:37:32.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:37:32.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:37:32.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:37:32.288+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:37:32.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:37:32.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T21:38:02.736+0000] {processor.py:157} INFO - Started process (PID=72015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:38:02.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:38:02.739+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:38:02.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:38:02.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:38:02.767+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:38:02.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:38:02.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:38:02.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:38:02.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T21:38:33.279+0000] {processor.py:157} INFO - Started process (PID=72040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:38:33.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:38:33.282+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:38:33.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:38:33.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:38:33.311+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:38:33.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:38:33.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:38:33.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:38:33.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T21:39:03.839+0000] {processor.py:157} INFO - Started process (PID=72065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:39:03.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:39:03.842+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:39:03.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:39:03.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:39:03.873+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:39:03.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:39:03.882+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:39:03.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:39:03.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T21:39:34.314+0000] {processor.py:157} INFO - Started process (PID=72090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:39:34.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:39:34.316+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:39:34.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:39:34.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:39:34.347+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:39:34.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:39:34.357+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:39:34.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:39:34.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T21:40:04.764+0000] {processor.py:157} INFO - Started process (PID=72115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:40:04.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:40:04.767+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:40:04.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:40:04.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:40:04.796+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:40:04.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:40:04.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:40:04.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:40:04.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T21:40:35.294+0000] {processor.py:157} INFO - Started process (PID=72140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:40:35.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:40:35.299+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:40:35.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:40:35.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:40:35.332+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:40:35.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:40:35.348+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:40:35.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:40:35.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T21:41:05.812+0000] {processor.py:157} INFO - Started process (PID=72165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:41:05.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:41:05.820+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:41:05.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:41:05.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:41:05.844+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:41:05.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:41:05.853+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:41:05.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:41:05.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:41:36.401+0000] {processor.py:157} INFO - Started process (PID=72190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:41:36.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:41:36.406+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:41:36.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:41:36.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:41:36.435+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:41:36.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:41:36.447+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:41:36.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:41:36.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T21:42:06.934+0000] {processor.py:157} INFO - Started process (PID=72215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:42:06.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:42:06.941+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:42:06.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:42:06.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:42:06.963+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:42:06.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:42:06.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:42:06.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:42:06.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T21:42:37.363+0000] {processor.py:157} INFO - Started process (PID=72240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:42:37.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:42:37.368+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:42:37.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:42:37.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:42:37.401+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:42:37.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:42:37.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:42:37.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:42:37.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T21:43:07.890+0000] {processor.py:157} INFO - Started process (PID=72265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:43:07.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:43:07.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:43:07.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:43:07.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:43:07.920+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:43:07.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:43:07.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:43:07.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:43:07.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:43:38.399+0000] {processor.py:157} INFO - Started process (PID=72290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:43:38.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:43:38.403+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:43:38.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:43:38.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:43:38.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:43:38.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:43:38.450+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:43:38.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:43:38.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T21:44:08.929+0000] {processor.py:157} INFO - Started process (PID=72315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:44:08.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:44:08.932+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:44:08.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:44:08.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:44:08.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:44:08.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:44:08.976+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:44:08.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:44:08.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T21:44:39.470+0000] {processor.py:157} INFO - Started process (PID=72340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:44:39.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:44:39.476+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:44:39.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:44:39.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:44:39.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:44:39.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:44:39.514+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:44:39.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:44:39.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T21:45:10.000+0000] {processor.py:157} INFO - Started process (PID=72365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:45:10.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:45:10.005+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:45:10.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:45:10.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:45:10.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:45:10.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:45:10.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:45:10.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:45:10.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T21:45:40.530+0000] {processor.py:157} INFO - Started process (PID=72390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:45:40.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:45:40.534+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:45:40.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:45:40.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:45:40.561+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:45:40.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:45:40.577+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:45:40.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:45:40.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T21:46:11.132+0000] {processor.py:157} INFO - Started process (PID=72415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:46:11.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:46:11.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:46:11.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:46:11.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:46:11.188+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:46:11.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:46:11.199+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:46:11.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:46:11.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T21:46:41.617+0000] {processor.py:157} INFO - Started process (PID=72440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:46:41.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:46:41.621+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:46:41.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:46:41.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:46:41.651+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:46:41.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:46:41.664+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:46:41.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:46:41.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T21:47:12.167+0000] {processor.py:157} INFO - Started process (PID=72465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:47:12.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:47:12.171+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:47:12.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:47:12.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:47:12.202+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:47:12.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:47:12.213+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:47:12.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:47:12.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T21:47:42.585+0000] {processor.py:157} INFO - Started process (PID=72490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:47:42.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:47:42.587+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:47:42.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:47:42.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:47:42.613+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:47:42.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:47:42.622+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:47:42.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:47:42.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T21:48:13.018+0000] {processor.py:157} INFO - Started process (PID=72515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:48:13.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:48:13.021+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:48:13.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:48:13.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:48:13.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:48:13.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:48:13.058+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:48:13.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:48:13.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:48:43.545+0000] {processor.py:157} INFO - Started process (PID=72540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:48:43.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:48:43.548+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:48:43.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:48:43.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:48:43.573+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:48:43.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:48:43.584+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:48:43.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:48:43.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T21:49:13.914+0000] {processor.py:157} INFO - Started process (PID=72565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:49:13.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:49:13.918+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:49:13.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:49:13.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:49:13.954+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:49:13.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:49:13.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:49:13.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:49:13.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T21:49:44.451+0000] {processor.py:157} INFO - Started process (PID=72590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:49:44.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:49:44.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:49:44.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:49:44.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:49:44.485+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:49:44.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:49:44.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:49:44.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:49:44.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T21:50:14.900+0000] {processor.py:157} INFO - Started process (PID=72615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:50:14.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:50:14.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:50:14.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:50:14.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:50:14.930+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:50:14.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:50:14.940+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:50:14.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:50:14.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T21:50:45.352+0000] {processor.py:157} INFO - Started process (PID=72640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:50:45.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:50:45.355+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:50:45.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:50:45.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:50:45.385+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:50:45.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:50:45.397+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:50:45.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:50:45.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T21:51:15.895+0000] {processor.py:157} INFO - Started process (PID=72665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:51:15.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:51:15.901+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:51:15.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:51:15.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:51:15.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:51:15.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:51:15.948+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:51:15.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:51:15.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T21:51:46.385+0000] {processor.py:157} INFO - Started process (PID=72690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:51:46.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:51:46.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:51:46.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:51:46.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:51:46.416+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:51:46.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:51:46.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:51:46.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:51:46.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:52:16.888+0000] {processor.py:157} INFO - Started process (PID=72715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:52:16.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:52:16.895+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:52:16.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:52:16.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:52:16.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:52:16.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:52:16.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:52:16.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:52:16.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-21T21:52:47.417+0000] {processor.py:157} INFO - Started process (PID=72740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:52:47.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:52:47.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:52:47.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:52:47.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:52:47.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:52:47.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:52:47.466+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:52:47.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:52:47.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T21:53:17.862+0000] {processor.py:157} INFO - Started process (PID=72765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:53:17.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:53:17.866+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:53:17.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:53:17.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:53:17.898+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:53:17.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:53:17.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:53:17.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:53:17.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T21:53:48.320+0000] {processor.py:157} INFO - Started process (PID=72790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:53:48.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:53:48.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:53:48.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:53:48.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:53:48.351+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:53:48.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:53:48.362+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:53:48.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:53:48.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T21:54:18.807+0000] {processor.py:157} INFO - Started process (PID=72815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:54:18.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:54:18.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:54:18.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:54:18.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:54:18.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:54:18.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:54:18.858+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:54:18.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:54:18.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T21:54:49.314+0000] {processor.py:157} INFO - Started process (PID=72840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:54:49.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:54:49.317+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:54:49.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:54:49.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:54:49.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:54:49.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:54:49.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:54:49.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:54:49.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T21:55:19.881+0000] {processor.py:157} INFO - Started process (PID=72865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:55:19.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:55:19.884+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:55:19.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:55:19.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:55:19.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:55:19.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:55:19.925+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:55:19.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:55:19.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T21:55:50.390+0000] {processor.py:157} INFO - Started process (PID=72889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:55:50.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:55:50.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:55:50.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:55:50.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:55:50.434+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:55:50.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:55:50.447+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:55:50.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:55:50.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-21T21:56:20.962+0000] {processor.py:157} INFO - Started process (PID=72915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:56:20.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:56:20.965+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:56:20.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:56:20.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:56:21.000+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:56:21.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:56:21.010+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:56:21.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:56:21.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T21:56:51.386+0000] {processor.py:157} INFO - Started process (PID=72940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:56:51.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:56:51.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:56:51.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:56:51.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:56:51.414+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:56:51.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:56:51.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:56:51.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:56:51.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T21:57:21.857+0000] {processor.py:157} INFO - Started process (PID=72965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:57:21.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:57:21.860+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:57:21.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:57:21.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:57:21.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:57:21.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:57:21.909+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:57:21.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:57:21.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T21:57:52.329+0000] {processor.py:157} INFO - Started process (PID=72990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:57:52.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:57:52.332+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:57:52.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:57:52.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:57:52.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:57:52.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:57:52.373+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:57:52.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:57:52.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T21:58:22.864+0000] {processor.py:157} INFO - Started process (PID=73015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:58:22.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:58:22.872+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:58:22.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:58:22.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:58:22.894+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:58:22.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:58:22.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:58:22.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:58:22.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T21:58:53.331+0000] {processor.py:157} INFO - Started process (PID=73040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:58:53.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:58:53.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:58:53.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:58:53.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:58:53.366+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:58:53.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:58:53.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:58:53.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:58:53.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T21:59:23.763+0000] {processor.py:157} INFO - Started process (PID=73065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:59:23.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:59:23.767+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:59:23.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:59:23.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:59:23.796+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:59:23.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:59:23.806+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:59:23.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:59:23.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T21:59:54.289+0000] {processor.py:157} INFO - Started process (PID=73090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:59:54.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T21:59:54.292+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:59:54.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:59:54.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T21:59:54.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:59:54.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T21:59:54.338+0000] {logging_mixin.py:151} INFO - [2024-07-21T21:59:54.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T21:59:54.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T22:00:24.871+0000] {processor.py:157} INFO - Started process (PID=73115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:00:24.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:00:24.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:00:24.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:00:24.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:00:24.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:00:24.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:00:24.914+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:00:24.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:00:24.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:00:55.309+0000] {processor.py:157} INFO - Started process (PID=73140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:00:55.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:00:55.312+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:00:55.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:00:55.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:00:55.342+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:00:55.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:00:55.354+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:00:55.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:00:55.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T22:01:25.875+0000] {processor.py:157} INFO - Started process (PID=73165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:01:25.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:01:25.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:01:25.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:01:25.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:01:25.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:01:25.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:01:25.932+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:01:25.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:01:25.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-21T22:01:56.414+0000] {processor.py:157} INFO - Started process (PID=73190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:01:56.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:01:56.417+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:01:56.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:01:56.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:01:56.440+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:01:56.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:01:56.450+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:01:56.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:01:56.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T22:02:26.852+0000] {processor.py:157} INFO - Started process (PID=73215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:02:26.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:02:26.857+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:02:26.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:02:26.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:02:26.884+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:02:26.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:02:26.894+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:02:26.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:02:26.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T22:02:57.325+0000] {processor.py:157} INFO - Started process (PID=73240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:02:57.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:02:57.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:02:57.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:02:57.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:02:57.362+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:02:57.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:02:57.377+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:02:57.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:02:57.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T22:03:27.756+0000] {processor.py:157} INFO - Started process (PID=73265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:03:27.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:03:27.758+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:03:27.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:03:27.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:03:27.786+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:03:27.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:03:27.797+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:03:27.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:03:27.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T22:03:58.248+0000] {processor.py:157} INFO - Started process (PID=73290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:03:58.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:03:58.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:03:58.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:03:58.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:03:58.280+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:03:58.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:03:58.294+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:03:58.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:03:58.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T22:04:28.715+0000] {processor.py:157} INFO - Started process (PID=73315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:04:28.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:04:28.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:04:28.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:04:28.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:04:28.755+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:04:28.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:04:28.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:04:28.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:04:28.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T22:04:59.186+0000] {processor.py:157} INFO - Started process (PID=73340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:04:59.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:04:59.189+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:04:59.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:04:59.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:04:59.220+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:04:59.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:04:59.230+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:04:59.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:04:59.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T22:05:29.712+0000] {processor.py:157} INFO - Started process (PID=73365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:05:29.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:05:29.715+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:05:29.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:05:29.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:05:29.739+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:05:29.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:05:29.754+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:05:29.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:05:29.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T22:06:00.191+0000] {processor.py:157} INFO - Started process (PID=73390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:06:00.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:06:00.196+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:06:00.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:06:00.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:06:00.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:06:00.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:06:00.236+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:06:00.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:06:00.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T22:06:30.632+0000] {processor.py:157} INFO - Started process (PID=73415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:06:30.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:06:30.637+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:06:30.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:06:30.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:06:30.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:06:30.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:06:30.683+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:06:30.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:06:30.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T22:07:01.077+0000] {processor.py:157} INFO - Started process (PID=73440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:07:01.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:07:01.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:07:01.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:07:01.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:07:01.108+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:07:01.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:07:01.118+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:07:01.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:07:01.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T22:07:31.520+0000] {processor.py:157} INFO - Started process (PID=73465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:07:31.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:07:31.522+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:07:31.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:07:31.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:07:31.549+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:07:31.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:07:31.559+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:07:31.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:07:31.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T22:08:02.049+0000] {processor.py:157} INFO - Started process (PID=73490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:08:02.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:08:02.051+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:08:02.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:08:02.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:08:02.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:08:02.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:08:02.092+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:08:02.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:08:02.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:08:32.540+0000] {processor.py:157} INFO - Started process (PID=73514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:08:32.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:08:32.545+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:08:32.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:08:32.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:08:32.578+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:08:32.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:08:32.588+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:08:32.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:08:32.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T22:09:02.915+0000] {processor.py:157} INFO - Started process (PID=73540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:09:02.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:09:02.919+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:09:02.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:09:02.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:09:02.944+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:09:02.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:09:02.955+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:09:02.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:09:02.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T22:09:33.410+0000] {processor.py:157} INFO - Started process (PID=73565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:09:33.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:09:33.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:09:33.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:09:33.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:09:33.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:09:33.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:09:33.460+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:09:33.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:09:33.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T22:10:03.882+0000] {processor.py:157} INFO - Started process (PID=73590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:10:03.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:10:03.885+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:10:03.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:10:03.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:10:03.913+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:10:03.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:10:03.924+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:10:03.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:10:03.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T22:10:34.308+0000] {processor.py:157} INFO - Started process (PID=73615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:10:34.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:10:34.310+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:10:34.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:10:34.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:10:34.335+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:10:34.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:10:34.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:10:34.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:10:34.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T22:11:04.730+0000] {processor.py:157} INFO - Started process (PID=73640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:11:04.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:11:04.734+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:11:04.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:11:04.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:11:04.764+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:11:04.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:11:04.774+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:11:04.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:11:04.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:11:35.140+0000] {processor.py:157} INFO - Started process (PID=73664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:11:35.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:11:35.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:11:35.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:11:35.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:11:35.172+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:11:35.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:11:35.184+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:11:35.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:11:35.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T22:12:05.579+0000] {processor.py:157} INFO - Started process (PID=73690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:12:05.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:12:05.584+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:12:05.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:12:05.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:12:05.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:12:05.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:12:05.618+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:12:05.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:12:05.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T22:12:36.035+0000] {processor.py:157} INFO - Started process (PID=73715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:12:36.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:12:36.037+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:12:36.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:12:36.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:12:36.066+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:12:36.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:12:36.076+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:12:36.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:12:36.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T22:13:06.488+0000] {processor.py:157} INFO - Started process (PID=73740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:13:06.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:13:06.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:13:06.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:13:06.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:13:06.529+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:13:06.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:13:06.539+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:13:06.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:13:06.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T22:13:37.020+0000] {processor.py:157} INFO - Started process (PID=73765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:13:37.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:13:37.024+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:13:37.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:13:37.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:13:37.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:13:37.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:13:37.060+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:13:37.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:13:37.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T22:14:07.496+0000] {processor.py:157} INFO - Started process (PID=73790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:14:07.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:14:07.501+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:14:07.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:14:07.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:14:07.533+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:14:07.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:14:07.548+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:14:07.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:14:07.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T22:14:38.018+0000] {processor.py:157} INFO - Started process (PID=73815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:14:38.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:14:38.021+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:14:38.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:14:38.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:14:38.052+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:14:38.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:14:38.063+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:14:38.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:14:38.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:15:08.532+0000] {processor.py:157} INFO - Started process (PID=73840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:15:08.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:15:08.536+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:15:08.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:15:08.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:15:08.573+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:15:08.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:15:08.583+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:15:08.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:15:08.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T22:15:39.095+0000] {processor.py:157} INFO - Started process (PID=73864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:15:39.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:15:39.098+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:15:39.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:15:39.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:15:39.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:15:39.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:15:39.140+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:15:39.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:15:39.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:16:09.617+0000] {processor.py:157} INFO - Started process (PID=73890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:16:09.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:16:09.622+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:16:09.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:16:09.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:16:09.654+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:16:09.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:16:09.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:16:09.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:16:09.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T22:16:40.181+0000] {processor.py:157} INFO - Started process (PID=73915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:16:40.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:16:40.185+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:16:40.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:16:40.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:16:40.214+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:16:40.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:16:40.227+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:16:40.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:16:40.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T22:17:10.775+0000] {processor.py:157} INFO - Started process (PID=73940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:17:10.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:17:10.780+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:17:10.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:17:10.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:17:10.815+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:17:10.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:17:10.826+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:17:10.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:17:10.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T22:17:41.221+0000] {processor.py:157} INFO - Started process (PID=73965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:17:41.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:17:41.224+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:17:41.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:17:41.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:17:41.251+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:17:41.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:17:41.264+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:17:41.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:17:41.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T22:18:11.868+0000] {processor.py:157} INFO - Started process (PID=73990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:18:11.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:18:11.872+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:18:11.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:18:11.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:18:11.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:18:11.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:18:11.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:18:11.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:18:11.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T22:18:42.000+0000] {processor.py:157} INFO - Started process (PID=74017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:18:42.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:18:42.004+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:18:42.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:18:42.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:18:42.036+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:18:42.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:18:42.046+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:18:42.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:18:42.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T22:19:12.408+0000] {processor.py:157} INFO - Started process (PID=74042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:19:12.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:19:12.411+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:19:12.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:19:12.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:19:12.442+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:19:12.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:19:12.454+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:19:12.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:19:12.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T22:19:42.813+0000] {processor.py:157} INFO - Started process (PID=74067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:19:42.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:19:42.817+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:19:42.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:19:42.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:19:42.845+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:19:42.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:19:42.859+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:19:42.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:19:42.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T22:20:13.259+0000] {processor.py:157} INFO - Started process (PID=74092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:20:13.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:20:13.262+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:20:13.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:20:13.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:20:13.285+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:20:13.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:20:13.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:20:13.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:20:13.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T22:35:44.320+0000] {processor.py:157} INFO - Started process (PID=74117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:35:44.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:35:44.329+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:35:44.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:35:44.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:35:44.430+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:35:44.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:35:44.484+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:35:44.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:35:44.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-07-21T22:36:15.017+0000] {processor.py:157} INFO - Started process (PID=74142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:36:15.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:36:15.022+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:36:15.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:36:15.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:36:15.065+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:36:15.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:36:15.077+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:36:15.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:36:15.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-21T22:36:45.573+0000] {processor.py:157} INFO - Started process (PID=74167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:36:45.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:36:45.576+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:36:45.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:36:45.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:36:45.605+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:36:45.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:36:45.620+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:36:45.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:36:45.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T22:37:16.045+0000] {processor.py:157} INFO - Started process (PID=74192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:37:16.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:37:16.048+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:37:16.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:37:16.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:37:16.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:37:16.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:37:16.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:37:16.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:37:16.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T22:37:46.475+0000] {processor.py:157} INFO - Started process (PID=74217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:37:46.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:37:46.478+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:37:46.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:37:46.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:37:46.504+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:37:46.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:37:46.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:37:46.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:37:46.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T22:38:16.974+0000] {processor.py:157} INFO - Started process (PID=74242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:38:16.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:38:16.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:38:16.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:38:16.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:38:17.014+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:38:17.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:38:17.030+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:38:17.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:38:17.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-21T22:38:47.454+0000] {processor.py:157} INFO - Started process (PID=74267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:38:47.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:38:47.459+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:38:47.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:38:47.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:38:47.483+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:38:47.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:38:47.493+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:38:47.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:38:47.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T22:39:17.962+0000] {processor.py:157} INFO - Started process (PID=74292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:39:17.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:39:17.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:39:17.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:39:17.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:39:17.991+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:39:17.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:39:18.001+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:39:18.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:39:18.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T22:39:48.379+0000] {processor.py:157} INFO - Started process (PID=74317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:39:48.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:39:48.383+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:39:48.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:39:48.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:39:48.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:39:48.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:39:48.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:39:48.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:39:48.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T22:40:18.815+0000] {processor.py:157} INFO - Started process (PID=74342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:40:18.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:40:18.818+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:40:18.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:40:18.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:40:18.852+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:40:18.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:40:18.862+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:40:18.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:40:18.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T22:40:49.290+0000] {processor.py:157} INFO - Started process (PID=74367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:40:49.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:40:49.295+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:40:49.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:40:49.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:40:49.322+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:40:49.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:40:49.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:40:49.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:40:49.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:41:19.838+0000] {processor.py:157} INFO - Started process (PID=74392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:41:19.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:41:19.842+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:41:19.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:41:19.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:41:19.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:41:19.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:41:19.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:41:19.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:41:19.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:41:50.253+0000] {processor.py:157} INFO - Started process (PID=74417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:41:50.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:41:50.256+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:41:50.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:41:50.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:41:50.282+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:41:50.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:41:50.295+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:41:50.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:41:50.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T22:42:20.746+0000] {processor.py:157} INFO - Started process (PID=74442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:42:20.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:42:20.749+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:42:20.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:42:20.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:42:20.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:42:20.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:42:20.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:42:20.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:42:20.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:42:51.254+0000] {processor.py:157} INFO - Started process (PID=74467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:42:51.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:42:51.256+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:42:51.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:42:51.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:42:51.286+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:42:51.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:42:51.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:42:51.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:42:51.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T22:43:21.753+0000] {processor.py:157} INFO - Started process (PID=74492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:43:21.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:43:21.757+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:43:21.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:43:21.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:43:21.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:43:21.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:43:21.801+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:43:21.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:43:21.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T22:43:52.284+0000] {processor.py:157} INFO - Started process (PID=74517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:43:52.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:43:52.286+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:43:52.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:43:52.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:43:52.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:43:52.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:43:52.318+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:43:52.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:43:52.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-21T22:44:22.780+0000] {processor.py:157} INFO - Started process (PID=74542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:44:22.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:44:22.783+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:44:22.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:44:22.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:44:22.823+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:44:22.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:44:22.835+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:44:22.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:44:22.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T22:44:53.269+0000] {processor.py:157} INFO - Started process (PID=74567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:44:53.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:44:53.276+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:44:53.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:44:53.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:44:53.300+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:44:53.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:44:53.310+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:44:53.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:44:53.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T22:45:23.710+0000] {processor.py:157} INFO - Started process (PID=74592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:45:23.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:45:23.714+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:45:23.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:45:23.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:45:23.740+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:45:23.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:45:23.750+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:45:23.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:45:23.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T22:45:54.180+0000] {processor.py:157} INFO - Started process (PID=74617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:45:54.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:45:54.183+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:45:54.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:45:54.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:45:54.215+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:45:54.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:45:54.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:45:54.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:45:54.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T22:46:24.559+0000] {processor.py:157} INFO - Started process (PID=74642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:46:24.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:46:24.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:46:24.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:46:24.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:46:24.589+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:46:24.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:46:24.599+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:46:24.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:46:24.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T22:46:55.048+0000] {processor.py:157} INFO - Started process (PID=74667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:46:55.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:46:55.051+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:46:55.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:46:55.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:46:55.080+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:46:55.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:46:55.092+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:46:55.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:46:55.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:47:25.547+0000] {processor.py:157} INFO - Started process (PID=74692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:47:25.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:47:25.550+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:47:25.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:47:25.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:47:25.576+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:47:25.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:47:25.585+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:47:25.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:47:25.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T22:47:56.076+0000] {processor.py:157} INFO - Started process (PID=74717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:47:56.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:47:56.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:47:56.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:47:56.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:47:56.110+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:47:56.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:47:56.121+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:47:56.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:47:56.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T22:48:26.467+0000] {processor.py:157} INFO - Started process (PID=74742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:48:26.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:48:26.471+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:48:26.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:48:26.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:48:26.501+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:48:26.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:48:26.512+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:48:26.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:48:26.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:48:56.910+0000] {processor.py:157} INFO - Started process (PID=74767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:48:56.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:48:56.915+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:48:56.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:48:56.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:48:56.951+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:48:56.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:48:56.962+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:48:56.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:48:56.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T22:49:27.431+0000] {processor.py:157} INFO - Started process (PID=74792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:49:27.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:49:27.435+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:49:27.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:49:27.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:49:27.462+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:49:27.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:49:27.472+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:49:27.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:49:27.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T22:49:57.892+0000] {processor.py:157} INFO - Started process (PID=74817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:49:57.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:49:57.896+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:49:57.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:49:57.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:49:57.928+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:49:57.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:49:57.938+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:49:57.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:49:57.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T22:50:28.345+0000] {processor.py:157} INFO - Started process (PID=74842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:50:28.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:50:28.348+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:50:28.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:50:28.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:50:28.379+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:50:28.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:50:28.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:50:28.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:50:28.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:50:58.837+0000] {processor.py:157} INFO - Started process (PID=74867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:50:58.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:50:58.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:50:58.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:50:58.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:50:58.870+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:50:58.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:50:58.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:50:58.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:50:58.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T22:51:29.320+0000] {processor.py:157} INFO - Started process (PID=74892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:51:29.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:51:29.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:51:29.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:51:29.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:51:29.353+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:51:29.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:51:29.364+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:51:29.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:51:29.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T22:51:59.769+0000] {processor.py:157} INFO - Started process (PID=74917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:51:59.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:51:59.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:51:59.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:51:59.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:51:59.803+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:51:59.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:51:59.813+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:51:59.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:51:59.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T22:52:30.229+0000] {processor.py:157} INFO - Started process (PID=74942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:52:30.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:52:30.234+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:52:30.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:52:30.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:52:30.267+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:52:30.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:52:30.279+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:52:30.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:52:30.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T22:53:00.738+0000] {processor.py:157} INFO - Started process (PID=74967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:53:00.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:53:00.742+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:53:00.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:53:00.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:53:00.772+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:53:00.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:53:00.785+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:53:00.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:53:00.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T22:53:31.278+0000] {processor.py:157} INFO - Started process (PID=74992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:53:31.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:53:31.281+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:53:31.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:53:31.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:53:31.309+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:53:31.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:53:31.320+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:53:31.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:53:31.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T22:54:01.731+0000] {processor.py:157} INFO - Started process (PID=75017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:54:01.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:54:01.736+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:54:01.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:54:01.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:54:01.776+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:54:01.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:54:01.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:54:01.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:54:01.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-21T22:54:32.281+0000] {processor.py:157} INFO - Started process (PID=75042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:54:32.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:54:32.285+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:54:32.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:54:32.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:54:32.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:54:32.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:54:32.324+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:54:32.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:54:32.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T22:55:02.724+0000] {processor.py:157} INFO - Started process (PID=75067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:55:02.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:55:02.729+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:55:02.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:55:02.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:55:02.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:55:02.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:55:02.769+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:55:02.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:55:02.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T22:55:33.254+0000] {processor.py:157} INFO - Started process (PID=75092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:55:33.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:55:33.259+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:55:33.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:55:33.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:55:33.295+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:55:33.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:55:33.307+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:55:33.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:55:33.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T22:56:03.775+0000] {processor.py:157} INFO - Started process (PID=75117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:56:03.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:56:03.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:56:03.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:56:03.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:56:03.805+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:56:03.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:56:03.814+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:56:03.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:56:03.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T22:56:34.313+0000] {processor.py:157} INFO - Started process (PID=75142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:56:34.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:56:34.315+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:56:34.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:56:34.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:56:34.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:56:34.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:56:34.352+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:56:34.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:56:34.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T22:57:04.753+0000] {processor.py:157} INFO - Started process (PID=75167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:57:04.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:57:04.754+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:57:04.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:57:04.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:57:04.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:57:04.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:57:04.790+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:57:04.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:57:04.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T22:57:35.081+0000] {processor.py:157} INFO - Started process (PID=75192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:57:35.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:57:35.083+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:57:35.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:57:35.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:57:35.114+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:57:35.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:57:35.126+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:57:35.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:57:35.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T22:58:05.615+0000] {processor.py:157} INFO - Started process (PID=75217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:58:05.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:58:05.619+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:58:05.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:58:05.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:58:05.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:58:05.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:58:05.661+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:58:05.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:58:05.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T22:58:36.065+0000] {processor.py:157} INFO - Started process (PID=75242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:58:36.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:58:36.068+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:58:36.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:58:36.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:58:36.094+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:58:36.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:58:36.107+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:58:36.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:58:36.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T22:59:06.588+0000] {processor.py:157} INFO - Started process (PID=75267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:59:06.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:59:06.593+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:59:06.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:59:06.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:59:06.618+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:59:06.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:59:06.628+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:59:06.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:59:06.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-21T22:59:37.109+0000] {processor.py:157} INFO - Started process (PID=75292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:59:37.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T22:59:37.113+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:59:37.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:59:37.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T22:59:37.143+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:59:37.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T22:59:37.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T22:59:37.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T22:59:37.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:00:07.666+0000] {processor.py:157} INFO - Started process (PID=75317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:00:07.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:00:07.670+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:00:07.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:00:07.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:00:07.705+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:00:07.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:00:07.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:00:07.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:00:07.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-21T23:00:38.071+0000] {processor.py:157} INFO - Started process (PID=75342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:00:38.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:00:38.074+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:00:38.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:00:38.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:00:38.104+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:00:38.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:00:38.117+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:00:38.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:00:38.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:01:08.516+0000] {processor.py:157} INFO - Started process (PID=75367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:01:08.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:01:08.519+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:01:08.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:01:08.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:01:08.547+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:01:08.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:01:08.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:01:08.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:01:08.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T23:01:39.076+0000] {processor.py:157} INFO - Started process (PID=75392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:01:39.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:01:39.082+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:01:39.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:01:39.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:01:39.117+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:01:39.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:01:39.130+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:01:39.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:01:39.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T23:02:09.543+0000] {processor.py:157} INFO - Started process (PID=75417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:02:09.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:02:09.546+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:02:09.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:02:09.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:02:09.574+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:02:09.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:02:09.583+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:02:09.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:02:09.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:02:40.020+0000] {processor.py:157} INFO - Started process (PID=75442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:02:40.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:02:40.023+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:02:40.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:02:40.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:02:40.053+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:02:40.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:02:40.062+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:02:40.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:02:40.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T23:03:10.438+0000] {processor.py:157} INFO - Started process (PID=75467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:03:10.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:03:10.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:03:10.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:03:10.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:03:10.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:03:10.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:03:10.488+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:03:10.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:03:10.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T23:03:40.939+0000] {processor.py:157} INFO - Started process (PID=75492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:03:40.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:03:40.943+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:03:40.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:03:40.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:03:40.974+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:03:40.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:03:40.986+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:03:40.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:03:40.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:04:11.360+0000] {processor.py:157} INFO - Started process (PID=75517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:04:11.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:04:11.365+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:04:11.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:04:11.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:04:11.394+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:04:11.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:04:11.405+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:04:11.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:04:11.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T23:04:41.745+0000] {processor.py:157} INFO - Started process (PID=75542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:04:41.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:04:41.750+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:04:41.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:04:41.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:04:41.782+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:04:41.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:04:41.796+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:04:41.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:04:41.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T23:05:12.273+0000] {processor.py:157} INFO - Started process (PID=75567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:05:12.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:05:12.276+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:05:12.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:05:12.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:05:12.303+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:05:12.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:05:12.313+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:05:12.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:05:12.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T23:05:42.788+0000] {processor.py:157} INFO - Started process (PID=75592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:05:42.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:05:42.793+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:05:42.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:05:42.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:05:42.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:05:42.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:05:42.833+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:05:42.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:05:42.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:06:13.252+0000] {processor.py:157} INFO - Started process (PID=75617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:06:13.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:06:13.256+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:06:13.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:06:13.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:06:13.283+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:06:13.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:06:13.293+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:06:13.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:06:13.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T23:06:43.767+0000] {processor.py:157} INFO - Started process (PID=75642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:06:43.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:06:43.769+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:06:43.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:06:43.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:06:43.795+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:06:43.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:06:43.805+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:06:43.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:06:43.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T23:07:14.291+0000] {processor.py:157} INFO - Started process (PID=75667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:07:14.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:07:14.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:07:14.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:07:14.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:07:14.323+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:07:14.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:07:14.337+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:07:14.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:07:14.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:07:44.812+0000] {processor.py:157} INFO - Started process (PID=75692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:07:44.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:07:44.815+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:07:44.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:07:44.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:07:44.843+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:07:44.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:07:44.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:07:44.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:07:44.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:08:15.342+0000] {processor.py:157} INFO - Started process (PID=75717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:08:15.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:08:15.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:08:15.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:08:15.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:08:15.379+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:08:15.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:08:15.390+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:08:15.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:08:15.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T23:08:45.737+0000] {processor.py:157} INFO - Started process (PID=75742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:08:45.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:08:45.740+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:08:45.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:08:45.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:08:45.766+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:08:45.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:08:45.776+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:08:45.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:08:45.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-21T23:09:16.192+0000] {processor.py:157} INFO - Started process (PID=75767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:09:16.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:09:16.195+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:09:16.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:09:16.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:09:16.219+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:09:16.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:09:16.230+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:09:16.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:09:16.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:09:46.663+0000] {processor.py:157} INFO - Started process (PID=75792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:09:46.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:09:46.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:09:46.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:09:46.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:09:46.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:09:46.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:09:46.709+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:09:46.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:09:46.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:10:17.175+0000] {processor.py:157} INFO - Started process (PID=75817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:10:17.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:10:17.178+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:10:17.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:10:17.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:10:17.207+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:10:17.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:10:17.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:10:17.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:10:17.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T23:10:47.693+0000] {processor.py:157} INFO - Started process (PID=75842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:10:47.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:10:47.695+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:10:47.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:10:47.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:10:47.719+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:10:47.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:10:47.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:10:47.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:10:47.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T23:11:18.149+0000] {processor.py:157} INFO - Started process (PID=75867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:11:18.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:11:18.152+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:11:18.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:11:18.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:11:18.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:11:18.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:11:18.187+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:11:18.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:11:18.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:11:48.563+0000] {processor.py:157} INFO - Started process (PID=75892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:11:48.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:11:48.566+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:11:48.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:11:48.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:11:48.595+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:11:48.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:11:48.606+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:11:48.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:11:48.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:12:19.040+0000] {processor.py:157} INFO - Started process (PID=75917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:12:19.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:12:19.044+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:12:19.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:12:19.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:12:19.078+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:12:19.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:12:19.093+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:12:19.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:12:19.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T23:12:49.486+0000] {processor.py:157} INFO - Started process (PID=75942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:12:49.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:12:49.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:12:49.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:12:49.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:12:49.518+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:12:49.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:12:49.529+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:12:49.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:12:49.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T23:13:19.940+0000] {processor.py:157} INFO - Started process (PID=75967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:13:19.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:13:19.945+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:13:19.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:13:19.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:13:19.977+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:13:19.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:13:19.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:13:19.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:13:19.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T23:13:50.373+0000] {processor.py:157} INFO - Started process (PID=75992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:13:50.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:13:50.375+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:13:50.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:13:50.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:13:50.400+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:13:50.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:13:50.410+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:13:50.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:13:50.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T23:14:20.880+0000] {processor.py:157} INFO - Started process (PID=76017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:14:20.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:14:20.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:14:20.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:14:20.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:14:20.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:14:20.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:14:20.922+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:14:20.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:14:20.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T23:14:51.387+0000] {processor.py:157} INFO - Started process (PID=76042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:14:51.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:14:51.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:14:51.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:14:51.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:14:51.418+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:14:51.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:14:51.429+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:14:51.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:14:51.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T23:15:21.831+0000] {processor.py:157} INFO - Started process (PID=76067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:15:21.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:15:21.834+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:15:21.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:15:21.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:15:21.868+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:15:21.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:15:21.883+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:15:21.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:15:21.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T23:15:52.343+0000] {processor.py:157} INFO - Started process (PID=76092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:15:52.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:15:52.349+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:15:52.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:15:52.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:15:52.376+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:15:52.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:15:52.386+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:15:52.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:15:52.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:16:22.898+0000] {processor.py:157} INFO - Started process (PID=76117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:16:22.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:16:22.902+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:16:22.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:16:22.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:16:22.935+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:16:22.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:16:22.947+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:16:22.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:16:22.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T23:16:53.410+0000] {processor.py:157} INFO - Started process (PID=76141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:16:53.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:16:53.415+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:16:53.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:16:53.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:16:53.443+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:16:53.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:16:53.456+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:16:53.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:16:53.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:17:23.927+0000] {processor.py:157} INFO - Started process (PID=76167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:17:23.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:17:23.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:17:23.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:17:23.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:17:23.961+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:17:23.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:17:23.971+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:17:23.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:17:23.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:17:54.423+0000] {processor.py:157} INFO - Started process (PID=76192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:17:54.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:17:54.426+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:17:54.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:17:54.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:17:54.455+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:17:54.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:17:54.467+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:17:54.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:17:54.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:18:24.933+0000] {processor.py:157} INFO - Started process (PID=76217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:18:24.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:18:24.936+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:18:24.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:18:24.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:18:24.967+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:18:24.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:18:24.979+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:18:24.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:18:24.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T23:18:55.344+0000] {processor.py:157} INFO - Started process (PID=76242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:18:55.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:18:55.347+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:18:55.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:18:55.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:18:55.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:18:55.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:18:55.389+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:18:55.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:18:55.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:19:25.891+0000] {processor.py:157} INFO - Started process (PID=76267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:19:25.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:19:25.894+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:19:25.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:19:25.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:19:25.921+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:19:25.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:19:25.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:19:25.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:19:25.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:19:56.396+0000] {processor.py:157} INFO - Started process (PID=76292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:19:56.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:19:56.399+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:19:56.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:19:56.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:19:56.430+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:19:56.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:19:56.441+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:19:56.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:19:56.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:20:26.842+0000] {processor.py:157} INFO - Started process (PID=76317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:20:26.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:20:26.844+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:20:26.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:20:26.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:20:26.881+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:20:26.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:20:26.893+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:20:26.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:20:26.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T23:20:57.383+0000] {processor.py:157} INFO - Started process (PID=76342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:20:57.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:20:57.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:20:57.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:20:57.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:20:57.419+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:20:57.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:20:57.431+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:20:57.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:20:57.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T23:21:27.882+0000] {processor.py:157} INFO - Started process (PID=76367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:21:27.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:21:27.886+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:21:27.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:21:27.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:21:27.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:21:27.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:21:27.924+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:21:27.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:21:27.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:21:58.300+0000] {processor.py:157} INFO - Started process (PID=76392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:21:58.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:21:58.302+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:21:58.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:21:58.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:21:58.331+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:21:58.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:21:58.341+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:21:58.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:21:58.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T23:22:28.738+0000] {processor.py:157} INFO - Started process (PID=76417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:22:28.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:22:28.743+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:22:28.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:22:28.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:22:28.772+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:22:28.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:22:28.784+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:22:28.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:22:28.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:22:59.238+0000] {processor.py:157} INFO - Started process (PID=76442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:22:59.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:22:59.242+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:22:59.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:22:59.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:22:59.273+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:22:59.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:22:59.285+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:22:59.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:22:59.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:23:29.728+0000] {processor.py:157} INFO - Started process (PID=76467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:23:29.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:23:29.731+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:23:29.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:23:29.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:23:29.760+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:23:29.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:23:29.771+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:23:29.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:23:29.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:24:00.208+0000] {processor.py:157} INFO - Started process (PID=76492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:24:00.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:24:00.213+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:24:00.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:24:00.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:24:00.242+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:24:00.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:24:00.255+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:24:00.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:24:00.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:24:30.663+0000] {processor.py:157} INFO - Started process (PID=76517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:24:30.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:24:30.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:24:30.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:24:30.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:24:30.695+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:24:30.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:24:30.705+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:24:30.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:24:30.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T23:25:01.176+0000] {processor.py:157} INFO - Started process (PID=76542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:25:01.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:25:01.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:25:01.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:25:01.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:25:01.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:25:01.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:25:01.228+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:25:01.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:25:01.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T23:25:31.687+0000] {processor.py:157} INFO - Started process (PID=76567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:25:31.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:25:31.689+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:25:31.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:25:31.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:25:31.720+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:25:31.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:25:31.730+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:25:31.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:25:31.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:26:02.136+0000] {processor.py:157} INFO - Started process (PID=76592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:26:02.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:26:02.138+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:26:02.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:26:02.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:26:02.169+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:26:02.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:26:02.181+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:26:02.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:26:02.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:26:32.598+0000] {processor.py:157} INFO - Started process (PID=76617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:26:32.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:26:32.602+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:26:32.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:26:32.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:26:32.629+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:26:32.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:26:32.639+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:26:32.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:26:32.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:27:03.058+0000] {processor.py:157} INFO - Started process (PID=76642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:27:03.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:27:03.063+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:27:03.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:27:03.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:27:03.090+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:27:03.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:27:03.102+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:27:03.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:27:03.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:27:33.485+0000] {processor.py:157} INFO - Started process (PID=76667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:27:33.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:27:33.490+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:27:33.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:27:33.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:27:33.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:27:33.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:27:33.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:27:33.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:27:33.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T23:28:03.957+0000] {processor.py:157} INFO - Started process (PID=76692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:28:03.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:28:03.961+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:28:03.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:28:03.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:28:03.987+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:28:03.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:28:03.997+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:28:03.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:28:04.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:28:34.471+0000] {processor.py:157} INFO - Started process (PID=76717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:28:34.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:28:34.475+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:28:34.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:28:34.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:28:34.511+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:28:34.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:28:34.525+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:28:34.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:28:34.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T23:29:04.997+0000] {processor.py:157} INFO - Started process (PID=76742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:29:04.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:29:04.999+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:29:04.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:29:05.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:29:05.028+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:29:05.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:29:05.039+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:29:05.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:29:05.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T23:29:35.570+0000] {processor.py:157} INFO - Started process (PID=76767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:29:35.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:29:35.576+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:29:35.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:29:35.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:29:35.609+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:29:35.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:29:35.619+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:29:35.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:29:35.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T23:30:06.050+0000] {processor.py:157} INFO - Started process (PID=76792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:30:06.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:30:06.053+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:30:06.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:30:06.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:30:06.085+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:30:06.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:30:06.098+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:30:06.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:30:06.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T23:30:36.554+0000] {processor.py:157} INFO - Started process (PID=76817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:30:36.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:30:36.560+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:30:36.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:30:36.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:30:36.592+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:30:36.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:30:36.604+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:30:36.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:30:36.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T23:31:07.092+0000] {processor.py:157} INFO - Started process (PID=76841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:31:07.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:31:07.096+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:31:07.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:31:07.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:31:07.129+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:31:07.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:31:07.139+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:31:07.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:31:07.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T23:31:37.597+0000] {processor.py:157} INFO - Started process (PID=76867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:31:37.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:31:37.601+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:31:37.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:31:37.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:31:37.636+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:31:37.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:31:37.648+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:31:37.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:31:37.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T23:32:08.045+0000] {processor.py:157} INFO - Started process (PID=76892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:32:08.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:32:08.049+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:32:08.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:32:08.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:32:08.081+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:32:08.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:32:08.093+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:32:08.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:32:08.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T23:32:38.530+0000] {processor.py:157} INFO - Started process (PID=76917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:32:38.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:32:38.534+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:32:38.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:32:38.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:32:38.563+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:32:38.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:32:38.573+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:32:38.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:32:38.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:33:09.004+0000] {processor.py:157} INFO - Started process (PID=76942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:33:09.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:33:09.007+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:33:09.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:33:09.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:33:09.038+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:33:09.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:33:09.050+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:33:09.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:33:09.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:33:39.484+0000] {processor.py:157} INFO - Started process (PID=76967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:33:39.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:33:39.487+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:33:39.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:33:39.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:33:39.516+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:33:39.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:33:39.527+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:33:39.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:33:39.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:34:09.937+0000] {processor.py:157} INFO - Started process (PID=76992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:34:09.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:34:09.942+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:34:09.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:34:09.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:34:09.975+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:34:09.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:34:09.988+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:34:09.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:34:09.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T23:34:40.488+0000] {processor.py:157} INFO - Started process (PID=77017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:34:40.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:34:40.496+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:34:40.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:34:40.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:34:40.542+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:34:40.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:34:40.555+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:34:40.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:34:40.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-21T23:35:10.972+0000] {processor.py:157} INFO - Started process (PID=77042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:35:10.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:35:10.976+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:35:10.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:35:10.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:35:11.013+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:35:11.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:35:11.026+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:35:11.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:35:11.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T23:35:41.432+0000] {processor.py:157} INFO - Started process (PID=77066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:35:41.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:35:41.437+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:35:41.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:35:41.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:35:41.479+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:35:41.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:35:41.491+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:35:41.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:35:41.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-21T23:36:12.157+0000] {processor.py:157} INFO - Started process (PID=77092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:36:12.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:36:12.254+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:36:12.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:36:12.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:36:12.280+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:36:12.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:36:12.290+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:36:12.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:36:12.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-21T23:36:42.398+0000] {processor.py:157} INFO - Started process (PID=77119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:36:42.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:36:42.405+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:36:42.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:36:42.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:36:42.432+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:36:42.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:36:42.444+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:36:42.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:36:42.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:37:12.926+0000] {processor.py:157} INFO - Started process (PID=77144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:37:12.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:37:12.931+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:37:12.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:37:12.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:37:12.957+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:37:12.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:37:12.966+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:37:12.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:37:12.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:37:43.383+0000] {processor.py:157} INFO - Started process (PID=77169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:37:43.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:37:43.387+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:37:43.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:37:43.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:37:43.422+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:37:43.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:37:43.433+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:37:43.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:37:43.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T23:38:13.871+0000] {processor.py:157} INFO - Started process (PID=77194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:38:13.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:38:13.874+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:38:13.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:38:13.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:38:13.901+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:38:13.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:38:13.912+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:38:13.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:38:13.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T23:38:44.375+0000] {processor.py:157} INFO - Started process (PID=77219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:38:44.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:38:44.378+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:38:44.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:38:44.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:38:44.410+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:38:44.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:38:44.423+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:38:44.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:38:44.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:39:14.819+0000] {processor.py:157} INFO - Started process (PID=77244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:39:14.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:39:14.825+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:39:14.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:39:14.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:39:14.853+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:39:14.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:39:14.863+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:39:14.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:39:14.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:39:45.335+0000] {processor.py:157} INFO - Started process (PID=77269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:39:45.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:39:45.337+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:39:45.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:39:45.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:39:45.367+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:39:45.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:39:45.380+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:39:45.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:39:45.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T23:40:15.802+0000] {processor.py:157} INFO - Started process (PID=77294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:40:15.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:40:15.807+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:40:15.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:40:15.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:40:15.841+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:40:15.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:40:15.855+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:40:15.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:40:15.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-21T23:40:46.242+0000] {processor.py:157} INFO - Started process (PID=77319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:40:46.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:40:46.245+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:40:46.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:40:46.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:40:46.276+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:40:46.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:40:46.289+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:40:46.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:40:46.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T23:41:16.763+0000] {processor.py:157} INFO - Started process (PID=77344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:41:16.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:41:16.768+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:41:16.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:41:16.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:41:16.800+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:41:16.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:41:16.813+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:41:16.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:41:16.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-21T23:41:47.241+0000] {processor.py:157} INFO - Started process (PID=77369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:41:47.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:41:47.244+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:41:47.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:41:47.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:41:47.272+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:41:47.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:41:47.282+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:41:47.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:41:47.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:42:17.784+0000] {processor.py:157} INFO - Started process (PID=77394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:42:17.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:42:17.788+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:42:17.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:42:17.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:42:17.814+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:42:17.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:42:17.824+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:42:17.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:42:17.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-21T23:42:48.212+0000] {processor.py:157} INFO - Started process (PID=77419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:42:48.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:42:48.216+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:42:48.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:42:48.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:42:48.275+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:42:48.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:42:48.292+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:42:48.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:42:48.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-21T23:43:18.725+0000] {processor.py:157} INFO - Started process (PID=77444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:43:18.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:43:18.728+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:43:18.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:43:18.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:43:18.761+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:43:18.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:43:18.773+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:43:18.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:43:18.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-21T23:43:49.222+0000] {processor.py:157} INFO - Started process (PID=77469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:43:49.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:43:49.225+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:43:49.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:43:49.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:43:49.256+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:43:49.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:43:49.266+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:43:49.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:43:49.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T23:44:19.662+0000] {processor.py:157} INFO - Started process (PID=77494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:44:19.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:44:19.665+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:44:19.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:44:19.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:44:19.692+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:44:19.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:44:19.705+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:44:19.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:44:19.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:44:50.182+0000] {processor.py:157} INFO - Started process (PID=77519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:44:50.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:44:50.184+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:44:50.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:44:50.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:44:50.214+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:44:50.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:44:50.224+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:44:50.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:44:50.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:45:20.590+0000] {processor.py:157} INFO - Started process (PID=77544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:45:20.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:45:20.597+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:45:20.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:45:20.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:45:20.629+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:45:20.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:45:20.643+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:45:20.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:45:20.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-21T23:45:51.145+0000] {processor.py:157} INFO - Started process (PID=77569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:45:51.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:45:51.148+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:45:51.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:45:51.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:45:51.177+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:45:51.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:45:51.189+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:45:51.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:45:51.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:46:21.593+0000] {processor.py:157} INFO - Started process (PID=77594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:46:21.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:46:21.596+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:46:21.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:46:21.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:46:21.624+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:46:21.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:46:21.634+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:46:21.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:46:21.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-21T23:46:52.068+0000] {processor.py:157} INFO - Started process (PID=77619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:46:52.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:46:52.072+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:46:52.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:46:52.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:46:52.101+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:46:52.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:46:52.114+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:46:52.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:46:52.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:47:22.512+0000] {processor.py:157} INFO - Started process (PID=77644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:47:22.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:47:22.519+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:47:22.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:47:22.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:47:22.555+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:47:22.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:47:22.566+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:47:22.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:47:22.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T23:47:52.949+0000] {processor.py:157} INFO - Started process (PID=77669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:47:52.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:47:52.952+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:47:52.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:47:52.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:47:52.982+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:47:52.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:47:52.993+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:47:52.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:47:53.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-21T23:48:23.421+0000] {processor.py:157} INFO - Started process (PID=77694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:48:23.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:48:23.425+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:48:23.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:48:23.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:48:23.449+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:48:23.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:48:23.458+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:48:23.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:48:23.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-21T23:48:53.870+0000] {processor.py:157} INFO - Started process (PID=77719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:48:53.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:48:53.873+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:48:53.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:48:53.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:48:53.903+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:48:53.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:48:53.917+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:48:53.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:48:53.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-21T23:49:24.335+0000] {processor.py:157} INFO - Started process (PID=77744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:49:24.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:49:24.338+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:49:24.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:49:24.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:49:24.370+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:49:24.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:49:24.381+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:49:24.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:49:24.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-21T23:49:54.741+0000] {processor.py:157} INFO - Started process (PID=77769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:49:54.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:49:54.745+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:49:54.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:49:54.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:49:54.777+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:49:54.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:49:54.789+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:49:54.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:49:54.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:50:25.197+0000] {processor.py:157} INFO - Started process (PID=77794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:50:25.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:50:25.202+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:50:25.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:50:25.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:50:25.236+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:50:25.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:50:25.247+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:50:25.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:50:25.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T23:50:55.639+0000] {processor.py:157} INFO - Started process (PID=77819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:50:55.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:50:55.646+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:50:55.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:50:55.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:50:55.667+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:50:55.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:50:55.677+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:50:55.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:50:55.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-21T23:51:26.120+0000] {processor.py:157} INFO - Started process (PID=77844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:51:26.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:51:26.124+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:51:26.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:51:26.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:51:26.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:51:26.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:51:26.164+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:51:26.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:51:26.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:51:56.631+0000] {processor.py:157} INFO - Started process (PID=77869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:51:56.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:51:56.633+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:51:56.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:51:56.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:51:56.655+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:51:56.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:51:56.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:51:56.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:51:56.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-21T23:52:27.151+0000] {processor.py:157} INFO - Started process (PID=77894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:52:27.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:52:27.154+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:52:27.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:52:27.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:52:27.187+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:52:27.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:52:27.198+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:52:27.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:52:27.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:52:57.663+0000] {processor.py:157} INFO - Started process (PID=77919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:52:57.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:52:57.666+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:52:57.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:52:57.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:52:57.699+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:52:57.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:52:57.712+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:52:57.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:52:57.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-21T23:53:28.157+0000] {processor.py:157} INFO - Started process (PID=77944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:53:28.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:53:28.160+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:53:28.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:53:28.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:53:28.192+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:53:28.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:53:28.203+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:53:28.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:53:28.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T23:53:58.699+0000] {processor.py:157} INFO - Started process (PID=77969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:53:58.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:53:58.702+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:53:58.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:53:58.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:53:58.731+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:53:58.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:53:58.742+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:53:58.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:53:58.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:54:29.143+0000] {processor.py:157} INFO - Started process (PID=77994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:54:29.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:54:29.147+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:54:29.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:54:29.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:54:29.182+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:54:29.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:54:29.191+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:54:29.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:54:29.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-21T23:54:59.665+0000] {processor.py:157} INFO - Started process (PID=78019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:54:59.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:54:59.668+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:54:59.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:54:59.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:54:59.697+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:54:59.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:54:59.710+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:54:59.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:54:59.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:55:30.080+0000] {processor.py:157} INFO - Started process (PID=78044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:55:30.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:55:30.085+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:55:30.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:55:30.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:55:30.114+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:55:30.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:55:30.125+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:55:30.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:55:30.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-21T23:56:00.650+0000] {processor.py:157} INFO - Started process (PID=78069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:56:00.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:56:00.657+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:56:00.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:56:00.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:56:00.696+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:56:00.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:56:00.709+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:56:00.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:56:00.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-21T23:56:35.300+0000] {processor.py:157} INFO - Started process (PID=78094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:56:35.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:56:35.305+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:56:35.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:56:35.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:56:35.334+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:56:35.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:56:35.345+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:56:35.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:56:35.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-21T23:57:05.733+0000] {processor.py:157} INFO - Started process (PID=78121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:57:05.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:57:05.738+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:57:05.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:57:05.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:57:05.771+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:57:05.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:57:05.792+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:57:05.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:57:05.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-21T23:57:36.254+0000] {processor.py:157} INFO - Started process (PID=78146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:57:36.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:57:36.259+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:57:36.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:57:36.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:57:36.296+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:57:36.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:57:36.308+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:57:36.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:57:36.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-21T23:58:06.774+0000] {processor.py:157} INFO - Started process (PID=78171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:58:06.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:58:06.779+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:58:06.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:58:06.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:58:06.810+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:58:06.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:58:06.822+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:58:06.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:58:06.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-21T23:58:37.251+0000] {processor.py:157} INFO - Started process (PID=78196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:58:37.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:58:37.254+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:58:37.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:58:37.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:58:37.277+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:58:37.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:58:37.287+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:58:37.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:58:37.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-21T23:59:07.717+0000] {processor.py:157} INFO - Started process (PID=78221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:59:07.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:59:07.721+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:59:07.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:59:07.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:59:07.749+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:59:07.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:59:07.759+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:59:07.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:59:07.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-21T23:59:38.228+0000] {processor.py:157} INFO - Started process (PID=78246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:59:38.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-21T23:59:38.233+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:59:38.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:59:38.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-21T23:59:38.260+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:59:38.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-21T23:59:38.272+0000] {logging_mixin.py:151} INFO - [2024-07-21T23:59:38.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-21T01:00:00+00:00, run_after=2024-07-22T01:00:00+00:00
[2024-07-21T23:59:38.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
