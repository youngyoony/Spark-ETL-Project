[2024-08-17T00:26:22.889+0000] {processor.py:157} INFO - Started process (PID=52162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T00:26:22.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T00:26:22.895+0000] {logging_mixin.py:151} INFO - [2024-08-17T00:26:22.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T00:26:22.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T00:26:22.950+0000] {logging_mixin.py:151} INFO - [2024-08-17T00:26:22.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T00:26:22.963+0000] {logging_mixin.py:151} INFO - [2024-08-17T00:26:22.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-15T01:00:00+00:00, run_after=2024-08-16T01:00:00+00:00
[2024-08-17T00:26:22.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T01:11:15.657+0000] {processor.py:157} INFO - Started process (PID=52178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T01:11:15.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T01:11:15.664+0000] {logging_mixin.py:151} INFO - [2024-08-17T01:11:15.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T01:11:15.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T01:11:15.776+0000] {logging_mixin.py:151} INFO - [2024-08-17T01:11:15.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T01:11:15.811+0000] {logging_mixin.py:151} INFO - [2024-08-17T01:11:15.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T01:11:15.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-08-17T01:38:37.508+0000] {processor.py:157} INFO - Started process (PID=52759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T01:38:37.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T01:38:37.516+0000] {logging_mixin.py:151} INFO - [2024-08-17T01:38:37.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T01:38:37.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T01:38:37.570+0000] {logging_mixin.py:151} INFO - [2024-08-17T01:38:37.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T01:38:37.583+0000] {logging_mixin.py:151} INFO - [2024-08-17T01:38:37.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T01:38:37.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T02:12:49.790+0000] {processor.py:157} INFO - Started process (PID=52996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:12:49.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T02:12:49.795+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:12:49.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:12:49.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:12:49.855+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:12:49.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T02:12:49.882+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:12:49.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T02:12:49.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-17T02:39:36.685+0000] {processor.py:157} INFO - Started process (PID=53007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:39:36.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T02:39:36.690+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:39:36.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:39:36.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:39:36.737+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:39:36.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T02:39:36.751+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:39:36.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T02:39:36.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T02:56:40.054+0000] {processor.py:157} INFO - Started process (PID=53018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:56:40.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T02:56:40.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:56:40.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:56:40.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T02:56:40.100+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:56:40.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T02:56:40.115+0000] {logging_mixin.py:151} INFO - [2024-08-17T02:56:40.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T02:56:40.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-17T03:40:32.440+0000] {processor.py:157} INFO - Started process (PID=53028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T03:40:32.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T03:40:32.443+0000] {logging_mixin.py:151} INFO - [2024-08-17T03:40:32.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T03:40:32.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T03:40:32.502+0000] {logging_mixin.py:151} INFO - [2024-08-17T03:40:32.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T03:40:32.526+0000] {logging_mixin.py:151} INFO - [2024-08-17T03:40:32.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T03:40:32.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-17T03:56:15.617+0000] {processor.py:157} INFO - Started process (PID=53037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T03:56:15.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T03:56:15.623+0000] {logging_mixin.py:151} INFO - [2024-08-17T03:56:15.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T03:56:15.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T03:56:15.689+0000] {logging_mixin.py:151} INFO - [2024-08-17T03:56:15.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T03:56:15.704+0000] {logging_mixin.py:151} INFO - [2024-08-17T03:56:15.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T03:56:15.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T04:41:36.377+0000] {processor.py:157} INFO - Started process (PID=53047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T04:41:36.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T04:41:36.383+0000] {logging_mixin.py:151} INFO - [2024-08-17T04:41:36.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T04:41:36.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T04:41:36.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T04:41:36.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T04:41:36.468+0000] {logging_mixin.py:151} INFO - [2024-08-17T04:41:36.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T04:41:36.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-17T04:42:06.806+0000] {processor.py:157} INFO - Started process (PID=53058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T04:42:06.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T04:42:06.822+0000] {logging_mixin.py:151} INFO - [2024-08-17T04:42:06.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T04:42:06.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T04:42:06.879+0000] {logging_mixin.py:151} INFO - [2024-08-17T04:42:06.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T04:42:06.895+0000] {logging_mixin.py:151} INFO - [2024-08-17T04:42:06.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T04:42:06.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-17T05:11:05.048+0000] {processor.py:157} INFO - Started process (PID=53070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:11:05.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T05:11:05.050+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:11:05.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:11:05.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:11:05.075+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:11:05.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T05:11:05.085+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:11:05.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T05:11:05.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T05:42:23.283+0000] {processor.py:157} INFO - Started process (PID=53079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:42:23.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T05:42:23.287+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:42:23.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:42:23.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:42:23.319+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:42:23.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T05:42:23.331+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:42:23.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T05:42:23.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T05:42:53.559+0000] {processor.py:157} INFO - Started process (PID=53089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:42:53.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T05:42:53.563+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:42:53.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:42:53.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T05:42:53.599+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:42:53.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T05:42:53.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T05:42:53.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T05:42:53.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T07:20:49.489+0000] {processor.py:157} INFO - Started process (PID=53099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T07:20:49.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T07:20:49.495+0000] {logging_mixin.py:151} INFO - [2024-08-17T07:20:49.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T07:20:49.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T07:20:49.572+0000] {logging_mixin.py:151} INFO - [2024-08-17T07:20:49.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T07:20:49.596+0000] {logging_mixin.py:151} INFO - [2024-08-17T07:20:49.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T07:20:49.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-17T09:03:31.537+0000] {processor.py:157} INFO - Started process (PID=53109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T09:03:31.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T09:03:31.546+0000] {logging_mixin.py:151} INFO - [2024-08-17T09:03:31.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T09:03:31.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T09:03:31.647+0000] {logging_mixin.py:151} INFO - [2024-08-17T09:03:31.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T09:03:31.684+0000] {logging_mixin.py:151} INFO - [2024-08-17T09:03:31.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T09:03:31.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-08-17T10:01:12.022+0000] {processor.py:157} INFO - Started process (PID=53119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T10:01:12.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T10:01:12.031+0000] {logging_mixin.py:151} INFO - [2024-08-17T10:01:12.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T10:01:12.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T10:01:12.121+0000] {logging_mixin.py:151} INFO - [2024-08-17T10:01:12.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T10:01:12.146+0000] {logging_mixin.py:151} INFO - [2024-08-17T10:01:12.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T10:01:12.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-17T10:01:42.516+0000] {processor.py:157} INFO - Started process (PID=53129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T10:01:42.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T10:01:42.521+0000] {logging_mixin.py:151} INFO - [2024-08-17T10:01:42.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T10:01:42.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T10:01:42.569+0000] {logging_mixin.py:151} INFO - [2024-08-17T10:01:42.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T10:01:42.584+0000] {logging_mixin.py:151} INFO - [2024-08-17T10:01:42.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T10:01:42.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-17T11:21:00.971+0000] {processor.py:157} INFO - Started process (PID=53141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T11:21:00.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T11:21:00.985+0000] {logging_mixin.py:151} INFO - [2024-08-17T11:21:00.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T11:21:01.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T11:21:01.055+0000] {logging_mixin.py:151} INFO - [2024-08-17T11:21:01.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T11:21:01.075+0000] {logging_mixin.py:151} INFO - [2024-08-17T11:21:01.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T11:21:01.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-17T12:02:20.628+0000] {processor.py:157} INFO - Started process (PID=53150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:02:20.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:02:20.634+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:02:20.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:02:20.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:02:20.711+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:02:20.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:02:20.746+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:02:20.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:02:20.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-17T12:02:51.142+0000] {processor.py:157} INFO - Started process (PID=53162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:02:51.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:02:51.156+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:02:51.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:02:51.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:02:51.246+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:02:51.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:02:51.286+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:02:51.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:02:51.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-08-17T12:18:42.375+0000] {processor.py:157} INFO - Started process (PID=53172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:18:42.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:18:42.383+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:18:42.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:18:42.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:18:42.434+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:18:42.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:18:42.467+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:18:42.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:18:42.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-17T12:19:12.843+0000] {processor.py:157} INFO - Started process (PID=53182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:19:12.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:19:12.853+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:19:12.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:19:12.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:19:12.930+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:19:12.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:19:12.951+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:19:12.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:19:12.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-17T12:19:43.177+0000] {processor.py:157} INFO - Started process (PID=53190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:19:43.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:19:43.188+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:19:43.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:19:43.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:19:43.270+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:19:43.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:19:43.286+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:19:43.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:19:43.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-17T12:20:13.560+0000] {processor.py:157} INFO - Started process (PID=53201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:20:13.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:20:13.570+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:20:13.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:20:13.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:20:13.617+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:20:13.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:20:13.630+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:20:13.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:20:13.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T12:20:43.817+0000] {processor.py:157} INFO - Started process (PID=53212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:20:43.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:20:43.822+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:20:43.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:20:43.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:20:43.847+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:20:43.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:20:43.858+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:20:43.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:20:43.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T12:21:14.171+0000] {processor.py:157} INFO - Started process (PID=53222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:21:14.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:21:14.178+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:21:14.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:21:14.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:21:14.230+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:21:14.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:21:14.244+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:21:14.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:21:14.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-17T12:21:44.452+0000] {processor.py:157} INFO - Started process (PID=53232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:21:44.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:21:44.457+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:21:44.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:21:44.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:21:44.487+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:21:44.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:21:44.497+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:21:44.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:21:44.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T12:22:14.791+0000] {processor.py:157} INFO - Started process (PID=53242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:22:14.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:22:14.795+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:22:14.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:22:14.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:22:14.859+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:22:14.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:22:14.872+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:22:14.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:22:14.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T12:22:45.078+0000] {processor.py:157} INFO - Started process (PID=53252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:22:45.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:22:45.081+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:22:45.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:22:45.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:22:45.108+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:22:45.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:22:45.119+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:22:45.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:22:45.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T12:23:15.427+0000] {processor.py:157} INFO - Started process (PID=53262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:23:15.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:23:15.439+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:23:15.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:23:15.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:23:15.481+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:23:15.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:23:15.494+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:23:15.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:23:15.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T12:23:45.843+0000] {processor.py:157} INFO - Started process (PID=53272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:23:45.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:23:45.850+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:23:45.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:23:45.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:23:45.883+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:23:45.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:23:45.897+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:23:45.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:23:45.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T12:24:16.171+0000] {processor.py:157} INFO - Started process (PID=53282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:24:16.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:24:16.174+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:24:16.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:24:16.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:24:16.216+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:24:16.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:24:16.227+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:24:16.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:24:16.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T12:24:46.518+0000] {processor.py:157} INFO - Started process (PID=53292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:24:46.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:24:46.523+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:24:46.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:24:46.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:24:46.549+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:24:46.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:24:46.560+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:24:46.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:24:46.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T12:25:16.861+0000] {processor.py:157} INFO - Started process (PID=53302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:25:16.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:25:16.863+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:25:16.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:25:16.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:25:16.889+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:25:16.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:25:16.901+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:25:16.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:25:16.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T12:25:47.208+0000] {processor.py:157} INFO - Started process (PID=53312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:25:47.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:25:47.213+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:25:47.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:25:47.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:25:47.251+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:25:47.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:25:47.262+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:25:47.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:25:47.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T12:26:17.569+0000] {processor.py:157} INFO - Started process (PID=53322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:26:17.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:26:17.573+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:26:17.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:26:17.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:26:17.603+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:26:17.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:26:17.615+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:26:17.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:26:17.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T12:26:47.912+0000] {processor.py:157} INFO - Started process (PID=53332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:26:47.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:26:47.917+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:26:47.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:26:47.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:26:47.957+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:26:47.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:26:47.969+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:26:47.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:26:47.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T12:27:18.207+0000] {processor.py:157} INFO - Started process (PID=53341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:27:18.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:27:18.211+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:27:18.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:27:18.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:27:18.241+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:27:18.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:27:18.254+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:27:18.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:27:18.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T12:27:48.484+0000] {processor.py:157} INFO - Started process (PID=53352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:27:48.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:27:48.487+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:27:48.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:27:48.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:27:48.515+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:27:48.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:27:48.527+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:27:48.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:27:48.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T12:28:18.793+0000] {processor.py:157} INFO - Started process (PID=53362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:28:18.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:28:18.799+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:28:18.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:28:18.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:28:18.848+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:28:18.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:28:18.861+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:28:18.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:28:18.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T12:28:49.073+0000] {processor.py:157} INFO - Started process (PID=53372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:28:49.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:28:49.078+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:28:49.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:28:49.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:28:49.108+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:28:49.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:28:49.122+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:28:49.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:28:49.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T12:29:19.390+0000] {processor.py:157} INFO - Started process (PID=53382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:29:19.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:29:19.396+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:29:19.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:29:19.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:29:19.439+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:29:19.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:29:19.452+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:29:19.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:29:19.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T12:29:49.877+0000] {processor.py:157} INFO - Started process (PID=53392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:29:49.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:29:49.885+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:29:49.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:29:49.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:29:49.926+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:29:49.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:29:49.946+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:29:49.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:29:49.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T12:30:20.124+0000] {processor.py:157} INFO - Started process (PID=53402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:30:20.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:30:20.127+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:30:20.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:30:20.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:30:20.151+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:30:20.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:30:20.162+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:30:20.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:30:20.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T12:30:50.455+0000] {processor.py:157} INFO - Started process (PID=53412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:30:50.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:30:50.458+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:30:50.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:30:50.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:30:50.485+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:30:50.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:30:50.498+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:30:50.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:30:50.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T12:31:20.818+0000] {processor.py:157} INFO - Started process (PID=53422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:31:20.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:31:20.824+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:31:20.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:31:20.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:31:20.863+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:31:20.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:31:20.875+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:31:20.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:31:20.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T12:31:51.165+0000] {processor.py:157} INFO - Started process (PID=53432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:31:51.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:31:51.167+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:31:51.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:31:51.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:31:51.196+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:31:51.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:31:51.209+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:31:51.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:31:51.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T12:32:21.493+0000] {processor.py:157} INFO - Started process (PID=53442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:32:21.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:32:21.496+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:32:21.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:32:21.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:32:21.522+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:32:21.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:32:21.531+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:32:21.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:32:21.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T12:32:51.899+0000] {processor.py:157} INFO - Started process (PID=53452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:32:51.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:32:51.908+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:32:51.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:32:51.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:32:51.983+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:32:51.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:32:52.000+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:32:52.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:32:52.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-17T12:33:22.334+0000] {processor.py:157} INFO - Started process (PID=53461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:33:22.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:33:22.344+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:33:22.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:33:22.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:33:22.461+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:33:22.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:33:22.480+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:33:22.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:33:22.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-08-17T12:33:52.702+0000] {processor.py:157} INFO - Started process (PID=53472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:33:52.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:33:52.707+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:33:52.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:33:52.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:33:52.772+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:33:52.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:33:52.784+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:33:52.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:33:52.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T12:34:23.051+0000] {processor.py:157} INFO - Started process (PID=53482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:34:23.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:34:23.063+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:34:23.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:34:23.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:34:23.117+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:34:23.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:34:23.145+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:34:23.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:34:23.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-17T12:34:53.330+0000] {processor.py:157} INFO - Started process (PID=53491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:34:53.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:34:53.339+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:34:53.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:34:53.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:34:53.416+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:34:53.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:34:53.430+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:34:53.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:34:53.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-17T12:35:23.811+0000] {processor.py:157} INFO - Started process (PID=53502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:35:23.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:35:23.818+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:35:23.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:35:23.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:35:23.882+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:35:23.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:35:23.895+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:35:23.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:35:23.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-17T12:35:54.175+0000] {processor.py:157} INFO - Started process (PID=53512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:35:54.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:35:54.182+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:35:54.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:35:54.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:35:54.261+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:35:54.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:35:54.285+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:35:54.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:35:54.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-17T12:36:24.503+0000] {processor.py:157} INFO - Started process (PID=53522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:36:24.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:36:24.510+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:36:24.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:36:24.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:36:24.575+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:36:24.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:36:24.598+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:36:24.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:36:24.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-17T12:36:54.863+0000] {processor.py:157} INFO - Started process (PID=53532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:36:54.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:36:54.870+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:36:54.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:36:54.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:36:54.940+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:36:54.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:36:54.965+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:36:54.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:36:54.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-17T12:37:25.211+0000] {processor.py:157} INFO - Started process (PID=53542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:37:25.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:37:25.224+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:37:25.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:37:25.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:37:25.276+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:37:25.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:37:25.290+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:37:25.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:37:25.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-17T12:37:55.509+0000] {processor.py:157} INFO - Started process (PID=53552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:37:55.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:37:55.519+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:37:55.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:37:55.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:37:55.582+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:37:55.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:37:55.595+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:37:55.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:37:55.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-17T12:38:25.814+0000] {processor.py:157} INFO - Started process (PID=53562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:38:25.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:38:25.838+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:38:25.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:38:25.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:38:25.883+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:38:25.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:38:25.910+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:38:25.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:38:25.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-17T12:38:56.201+0000] {processor.py:157} INFO - Started process (PID=53572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:38:56.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:38:56.215+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:38:56.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:38:56.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:38:56.271+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:38:56.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:38:56.288+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:38:56.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:38:56.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T12:39:26.531+0000] {processor.py:157} INFO - Started process (PID=53582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:39:26.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:39:26.559+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:39:26.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:39:26.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:39:26.623+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:39:26.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:39:26.646+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:39:26.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:39:26.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-17T12:39:56.896+0000] {processor.py:157} INFO - Started process (PID=53592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:39:56.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:39:56.908+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:39:56.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:39:56.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:39:56.966+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:39:56.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:39:56.986+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:39:56.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:39:56.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-17T12:40:27.232+0000] {processor.py:157} INFO - Started process (PID=53602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:40:27.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:40:27.242+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:40:27.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:40:27.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:40:27.321+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:40:27.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:40:27.336+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:40:27.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:40:27.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-17T12:40:57.553+0000] {processor.py:157} INFO - Started process (PID=53612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:40:57.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:40:57.568+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:40:57.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:40:57.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:40:57.622+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:40:57.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:40:57.635+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:40:57.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:40:57.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T12:41:27.864+0000] {processor.py:157} INFO - Started process (PID=53621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:41:27.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:41:27.869+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:41:27.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:41:27.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:41:27.935+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:41:27.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:41:27.949+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:41:27.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:41:27.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T12:41:58.324+0000] {processor.py:157} INFO - Started process (PID=53632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:41:58.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:41:58.332+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:41:58.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:41:58.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:41:58.388+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:41:58.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:41:58.402+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:41:58.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:41:58.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-17T12:42:28.607+0000] {processor.py:157} INFO - Started process (PID=53642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:42:28.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:42:28.611+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:42:28.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:42:28.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:42:28.640+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:42:28.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:42:28.651+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:42:28.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:42:28.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T12:42:59.037+0000] {processor.py:157} INFO - Started process (PID=53652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:42:59.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:42:59.044+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:42:59.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:42:59.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:42:59.104+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:42:59.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:42:59.117+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:42:59.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:42:59.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T12:43:29.449+0000] {processor.py:157} INFO - Started process (PID=53662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:43:29.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:43:29.456+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:43:29.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:43:29.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:43:29.514+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:43:29.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:43:29.532+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:43:29.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:43:29.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-17T12:43:59.881+0000] {processor.py:157} INFO - Started process (PID=53672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:43:59.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:43:59.885+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:43:59.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:43:59.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:43:59.923+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:43:59.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:43:59.936+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:43:59.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:43:59.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T12:44:30.287+0000] {processor.py:157} INFO - Started process (PID=53682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:44:30.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:44:30.296+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:44:30.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:44:30.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:44:30.368+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:44:30.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:44:30.386+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:44:30.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:44:30.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-17T12:45:00.701+0000] {processor.py:157} INFO - Started process (PID=53692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:45:00.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:45:00.706+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:45:00.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:45:00.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:45:00.746+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:45:00.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:45:00.761+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:45:00.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:45:00.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T12:45:30.995+0000] {processor.py:157} INFO - Started process (PID=53702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:45:30.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:45:30.998+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:45:30.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:45:31.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:45:31.026+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:45:31.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:45:31.042+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:45:31.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:45:31.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T12:46:01.370+0000] {processor.py:157} INFO - Started process (PID=53712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:46:01.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:46:01.376+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:46:01.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:46:01.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:46:01.440+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:46:01.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:46:01.454+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:46:01.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:46:01.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-17T12:46:31.704+0000] {processor.py:157} INFO - Started process (PID=53722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:46:31.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:46:31.706+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:46:31.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:46:31.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:46:31.737+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:46:31.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:46:31.749+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:46:31.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:46:31.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T12:47:02.110+0000] {processor.py:157} INFO - Started process (PID=53732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:47:02.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:47:02.116+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:47:02.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:47:02.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:47:02.187+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:47:02.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:47:02.203+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:47:02.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:47:02.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T12:47:32.511+0000] {processor.py:157} INFO - Started process (PID=53742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:47:32.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:47:32.517+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:47:32.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:47:32.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:47:32.549+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:47:32.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:47:32.562+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:47:32.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:47:32.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T12:48:02.927+0000] {processor.py:157} INFO - Started process (PID=53752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:48:02.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:48:02.932+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:48:02.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:48:02.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:48:02.990+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:48:02.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:48:03.004+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:48:03.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:48:03.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-17T12:48:33.204+0000] {processor.py:157} INFO - Started process (PID=53762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:48:33.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:48:33.207+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:48:33.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:48:33.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:48:33.234+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:48:33.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:48:33.244+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:48:33.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:48:33.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T12:49:03.600+0000] {processor.py:157} INFO - Started process (PID=53772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:49:03.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:49:03.607+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:49:03.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:49:03.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:49:03.657+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:49:03.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:49:03.682+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:49:03.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:49:03.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T12:49:33.905+0000] {processor.py:157} INFO - Started process (PID=53782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:49:33.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:49:33.920+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:49:33.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:49:33.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:49:33.980+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:49:33.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:49:33.993+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:49:33.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:49:34.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-17T12:50:04.262+0000] {processor.py:157} INFO - Started process (PID=53792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:50:04.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:50:04.269+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:50:04.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:50:04.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:50:04.329+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:50:04.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:50:04.344+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:50:04.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:50:04.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T12:50:34.643+0000] {processor.py:157} INFO - Started process (PID=53802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:50:34.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:50:34.650+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:50:34.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:50:34.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:50:34.695+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:50:34.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:50:34.708+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:50:34.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:50:34.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-17T12:51:04.985+0000] {processor.py:157} INFO - Started process (PID=53812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:51:04.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:51:04.992+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:51:04.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:51:05.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:51:05.054+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:51:05.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:51:05.068+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:51:05.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:51:05.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T12:51:35.375+0000] {processor.py:157} INFO - Started process (PID=53822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:51:35.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:51:35.383+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:51:35.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:51:35.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:51:35.442+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:51:35.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:51:35.462+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:51:35.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:51:35.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-17T12:52:05.727+0000] {processor.py:157} INFO - Started process (PID=53832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:52:05.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:52:05.737+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:52:05.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:52:05.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:52:05.777+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:52:05.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:52:05.791+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:52:05.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:52:05.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T12:52:36.097+0000] {processor.py:157} INFO - Started process (PID=53842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:52:36.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:52:36.100+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:52:36.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:52:36.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:52:36.129+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:52:36.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:52:36.139+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:52:36.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:52:36.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T12:53:06.490+0000] {processor.py:157} INFO - Started process (PID=53852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:53:06.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:53:06.496+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:53:06.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:53:06.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:53:06.551+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:53:06.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:53:06.564+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:53:06.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:53:06.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T12:53:36.774+0000] {processor.py:157} INFO - Started process (PID=53862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:53:36.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:53:36.780+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:53:36.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:53:36.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:53:36.808+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:53:36.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:53:36.818+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:53:36.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:53:36.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T12:54:07.210+0000] {processor.py:157} INFO - Started process (PID=53872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:54:07.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:54:07.215+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:54:07.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:54:07.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:54:07.257+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:54:07.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:54:07.270+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:54:07.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:54:07.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T12:54:37.508+0000] {processor.py:157} INFO - Started process (PID=53882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:54:37.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:54:37.512+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:54:37.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:54:37.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:54:37.541+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:54:37.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:54:37.551+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:54:37.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:54:37.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T12:55:07.922+0000] {processor.py:157} INFO - Started process (PID=53892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:55:07.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:55:07.944+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:55:07.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:55:07.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:55:08.008+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:55:08.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:55:08.022+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:55:08.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:55:08.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-17T12:55:38.240+0000] {processor.py:157} INFO - Started process (PID=53902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:55:38.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:55:38.246+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:55:38.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:55:38.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:55:38.297+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:55:38.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:55:38.310+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:55:38.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:55:38.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-17T12:56:08.554+0000] {processor.py:157} INFO - Started process (PID=53912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:56:08.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:56:08.556+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:56:08.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:56:08.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:56:08.607+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:56:08.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:56:08.631+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:56:08.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:56:08.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T12:56:38.894+0000] {processor.py:157} INFO - Started process (PID=53921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:56:38.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:56:38.900+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:56:38.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:56:38.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:56:38.947+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:56:38.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:56:38.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:56:38.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:56:38.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-17T12:57:09.271+0000] {processor.py:157} INFO - Started process (PID=53932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:57:09.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:57:09.277+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:57:09.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:57:09.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:57:09.314+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:57:09.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:57:09.327+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:57:09.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:57:09.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T12:57:39.688+0000] {processor.py:157} INFO - Started process (PID=53942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:57:39.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:57:39.692+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:57:39.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:57:39.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:57:39.723+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:57:39.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:57:39.745+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:57:39.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:57:39.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T12:58:10.096+0000] {processor.py:157} INFO - Started process (PID=53951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:58:10.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:58:10.101+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:58:10.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:58:10.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:58:10.176+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:58:10.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:58:10.188+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:58:10.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:58:10.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-17T12:58:40.402+0000] {processor.py:157} INFO - Started process (PID=53962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:58:40.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:58:40.413+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:58:40.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:58:40.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:58:40.449+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:58:40.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:58:40.461+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:58:40.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:58:40.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T12:59:10.785+0000] {processor.py:157} INFO - Started process (PID=53972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:59:10.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:59:10.793+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:59:10.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:59:10.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:59:10.858+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:59:10.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:59:10.872+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:59:10.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:59:10.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T12:59:41.082+0000] {processor.py:157} INFO - Started process (PID=53982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:59:41.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T12:59:41.088+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:59:41.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:59:41.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T12:59:41.134+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:59:41.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T12:59:41.149+0000] {logging_mixin.py:151} INFO - [2024-08-17T12:59:41.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T12:59:41.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T13:00:11.407+0000] {processor.py:157} INFO - Started process (PID=53992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:00:11.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:00:11.411+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:00:11.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:00:11.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:00:11.441+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:00:11.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:00:11.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:00:11.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:00:11.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T13:00:41.806+0000] {processor.py:157} INFO - Started process (PID=54002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:00:41.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:00:41.811+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:00:41.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:00:41.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:00:41.868+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:00:41.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:00:41.881+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:00:41.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:00:41.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T13:01:12.154+0000] {processor.py:157} INFO - Started process (PID=54012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:01:12.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:01:12.166+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:01:12.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:01:12.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:01:12.216+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:01:12.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:01:12.230+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:01:12.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:01:12.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T13:01:42.418+0000] {processor.py:157} INFO - Started process (PID=54022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:01:42.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:01:42.421+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:01:42.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:01:42.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:01:42.443+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:01:42.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:01:42.452+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:01:42.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:01:42.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-17T13:02:12.732+0000] {processor.py:157} INFO - Started process (PID=54032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:02:12.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:02:12.738+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:02:12.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:02:12.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:02:12.807+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:02:12.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:02:12.821+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:02:12.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:02:12.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T13:02:43.025+0000] {processor.py:157} INFO - Started process (PID=54042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:02:43.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:02:43.029+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:02:43.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:02:43.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:02:43.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:02:43.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:02:43.076+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:02:43.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:02:43.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T13:03:13.429+0000] {processor.py:157} INFO - Started process (PID=54052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:03:13.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:03:13.437+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:03:13.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:03:13.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:03:13.483+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:03:13.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:03:13.499+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:03:13.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:03:13.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T13:03:43.701+0000] {processor.py:157} INFO - Started process (PID=54062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:03:43.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:03:43.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:03:43.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:03:43.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:03:43.733+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:03:43.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:03:43.743+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:03:43.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:03:43.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T13:04:14.140+0000] {processor.py:157} INFO - Started process (PID=54072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:04:14.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:04:14.151+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:04:14.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:04:14.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:04:14.206+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:04:14.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:04:14.219+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:04:14.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:04:14.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T13:04:44.462+0000] {processor.py:157} INFO - Started process (PID=54082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:04:44.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:04:44.465+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:04:44.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:04:44.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:04:44.493+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:04:44.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:04:44.505+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:04:44.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:04:44.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T13:05:14.839+0000] {processor.py:157} INFO - Started process (PID=54092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:05:14.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:05:14.845+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:05:14.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:05:14.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:05:14.908+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:05:14.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:05:14.922+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:05:14.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:05:14.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T13:05:45.258+0000] {processor.py:157} INFO - Started process (PID=54102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:05:45.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:05:45.263+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:05:45.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:05:45.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:05:45.287+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:05:45.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:05:45.296+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:05:45.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:05:45.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T13:06:15.617+0000] {processor.py:157} INFO - Started process (PID=54111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:06:15.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:06:15.636+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:06:15.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:06:15.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:06:15.695+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:06:15.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:06:15.724+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:06:15.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:06:15.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-17T13:06:45.884+0000] {processor.py:157} INFO - Started process (PID=54122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:06:45.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:06:45.887+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:06:45.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:06:45.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:06:45.914+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:06:45.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:06:45.927+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:06:45.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:06:45.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T13:07:16.285+0000] {processor.py:157} INFO - Started process (PID=54131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:07:16.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:07:16.313+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:07:16.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:07:16.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:07:16.372+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:07:16.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:07:16.386+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:07:16.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:07:16.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-17T13:07:46.638+0000] {processor.py:157} INFO - Started process (PID=54142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:07:46.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:07:46.641+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:07:46.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:07:46.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:07:46.668+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:07:46.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:07:46.678+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:07:46.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:07:46.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T13:08:17.004+0000] {processor.py:157} INFO - Started process (PID=54152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:08:17.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:08:17.008+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:08:17.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:08:17.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:08:17.073+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:08:17.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:08:17.086+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:08:17.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:08:17.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T13:08:47.344+0000] {processor.py:157} INFO - Started process (PID=54162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:08:47.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:08:47.349+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:08:47.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:08:47.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:08:47.375+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:08:47.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:08:47.385+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:08:47.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:08:47.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T13:09:17.735+0000] {processor.py:157} INFO - Started process (PID=54172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:09:17.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:09:17.741+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:09:17.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:09:17.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:09:17.811+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:09:17.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:09:17.824+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:09:17.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:09:17.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T13:09:48.009+0000] {processor.py:157} INFO - Started process (PID=54182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:09:48.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:09:48.012+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:09:48.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:09:48.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:09:48.041+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:09:48.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:09:48.052+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:09:48.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:09:48.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T13:10:18.402+0000] {processor.py:157} INFO - Started process (PID=54192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:10:18.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:10:18.412+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:10:18.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:10:18.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:10:18.455+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:10:18.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:10:18.469+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:10:18.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:10:18.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-17T13:10:48.732+0000] {processor.py:157} INFO - Started process (PID=54202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:10:48.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:10:48.737+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:10:48.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:10:48.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:10:48.771+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:10:48.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:10:48.784+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:10:48.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:10:48.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T13:11:19.129+0000] {processor.py:157} INFO - Started process (PID=54212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:11:19.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:11:19.156+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:11:19.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:11:19.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:11:19.204+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:11:19.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:11:19.218+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:11:19.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:11:19.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T13:11:49.541+0000] {processor.py:157} INFO - Started process (PID=54222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:11:49.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:11:49.545+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:11:49.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:11:49.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:11:49.567+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:11:49.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:11:49.576+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:11:49.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:11:49.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-17T13:12:19.916+0000] {processor.py:157} INFO - Started process (PID=54232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:12:19.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:12:19.923+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:12:19.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:12:19.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:12:19.997+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:12:19.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:12:20.010+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:12:20.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:12:20.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-17T13:12:50.192+0000] {processor.py:157} INFO - Started process (PID=54242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:12:50.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:12:50.197+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:12:50.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:12:50.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:12:50.227+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:12:50.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:12:50.239+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:12:50.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:12:50.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T13:13:20.621+0000] {processor.py:157} INFO - Started process (PID=54251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:13:20.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:13:20.637+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:13:20.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:13:20.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:13:20.699+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:13:20.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:13:20.713+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:13:20.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:13:20.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-17T13:13:50.983+0000] {processor.py:157} INFO - Started process (PID=54262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:13:50.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:13:50.991+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:13:50.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:13:51.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:13:51.015+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:13:51.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:13:51.026+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:13:51.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:13:51.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T13:14:21.366+0000] {processor.py:157} INFO - Started process (PID=54272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:14:21.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:14:21.372+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:14:21.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:14:21.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:14:21.439+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:14:21.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:14:21.452+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:14:21.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:14:21.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T13:14:51.684+0000] {processor.py:157} INFO - Started process (PID=54282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:14:51.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:14:51.686+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:14:51.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:14:51.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:14:51.715+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:14:51.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:14:51.726+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:14:51.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:14:51.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T13:15:22.048+0000] {processor.py:157} INFO - Started process (PID=54291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:15:22.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:15:22.054+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:15:22.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:15:22.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:15:22.109+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:15:22.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:15:22.124+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:15:22.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:15:22.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T13:15:52.347+0000] {processor.py:157} INFO - Started process (PID=54302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:15:52.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:15:52.349+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:15:52.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:15:52.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:15:52.375+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:15:52.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:15:52.385+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:15:52.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:15:52.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T13:16:22.744+0000] {processor.py:157} INFO - Started process (PID=54312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:16:22.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:16:22.750+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:16:22.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:16:22.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:16:22.814+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:16:22.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:16:22.827+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:16:22.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:16:22.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T13:16:53.149+0000] {processor.py:157} INFO - Started process (PID=54322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:16:53.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:16:53.153+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:16:53.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:16:53.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:16:53.180+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:16:53.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:16:53.190+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:16:53.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:16:53.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T13:17:23.477+0000] {processor.py:157} INFO - Started process (PID=54332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:17:23.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:17:23.483+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:17:23.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:17:23.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:17:23.558+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:17:23.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:17:23.573+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:17:23.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:17:23.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-17T13:17:53.945+0000] {processor.py:157} INFO - Started process (PID=54342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:17:53.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:17:53.951+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:17:53.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:17:53.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:17:53.996+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:17:53.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:17:54.011+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:17:54.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:17:54.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-17T13:18:24.252+0000] {processor.py:157} INFO - Started process (PID=54352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:18:24.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:18:24.255+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:18:24.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:18:24.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:18:24.284+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:18:24.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:18:24.295+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:18:24.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:18:24.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T13:18:54.679+0000] {processor.py:157} INFO - Started process (PID=54362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:18:54.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:18:54.691+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:18:54.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:18:54.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:18:54.748+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:18:54.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:18:54.760+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:18:54.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:18:54.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T13:19:25.055+0000] {processor.py:157} INFO - Started process (PID=54372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:19:25.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:19:25.061+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:19:25.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:19:25.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:19:25.125+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:19:25.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:19:25.140+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:19:25.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:19:25.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T13:19:55.407+0000] {processor.py:157} INFO - Started process (PID=54382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:19:55.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:19:55.418+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:19:55.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:19:55.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:19:55.476+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:19:55.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:19:55.493+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:19:55.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:19:55.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-17T13:20:25.746+0000] {processor.py:157} INFO - Started process (PID=54392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:20:25.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:20:25.756+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:20:25.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:20:25.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:20:25.809+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:20:25.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:20:25.823+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:20:25.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:20:25.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-17T13:20:56.122+0000] {processor.py:157} INFO - Started process (PID=54402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:20:56.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:20:56.130+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:20:56.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:20:56.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:20:56.174+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:20:56.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:20:56.187+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:20:56.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:20:56.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T13:21:26.494+0000] {processor.py:157} INFO - Started process (PID=54412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:21:26.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:21:26.504+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:21:26.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:21:26.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:21:26.559+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:21:26.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:21:26.582+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:21:26.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:21:26.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T13:21:56.788+0000] {processor.py:157} INFO - Started process (PID=54422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:21:56.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:21:56.795+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:21:56.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:21:56.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:21:56.836+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:21:56.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:21:56.850+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:21:56.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:21:56.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-17T13:22:27.141+0000] {processor.py:157} INFO - Started process (PID=54432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:22:27.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:22:27.144+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:22:27.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:22:27.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:22:27.172+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:22:27.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:22:27.182+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:22:27.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:22:27.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T13:22:57.460+0000] {processor.py:157} INFO - Started process (PID=54440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:22:57.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:22:57.479+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:22:57.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:22:57.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:22:57.538+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:22:57.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:22:57.552+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:22:57.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:22:57.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-17T13:23:27.753+0000] {processor.py:157} INFO - Started process (PID=54452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:23:27.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:23:27.756+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:23:27.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:23:27.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:23:27.782+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:23:27.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:23:27.793+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:23:27.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:23:27.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T13:23:58.154+0000] {processor.py:157} INFO - Started process (PID=54462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:23:58.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:23:58.159+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:23:58.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:23:58.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:23:58.197+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:23:58.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:23:58.210+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:23:58.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:23:58.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T13:24:28.552+0000] {processor.py:157} INFO - Started process (PID=54472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:24:28.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:24:28.555+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:24:28.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:24:28.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:24:28.581+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:24:28.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:24:28.594+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:24:28.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:24:28.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T13:24:58.936+0000] {processor.py:157} INFO - Started process (PID=54482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:24:58.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:24:58.941+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:24:58.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:24:58.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:24:58.965+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:24:58.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:24:58.975+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:24:58.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:24:58.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T13:25:29.333+0000] {processor.py:157} INFO - Started process (PID=54492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:25:29.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:25:29.338+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:25:29.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:25:29.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:25:29.386+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:25:29.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:25:29.405+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:25:29.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:25:29.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T13:25:59.637+0000] {processor.py:157} INFO - Started process (PID=54502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:25:59.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:25:59.640+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:25:59.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:25:59.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:25:59.668+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:25:59.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:25:59.678+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:25:59.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:25:59.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T13:26:30.020+0000] {processor.py:157} INFO - Started process (PID=54511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:26:30.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:26:30.026+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:26:30.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:26:30.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:26:30.090+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:26:30.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:26:30.105+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:26:30.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:26:30.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-17T13:27:00.448+0000] {processor.py:157} INFO - Started process (PID=54522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:27:00.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:27:00.453+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:27:00.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:27:00.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:27:00.484+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:27:00.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:27:00.494+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:27:00.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:27:00.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T13:27:30.833+0000] {processor.py:157} INFO - Started process (PID=54531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:27:30.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:27:30.839+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:27:30.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:27:30.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:27:30.908+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:27:30.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:27:30.921+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:27:30.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:27:30.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-17T13:28:01.290+0000] {processor.py:157} INFO - Started process (PID=54542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:28:01.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:28:01.299+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:28:01.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:28:01.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:28:01.353+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:28:01.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:28:01.376+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:28:01.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:28:01.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-17T13:28:31.645+0000] {processor.py:157} INFO - Started process (PID=54552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:28:31.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:28:31.654+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:28:31.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:28:31.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:28:31.747+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:28:31.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:28:31.761+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:28:31.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:28:31.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-17T13:29:02.137+0000] {processor.py:157} INFO - Started process (PID=54561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:29:02.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:29:02.151+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:29:02.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:29:02.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:29:02.195+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:29:02.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:29:02.225+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:29:02.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:29:02.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-17T13:29:32.593+0000] {processor.py:157} INFO - Started process (PID=54572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:29:32.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:29:32.608+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:29:32.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:29:32.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:29:32.652+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:29:32.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:29:32.674+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:29:32.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:29:32.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T13:30:02.864+0000] {processor.py:157} INFO - Started process (PID=54582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:30:02.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:30:02.871+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:30:02.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:30:02.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:30:02.916+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:30:02.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:30:02.930+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:30:02.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:30:02.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T13:30:33.247+0000] {processor.py:157} INFO - Started process (PID=54592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:30:33.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:30:33.251+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:30:33.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:30:33.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:30:33.289+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:30:33.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:30:33.303+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:30:33.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:30:33.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T13:31:03.630+0000] {processor.py:157} INFO - Started process (PID=54602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:31:03.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:31:03.633+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:31:03.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:31:03.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:31:03.660+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:31:03.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:31:03.672+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:31:03.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:31:03.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T13:31:33.959+0000] {processor.py:157} INFO - Started process (PID=54612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:31:33.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:31:33.966+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:31:33.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:31:33.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:31:34.008+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:31:34.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:31:34.037+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:31:34.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:31:34.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-17T13:32:04.258+0000] {processor.py:157} INFO - Started process (PID=54622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:32:04.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:32:04.266+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:32:04.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:32:04.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:32:04.315+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:32:04.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:32:04.330+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:32:04.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:32:04.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T13:32:34.584+0000] {processor.py:157} INFO - Started process (PID=54632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:32:34.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:32:34.587+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:32:34.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:32:34.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:32:34.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:32:34.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:32:34.622+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:32:34.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:32:34.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T13:33:04.891+0000] {processor.py:157} INFO - Started process (PID=54642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:33:04.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:33:04.900+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:33:04.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:33:04.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:33:04.953+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:33:04.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:33:04.971+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:33:04.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:33:04.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T13:33:35.216+0000] {processor.py:157} INFO - Started process (PID=54652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:33:35.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:33:35.223+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:33:35.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:33:35.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:33:35.259+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:33:35.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:33:35.274+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:33:35.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:33:35.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T13:34:05.672+0000] {processor.py:157} INFO - Started process (PID=54662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:34:05.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:34:05.679+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:34:05.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:34:05.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:34:05.715+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:34:05.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:34:05.728+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:34:05.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:34:05.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-17T13:34:36.026+0000] {processor.py:157} INFO - Started process (PID=54672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:34:36.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:34:36.030+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:34:36.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:34:36.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:34:36.064+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:34:36.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:34:36.074+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:34:36.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:34:36.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T13:35:06.380+0000] {processor.py:157} INFO - Started process (PID=54682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:35:06.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:35:06.386+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:35:06.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:35:06.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:35:06.432+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:35:06.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:35:06.446+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:35:06.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:35:06.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T13:35:36.699+0000] {processor.py:157} INFO - Started process (PID=54692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:35:36.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:35:36.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:35:36.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:35:36.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:35:36.743+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:35:36.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:35:36.757+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:35:36.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:35:36.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T13:36:06.984+0000] {processor.py:157} INFO - Started process (PID=54702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:36:06.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:36:06.986+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:36:06.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:36:06.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:36:07.014+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:36:07.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:36:07.025+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:36:07.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:36:07.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T13:36:37.315+0000] {processor.py:157} INFO - Started process (PID=54712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:36:37.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:36:37.320+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:36:37.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:36:37.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:36:37.373+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:36:37.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:36:37.395+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:36:37.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:36:37.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-17T13:37:07.638+0000] {processor.py:157} INFO - Started process (PID=54722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:37:07.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:37:07.644+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:37:07.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:37:07.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:37:07.695+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:37:07.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:37:07.710+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:37:07.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:37:07.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T13:37:37.974+0000] {processor.py:157} INFO - Started process (PID=54732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:37:37.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:37:37.976+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:37:37.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:37:37.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:37:38.004+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:37:38.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:37:38.014+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:37:38.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:37:38.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T13:38:08.276+0000] {processor.py:157} INFO - Started process (PID=54741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:38:08.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:38:08.282+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:38:08.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:38:08.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:38:08.325+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:38:08.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:38:08.339+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:38:08.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:38:08.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T13:38:38.657+0000] {processor.py:157} INFO - Started process (PID=54752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:38:38.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:38:38.661+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:38:38.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:38:38.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:38:38.692+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:38:38.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:38:38.704+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:38:38.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:38:38.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T13:39:09.073+0000] {processor.py:157} INFO - Started process (PID=54762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:39:09.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:39:09.080+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:39:09.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:39:09.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:39:09.128+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:39:09.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:39:09.141+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:39:09.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:39:09.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T13:39:39.477+0000] {processor.py:157} INFO - Started process (PID=54772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:39:39.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:39:39.484+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:39:39.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:39:39.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:39:39.520+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:39:39.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:39:39.532+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:39:39.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:39:39.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T13:40:09.878+0000] {processor.py:157} INFO - Started process (PID=54782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:40:09.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:40:09.883+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:40:09.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:40:09.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:40:09.929+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:40:09.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:40:09.942+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:40:09.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:40:09.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T13:40:40.283+0000] {processor.py:157} INFO - Started process (PID=54792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:40:40.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:40:40.289+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:40:40.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:40:40.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:40:40.333+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:40:40.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:40:40.345+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:40:40.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:40:40.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T13:41:10.663+0000] {processor.py:157} INFO - Started process (PID=54802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:41:10.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:41:10.670+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:41:10.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:41:10.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:41:10.708+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:41:10.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:41:10.722+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:41:10.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:41:10.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T13:41:40.959+0000] {processor.py:157} INFO - Started process (PID=54812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:41:40.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:41:40.964+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:41:40.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:41:40.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:41:40.991+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:41:40.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:41:41.003+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:41:41.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:41:41.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T13:42:11.314+0000] {processor.py:157} INFO - Started process (PID=54822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:42:11.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:42:11.323+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:42:11.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:42:11.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:42:11.362+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:42:11.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:42:11.375+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:42:11.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:42:11.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T13:42:41.620+0000] {processor.py:157} INFO - Started process (PID=54832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:42:41.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:42:41.623+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:42:41.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:42:41.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:42:41.651+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:42:41.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:42:41.663+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:42:41.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:42:41.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T13:43:11.964+0000] {processor.py:157} INFO - Started process (PID=54842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:43:11.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:43:11.967+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:43:11.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:43:11.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:43:11.993+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:43:11.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:43:12.002+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:43:12.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:43:12.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T13:43:42.342+0000] {processor.py:157} INFO - Started process (PID=54852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:43:42.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:43:42.346+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:43:42.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:43:42.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:43:42.380+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:43:42.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:43:42.389+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:43:42.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:43:42.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T13:44:12.661+0000] {processor.py:157} INFO - Started process (PID=54861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:44:12.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:44:12.672+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:44:12.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:44:12.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:44:12.716+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:44:12.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:44:12.740+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:44:12.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:44:12.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T13:44:42.973+0000] {processor.py:157} INFO - Started process (PID=54872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:44:42.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:44:42.976+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:44:42.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:44:42.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:44:43.007+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:44:43.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:44:43.021+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:44:43.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:44:43.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T13:45:13.389+0000] {processor.py:157} INFO - Started process (PID=54880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:45:13.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:45:13.395+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:45:13.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:45:13.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:45:13.447+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:45:13.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:45:13.462+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:45:13.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:45:13.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T13:45:43.655+0000] {processor.py:157} INFO - Started process (PID=54892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:45:43.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:45:43.663+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:45:43.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:45:43.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:45:43.703+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:45:43.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:45:43.716+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:45:43.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:45:43.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-17T13:46:13.989+0000] {processor.py:157} INFO - Started process (PID=54902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:46:13.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:46:13.995+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:46:13.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:46:14.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:46:14.062+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:46:14.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:46:14.074+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:46:14.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:46:14.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T13:46:44.276+0000] {processor.py:157} INFO - Started process (PID=54912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:46:44.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:46:44.279+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:46:44.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:46:44.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:46:44.308+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:46:44.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:46:44.318+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:46:44.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:46:44.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T13:47:14.559+0000] {processor.py:157} INFO - Started process (PID=54921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:47:14.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:47:14.563+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:47:14.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:47:14.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:47:14.609+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:47:14.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:47:14.622+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:47:14.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:47:14.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-17T13:47:44.877+0000] {processor.py:157} INFO - Started process (PID=54932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:47:44.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:47:44.879+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:47:44.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:47:44.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:47:44.908+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:47:44.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:47:44.917+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:47:44.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:47:44.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T13:48:15.314+0000] {processor.py:157} INFO - Started process (PID=54942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:48:15.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:48:15.332+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:48:15.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:48:15.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:48:15.394+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:48:15.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:48:15.410+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:48:15.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:48:15.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-17T13:48:45.590+0000] {processor.py:157} INFO - Started process (PID=54952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:48:45.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:48:45.593+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:48:45.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:48:45.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:48:45.619+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:48:45.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:48:45.629+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:48:45.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:48:45.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T13:49:15.911+0000] {processor.py:157} INFO - Started process (PID=54961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:49:15.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:49:15.917+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:49:15.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:49:15.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:49:15.986+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:49:15.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:49:15.998+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:49:15.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:49:16.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-17T13:49:46.234+0000] {processor.py:157} INFO - Started process (PID=54972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:49:46.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:49:46.238+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:49:46.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:49:46.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:49:46.267+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:49:46.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:49:46.276+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:49:46.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:49:46.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T13:50:16.669+0000] {processor.py:157} INFO - Started process (PID=54982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:50:16.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:50:16.677+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:50:16.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:50:16.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:50:16.725+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:50:16.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:50:16.738+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:50:16.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:50:16.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T13:50:47.097+0000] {processor.py:157} INFO - Started process (PID=54992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:50:47.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:50:47.104+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:50:47.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:50:47.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:50:47.154+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:50:47.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:50:47.181+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:50:47.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:50:47.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-17T13:51:17.428+0000] {processor.py:157} INFO - Started process (PID=55001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:51:17.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:51:17.435+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:51:17.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:51:17.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:51:17.496+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:51:17.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:51:17.509+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:51:17.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:51:17.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T13:51:47.758+0000] {processor.py:157} INFO - Started process (PID=55012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:51:47.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:51:47.764+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:51:47.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:51:47.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:51:47.810+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:51:47.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:51:47.829+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:51:47.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:51:47.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T13:52:18.076+0000] {processor.py:157} INFO - Started process (PID=55022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:52:18.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:52:18.081+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:52:18.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:52:18.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:52:18.111+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:52:18.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:52:18.120+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:52:18.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:52:18.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T13:52:48.447+0000] {processor.py:157} INFO - Started process (PID=55031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:52:48.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:52:48.452+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:52:48.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:52:48.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:52:48.491+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:52:48.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:52:48.504+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:52:48.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:52:48.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T13:53:18.781+0000] {processor.py:157} INFO - Started process (PID=55042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:53:18.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:53:18.786+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:53:18.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:53:18.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:53:18.810+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:53:18.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:53:18.821+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:53:18.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:53:18.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T13:53:49.153+0000] {processor.py:157} INFO - Started process (PID=55052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:53:49.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:53:49.159+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:53:49.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:53:49.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:53:49.196+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:53:49.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:53:49.208+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:53:49.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:53:49.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T13:54:19.560+0000] {processor.py:157} INFO - Started process (PID=55062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:54:19.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:54:19.563+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:54:19.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:54:19.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:54:19.605+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:54:19.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:54:19.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:54:19.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:54:19.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T13:54:49.868+0000] {processor.py:157} INFO - Started process (PID=55072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:54:49.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:54:49.870+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:54:49.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:54:49.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:54:49.898+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:54:49.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:54:49.908+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:54:49.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:54:49.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T13:55:20.277+0000] {processor.py:157} INFO - Started process (PID=55082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:55:20.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:55:20.285+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:55:20.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:55:20.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:55:20.316+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:55:20.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:55:20.326+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:55:20.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:55:20.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T13:55:50.607+0000] {processor.py:157} INFO - Started process (PID=55092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:55:50.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:55:50.609+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:55:50.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:55:50.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:55:50.649+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:55:50.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:55:50.664+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:55:50.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:55:50.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T13:56:20.919+0000] {processor.py:157} INFO - Started process (PID=55102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:56:20.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:56:20.925+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:56:20.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:56:20.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:56:20.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:56:20.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:56:20.969+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:56:20.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:56:20.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T13:56:51.277+0000] {processor.py:157} INFO - Started process (PID=55112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:56:51.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:56:51.280+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:56:51.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:56:51.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:56:51.317+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:56:51.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:56:51.330+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:56:51.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:56:51.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T13:57:21.684+0000] {processor.py:157} INFO - Started process (PID=55122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:57:21.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:57:21.691+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:57:21.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:57:21.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:57:21.718+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:57:21.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:57:21.727+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:57:21.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:57:21.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T13:57:52.012+0000] {processor.py:157} INFO - Started process (PID=55132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:57:52.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:57:52.018+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:57:52.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:57:52.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:57:52.046+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:57:52.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:57:52.058+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:57:52.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:57:52.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T13:58:22.365+0000] {processor.py:157} INFO - Started process (PID=55142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:58:22.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:58:22.367+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:58:22.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:58:22.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:58:22.419+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:58:22.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:58:22.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:58:22.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:58:22.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T13:58:52.655+0000] {processor.py:157} INFO - Started process (PID=55152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:58:52.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:58:52.657+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:58:52.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:58:52.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:58:52.683+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:58:52.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:58:52.693+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:58:52.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:58:53.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.606 seconds
[2024-08-17T13:59:23.563+0000] {processor.py:157} INFO - Started process (PID=55162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:59:23.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:59:23.569+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:59:23.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:59:23.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:59:23.621+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:59:23.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:59:23.635+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:59:23.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:59:23.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T13:59:53.898+0000] {processor.py:157} INFO - Started process (PID=55172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:59:53.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T13:59:53.904+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:59:53.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:59:53.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T13:59:53.938+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:59:53.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T13:59:53.949+0000] {logging_mixin.py:151} INFO - [2024-08-17T13:59:53.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T13:59:53.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T14:00:24.263+0000] {processor.py:157} INFO - Started process (PID=55182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:00:24.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:00:24.267+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:00:24.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:00:24.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:00:24.324+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:00:24.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:00:24.339+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:00:24.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:00:24.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T14:00:54.592+0000] {processor.py:157} INFO - Started process (PID=55192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:00:54.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:00:54.596+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:00:54.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:00:54.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:00:54.622+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:00:54.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:00:54.635+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:00:54.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:00:54.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T14:01:24.909+0000] {processor.py:157} INFO - Started process (PID=55202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:01:24.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:01:24.914+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:01:24.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:01:24.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:01:24.944+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:01:24.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:01:24.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:01:24.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:01:24.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T14:01:55.263+0000] {processor.py:157} INFO - Started process (PID=55212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:01:55.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:01:55.266+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:01:55.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:01:55.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:01:55.299+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:01:55.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:01:55.311+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:01:55.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:01:55.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-08-17T14:02:25.834+0000] {processor.py:157} INFO - Started process (PID=55222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:02:25.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:02:25.840+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:02:25.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:02:25.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:02:25.874+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:02:25.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:02:25.886+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:02:25.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:02:25.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T14:02:56.223+0000] {processor.py:157} INFO - Started process (PID=55232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:02:56.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:02:56.227+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:02:56.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:02:56.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:02:56.265+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:02:56.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:02:56.277+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:02:56.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:02:56.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T14:03:26.578+0000] {processor.py:157} INFO - Started process (PID=55242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:03:26.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:03:26.582+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:03:26.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:03:26.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:03:26.618+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:03:26.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:03:26.639+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:03:26.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:03:26.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T14:03:56.967+0000] {processor.py:157} INFO - Started process (PID=55252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:03:56.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:03:56.969+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:03:56.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:03:56.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:03:56.997+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:03:56.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:03:57.008+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:03:57.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:03:57.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T14:04:27.330+0000] {processor.py:157} INFO - Started process (PID=55262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:04:27.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:04:27.351+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:04:27.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:04:27.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:04:27.388+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:04:27.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:04:27.400+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:04:27.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:04:27.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T14:04:57.735+0000] {processor.py:157} INFO - Started process (PID=55272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:04:57.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:04:57.737+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:04:57.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:04:57.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:04:57.762+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:04:57.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:04:57.773+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:04:57.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:04:57.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-08-17T14:05:28.095+0000] {processor.py:157} INFO - Started process (PID=55282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:05:28.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:05:28.101+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:05:28.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:05:28.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:05:28.133+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:05:28.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:05:28.144+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:05:28.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:05:28.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T14:05:58.460+0000] {processor.py:157} INFO - Started process (PID=55292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:05:58.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:05:58.467+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:05:58.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:05:58.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:05:58.501+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:05:58.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:05:58.515+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:05:58.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:05:58.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T14:06:28.780+0000] {processor.py:157} INFO - Started process (PID=55302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:06:28.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:06:28.786+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:06:28.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:06:28.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:06:28.824+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:06:28.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:06:28.836+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:06:28.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:06:28.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T14:06:59.182+0000] {processor.py:157} INFO - Started process (PID=55312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:06:59.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:06:59.185+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:06:59.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:06:59.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:06:59.218+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:06:59.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:06:59.230+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:06:59.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:06:59.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T14:07:29.557+0000] {processor.py:157} INFO - Started process (PID=55322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:07:29.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:07:29.563+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:07:29.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:07:29.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:07:29.600+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:07:29.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:07:29.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:07:29.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:07:29.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T14:07:59.886+0000] {processor.py:157} INFO - Started process (PID=55332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:07:59.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:07:59.889+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:07:59.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:07:59.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:07:59.915+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:07:59.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:07:59.926+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:07:59.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:08:00.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.269 seconds
[2024-08-17T14:08:30.252+0000] {processor.py:157} INFO - Started process (PID=55342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:08:30.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:08:30.257+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:08:30.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:08:30.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:08:30.294+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:08:30.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:08:30.306+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:08:30.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:08:30.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T14:09:00.583+0000] {processor.py:157} INFO - Started process (PID=55352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:09:00.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:09:00.585+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:09:00.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:09:00.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:09:00.610+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:09:00.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:09:00.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:09:00.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:09:00.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T14:09:30.932+0000] {processor.py:157} INFO - Started process (PID=55362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:09:30.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:09:30.948+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:09:30.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:09:30.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:09:31.008+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:09:31.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:09:31.022+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:09:31.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:09:31.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T14:10:01.312+0000] {processor.py:157} INFO - Started process (PID=55372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:10:01.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:10:01.318+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:10:01.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:10:01.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:10:01.360+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:10:01.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:10:01.374+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:10:01.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:10:01.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T14:10:31.628+0000] {processor.py:157} INFO - Started process (PID=55382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:10:31.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:10:31.631+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:10:31.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:10:31.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:10:31.659+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:10:31.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:10:31.670+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:10:31.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:10:31.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T14:11:02.021+0000] {processor.py:157} INFO - Started process (PID=55392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:11:02.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:11:02.029+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:11:02.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:11:02.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:11:02.098+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:11:02.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:11:02.113+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:11:02.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:11:02.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.273 seconds
[2024-08-17T14:11:32.318+0000] {processor.py:157} INFO - Started process (PID=55402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:11:32.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:11:32.322+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:11:32.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:11:32.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:11:32.349+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:11:32.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:11:32.359+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:11:32.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:11:32.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T14:12:02.731+0000] {processor.py:157} INFO - Started process (PID=55411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:12:02.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:12:02.738+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:12:02.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:12:02.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:12:02.788+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:12:02.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:12:02.803+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:12:02.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:12:02.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T14:12:33.017+0000] {processor.py:157} INFO - Started process (PID=55422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:12:33.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:12:33.023+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:12:33.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:12:33.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:12:33.051+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:12:33.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:12:33.061+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:12:33.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:12:33.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T14:13:03.457+0000] {processor.py:157} INFO - Started process (PID=55432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:13:03.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:13:03.480+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:13:03.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:13:03.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:13:03.525+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:13:03.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:13:03.539+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:13:03.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:13:03.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T14:13:33.753+0000] {processor.py:157} INFO - Started process (PID=55442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:13:33.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:13:33.756+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:13:33.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:13:33.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:13:33.782+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:13:33.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:13:33.791+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:13:33.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:13:33.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T14:14:04.099+0000] {processor.py:157} INFO - Started process (PID=55452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:14:04.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:14:04.104+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:14:04.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:14:04.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:14:04.150+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:14:04.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:14:04.316+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:14:04.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:14:04.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-08-17T14:14:34.425+0000] {processor.py:157} INFO - Started process (PID=55462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:14:34.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:14:34.431+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:14:34.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:14:34.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:14:34.472+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:14:34.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:14:34.496+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:14:34.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:14:34.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T14:15:04.749+0000] {processor.py:157} INFO - Started process (PID=55472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:15:04.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:15:04.753+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:15:04.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:15:04.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:15:04.786+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:15:04.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:15:04.796+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:15:04.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:15:04.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T14:15:35.103+0000] {processor.py:157} INFO - Started process (PID=55482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:15:35.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:15:35.110+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:15:35.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:15:35.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:15:35.156+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:15:35.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:15:35.169+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:15:35.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:15:35.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T14:16:05.431+0000] {processor.py:157} INFO - Started process (PID=55492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:16:05.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:16:05.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:16:05.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:16:05.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:16:05.491+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:16:05.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:16:05.504+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:16:05.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:16:05.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-17T14:16:35.721+0000] {processor.py:157} INFO - Started process (PID=55502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:16:35.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:16:35.728+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:16:35.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:16:35.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:16:35.752+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:16:35.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:16:35.763+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:16:35.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:16:35.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T14:17:06.076+0000] {processor.py:157} INFO - Started process (PID=55512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:17:06.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:17:06.082+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:17:06.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:17:06.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:17:06.138+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:17:06.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:17:06.309+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:17:06.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:17:06.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-08-17T14:17:36.386+0000] {processor.py:157} INFO - Started process (PID=55522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:17:36.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:17:36.390+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:17:36.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:17:36.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:17:36.421+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:17:36.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:17:36.431+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:17:36.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:17:36.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T14:18:06.680+0000] {processor.py:157} INFO - Started process (PID=55532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:18:06.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:18:06.693+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:18:06.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:18:06.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:18:06.737+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:18:06.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:18:06.752+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:18:06.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:18:06.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T14:18:36.948+0000] {processor.py:157} INFO - Started process (PID=55542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:18:36.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:18:36.952+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:18:36.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:18:36.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:18:37.008+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:18:37.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:18:37.018+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:18:37.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:18:37.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T14:19:07.408+0000] {processor.py:157} INFO - Started process (PID=55552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:19:07.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:19:07.415+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:19:07.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:19:07.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:19:07.459+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:19:07.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:19:07.472+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:19:07.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:19:07.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T14:19:37.889+0000] {processor.py:157} INFO - Started process (PID=55562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:19:37.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:19:37.897+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:19:37.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:19:37.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:19:37.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:19:37.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:19:37.972+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:19:37.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:19:37.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T14:20:08.189+0000] {processor.py:157} INFO - Started process (PID=55572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:20:08.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:20:08.201+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:20:08.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:20:08.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:20:08.269+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:20:08.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:20:08.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:20:08.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:20:08.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.280 seconds
[2024-08-17T14:20:38.546+0000] {processor.py:157} INFO - Started process (PID=55582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:20:38.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:20:38.553+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:20:38.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:20:38.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:20:38.615+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:20:38.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:20:38.628+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:20:38.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:20:38.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-17T14:21:08.948+0000] {processor.py:157} INFO - Started process (PID=55592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:21:08.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:21:08.969+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:21:08.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:21:09.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:21:09.047+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:21:09.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:21:09.062+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:21:09.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:21:09.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-17T14:21:39.293+0000] {processor.py:157} INFO - Started process (PID=55602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:21:39.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:21:39.303+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:21:39.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:21:39.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:21:39.348+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:21:39.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:21:39.371+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:21:39.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:21:39.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T14:22:09.754+0000] {processor.py:157} INFO - Started process (PID=55612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:22:09.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:22:09.758+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:22:09.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:22:09.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:22:09.785+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:22:09.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:22:09.797+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:22:09.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:22:09.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T14:22:40.091+0000] {processor.py:157} INFO - Started process (PID=55622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:22:40.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:22:40.099+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:22:40.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:22:40.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:22:40.161+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:22:40.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:22:40.176+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:22:40.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:22:40.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.252 seconds
[2024-08-17T14:23:10.657+0000] {processor.py:157} INFO - Started process (PID=55632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:23:10.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:23:10.662+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:23:10.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:23:10.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:23:10.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:23:10.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:23:10.827+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:23:10.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:23:10.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-08-17T14:23:40.971+0000] {processor.py:157} INFO - Started process (PID=55642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:23:40.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:23:40.979+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:23:40.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:23:40.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:23:41.003+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:23:41.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:23:41.013+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:23:41.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:23:41.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T14:24:11.334+0000] {processor.py:157} INFO - Started process (PID=55652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:24:11.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:24:11.356+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:24:11.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:24:11.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:24:11.399+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:24:11.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:24:11.422+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:24:11.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:24:11.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T14:24:41.781+0000] {processor.py:157} INFO - Started process (PID=55662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:24:41.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:24:41.785+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:24:41.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:24:41.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:24:41.813+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:24:41.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:24:41.823+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:24:41.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:24:41.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T14:25:12.172+0000] {processor.py:157} INFO - Started process (PID=55672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:25:12.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:25:12.184+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:25:12.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:25:12.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:25:12.251+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:25:12.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:25:12.268+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:25:12.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:25:12.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-17T14:25:42.480+0000] {processor.py:157} INFO - Started process (PID=55682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:25:42.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:25:42.485+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:25:42.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:25:42.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:25:42.524+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:25:42.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:25:42.539+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:25:42.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:25:42.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.241 seconds
[2024-08-17T14:26:12.841+0000] {processor.py:157} INFO - Started process (PID=55692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:26:12.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:26:12.845+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:26:12.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:26:12.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:26:12.877+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:26:12.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:26:12.979+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:26:12.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:26:12.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-17T14:26:43.302+0000] {processor.py:157} INFO - Started process (PID=55702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:26:43.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:26:43.310+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:26:43.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:26:43.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:26:43.371+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:26:43.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:26:43.387+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:26:43.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:26:43.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T14:27:13.597+0000] {processor.py:157} INFO - Started process (PID=55712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:27:13.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:27:13.601+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:27:13.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:27:13.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:27:13.641+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:27:13.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:27:13.658+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:27:13.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:27:13.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T14:27:43.965+0000] {processor.py:157} INFO - Started process (PID=55722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:27:43.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:27:43.973+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:27:43.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:27:43.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:27:44.018+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:27:44.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:27:44.040+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:27:44.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:27:44.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-17T14:28:14.331+0000] {processor.py:157} INFO - Started process (PID=55732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:28:14.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:28:14.353+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:28:14.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:28:14.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:28:14.394+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:28:14.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:28:14.408+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:28:14.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:28:14.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T14:28:44.618+0000] {processor.py:157} INFO - Started process (PID=55742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:28:44.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:28:44.621+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:28:44.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:28:44.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:28:44.649+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:28:44.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:28:44.660+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:28:44.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:28:44.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.216 seconds
[2024-08-17T14:29:15.194+0000] {processor.py:157} INFO - Started process (PID=55752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:29:15.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:29:15.201+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:29:15.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:29:15.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:29:15.262+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:29:15.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:29:15.354+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:29:15.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:29:15.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-17T14:29:45.663+0000] {processor.py:157} INFO - Started process (PID=55762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:29:45.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:29:45.665+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:29:45.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:29:45.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:29:45.692+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:29:45.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:29:45.702+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:29:45.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:29:45.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T14:30:16.065+0000] {processor.py:157} INFO - Started process (PID=55771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:30:16.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:30:16.089+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:30:16.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:30:16.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:30:16.141+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:30:16.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:30:16.167+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:30:16.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:30:16.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-17T14:30:46.401+0000] {processor.py:157} INFO - Started process (PID=55782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:30:46.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:30:46.405+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:30:46.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:30:46.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:30:46.433+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:30:46.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:30:46.445+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:30:46.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:30:46.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T14:31:16.793+0000] {processor.py:157} INFO - Started process (PID=55791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:31:16.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:31:16.798+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:31:16.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:31:16.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:31:16.848+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:31:16.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:31:16.862+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:31:16.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:31:16.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-17T14:31:47.081+0000] {processor.py:157} INFO - Started process (PID=55802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:31:47.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:31:47.085+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:31:47.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:31:47.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:31:47.114+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:31:47.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:31:47.126+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:31:47.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:31:47.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-08-17T14:32:17.405+0000] {processor.py:157} INFO - Started process (PID=55811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:32:17.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:32:17.428+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:32:17.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:32:17.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:32:17.476+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:32:17.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:32:17.615+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:32:17.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:32:17.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-08-17T14:32:47.867+0000] {processor.py:157} INFO - Started process (PID=55822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:32:47.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:32:47.871+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:32:47.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:32:47.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:32:47.919+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:32:47.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:32:47.933+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:32:47.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:32:47.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T14:33:18.397+0000] {processor.py:157} INFO - Started process (PID=55832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:33:18.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:33:18.404+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:33:18.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:33:18.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:33:18.456+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:33:18.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:33:18.469+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:33:18.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:33:18.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-17T14:33:48.727+0000] {processor.py:157} INFO - Started process (PID=55842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:33:48.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:33:48.729+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:33:48.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:33:48.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:33:48.756+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:33:48.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:33:48.766+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:33:48.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:33:48.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T14:34:19.031+0000] {processor.py:157} INFO - Started process (PID=55852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:34:19.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:34:19.035+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:34:19.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:34:19.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:34:19.064+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:34:19.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:34:19.074+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:34:19.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:34:19.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T14:34:49.431+0000] {processor.py:157} INFO - Started process (PID=55862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:34:49.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:34:49.439+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:34:49.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:34:49.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:34:49.476+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:34:49.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:34:49.489+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:34:49.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:34:49.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-08-17T14:35:19.729+0000] {processor.py:157} INFO - Started process (PID=55872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:35:19.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:35:19.731+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:35:19.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:35:19.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:35:19.755+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:35:19.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:35:19.836+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:35:19.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:35:19.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-17T14:35:50.171+0000] {processor.py:157} INFO - Started process (PID=55882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:35:50.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:35:50.176+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:35:50.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:35:50.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:35:50.206+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:35:50.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:35:50.219+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:35:50.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:35:50.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T14:36:20.500+0000] {processor.py:157} INFO - Started process (PID=55892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:36:20.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:36:20.510+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:36:20.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:36:20.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:36:20.542+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:36:20.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:36:20.556+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:36:20.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:36:20.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T14:36:50.830+0000] {processor.py:157} INFO - Started process (PID=55902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:36:50.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:36:50.834+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:36:50.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:36:50.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:36:50.861+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:36:50.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:36:50.872+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:36:50.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:36:50.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T14:37:21.210+0000] {processor.py:157} INFO - Started process (PID=55912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:37:21.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:37:21.213+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:37:21.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:37:21.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:37:21.242+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:37:21.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:37:21.253+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:37:21.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:37:21.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T14:37:51.602+0000] {processor.py:157} INFO - Started process (PID=55922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:37:51.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:37:51.607+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:37:51.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:37:51.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:37:51.637+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:37:51.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:37:51.813+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:37:51.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:37:51.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-08-17T14:38:21.921+0000] {processor.py:157} INFO - Started process (PID=55931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:38:21.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:38:21.929+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:38:21.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:38:21.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:38:21.963+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:38:21.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:38:22.046+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:38:22.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:38:22.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-17T14:38:52.383+0000] {processor.py:157} INFO - Started process (PID=55942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:38:52.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:38:52.386+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:38:52.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:38:52.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:38:52.417+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:38:52.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:38:52.428+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:38:52.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:38:52.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T14:39:22.801+0000] {processor.py:157} INFO - Started process (PID=55952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:39:22.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:39:22.804+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:39:22.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:39:22.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:39:22.833+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:39:22.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:39:22.843+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:39:22.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:39:22.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T14:39:53.120+0000] {processor.py:157} INFO - Started process (PID=55962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:39:53.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:39:53.123+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:39:53.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:39:53.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:39:53.151+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:39:53.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:39:53.165+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:39:53.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:39:53.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T14:40:23.471+0000] {processor.py:157} INFO - Started process (PID=55972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:40:23.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:40:23.475+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:40:23.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:40:23.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:40:23.511+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:40:23.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:40:23.525+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:40:23.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:40:23.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T14:40:53.828+0000] {processor.py:157} INFO - Started process (PID=55982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:40:53.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:40:53.831+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:40:53.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:40:53.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:40:53.863+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:40:53.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:40:54.044+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:40:54.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:40:54.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-08-17T14:41:24.110+0000] {processor.py:157} INFO - Started process (PID=55992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:41:24.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:41:24.113+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:41:24.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:41:24.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:41:24.143+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:41:24.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:41:24.227+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:41:24.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:41:24.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-17T14:41:54.391+0000] {processor.py:157} INFO - Started process (PID=56002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:41:54.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:41:54.399+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:41:54.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:41:54.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:41:54.436+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:41:54.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:41:54.448+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:41:54.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:41:54.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T14:42:24.785+0000] {processor.py:157} INFO - Started process (PID=56012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:42:24.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:42:24.788+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:42:24.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:42:24.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:42:24.821+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:42:24.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:42:24.832+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:42:24.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:42:24.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T14:42:55.126+0000] {processor.py:157} INFO - Started process (PID=56022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:42:55.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:42:55.129+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:42:55.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:42:55.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:42:55.156+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:42:55.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:42:55.168+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:42:55.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:42:55.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T14:43:25.521+0000] {processor.py:157} INFO - Started process (PID=56032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:43:25.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:43:25.528+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:43:25.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:43:25.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:43:25.565+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:43:25.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:43:25.576+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:43:25.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:43:25.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-08-17T14:43:55.813+0000] {processor.py:157} INFO - Started process (PID=56042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:43:55.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:43:55.816+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:43:55.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:43:55.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:43:55.847+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:43:55.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:43:55.927+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:43:55.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:43:55.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-17T14:44:26.140+0000] {processor.py:157} INFO - Started process (PID=56052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:44:26.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:44:26.145+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:44:26.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:44:26.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:44:26.175+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:44:26.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:44:26.261+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:44:26.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:44:26.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-17T14:44:56.444+0000] {processor.py:157} INFO - Started process (PID=56062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:44:56.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:44:56.447+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:44:56.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:44:56.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:44:56.475+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:44:56.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:44:56.486+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:44:56.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:44:56.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T14:45:26.786+0000] {processor.py:157} INFO - Started process (PID=56072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:45:26.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:45:26.796+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:45:26.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:45:26.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:45:26.846+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:45:26.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:45:26.862+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:45:26.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:45:26.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T14:45:57.119+0000] {processor.py:157} INFO - Started process (PID=56082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:45:57.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:45:57.126+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:45:57.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:45:57.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:45:57.167+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:45:57.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:45:57.180+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:45:57.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:45:57.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T14:46:27.412+0000] {processor.py:157} INFO - Started process (PID=56092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:46:27.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:46:27.416+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:46:27.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:46:27.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:46:27.441+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:46:27.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:46:27.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:46:27.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:46:27.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-08-17T14:46:57.700+0000] {processor.py:157} INFO - Started process (PID=56102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:46:57.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:46:57.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:46:57.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:46:57.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:46:57.735+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:46:57.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:46:57.817+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:46:57.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:46:57.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-17T14:47:28.178+0000] {processor.py:157} INFO - Started process (PID=56112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:47:28.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:47:28.184+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:47:28.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:47:28.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:47:28.218+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:47:28.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:47:28.329+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:47:28.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:47:28.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-17T14:47:58.470+0000] {processor.py:157} INFO - Started process (PID=56122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:47:58.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:47:58.478+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:47:58.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:47:58.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:47:58.503+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:47:58.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:47:58.511+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:47:58.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:47:58.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T14:48:28.866+0000] {processor.py:157} INFO - Started process (PID=56132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:48:28.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:48:28.873+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:48:28.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:48:28.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:48:28.911+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:48:28.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:48:28.923+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:48:28.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:48:28.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T14:48:59.225+0000] {processor.py:157} INFO - Started process (PID=56142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:48:59.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:48:59.228+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:48:59.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:48:59.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:48:59.261+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:48:59.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:48:59.272+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:48:59.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:48:59.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T14:49:29.578+0000] {processor.py:157} INFO - Started process (PID=56152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:49:29.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:49:29.581+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:49:29.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:49:29.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:49:29.609+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:49:29.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:49:29.621+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:49:29.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:49:29.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-08-17T14:50:00.155+0000] {processor.py:157} INFO - Started process (PID=56162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:50:00.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:50:00.160+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:50:00.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:50:00.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:50:00.201+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:50:00.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:50:00.312+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:50:00.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:50:00.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-08-17T14:50:30.471+0000] {processor.py:157} INFO - Started process (PID=56172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:50:30.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:50:30.475+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:50:30.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:50:30.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:50:30.510+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:50:30.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:50:30.652+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:50:30.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:50:30.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-17T14:51:00.863+0000] {processor.py:157} INFO - Started process (PID=56182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:51:00.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:51:00.868+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:51:00.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:51:00.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:51:00.932+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:51:00.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:51:00.947+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:51:00.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:51:00.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T14:51:31.264+0000] {processor.py:157} INFO - Started process (PID=56191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:51:31.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:51:31.270+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:51:31.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:51:31.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:51:31.316+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:51:31.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:51:31.330+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:51:31.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:51:31.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-17T14:52:01.597+0000] {processor.py:157} INFO - Started process (PID=56202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:52:01.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:52:01.602+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:52:01.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:52:01.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:52:01.641+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:52:01.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:52:01.654+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:52:01.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:52:01.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T14:52:31.878+0000] {processor.py:157} INFO - Started process (PID=56212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:52:31.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:52:31.880+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:52:31.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:52:31.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:52:31.909+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:52:31.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:52:31.920+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:52:31.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:52:32.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-08-17T14:53:02.429+0000] {processor.py:157} INFO - Started process (PID=56222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:53:02.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:53:02.433+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:53:02.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:53:02.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:53:02.473+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:53:02.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:53:02.594+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:53:02.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:53:02.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-17T14:53:32.903+0000] {processor.py:157} INFO - Started process (PID=56232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:53:32.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:53:32.905+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:53:32.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:53:32.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:53:32.933+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:53:32.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:53:33.021+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:53:33.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:53:33.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-17T14:54:03.403+0000] {processor.py:157} INFO - Started process (PID=56242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:54:03.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:54:03.410+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:54:03.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:54:03.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:54:03.447+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:54:03.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:54:03.462+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:54:03.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:54:03.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T14:54:33.693+0000] {processor.py:157} INFO - Started process (PID=56252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:54:33.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:54:33.696+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:54:33.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:54:33.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:54:33.726+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:54:33.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:54:33.738+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:54:33.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:54:33.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T14:55:04.053+0000] {processor.py:157} INFO - Started process (PID=56262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:55:04.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:55:04.057+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:55:04.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:55:04.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:55:04.082+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:55:04.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:55:04.092+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:55:04.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:55:04.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T14:55:34.386+0000] {processor.py:157} INFO - Started process (PID=56272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:55:34.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:55:34.389+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:55:34.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:55:34.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:55:34.416+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:55:34.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:55:34.426+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:55:34.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:55:34.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-08-17T14:56:04.699+0000] {processor.py:157} INFO - Started process (PID=56282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:56:04.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:56:04.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:56:04.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:56:04.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:56:04.755+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:56:04.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:56:04.846+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:56:04.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:56:04.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-17T14:56:35.074+0000] {processor.py:157} INFO - Started process (PID=56292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:56:35.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:56:35.080+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:56:35.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:56:35.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:56:35.110+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:56:35.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:56:35.270+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:56:35.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:56:35.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-08-17T14:57:05.579+0000] {processor.py:157} INFO - Started process (PID=56302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:57:05.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:57:05.585+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:57:05.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:57:05.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:57:05.629+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:57:05.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:57:05.641+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:57:05.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:57:05.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T14:57:35.861+0000] {processor.py:157} INFO - Started process (PID=56312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:57:35.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:57:35.864+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:57:35.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:57:35.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:57:35.889+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:57:35.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:57:35.899+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:57:35.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:57:35.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-17T14:58:06.221+0000] {processor.py:157} INFO - Started process (PID=56322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:58:06.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:58:06.227+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:58:06.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:58:06.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:58:06.266+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:58:06.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:58:06.279+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:58:06.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:58:06.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T14:58:36.558+0000] {processor.py:157} INFO - Started process (PID=56332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:58:36.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:58:36.562+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:58:36.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:58:36.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:58:36.587+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:58:36.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:58:36.598+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:58:36.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:58:36.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-17T14:59:07.051+0000] {processor.py:157} INFO - Started process (PID=56342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:59:07.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:59:07.056+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:59:07.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:59:07.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:59:07.084+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:59:07.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:59:07.170+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:59:07.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:59:07.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-17T14:59:37.436+0000] {processor.py:157} INFO - Started process (PID=56352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:59:37.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T14:59:37.460+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:59:37.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:59:37.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T14:59:37.739+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:59:37.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T14:59:37.748+0000] {logging_mixin.py:151} INFO - [2024-08-17T14:59:37.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T14:59:37.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.329 seconds
[2024-08-17T15:00:08.017+0000] {processor.py:157} INFO - Started process (PID=56362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:00:08.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:00:08.023+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:00:08.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:00:08.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:00:08.074+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:00:08.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:00:08.088+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:00:08.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:00:08.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T15:00:38.307+0000] {processor.py:157} INFO - Started process (PID=56372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:00:38.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:00:38.310+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:00:38.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:00:38.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:00:38.340+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:00:38.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:00:38.352+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:00:38.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:00:38.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T15:01:08.675+0000] {processor.py:157} INFO - Started process (PID=56382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:01:08.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:01:08.680+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:01:08.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:01:08.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:01:08.718+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:01:08.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:01:08.733+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:01:08.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:01:08.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T15:01:38.941+0000] {processor.py:157} INFO - Started process (PID=56392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:01:38.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:01:38.943+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:01:38.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:01:38.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:01:38.972+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:01:38.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:01:39.137+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:01:39.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:01:39.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-08-17T15:02:09.479+0000] {processor.py:157} INFO - Started process (PID=56402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:02:09.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:02:09.483+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:02:09.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:02:09.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:02:09.510+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:02:09.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:02:09.593+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:02:09.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:02:09.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-17T15:02:39.796+0000] {processor.py:157} INFO - Started process (PID=56411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:02:39.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:02:39.799+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:02:39.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:02:39.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:02:39.952+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:02:39.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:02:39.959+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:02:39.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:02:39.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-08-17T15:03:10.286+0000] {processor.py:157} INFO - Started process (PID=56422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:03:10.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:03:10.294+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:03:10.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:03:10.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:03:10.362+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:03:10.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:03:10.376+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:03:10.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:03:10.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-17T15:03:40.710+0000] {processor.py:157} INFO - Started process (PID=56432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:03:40.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:03:40.713+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:03:40.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:03:40.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:03:40.742+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:03:40.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:03:40.756+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:03:40.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:03:40.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T15:04:11.130+0000] {processor.py:157} INFO - Started process (PID=56442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:04:11.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:04:11.136+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:04:11.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:04:11.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:04:11.171+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:04:11.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:04:11.185+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:04:11.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:04:11.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-08-17T15:04:41.622+0000] {processor.py:157} INFO - Started process (PID=56452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:04:41.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:04:41.625+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:04:41.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:04:41.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:04:41.658+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:04:41.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:04:41.743+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:04:41.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:04:41.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-17T15:05:11.968+0000] {processor.py:157} INFO - Started process (PID=56462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:05:11.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:05:11.972+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:05:11.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:05:11.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:05:12.011+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:05:12.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:05:12.194+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:05:12.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:05:12.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.240 seconds
[2024-08-17T15:05:42.528+0000] {processor.py:157} INFO - Started process (PID=56472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:05:42.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:05:42.533+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:05:42.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:05:42.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:05:42.640+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:05:42.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:05:42.647+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:05:42.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:05:42.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-17T15:06:12.884+0000] {processor.py:157} INFO - Started process (PID=56482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:06:12.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:06:12.890+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:06:12.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:06:12.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:06:12.923+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:06:12.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:06:12.934+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:06:12.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:06:12.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T15:06:43.204+0000] {processor.py:157} INFO - Started process (PID=56492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:06:43.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:06:43.208+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:06:43.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:06:43.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:06:43.232+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:06:43.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:06:43.242+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:06:43.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:06:43.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T15:07:13.576+0000] {processor.py:157} INFO - Started process (PID=56502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:07:13.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:07:13.578+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:07:13.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:07:13.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:07:13.610+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:07:13.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:07:13.623+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:07:13.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:07:13.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-08-17T15:07:43.877+0000] {processor.py:157} INFO - Started process (PID=56512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:07:43.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:07:43.882+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:07:43.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:07:43.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:07:43.915+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:07:43.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:07:43.997+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:07:43.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:07:44.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-17T15:08:14.293+0000] {processor.py:157} INFO - Started process (PID=56522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:08:14.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:08:14.298+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:08:14.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:08:14.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:08:14.334+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:08:14.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:08:14.414+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:08:14.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:08:14.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-17T15:08:44.759+0000] {processor.py:157} INFO - Started process (PID=56532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:08:44.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:08:44.765+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:08:44.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:08:44.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:08:44.965+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:08:44.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:08:44.974+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:08:44.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:08:44.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-08-17T15:09:15.127+0000] {processor.py:157} INFO - Started process (PID=56542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:09:15.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:09:15.135+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:09:15.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:09:15.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:09:15.202+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:09:15.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:09:15.230+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:09:15.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:09:15.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-17T15:09:45.550+0000] {processor.py:157} INFO - Started process (PID=56552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:09:45.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:09:45.560+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:09:45.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:09:45.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:09:45.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:09:45.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:09:45.632+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:09:45.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:09:45.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-17T15:10:15.993+0000] {processor.py:157} INFO - Started process (PID=56562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:10:15.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:10:16.000+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:10:15.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:10:16.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:10:16.059+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:10:16.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:10:16.075+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:10:16.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:10:16.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.256 seconds
[2024-08-17T15:10:46.351+0000] {processor.py:157} INFO - Started process (PID=56572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:10:46.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:10:46.358+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:10:46.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:10:46.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:10:46.413+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:10:46.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:10:46.583+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:10:46.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:10:46.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.254 seconds
[2024-08-17T15:11:16.770+0000] {processor.py:157} INFO - Started process (PID=56582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:11:16.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:11:16.775+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:11:16.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:11:16.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:11:16.835+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:11:16.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:11:17.006+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:11:17.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:11:17.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-08-17T15:11:47.281+0000] {processor.py:157} INFO - Started process (PID=56592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:11:47.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:11:47.285+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:11:47.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:11:47.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:11:47.436+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:11:47.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:11:47.448+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:11:47.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:11:47.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-17T15:12:17.614+0000] {processor.py:157} INFO - Started process (PID=56602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:12:17.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:12:17.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:12:17.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:12:17.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:12:17.662+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:12:17.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:12:17.675+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:12:17.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:12:17.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T15:12:47.956+0000] {processor.py:157} INFO - Started process (PID=56612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:12:47.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:12:47.959+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:12:47.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:12:47.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:12:47.987+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:12:47.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:12:47.998+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:12:47.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:12:48.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T15:13:18.276+0000] {processor.py:157} INFO - Started process (PID=56622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:13:18.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:13:18.279+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:13:18.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:13:18.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:13:18.346+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:13:18.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:13:18.373+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:13:18.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:13:18.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.267 seconds
[2024-08-17T15:13:48.783+0000] {processor.py:157} INFO - Started process (PID=56632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:13:48.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:13:48.788+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:13:48.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:13:48.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:13:48.866+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:13:48.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:13:49.035+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:13:49.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:13:49.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.269 seconds
[2024-08-17T15:14:19.369+0000] {processor.py:157} INFO - Started process (PID=56641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:14:19.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:14:19.376+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:14:19.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:14:19.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:14:19.434+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:14:19.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:14:19.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:14:19.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:14:19.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.262 seconds
[2024-08-17T15:14:49.907+0000] {processor.py:157} INFO - Started process (PID=56652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:14:49.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:14:49.913+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:14:49.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:14:49.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:14:50.045+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:14:50.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:14:50.052+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:14:50.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:14:50.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-17T15:15:20.492+0000] {processor.py:157} INFO - Started process (PID=56662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:15:20.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:15:20.498+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:15:20.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:15:20.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:15:20.538+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:15:20.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:15:20.551+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:15:20.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:15:20.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T15:15:50.878+0000] {processor.py:157} INFO - Started process (PID=56672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:15:50.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:15:50.882+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:15:50.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:15:50.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:15:50.908+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:15:50.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:15:50.919+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:15:50.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:15:50.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T15:16:21.181+0000] {processor.py:157} INFO - Started process (PID=56682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:16:21.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:16:21.187+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:16:21.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:16:21.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:16:21.260+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:16:21.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:16:21.273+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:16:21.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:16:21.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.241 seconds
[2024-08-17T15:16:51.508+0000] {processor.py:157} INFO - Started process (PID=56692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:16:51.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:16:51.513+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:16:51.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:16:51.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:16:51.544+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:16:51.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:16:51.626+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:16:51.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:16:51.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-17T15:17:21.950+0000] {processor.py:157} INFO - Started process (PID=56702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:17:21.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:17:21.956+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:17:21.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:17:21.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:17:22.079+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:17:22.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:17:22.090+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:17:22.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:17:22.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-17T15:17:52.404+0000] {processor.py:157} INFO - Started process (PID=56712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:17:52.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:17:52.407+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:17:52.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:17:52.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:17:52.523+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:17:52.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:17:52.530+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:17:52.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:17:52.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-17T15:18:22.729+0000] {processor.py:157} INFO - Started process (PID=56722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:18:22.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:18:22.734+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:18:22.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:18:22.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:18:22.764+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:18:22.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:18:22.775+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:18:22.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:18:22.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T15:18:53.075+0000] {processor.py:157} INFO - Started process (PID=56732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:18:53.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:18:53.081+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:18:53.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:18:53.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:18:53.120+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:18:53.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:18:53.134+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:18:53.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:18:53.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T15:19:23.437+0000] {processor.py:157} INFO - Started process (PID=56742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:19:23.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:19:23.442+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:19:23.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:19:23.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:19:23.469+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:19:23.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:19:23.601+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:19:23.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:19:23.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-17T15:19:53.932+0000] {processor.py:157} INFO - Started process (PID=56752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:19:53.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:19:53.939+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:19:53.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:19:53.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:19:53.971+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:19:53.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:19:54.049+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:19:54.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:19:54.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-17T15:20:24.273+0000] {processor.py:157} INFO - Started process (PID=56762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:20:24.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:20:24.278+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:20:24.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:20:24.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:20:24.481+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:20:24.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:20:24.491+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:20:24.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:20:24.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-08-17T15:20:54.829+0000] {processor.py:157} INFO - Started process (PID=56772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:20:54.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:20:54.833+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:20:54.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:20:54.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:20:54.975+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:20:54.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:20:54.985+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:20:54.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:20:54.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-17T15:21:25.342+0000] {processor.py:157} INFO - Started process (PID=56782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:21:25.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:21:25.356+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:21:25.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:21:25.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:21:25.399+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:21:25.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:21:25.421+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:21:25.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:21:25.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T15:21:55.690+0000] {processor.py:157} INFO - Started process (PID=56792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:21:55.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:21:55.695+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:21:55.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:21:55.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:21:55.735+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:21:55.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:21:55.747+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:21:55.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:21:55.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T15:22:26.049+0000] {processor.py:157} INFO - Started process (PID=56802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:22:26.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:22:26.052+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:22:26.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:22:26.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:22:26.080+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:22:26.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:22:26.191+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:22:26.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:22:26.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-17T15:22:56.572+0000] {processor.py:157} INFO - Started process (PID=56812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:22:56.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:22:56.575+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:22:56.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:22:56.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:22:56.607+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:22:56.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:22:56.709+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:22:56.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:22:56.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-17T15:23:26.923+0000] {processor.py:157} INFO - Started process (PID=56822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:23:26.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:23:26.944+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:23:26.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:23:26.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:23:27.133+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:23:27.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:23:27.143+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:23:27.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:23:27.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-08-17T15:23:57.200+0000] {processor.py:157} INFO - Started process (PID=56832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:23:57.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:23:57.204+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:23:57.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:23:57.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:23:57.302+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:23:57.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:23:57.310+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:23:57.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:23:57.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-17T15:24:27.702+0000] {processor.py:157} INFO - Started process (PID=56842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:24:27.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:24:27.707+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:24:27.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:24:27.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:24:27.746+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:24:27.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:24:27.759+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:24:27.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:24:27.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T15:24:57.991+0000] {processor.py:157} INFO - Started process (PID=56852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:24:57.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:24:57.993+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:24:57.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:24:58.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:24:58.020+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:24:58.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:24:58.029+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:24:58.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:24:58.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-17T15:25:28.480+0000] {processor.py:157} INFO - Started process (PID=56862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:25:28.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:25:28.484+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:25:28.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:25:28.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:25:28.524+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:25:28.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:25:28.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:25:28.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:25:28.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-17T15:25:59.030+0000] {processor.py:157} INFO - Started process (PID=56872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:25:59.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:25:59.049+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:25:59.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:25:59.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:25:59.095+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:25:59.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:25:59.248+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:25:59.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:25:59.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-08-17T15:26:29.325+0000] {processor.py:157} INFO - Started process (PID=56882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:26:29.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:26:29.330+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:26:29.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:26:29.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:26:29.499+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:26:29.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:26:29.508+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:26:29.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:26:29.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-17T15:26:59.765+0000] {processor.py:157} INFO - Started process (PID=56892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:26:59.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:26:59.772+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:26:59.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:26:59.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:26:59.811+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:26:59.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:26:59.827+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:26:59.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:26:59.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T15:27:30.164+0000] {processor.py:157} INFO - Started process (PID=56902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:27:30.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:27:30.173+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:27:30.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:27:30.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:27:30.237+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:27:30.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:27:30.257+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:27:30.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:27:30.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-17T15:28:00.407+0000] {processor.py:157} INFO - Started process (PID=56912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:28:00.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:28:00.412+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:28:00.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:28:00.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:28:00.440+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:28:00.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:28:00.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:28:00.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:28:00.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-08-17T15:28:30.780+0000] {processor.py:157} INFO - Started process (PID=56922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:28:30.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:28:30.804+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:28:30.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:28:30.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:28:30.854+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:28:30.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:28:31.018+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:28:31.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:28:31.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.262 seconds
[2024-08-17T15:29:01.257+0000] {processor.py:157} INFO - Started process (PID=56932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:29:01.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:29:01.266+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:29:01.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:29:01.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:29:01.322+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:29:01.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:29:01.479+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:29:01.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:29:01.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-08-17T15:29:31.553+0000] {processor.py:157} INFO - Started process (PID=56942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:29:31.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:29:31.560+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:29:31.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:29:31.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:29:31.681+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:29:31.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:29:31.689+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:29:31.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:29:31.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-17T15:30:01.916+0000] {processor.py:157} INFO - Started process (PID=56951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:30:01.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:30:01.927+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:30:01.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:30:01.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:30:01.988+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:30:01.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:30:02.002+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:30:02.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:30:02.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T15:30:32.247+0000] {processor.py:157} INFO - Started process (PID=56962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:30:32.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:30:32.255+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:30:32.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:30:32.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:30:32.294+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:30:32.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:30:32.305+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:30:32.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:30:32.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T15:31:02.583+0000] {processor.py:157} INFO - Started process (PID=56972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:31:02.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:31:02.590+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:31:02.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:31:02.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:31:02.633+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:31:02.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:31:02.646+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:31:02.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:31:02.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-08-17T15:31:32.935+0000] {processor.py:157} INFO - Started process (PID=56982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:31:32.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:31:32.943+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:31:32.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:31:32.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:31:32.994+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:31:32.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:31:33.110+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:31:33.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:31:33.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-17T15:32:03.318+0000] {processor.py:157} INFO - Started process (PID=56992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:32:03.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:32:03.325+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:32:03.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:32:03.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:32:03.366+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:32:03.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:32:03.488+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:32:03.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:32:03.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-17T15:32:33.603+0000] {processor.py:157} INFO - Started process (PID=57002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:32:33.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:32:33.610+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:32:33.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:32:33.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:32:33.733+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:32:33.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:32:33.742+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:32:33.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:32:33.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-17T15:33:04.099+0000] {processor.py:157} INFO - Started process (PID=57012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:33:04.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:33:04.102+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:33:04.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:33:04.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:33:04.131+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:33:04.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:33:04.142+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:33:04.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:33:04.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T15:33:34.441+0000] {processor.py:157} INFO - Started process (PID=57022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:33:34.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:33:34.454+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:33:34.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:33:34.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:33:34.496+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:33:34.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:33:34.522+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:33:34.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:33:34.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-17T15:34:04.808+0000] {processor.py:157} INFO - Started process (PID=57032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:34:04.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:34:04.817+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:34:04.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:34:04.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:34:04.862+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:34:04.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:34:04.881+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:34:04.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:34:05.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-08-17T15:34:35.157+0000] {processor.py:157} INFO - Started process (PID=57042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:34:35.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:34:35.164+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:34:35.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:34:35.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:34:35.232+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:34:35.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:34:35.395+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:34:35.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:34:35.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-08-17T15:35:05.629+0000] {processor.py:157} INFO - Started process (PID=57052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:35:05.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:35:05.636+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:35:05.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:35:05.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:35:05.701+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:35:05.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:35:05.845+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:35:05.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:35:05.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-08-17T15:35:35.964+0000] {processor.py:157} INFO - Started process (PID=57062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:35:35.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:35:35.968+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:35:35.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:35:35.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:35:36.109+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:35:36.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:35:36.119+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:35:36.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:35:36.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-17T15:36:06.439+0000] {processor.py:157} INFO - Started process (PID=57072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:36:06.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:36:06.444+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:36:06.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:36:06.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:36:06.567+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:36:06.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:36:06.575+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:36:06.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:36:06.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-17T15:36:36.725+0000] {processor.py:157} INFO - Started process (PID=57082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:36:36.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:36:36.729+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:36:36.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:36:36.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:36:36.763+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:36:36.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:36:36.774+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:36:36.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:36:36.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T15:37:07.133+0000] {processor.py:157} INFO - Started process (PID=57092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:37:07.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:37:07.144+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:37:07.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:37:07.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:37:07.197+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:37:07.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:37:07.212+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:37:07.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:37:07.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T15:37:37.443+0000] {processor.py:157} INFO - Started process (PID=57102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:37:37.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:37:37.445+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:37:37.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:37:37.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:37:37.471+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:37:37.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:37:37.482+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:37:37.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:37:37.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T15:38:07.746+0000] {processor.py:157} INFO - Started process (PID=57112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:38:07.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:38:07.754+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:38:07.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:38:07.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:38:07.795+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:38:07.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:38:07.810+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:38:07.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:38:07.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-17T15:38:38.027+0000] {processor.py:157} INFO - Started process (PID=57122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:38:38.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:38:38.030+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:38:38.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:38:38.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:38:38.058+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:38:38.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:38:38.068+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:38:38.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:38:38.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T15:39:08.484+0000] {processor.py:157} INFO - Started process (PID=57132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:39:08.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:39:08.490+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:39:08.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:39:08.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:39:08.531+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:39:08.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:39:08.544+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:39:08.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:39:08.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-17T15:39:38.764+0000] {processor.py:157} INFO - Started process (PID=57142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:39:38.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:39:38.767+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:39:38.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:39:38.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:39:38.801+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:39:38.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:39:38.810+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:39:38.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:39:38.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T15:40:09.058+0000] {processor.py:157} INFO - Started process (PID=57152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:40:09.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:40:09.069+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:40:09.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:40:09.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:40:09.135+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:40:09.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:40:09.148+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:40:09.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:40:09.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-17T15:40:39.367+0000] {processor.py:157} INFO - Started process (PID=57162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:40:39.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:40:39.372+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:40:39.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:40:39.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:40:39.401+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:40:39.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:40:39.411+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:40:39.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:40:39.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T15:41:09.770+0000] {processor.py:157} INFO - Started process (PID=57172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:41:09.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:41:09.774+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:41:09.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:41:09.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:41:09.840+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:41:09.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:41:09.855+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:41:09.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:41:09.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T15:41:40.221+0000] {processor.py:157} INFO - Started process (PID=57182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:41:40.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:41:40.226+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:41:40.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:41:40.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:41:40.250+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:41:40.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:41:40.259+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:41:40.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:41:40.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T15:42:10.657+0000] {processor.py:157} INFO - Started process (PID=57192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:42:10.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:42:10.660+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:42:10.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:42:10.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:42:10.720+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:42:10.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:42:10.734+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:42:10.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:42:10.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-17T15:42:40.961+0000] {processor.py:157} INFO - Started process (PID=57202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:42:40.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:42:40.965+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:42:40.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:42:40.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:42:41.008+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:42:41.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:42:41.017+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:42:41.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:42:41.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T15:43:11.374+0000] {processor.py:157} INFO - Started process (PID=57212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:43:11.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:43:11.379+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:43:11.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:43:11.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:43:11.442+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:43:11.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:43:11.459+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:43:11.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:43:11.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T15:43:41.688+0000] {processor.py:157} INFO - Started process (PID=57222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:43:41.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:43:41.692+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:43:41.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:43:41.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:43:41.718+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:43:41.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:43:41.729+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:43:41.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:43:41.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T15:44:12.068+0000] {processor.py:157} INFO - Started process (PID=57232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:44:12.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:44:12.072+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:44:12.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:44:12.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:44:12.138+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:44:12.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:44:12.151+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:44:12.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:44:12.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T15:44:42.366+0000] {processor.py:157} INFO - Started process (PID=57242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:44:42.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:44:42.369+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:44:42.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:44:42.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:44:42.396+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:44:42.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:44:42.409+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:44:42.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:44:42.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T15:45:12.760+0000] {processor.py:157} INFO - Started process (PID=57252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:45:12.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:45:12.764+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:45:12.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:45:12.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:45:12.808+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:45:12.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:45:12.822+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:45:12.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:45:12.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T15:45:43.082+0000] {processor.py:157} INFO - Started process (PID=57262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:45:43.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:45:43.086+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:45:43.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:45:43.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:45:43.148+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:45:43.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:45:43.162+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:45:43.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:45:43.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T15:46:13.400+0000] {processor.py:157} INFO - Started process (PID=57272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:46:13.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:46:13.401+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:46:13.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:46:13.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:46:13.431+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:46:13.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:46:13.440+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:46:13.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:46:13.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T15:46:43.714+0000] {processor.py:157} INFO - Started process (PID=57282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:46:43.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:46:43.717+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:46:43.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:46:43.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:46:43.786+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:46:43.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:46:43.801+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:46:43.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:46:43.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T15:47:14.088+0000] {processor.py:157} INFO - Started process (PID=57292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:47:14.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:47:14.095+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:47:14.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:47:14.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:47:14.126+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:47:14.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:47:14.137+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:47:14.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:47:14.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T15:47:44.468+0000] {processor.py:157} INFO - Started process (PID=57302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:47:44.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:47:44.473+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:47:44.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:47:44.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:47:44.548+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:47:44.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:47:44.564+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:47:44.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:47:44.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-17T15:48:14.815+0000] {processor.py:157} INFO - Started process (PID=57312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:48:14.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:48:14.820+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:48:14.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:48:14.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:48:14.868+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:48:14.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:48:14.883+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:48:14.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:48:14.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T15:48:45.141+0000] {processor.py:157} INFO - Started process (PID=57322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:48:45.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:48:45.144+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:48:45.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:48:45.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:48:45.168+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:48:45.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:48:45.178+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:48:45.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:48:45.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-17T15:49:15.556+0000] {processor.py:157} INFO - Started process (PID=57332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:49:15.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:49:15.562+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:49:15.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:49:15.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:49:15.609+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:49:15.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:49:15.623+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:49:15.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:49:15.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-17T15:49:45.915+0000] {processor.py:157} INFO - Started process (PID=57342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:49:45.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:49:45.919+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:49:45.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:49:45.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:49:45.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:49:45.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:49:45.973+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:49:45.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:49:45.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T15:50:16.273+0000] {processor.py:157} INFO - Started process (PID=57352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:50:16.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:50:16.290+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:50:16.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:50:16.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:50:16.333+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:50:16.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:50:16.347+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:50:16.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:50:16.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T15:50:46.613+0000] {processor.py:157} INFO - Started process (PID=57362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:50:46.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:50:46.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:50:46.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:50:46.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:50:46.708+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:50:46.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:50:46.731+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:50:46.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:50:46.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-17T15:51:16.921+0000] {processor.py:157} INFO - Started process (PID=57372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:51:16.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:51:16.928+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:51:16.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:51:16.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:51:16.982+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:51:16.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:51:17.002+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:51:17.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:51:17.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T15:51:47.293+0000] {processor.py:157} INFO - Started process (PID=57382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:51:47.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:51:47.299+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:51:47.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:51:47.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:51:47.354+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:51:47.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:51:47.372+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:51:47.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:51:47.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T15:52:17.674+0000] {processor.py:157} INFO - Started process (PID=57392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:52:17.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:52:17.679+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:52:17.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:52:17.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:52:17.735+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:52:17.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:52:17.750+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:52:17.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:52:17.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T15:52:47.980+0000] {processor.py:157} INFO - Started process (PID=57402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:52:47.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:52:47.984+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:52:47.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:52:47.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:52:48.013+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:52:48.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:52:48.023+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:52:48.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:52:48.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T15:53:18.388+0000] {processor.py:157} INFO - Started process (PID=57412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:53:18.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:53:18.392+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:53:18.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:53:18.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:53:18.453+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:53:18.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:53:18.471+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:53:18.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:53:18.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T15:53:48.803+0000] {processor.py:157} INFO - Started process (PID=57422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:53:48.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:53:48.806+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:53:48.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:53:48.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:53:48.837+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:53:48.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:53:48.847+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:53:48.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:53:48.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T15:54:19.244+0000] {processor.py:157} INFO - Started process (PID=57432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:54:19.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:54:19.257+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:54:19.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:54:19.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:54:19.298+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:54:19.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:54:19.312+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:54:19.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:54:19.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-17T15:54:49.552+0000] {processor.py:157} INFO - Started process (PID=57442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:54:49.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:54:49.554+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:54:49.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:54:49.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:54:49.587+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:54:49.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:54:49.608+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:54:49.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:54:49.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T15:55:19.962+0000] {processor.py:157} INFO - Started process (PID=57452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:55:19.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:55:19.966+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:55:19.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:55:19.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:55:20.023+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:55:20.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:55:20.038+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:55:20.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:55:20.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T15:55:50.267+0000] {processor.py:157} INFO - Started process (PID=57462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:55:50.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:55:50.271+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:55:50.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:55:50.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:55:50.304+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:55:50.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:55:50.314+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:55:50.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:55:50.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T15:56:20.571+0000] {processor.py:157} INFO - Started process (PID=57472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:56:20.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:56:20.583+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:56:20.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:56:20.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:56:20.641+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:56:20.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:56:20.654+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:56:20.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:56:20.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T15:56:50.841+0000] {processor.py:157} INFO - Started process (PID=57482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:56:50.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:56:50.844+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:56:50.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:56:50.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:56:50.878+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:56:50.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:56:50.890+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:56:50.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:56:50.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T15:57:21.238+0000] {processor.py:157} INFO - Started process (PID=57491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:57:21.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:57:21.259+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:57:21.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:57:21.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:57:21.304+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:57:21.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:57:21.321+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:57:21.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:57:21.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-17T15:57:51.514+0000] {processor.py:157} INFO - Started process (PID=57502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:57:51.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:57:51.519+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:57:51.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:57:51.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:57:51.545+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:57:51.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:57:51.557+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:57:51.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:57:51.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T15:58:21.917+0000] {processor.py:157} INFO - Started process (PID=57512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:58:21.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:58:21.920+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:58:21.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:58:21.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:58:21.976+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:58:21.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:58:21.991+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:58:21.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:58:22.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-17T15:58:52.258+0000] {processor.py:157} INFO - Started process (PID=57522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:58:52.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:58:52.278+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:58:52.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:58:52.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:58:52.345+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:58:52.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:58:52.365+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:58:52.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:58:52.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-17T15:59:22.581+0000] {processor.py:157} INFO - Started process (PID=57532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:59:22.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:59:22.588+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:59:22.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:59:22.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:59:22.640+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:59:22.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:59:22.656+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:59:22.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:59:22.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T15:59:52.894+0000] {processor.py:157} INFO - Started process (PID=57541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:59:52.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T15:59:52.905+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:59:52.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:59:52.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T15:59:52.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:59:52.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T15:59:52.972+0000] {logging_mixin.py:151} INFO - [2024-08-17T15:59:52.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T15:59:52.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-17T16:00:23.230+0000] {processor.py:157} INFO - Started process (PID=57552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:00:23.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:00:23.241+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:00:23.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:00:23.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:00:23.283+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:00:23.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:00:23.297+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:00:23.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:00:23.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T16:00:53.589+0000] {processor.py:157} INFO - Started process (PID=57562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:00:53.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:00:53.619+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:00:53.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:00:53.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:00:53.664+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:00:53.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:00:53.679+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:00:53.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:00:53.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-17T16:01:23.879+0000] {processor.py:157} INFO - Started process (PID=57572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:01:23.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:01:23.885+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:01:23.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:01:23.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:01:23.932+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:01:23.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:01:23.948+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:01:23.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:01:23.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T16:01:54.237+0000] {processor.py:157} INFO - Started process (PID=57582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:01:54.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:01:54.241+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:01:54.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:01:54.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:01:54.287+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:01:54.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:01:54.298+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:01:54.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:01:54.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T16:02:24.690+0000] {processor.py:157} INFO - Started process (PID=57592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:02:24.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:02:24.695+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:02:24.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:02:24.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:02:24.747+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:02:24.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:02:24.761+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:02:24.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:02:24.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T16:02:55.047+0000] {processor.py:157} INFO - Started process (PID=57602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:02:55.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:02:55.056+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:02:55.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:02:55.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:02:55.173+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:02:55.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:02:55.193+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:02:55.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:02:55.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-17T16:03:25.384+0000] {processor.py:157} INFO - Started process (PID=57612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:03:25.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:03:25.408+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:03:25.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:03:25.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:03:25.482+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:03:25.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:03:25.499+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:03:25.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:03:25.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-17T16:03:55.790+0000] {processor.py:157} INFO - Started process (PID=57621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:03:55.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:03:55.799+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:03:55.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:03:55.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:03:55.849+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:03:55.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:03:55.869+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:03:55.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:03:55.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-17T16:04:26.132+0000] {processor.py:157} INFO - Started process (PID=57631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:04:26.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:04:26.138+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:04:26.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:04:26.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:04:26.191+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:04:26.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:04:26.208+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:04:26.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:04:26.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T16:04:56.472+0000] {processor.py:157} INFO - Started process (PID=57642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:04:56.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:04:56.478+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:04:56.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:04:56.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:04:56.532+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:04:56.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:04:56.546+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:04:56.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:04:56.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T16:05:26.965+0000] {processor.py:157} INFO - Started process (PID=57652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:05:26.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:05:26.972+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:05:26.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:05:26.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:05:27.016+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:05:27.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:05:27.030+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:05:27.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:05:27.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-17T16:05:57.406+0000] {processor.py:157} INFO - Started process (PID=57662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:05:57.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:05:57.414+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:05:57.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:05:57.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:05:57.471+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:05:57.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:05:57.486+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:05:57.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:05:57.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T16:06:27.779+0000] {processor.py:157} INFO - Started process (PID=57672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:06:27.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:06:27.785+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:06:27.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:06:27.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:06:27.945+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:06:27.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:06:27.973+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:06:27.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:06:27.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-08-17T16:06:58.081+0000] {processor.py:157} INFO - Started process (PID=57682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:06:58.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:06:58.118+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:06:58.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:06:58.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:06:58.173+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:06:58.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:06:58.192+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:06:58.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:06:58.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-17T16:07:28.587+0000] {processor.py:157} INFO - Started process (PID=57692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:07:28.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:07:28.593+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:07:28.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:07:28.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:07:28.688+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:07:28.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:07:28.707+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:07:28.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:07:28.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-17T16:07:58.913+0000] {processor.py:157} INFO - Started process (PID=57702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:07:58.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:07:58.920+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:07:58.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:07:58.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:07:58.975+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:07:58.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:07:58.991+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:07:58.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:07:59.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T16:08:29.367+0000] {processor.py:157} INFO - Started process (PID=57712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:08:29.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:08:29.372+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:08:29.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:08:29.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:08:29.434+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:08:29.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:08:29.465+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:08:29.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:08:29.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-17T16:08:59.699+0000] {processor.py:157} INFO - Started process (PID=57722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:08:59.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:08:59.704+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:08:59.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:08:59.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:08:59.756+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:08:59.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:08:59.771+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:08:59.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:08:59.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T16:09:30.082+0000] {processor.py:157} INFO - Started process (PID=57732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:09:30.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:09:30.089+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:09:30.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:09:30.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:09:30.157+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:09:30.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:09:30.224+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:09:30.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:09:30.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-17T16:10:00.596+0000] {processor.py:157} INFO - Started process (PID=57740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:10:00.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:10:00.610+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:10:00.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:10:00.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:10:00.670+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:10:00.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:10:00.684+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:10:00.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:10:00.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-17T16:10:30.879+0000] {processor.py:157} INFO - Started process (PID=57752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:10:30.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:10:30.884+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:10:30.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:10:30.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:10:30.917+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:10:30.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:10:30.928+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:10:30.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:10:30.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T16:11:01.234+0000] {processor.py:157} INFO - Started process (PID=57762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:11:01.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:11:01.237+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:11:01.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:11:01.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:11:01.275+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:11:01.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:11:01.288+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:11:01.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:11:01.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T16:11:31.592+0000] {processor.py:157} INFO - Started process (PID=57770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:11:31.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:11:31.597+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:11:31.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:11:31.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:11:31.631+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:11:31.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:11:31.641+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:11:31.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:11:31.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T16:12:01.970+0000] {processor.py:157} INFO - Started process (PID=57782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:12:01.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:12:01.974+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:12:01.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:12:01.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:12:02.017+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:12:02.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:12:02.031+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:12:02.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:12:02.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T16:12:32.311+0000] {processor.py:157} INFO - Started process (PID=57792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:12:32.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:12:32.317+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:12:32.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:12:32.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:12:32.352+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:12:32.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:12:32.366+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:12:32.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:12:32.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T16:13:02.689+0000] {processor.py:157} INFO - Started process (PID=57802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:13:02.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:13:02.692+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:13:02.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:13:02.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:13:02.718+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:13:02.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:13:02.728+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:13:02.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:13:02.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T16:13:33.026+0000] {processor.py:157} INFO - Started process (PID=57812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:13:33.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:13:33.030+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:13:33.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:13:33.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:13:33.061+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:13:33.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:13:33.073+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:13:33.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:13:33.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T16:14:03.362+0000] {processor.py:157} INFO - Started process (PID=57822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:14:03.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:14:03.369+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:14:03.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:14:03.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:14:03.406+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:14:03.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:14:03.417+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:14:03.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:14:03.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T16:14:33.719+0000] {processor.py:157} INFO - Started process (PID=57832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:14:33.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:14:33.726+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:14:33.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:14:33.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:14:33.762+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:14:33.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:14:33.776+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:14:33.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:14:33.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T16:15:04.075+0000] {processor.py:157} INFO - Started process (PID=57842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:15:04.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:15:04.078+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:15:04.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:15:04.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:15:04.122+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:15:04.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:15:04.136+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:15:04.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:15:04.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T16:15:34.532+0000] {processor.py:157} INFO - Started process (PID=57852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:15:34.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:15:34.542+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:15:34.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:15:34.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:15:34.572+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:15:34.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:15:34.582+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:15:34.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:15:34.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T16:16:04.968+0000] {processor.py:157} INFO - Started process (PID=57862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:16:04.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:16:04.976+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:16:04.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:16:04.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:16:05.045+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:16:05.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:16:05.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:16:05.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:16:05.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-17T16:16:35.269+0000] {processor.py:157} INFO - Started process (PID=57871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:16:35.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:16:35.293+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:16:35.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:16:35.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:16:35.341+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:16:35.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:16:35.365+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:16:35.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:16:35.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-17T16:17:05.563+0000] {processor.py:157} INFO - Started process (PID=57882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:17:05.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:17:05.566+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:17:05.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:17:05.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:17:05.597+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:17:05.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:17:05.614+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:17:05.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:17:05.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T16:17:35.952+0000] {processor.py:157} INFO - Started process (PID=57892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:17:35.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:17:35.957+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:17:35.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:17:35.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:17:36.018+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:17:36.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:17:36.032+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:17:36.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:17:36.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T16:18:06.322+0000] {processor.py:157} INFO - Started process (PID=57902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:18:06.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:18:06.331+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:18:06.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:18:06.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:18:06.390+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:18:06.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:18:06.427+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:18:06.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:18:06.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-17T16:18:36.630+0000] {processor.py:157} INFO - Started process (PID=57912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:18:36.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:18:36.637+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:18:36.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:18:36.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:18:36.704+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:18:36.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:18:36.721+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:18:36.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:18:36.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-17T16:19:07.015+0000] {processor.py:157} INFO - Started process (PID=57922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:19:07.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:19:07.022+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:19:07.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:19:07.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:19:07.063+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:19:07.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:19:07.079+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:19:07.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:19:07.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-17T16:19:37.379+0000] {processor.py:157} INFO - Started process (PID=57932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:19:37.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:19:37.384+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:19:37.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:19:37.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:19:37.424+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:19:37.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:19:37.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:19:37.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:19:37.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T16:20:07.712+0000] {processor.py:157} INFO - Started process (PID=57942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:20:07.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:20:07.727+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:20:07.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:20:07.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:20:07.774+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:20:07.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:20:07.788+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:20:07.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:20:07.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-17T16:20:38.035+0000] {processor.py:157} INFO - Started process (PID=57952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:20:38.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:20:38.042+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:20:38.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:20:38.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:20:38.106+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:20:38.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:20:38.140+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:20:38.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:20:38.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-17T16:21:08.414+0000] {processor.py:157} INFO - Started process (PID=57962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:21:08.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:21:08.423+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:21:08.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:21:08.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:21:08.491+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:21:08.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:21:08.528+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:21:08.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:21:08.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-17T16:21:38.781+0000] {processor.py:157} INFO - Started process (PID=57972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:21:38.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:21:38.789+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:21:38.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:21:38.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:21:38.844+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:21:38.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:21:38.859+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:21:38.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:21:38.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T16:22:09.133+0000] {processor.py:157} INFO - Started process (PID=57981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:22:09.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:22:09.140+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:22:09.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:22:09.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:22:09.195+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:22:09.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:22:09.209+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:22:09.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:22:09.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-17T16:22:39.439+0000] {processor.py:157} INFO - Started process (PID=57992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:22:39.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:22:39.444+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:22:39.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:22:39.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:22:39.485+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:22:39.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:22:39.499+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:22:39.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:22:39.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-17T16:23:09.887+0000] {processor.py:157} INFO - Started process (PID=58002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:23:09.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:23:09.903+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:23:09.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:23:09.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:23:10.005+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:23:10.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:23:10.026+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:23:10.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:23:10.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-17T16:23:40.256+0000] {processor.py:157} INFO - Started process (PID=58012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:23:40.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:23:40.263+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:23:40.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:23:40.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:23:40.306+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:23:40.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:23:40.320+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:23:40.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:23:40.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-17T16:24:10.580+0000] {processor.py:157} INFO - Started process (PID=58022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:24:10.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:24:10.589+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:24:10.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:24:10.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:24:10.669+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:24:10.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:24:10.684+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:24:10.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:24:10.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-17T16:24:40.868+0000] {processor.py:157} INFO - Started process (PID=58032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:24:40.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:24:40.888+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:24:40.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:24:40.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:24:40.939+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:24:40.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:24:40.955+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:24:40.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:24:40.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T16:25:11.281+0000] {processor.py:157} INFO - Started process (PID=58041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:25:11.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:25:11.292+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:25:11.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:25:11.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:25:11.340+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:25:11.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:25:11.357+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:25:11.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:25:11.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-17T16:25:41.702+0000] {processor.py:157} INFO - Started process (PID=58052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:25:41.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:25:41.712+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:25:41.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:25:41.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:25:41.811+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:25:41.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:25:41.829+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:25:41.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:25:41.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-17T16:26:12.074+0000] {processor.py:157} INFO - Started process (PID=58062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:26:12.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:26:12.082+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:26:12.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:26:12.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:26:12.132+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:26:12.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:26:12.159+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:26:12.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:26:12.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T16:26:42.517+0000] {processor.py:157} INFO - Started process (PID=58072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:26:42.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:26:42.527+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:26:42.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:26:42.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:26:42.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:26:42.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:26:42.635+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:26:42.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:26:42.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-17T16:27:12.817+0000] {processor.py:157} INFO - Started process (PID=58081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:27:12.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:27:12.827+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:27:12.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:27:12.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:27:12.881+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:27:12.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:27:12.897+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:27:12.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:27:12.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T16:27:43.362+0000] {processor.py:157} INFO - Started process (PID=58092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:27:43.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:27:43.370+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:27:43.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:27:43.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:27:43.421+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:27:43.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:27:43.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:27:43.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:27:43.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-17T16:28:13.657+0000] {processor.py:157} INFO - Started process (PID=58102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:28:13.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:28:13.664+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:28:13.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:28:13.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:28:13.728+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:28:13.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:28:13.752+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:28:13.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:28:13.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-17T16:28:43.971+0000] {processor.py:157} INFO - Started process (PID=58112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:28:43.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:28:43.986+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:28:43.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:28:44.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:28:44.041+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:28:44.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:28:44.057+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:28:44.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:28:44.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-17T16:29:14.472+0000] {processor.py:157} INFO - Started process (PID=58121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:29:14.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:29:14.480+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:29:14.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:29:14.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:29:14.616+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:29:14.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:29:14.712+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:29:14.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:29:14.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.278 seconds
[2024-08-17T16:29:45.101+0000] {processor.py:157} INFO - Started process (PID=58132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:29:45.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:29:45.108+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:29:45.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:29:45.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:29:45.202+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:29:45.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:29:45.227+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:29:45.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:29:45.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-17T16:30:15.429+0000] {processor.py:157} INFO - Started process (PID=58142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:30:15.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:30:15.441+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:30:15.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:30:15.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:30:15.495+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:30:15.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:30:15.508+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:30:15.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:30:15.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T16:30:45.757+0000] {processor.py:157} INFO - Started process (PID=58152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:30:45.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:30:45.759+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:30:45.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:30:45.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:30:45.788+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:30:45.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:30:45.799+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:30:45.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:30:45.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T16:31:16.132+0000] {processor.py:157} INFO - Started process (PID=58162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:31:16.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:31:16.137+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:31:16.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:31:16.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:31:16.189+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:31:16.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:31:16.208+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:31:16.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:31:16.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T16:31:46.407+0000] {processor.py:157} INFO - Started process (PID=58172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:31:46.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:31:46.411+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:31:46.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:31:46.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:31:46.443+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:31:46.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:31:46.454+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:31:46.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:31:46.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T16:32:16.866+0000] {processor.py:157} INFO - Started process (PID=58182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:32:16.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:32:16.876+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:32:16.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:32:16.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:32:16.996+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:32:16.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:32:17.018+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:32:17.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:32:17.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-17T16:32:47.210+0000] {processor.py:157} INFO - Started process (PID=58192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:32:47.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:32:47.216+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:32:47.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:32:47.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:32:47.257+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:32:47.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:32:47.270+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:32:47.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:32:47.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T16:33:17.622+0000] {processor.py:157} INFO - Started process (PID=58202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:33:17.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:33:17.634+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:33:17.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:33:17.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:33:17.677+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:33:17.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:33:17.700+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:33:17.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:33:17.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-17T16:33:47.998+0000] {processor.py:157} INFO - Started process (PID=58212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:33:48.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:33:48.012+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:33:48.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:33:48.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:33:48.065+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:33:48.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:33:48.080+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:33:48.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:33:48.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-17T16:34:18.491+0000] {processor.py:157} INFO - Started process (PID=58222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:34:18.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:34:18.503+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:34:18.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:34:18.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:34:18.553+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:34:18.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:34:18.567+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:34:18.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:34:18.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-17T16:34:48.779+0000] {processor.py:157} INFO - Started process (PID=58232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:34:48.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:34:48.781+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:34:48.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:34:48.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:34:48.807+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:34:48.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:34:48.816+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:34:48.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:34:48.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-17T16:35:19.085+0000] {processor.py:157} INFO - Started process (PID=58242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:35:19.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:35:19.089+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:35:19.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:35:19.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:35:19.126+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:35:19.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:35:19.140+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:35:19.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:35:19.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T16:35:49.370+0000] {processor.py:157} INFO - Started process (PID=58252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:35:49.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:35:49.373+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:35:49.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:35:49.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:35:49.403+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:35:49.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:35:49.414+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:35:49.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:35:49.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T16:36:19.736+0000] {processor.py:157} INFO - Started process (PID=58262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:36:19.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:36:19.741+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:36:19.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:36:19.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:36:19.779+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:36:19.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:36:19.792+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:36:19.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:36:19.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T16:36:49.998+0000] {processor.py:157} INFO - Started process (PID=58272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:36:49.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:36:50.001+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:36:50.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:36:50.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:36:50.027+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:36:50.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:36:50.038+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:36:50.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:36:50.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T16:37:20.363+0000] {processor.py:157} INFO - Started process (PID=58282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:37:20.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:37:20.369+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:37:20.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:37:20.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:37:20.409+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:37:20.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:37:20.423+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:37:20.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:37:20.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T16:37:50.747+0000] {processor.py:157} INFO - Started process (PID=58292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:37:50.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:37:50.751+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:37:50.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:37:50.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:37:50.778+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:37:50.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:37:50.788+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:37:50.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:37:50.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T16:38:21.123+0000] {processor.py:157} INFO - Started process (PID=58302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:38:21.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:38:21.132+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:38:21.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:38:21.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:38:21.182+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:38:21.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:38:21.195+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:38:21.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:38:21.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T16:38:51.407+0000] {processor.py:157} INFO - Started process (PID=58312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:38:51.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:38:51.411+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:38:51.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:38:51.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:38:51.440+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:38:51.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:38:51.451+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:38:51.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:38:51.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T16:39:21.841+0000] {processor.py:157} INFO - Started process (PID=58321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:39:21.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:39:21.846+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:39:21.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:39:21.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:39:21.920+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:39:21.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:39:21.935+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:39:21.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:39:21.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-17T16:39:52.150+0000] {processor.py:157} INFO - Started process (PID=58332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:39:52.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:39:52.153+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:39:52.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:39:52.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:39:52.180+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:39:52.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:39:52.194+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:39:52.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:39:52.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T16:40:22.777+0000] {processor.py:157} INFO - Started process (PID=58342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:40:22.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:40:22.786+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:40:22.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:40:22.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:40:22.867+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:40:22.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:40:22.888+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:40:22.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:40:22.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-17T16:40:53.056+0000] {processor.py:157} INFO - Started process (PID=58352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:40:53.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:40:53.061+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:40:53.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:40:53.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:40:53.108+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:40:53.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:40:53.123+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:40:53.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:40:53.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T16:41:23.463+0000] {processor.py:157} INFO - Started process (PID=58362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:41:23.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:41:23.466+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:41:23.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:41:23.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:41:23.509+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:41:23.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:41:23.525+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:41:23.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:41:23.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-17T16:41:53.773+0000] {processor.py:157} INFO - Started process (PID=58372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:41:53.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:41:53.776+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:41:53.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:41:53.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:41:53.806+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:41:53.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:41:53.817+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:41:53.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:41:53.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T16:42:24.078+0000] {processor.py:157} INFO - Started process (PID=58382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:42:24.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:42:24.082+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:42:24.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:42:24.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:42:24.136+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:42:24.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:42:24.150+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:42:24.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:42:24.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T16:42:54.338+0000] {processor.py:157} INFO - Started process (PID=58392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:42:54.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:42:54.343+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:42:54.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:42:54.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:42:54.371+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:42:54.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:42:54.381+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:42:54.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:42:54.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T16:43:24.702+0000] {processor.py:157} INFO - Started process (PID=58402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:43:24.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:43:24.704+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:43:24.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:43:24.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:43:24.732+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:43:24.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:43:24.743+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:43:24.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:43:24.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T16:43:55.064+0000] {processor.py:157} INFO - Started process (PID=58412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:43:55.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:43:55.069+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:43:55.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:43:55.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:43:55.106+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:43:55.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:43:55.120+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:43:55.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:43:55.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T16:44:25.354+0000] {processor.py:157} INFO - Started process (PID=58422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:44:25.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:44:25.360+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:44:25.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:44:25.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:44:25.392+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:44:25.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:44:25.404+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:44:25.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:44:25.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T16:44:55.699+0000] {processor.py:157} INFO - Started process (PID=58432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:44:55.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:44:55.702+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:44:55.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:44:55.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:44:55.725+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:44:55.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:44:55.735+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:44:55.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:44:55.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-17T16:45:26.086+0000] {processor.py:157} INFO - Started process (PID=58442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:45:26.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:45:26.093+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:45:26.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:45:26.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:45:26.143+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:45:26.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:45:26.160+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:45:26.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:45:26.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-17T16:45:56.340+0000] {processor.py:157} INFO - Started process (PID=58452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:45:56.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:45:56.345+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:45:56.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:45:56.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:45:56.383+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:45:56.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:45:56.397+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:45:56.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:45:56.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T16:46:26.667+0000] {processor.py:157} INFO - Started process (PID=58462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:46:26.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:46:26.672+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:46:26.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:46:26.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:46:26.710+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:46:26.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:46:26.724+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:46:26.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:46:26.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T16:46:57.021+0000] {processor.py:157} INFO - Started process (PID=58472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:46:57.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:46:57.024+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:46:57.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:46:57.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:46:57.050+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:46:57.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:46:57.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:46:57.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:46:57.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T16:47:27.382+0000] {processor.py:157} INFO - Started process (PID=58482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:47:27.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:47:27.387+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:47:27.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:47:27.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:47:27.427+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:47:27.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:47:27.440+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:47:27.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:47:27.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T16:47:57.759+0000] {processor.py:157} INFO - Started process (PID=58492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:47:57.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:47:57.764+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:47:57.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:47:57.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:47:57.792+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:47:57.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:47:57.802+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:47:57.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:47:57.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T16:48:28.176+0000] {processor.py:157} INFO - Started process (PID=58502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:48:28.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:48:28.187+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:48:28.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:48:28.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:48:28.235+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:48:28.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:48:28.266+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:48:28.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:48:28.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-17T16:48:58.489+0000] {processor.py:157} INFO - Started process (PID=58512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:48:58.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:48:58.496+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:48:58.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:48:58.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:48:58.559+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:48:58.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:48:58.575+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:48:58.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:48:58.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-17T16:49:28.814+0000] {processor.py:157} INFO - Started process (PID=58522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:49:28.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:49:28.817+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:49:28.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:49:28.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:49:28.844+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:49:28.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:49:28.856+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:49:28.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:49:28.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T16:49:59.277+0000] {processor.py:157} INFO - Started process (PID=58532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:49:59.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:49:59.282+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:49:59.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:49:59.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:49:59.326+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:49:59.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:49:59.348+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:49:59.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:49:59.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T16:50:29.580+0000] {processor.py:157} INFO - Started process (PID=58542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:50:29.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:50:29.585+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:50:29.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:50:29.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:50:29.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:50:29.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:50:29.634+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:50:29.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:50:29.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T16:51:00.039+0000] {processor.py:157} INFO - Started process (PID=58552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:51:00.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:51:00.044+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:51:00.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:51:00.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:51:00.089+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:51:00.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:51:00.105+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:51:00.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:51:00.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-17T16:51:30.419+0000] {processor.py:157} INFO - Started process (PID=58562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:51:30.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:51:30.425+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:51:30.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:51:30.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:51:30.477+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:51:30.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:51:30.495+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:51:30.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:51:30.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T16:52:00.720+0000] {processor.py:157} INFO - Started process (PID=58571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:52:00.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:52:00.728+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:52:00.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:52:00.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:52:00.777+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:52:00.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:52:00.790+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:52:00.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:52:00.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T16:52:31.138+0000] {processor.py:157} INFO - Started process (PID=58582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:52:31.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:52:31.140+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:52:31.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:52:31.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:52:31.168+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:52:31.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:52:31.178+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:52:31.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:52:31.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T16:53:01.530+0000] {processor.py:157} INFO - Started process (PID=58592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:53:01.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:53:01.535+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:53:01.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:53:01.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:53:01.577+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:53:01.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:53:01.601+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:53:01.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:53:01.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-17T16:53:31.798+0000] {processor.py:157} INFO - Started process (PID=58602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:53:31.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:53:31.803+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:53:31.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:53:31.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:53:31.839+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:53:31.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:53:31.852+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:53:31.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:53:31.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T16:54:02.233+0000] {processor.py:157} INFO - Started process (PID=58612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:54:02.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:54:02.238+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:54:02.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:54:02.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:54:02.303+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:54:02.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:54:02.319+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:54:02.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:54:02.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T16:54:32.572+0000] {processor.py:157} INFO - Started process (PID=58622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:54:32.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:54:32.584+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:54:32.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:54:32.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:54:32.636+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:54:32.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:54:32.651+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:54:32.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:54:32.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-17T16:55:02.846+0000] {processor.py:157} INFO - Started process (PID=58632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:55:02.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:55:02.848+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:55:02.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:55:02.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:55:02.882+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:55:02.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:55:02.893+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:55:02.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:55:02.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T16:55:33.230+0000] {processor.py:157} INFO - Started process (PID=58642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:55:33.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:55:33.244+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:55:33.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:55:33.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:55:33.298+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:55:33.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:55:33.313+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:55:33.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:55:33.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-17T16:56:03.539+0000] {processor.py:157} INFO - Started process (PID=58652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:56:03.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:56:03.543+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:56:03.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:56:03.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:56:03.570+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:56:03.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:56:03.581+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:56:03.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:56:03.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T16:56:33.905+0000] {processor.py:157} INFO - Started process (PID=58662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:56:33.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:56:33.912+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:56:33.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:56:33.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:56:33.978+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:56:33.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:56:33.992+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:56:33.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:56:34.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T16:57:04.207+0000] {processor.py:157} INFO - Started process (PID=58671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:57:04.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:57:04.219+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:57:04.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:57:04.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:57:04.269+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:57:04.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:57:04.292+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:57:04.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:57:04.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-17T16:57:34.584+0000] {processor.py:157} INFO - Started process (PID=58682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:57:34.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:57:34.606+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:57:34.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:57:34.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:57:34.648+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:57:34.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:57:34.668+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:57:34.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:57:34.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T16:58:04.887+0000] {processor.py:157} INFO - Started process (PID=58692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:58:04.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:58:04.894+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:58:04.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:58:04.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:58:04.937+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:58:04.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:58:04.950+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:58:04.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:58:04.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T16:58:35.316+0000] {processor.py:157} INFO - Started process (PID=58702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:58:35.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:58:35.321+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:58:35.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:58:35.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:58:35.359+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:58:35.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:58:35.372+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:58:35.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:58:35.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T16:59:06.021+0000] {processor.py:157} INFO - Started process (PID=58712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:59:06.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:59:06.029+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:59:06.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:59:06.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:59:06.101+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:59:06.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:59:06.123+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:59:06.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:59:06.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-17T16:59:36.343+0000] {processor.py:157} INFO - Started process (PID=58722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:59:36.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T16:59:36.348+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:59:36.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:59:36.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T16:59:36.405+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:59:36.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T16:59:36.422+0000] {logging_mixin.py:151} INFO - [2024-08-17T16:59:36.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T16:59:36.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T17:00:06.655+0000] {processor.py:157} INFO - Started process (PID=58732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:00:06.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:00:06.660+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:00:06.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:00:06.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:00:06.697+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:00:06.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:00:06.710+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:00:06.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:00:06.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T17:00:36.891+0000] {processor.py:157} INFO - Started process (PID=58742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:00:36.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:00:36.893+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:00:36.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:00:36.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:00:36.922+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:00:36.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:00:36.935+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:00:36.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:00:36.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T17:01:07.145+0000] {processor.py:157} INFO - Started process (PID=58752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:01:07.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:01:07.147+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:01:07.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:01:07.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:01:07.173+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:01:07.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:01:07.186+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:01:07.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:01:07.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T17:01:37.477+0000] {processor.py:157} INFO - Started process (PID=58762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:01:37.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:01:37.482+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:01:37.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:01:37.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:01:37.524+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:01:37.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:01:37.538+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:01:37.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:01:37.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-17T17:02:07.740+0000] {processor.py:157} INFO - Started process (PID=58772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:02:07.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:02:07.743+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:02:07.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:02:07.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:02:07.768+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:02:07.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:02:07.778+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:02:07.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:02:07.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T17:02:38.058+0000] {processor.py:157} INFO - Started process (PID=58782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:02:38.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:02:38.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:02:38.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:02:38.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:02:38.088+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:02:38.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:02:38.099+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:02:38.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:02:38.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T17:03:08.350+0000] {processor.py:157} INFO - Started process (PID=58792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:03:08.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:03:08.356+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:03:08.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:03:08.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:03:08.394+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:03:08.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:03:08.408+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:03:08.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:03:08.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T17:03:38.736+0000] {processor.py:157} INFO - Started process (PID=58802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:03:38.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:03:38.740+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:03:38.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:03:38.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:03:38.766+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:03:38.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:03:38.777+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:03:38.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:03:38.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T17:04:09.138+0000] {processor.py:157} INFO - Started process (PID=58810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:04:09.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:04:09.143+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:04:09.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:04:09.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:04:09.192+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:04:09.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:04:09.206+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:04:09.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:04:09.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T17:04:39.435+0000] {processor.py:157} INFO - Started process (PID=58822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:04:39.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:04:39.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:04:39.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:04:39.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:04:39.466+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:04:39.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:04:39.479+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:04:39.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:04:39.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T17:05:09.800+0000] {processor.py:157} INFO - Started process (PID=58832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:05:09.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:05:09.808+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:05:09.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:05:09.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:05:09.845+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:05:09.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:05:09.859+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:05:09.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:05:09.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T17:05:40.112+0000] {processor.py:157} INFO - Started process (PID=58842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:05:40.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:05:40.118+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:05:40.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:05:40.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:05:40.146+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:05:40.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:05:40.157+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:05:40.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:05:40.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T17:06:10.412+0000] {processor.py:157} INFO - Started process (PID=58852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:06:10.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:06:10.415+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:06:10.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:06:10.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:06:10.472+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:06:10.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:06:10.485+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:06:10.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:06:10.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T17:06:40.731+0000] {processor.py:157} INFO - Started process (PID=58862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:06:40.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:06:40.740+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:06:40.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:06:40.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:06:40.771+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:06:40.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:06:40.781+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:06:40.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:06:40.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T17:07:11.127+0000] {processor.py:157} INFO - Started process (PID=58872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:07:11.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:07:11.131+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:07:11.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:07:11.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:07:11.183+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:07:11.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:07:11.198+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:07:11.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:07:11.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-17T17:07:41.409+0000] {processor.py:157} INFO - Started process (PID=58882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:07:41.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:07:41.411+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:07:41.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:07:41.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:07:41.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:07:41.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:07:41.448+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:07:41.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:07:41.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T17:08:11.707+0000] {processor.py:157} INFO - Started process (PID=58892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:08:11.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:08:11.712+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:08:11.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:08:11.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:08:11.748+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:08:11.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:08:11.761+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:08:11.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:08:11.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T17:08:42.087+0000] {processor.py:157} INFO - Started process (PID=58902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:08:42.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:08:42.091+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:08:42.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:08:42.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:08:42.120+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:08:42.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:08:42.131+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:08:42.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:08:42.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T17:09:12.379+0000] {processor.py:157} INFO - Started process (PID=58912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:09:12.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:09:12.382+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:09:12.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:09:12.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:09:12.416+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:09:12.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:09:12.430+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:09:12.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:09:12.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T17:09:42.786+0000] {processor.py:157} INFO - Started process (PID=58921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:09:42.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:09:42.801+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:09:42.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:09:42.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:09:42.837+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:09:42.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:09:42.847+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:09:42.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:09:42.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-17T17:10:13.167+0000] {processor.py:157} INFO - Started process (PID=58932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:10:13.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:10:13.170+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:10:13.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:10:13.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:10:13.211+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:10:13.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:10:13.224+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:10:13.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:10:13.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T17:10:43.443+0000] {processor.py:157} INFO - Started process (PID=58941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:10:43.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:10:43.448+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:10:43.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:10:43.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:10:43.478+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:10:43.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:10:43.492+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:10:43.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:10:43.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T17:11:13.755+0000] {processor.py:157} INFO - Started process (PID=58952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:11:13.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:11:13.757+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:11:13.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:11:13.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:11:13.812+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:11:13.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:11:13.827+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:11:13.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:11:13.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-17T17:11:44.052+0000] {processor.py:157} INFO - Started process (PID=58962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:11:44.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:11:44.057+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:11:44.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:11:44.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:11:44.087+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:11:44.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:11:44.101+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:11:44.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:11:44.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T17:12:14.428+0000] {processor.py:157} INFO - Started process (PID=58972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:12:14.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:12:14.432+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:12:14.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:12:14.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:12:14.467+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:12:14.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:12:14.480+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:12:14.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:12:14.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T17:12:44.816+0000] {processor.py:157} INFO - Started process (PID=58982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:12:44.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:12:44.819+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:12:44.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:12:44.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:12:44.851+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:12:44.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:12:44.865+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:12:44.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:12:44.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T17:13:15.197+0000] {processor.py:157} INFO - Started process (PID=58992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:13:15.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:13:15.201+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:13:15.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:13:15.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:13:15.236+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:13:15.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:13:15.249+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:13:15.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:13:15.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T17:13:45.471+0000] {processor.py:157} INFO - Started process (PID=59002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:13:45.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:13:45.474+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:13:45.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:13:45.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:13:45.508+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:13:45.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:13:45.520+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:13:45.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:13:45.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T17:14:15.876+0000] {processor.py:157} INFO - Started process (PID=59012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:14:15.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:14:15.879+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:14:15.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:14:15.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:14:15.914+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:14:15.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:14:15.926+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:14:15.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:14:15.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T17:14:46.236+0000] {processor.py:157} INFO - Started process (PID=59022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:14:46.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:14:46.241+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:14:46.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:14:46.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:14:46.280+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:14:46.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:14:46.295+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:14:46.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:14:46.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T17:15:16.560+0000] {processor.py:157} INFO - Started process (PID=59032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:15:16.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:15:16.566+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:15:16.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:15:16.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:15:16.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:15:16.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:15:16.623+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:15:16.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:15:16.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T17:15:46.964+0000] {processor.py:157} INFO - Started process (PID=59042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:15:46.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:15:46.971+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:15:46.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:15:46.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:15:47.022+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:15:47.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:15:47.038+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:15:47.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:15:47.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T17:16:17.269+0000] {processor.py:157} INFO - Started process (PID=59052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:16:17.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:16:17.273+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:16:17.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:16:17.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:16:17.303+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:16:17.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:16:17.316+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:16:17.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:16:17.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T17:16:47.600+0000] {processor.py:157} INFO - Started process (PID=59061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:16:47.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:16:47.619+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:16:47.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:16:47.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:16:47.675+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:16:47.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:16:47.690+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:16:47.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:16:47.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-17T17:17:18.050+0000] {processor.py:157} INFO - Started process (PID=59072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:17:18.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:17:18.054+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:17:18.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:17:18.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:17:18.090+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:17:18.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:17:18.103+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:17:18.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:17:18.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T17:17:48.422+0000] {processor.py:157} INFO - Started process (PID=59082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:17:48.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:17:48.424+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:17:48.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:17:48.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:17:48.455+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:17:48.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:17:48.472+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:17:48.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:17:48.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T17:18:18.794+0000] {processor.py:157} INFO - Started process (PID=59092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:18:18.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:18:18.800+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:18:18.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:18:18.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:18:18.836+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:18:18.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:18:18.848+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:18:18.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:18:18.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T17:18:49.124+0000] {processor.py:157} INFO - Started process (PID=59102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:18:49.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:18:49.127+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:18:49.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:18:49.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:18:49.158+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:18:49.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:18:49.171+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:18:49.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:18:49.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T17:19:19.474+0000] {processor.py:157} INFO - Started process (PID=59112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:19:19.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:19:19.479+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:19:19.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:19:19.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:19:19.515+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:19:19.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:19:19.525+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:19:19.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:19:19.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T17:19:49.816+0000] {processor.py:157} INFO - Started process (PID=59122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:19:49.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:19:49.824+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:19:49.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:19:49.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:19:49.890+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:19:49.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:19:49.915+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:19:49.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:19:49.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-17T17:20:20.304+0000] {processor.py:157} INFO - Started process (PID=59132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:20:20.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:20:20.311+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:20:20.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:20:20.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:20:20.352+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:20:20.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:20:20.367+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:20:20.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:20:20.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T17:20:50.673+0000] {processor.py:157} INFO - Started process (PID=59142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:20:50.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:20:50.676+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:20:50.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:20:50.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:20:50.703+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:20:50.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:20:50.712+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:20:50.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:20:50.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T17:21:21.052+0000] {processor.py:157} INFO - Started process (PID=59152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:21:21.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:21:21.059+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:21:21.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:21:21.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:21:21.121+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:21:21.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:21:21.139+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:21:21.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:21:21.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T17:21:51.373+0000] {processor.py:157} INFO - Started process (PID=59162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:21:51.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:21:51.377+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:21:51.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:21:51.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:21:51.400+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:21:51.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:21:51.410+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:21:51.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:21:51.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-17T17:22:21.731+0000] {processor.py:157} INFO - Started process (PID=59172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:22:21.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:22:21.736+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:22:21.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:22:21.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:22:21.812+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:22:21.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:22:21.827+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:22:21.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:22:21.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-17T17:22:52.028+0000] {processor.py:157} INFO - Started process (PID=59182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:22:52.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:22:52.030+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:22:52.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:22:52.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:22:52.055+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:22:52.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:22:52.065+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:22:52.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:22:52.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-17T17:23:22.368+0000] {processor.py:157} INFO - Started process (PID=59192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:23:22.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:23:22.374+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:23:22.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:23:22.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:23:22.439+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:23:22.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:23:22.452+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:23:22.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:23:22.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T17:23:52.819+0000] {processor.py:157} INFO - Started process (PID=59202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:23:52.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:23:52.825+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:23:52.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:23:52.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:23:52.868+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:23:52.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:23:52.883+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:23:52.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:23:52.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-17T17:24:23.194+0000] {processor.py:157} INFO - Started process (PID=59212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:24:23.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:24:23.234+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:24:23.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:24:23.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:24:23.329+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:24:23.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:24:23.346+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:24:23.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:24:23.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-17T17:24:53.519+0000] {processor.py:157} INFO - Started process (PID=59222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:24:53.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:24:53.528+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:24:53.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:24:53.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:24:53.649+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:24:53.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:24:53.672+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:24:53.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:24:53.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-17T17:25:23.884+0000] {processor.py:157} INFO - Started process (PID=59232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:25:23.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:25:23.890+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:25:23.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:25:23.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:25:23.935+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:25:23.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:25:23.953+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:25:23.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:25:23.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T17:25:54.199+0000] {processor.py:157} INFO - Started process (PID=59242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:25:54.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:25:54.202+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:25:54.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:25:54.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:25:54.229+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:25:54.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:25:54.239+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:25:54.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:25:54.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T17:26:24.526+0000] {processor.py:157} INFO - Started process (PID=59252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:26:24.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:26:24.531+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:26:24.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:26:24.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:26:24.577+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:26:24.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:26:24.592+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:26:24.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:26:24.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T17:26:54.830+0000] {processor.py:157} INFO - Started process (PID=59262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:26:54.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:26:54.833+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:26:54.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:26:54.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:26:54.858+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:26:54.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:26:54.870+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:26:54.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:26:54.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T17:27:25.238+0000] {processor.py:157} INFO - Started process (PID=59272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:27:25.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:27:25.245+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:27:25.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:27:25.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:27:25.286+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:27:25.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:27:25.300+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:27:25.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:27:25.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-17T17:27:55.538+0000] {processor.py:157} INFO - Started process (PID=59282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:27:55.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:27:55.543+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:27:55.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:27:55.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:27:55.569+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:27:55.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:27:55.579+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:27:55.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:27:55.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T17:28:25.862+0000] {processor.py:157} INFO - Started process (PID=59292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:28:25.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:28:25.866+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:28:25.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:28:25.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:28:25.903+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:28:25.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:28:25.916+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:28:25.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:28:25.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T17:28:56.229+0000] {processor.py:157} INFO - Started process (PID=59302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:28:56.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:28:56.233+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:28:56.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:28:56.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:28:56.258+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:28:56.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:28:56.270+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:28:56.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:28:56.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T17:29:26.624+0000] {processor.py:157} INFO - Started process (PID=59312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:29:26.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:29:26.628+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:29:26.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:29:26.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:29:26.665+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:29:26.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:29:26.679+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:29:26.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:29:26.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T17:29:57.017+0000] {processor.py:157} INFO - Started process (PID=59322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:29:57.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:29:57.021+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:29:57.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:29:57.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:29:57.073+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:29:57.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:29:57.088+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:29:57.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:29:57.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-17T17:30:27.335+0000] {processor.py:157} INFO - Started process (PID=59332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:30:27.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:30:27.342+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:30:27.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:30:27.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:30:27.412+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:30:27.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:30:27.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:30:27.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:30:27.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-17T17:30:57.665+0000] {processor.py:157} INFO - Started process (PID=59342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:30:57.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:30:57.669+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:30:57.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:30:57.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:30:57.713+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:30:57.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:30:57.730+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:30:57.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:30:57.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T17:31:27.963+0000] {processor.py:157} INFO - Started process (PID=59352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:31:27.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:31:27.965+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:31:27.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:31:27.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:31:27.992+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:31:27.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:31:28.005+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:31:28.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:31:28.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T17:31:58.298+0000] {processor.py:157} INFO - Started process (PID=59362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:31:58.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:31:58.300+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:31:58.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:31:58.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:31:58.328+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:31:58.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:31:58.339+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:31:58.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:31:58.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T17:32:28.704+0000] {processor.py:157} INFO - Started process (PID=59372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:32:28.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:32:28.709+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:32:28.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:32:28.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:32:28.749+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:32:28.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:32:28.764+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:32:28.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:32:28.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T17:32:59.051+0000] {processor.py:157} INFO - Started process (PID=59382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:32:59.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:32:59.053+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:32:59.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:32:59.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:32:59.079+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:32:59.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:32:59.090+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:32:59.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:32:59.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T17:33:29.336+0000] {processor.py:157} INFO - Started process (PID=59392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:33:29.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:33:29.339+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:33:29.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:33:29.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:33:29.365+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:33:29.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:33:29.378+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:33:29.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:33:29.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T17:33:59.720+0000] {processor.py:157} INFO - Started process (PID=59402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:33:59.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:33:59.727+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:33:59.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:33:59.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:33:59.764+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:33:59.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:33:59.779+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:33:59.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:33:59.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T17:34:30.027+0000] {processor.py:157} INFO - Started process (PID=59412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:34:30.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:34:30.030+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:34:30.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:34:30.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:34:30.055+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:34:30.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:34:30.064+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:34:30.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:34:30.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-17T17:35:00.308+0000] {processor.py:157} INFO - Started process (PID=59422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:35:00.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:35:00.312+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:35:00.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:35:00.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:35:00.350+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:35:00.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:35:00.365+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:35:00.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:35:00.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T17:35:30.628+0000] {processor.py:157} INFO - Started process (PID=59432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:35:30.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:35:30.631+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:35:30.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:35:30.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:35:30.659+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:35:30.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:35:30.671+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:35:30.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:35:30.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T17:36:01.020+0000] {processor.py:157} INFO - Started process (PID=59442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:36:01.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:36:01.025+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:36:01.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:36:01.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:36:01.069+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:36:01.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:36:01.087+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:36:01.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:36:01.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T17:36:31.283+0000] {processor.py:157} INFO - Started process (PID=59452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:36:31.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:36:31.289+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:36:31.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:36:31.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:36:31.333+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:36:31.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:36:31.348+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:36:31.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:36:31.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T17:37:01.607+0000] {processor.py:157} INFO - Started process (PID=59462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:37:01.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:37:01.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:37:01.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:37:01.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:37:01.649+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:37:01.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:37:01.663+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:37:01.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:37:01.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T17:37:31.930+0000] {processor.py:157} INFO - Started process (PID=59472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:37:31.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:37:31.938+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:37:31.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:37:31.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:37:31.960+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:37:31.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:37:31.971+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:37:31.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:37:31.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T17:38:02.289+0000] {processor.py:157} INFO - Started process (PID=59482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:38:02.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:38:02.296+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:38:02.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:38:02.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:38:02.364+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:38:02.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:38:02.384+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:38:02.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:38:02.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-17T17:38:32.607+0000] {processor.py:157} INFO - Started process (PID=59492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:38:32.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:38:32.614+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:38:32.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:38:32.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:38:32.653+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:38:32.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:38:32.668+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:38:32.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:38:32.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T17:39:03.007+0000] {processor.py:157} INFO - Started process (PID=59502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:39:03.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:39:03.017+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:39:03.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:39:03.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:39:03.048+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:39:03.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:39:03.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:39:03.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:39:03.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T17:39:33.393+0000] {processor.py:157} INFO - Started process (PID=59512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:39:33.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:39:33.399+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:39:33.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:39:33.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:39:33.444+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:39:33.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:39:33.481+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:39:33.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:39:33.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-17T17:40:03.862+0000] {processor.py:157} INFO - Started process (PID=59522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:40:03.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:40:03.871+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:40:03.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:40:03.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:40:03.927+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:40:03.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:40:03.943+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:40:03.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:40:03.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T17:40:34.150+0000] {processor.py:157} INFO - Started process (PID=59532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:40:34.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:40:34.153+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:40:34.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:40:34.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:40:34.178+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:40:34.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:40:34.190+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:40:34.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:40:34.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T17:41:04.465+0000] {processor.py:157} INFO - Started process (PID=59542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:41:04.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:41:04.471+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:41:04.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:41:04.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:41:04.537+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:41:04.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:41:04.554+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:41:04.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:41:04.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T17:41:34.805+0000] {processor.py:157} INFO - Started process (PID=59552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:41:34.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:41:34.808+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:41:34.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:41:34.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:41:34.850+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:41:34.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:41:34.865+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:41:34.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:41:34.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T17:42:05.290+0000] {processor.py:157} INFO - Started process (PID=59562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:42:05.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:42:05.298+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:42:05.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:42:05.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:42:05.360+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:42:05.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:42:05.379+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:42:05.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:42:05.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T17:42:35.727+0000] {processor.py:157} INFO - Started process (PID=59572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:42:35.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:42:35.740+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:42:35.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:42:35.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:42:35.803+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:42:35.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:42:35.818+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:42:35.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:42:35.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-17T17:43:06.034+0000] {processor.py:157} INFO - Started process (PID=59582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:43:06.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:43:06.040+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:43:06.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:43:06.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:43:06.107+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:43:06.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:43:06.122+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:43:06.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:43:06.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T17:43:36.400+0000] {processor.py:157} INFO - Started process (PID=59592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:43:36.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:43:36.407+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:43:36.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:43:36.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:43:36.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:43:36.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:43:36.467+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:43:36.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:43:36.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-17T17:44:06.801+0000] {processor.py:157} INFO - Started process (PID=59602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:44:06.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:44:06.820+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:44:06.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:44:06.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:44:06.869+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:44:06.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:44:06.885+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:44:06.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:44:06.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T17:44:37.153+0000] {processor.py:157} INFO - Started process (PID=59612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:44:37.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:44:37.159+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:44:37.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:44:37.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:44:37.223+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:44:37.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:44:37.241+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:44:37.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:44:37.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T17:45:07.449+0000] {processor.py:157} INFO - Started process (PID=59622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:45:07.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:45:07.462+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:45:07.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:45:07.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:45:07.504+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:45:07.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:45:07.519+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:45:07.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:45:07.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T17:45:37.706+0000] {processor.py:157} INFO - Started process (PID=59632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:45:37.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:45:37.709+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:45:37.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:45:37.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:45:37.738+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:45:37.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:45:37.749+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:45:37.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:45:37.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T17:46:08.075+0000] {processor.py:157} INFO - Started process (PID=59642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:46:08.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:46:08.082+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:46:08.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:46:08.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:46:08.144+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:46:08.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:46:08.170+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:46:08.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:46:08.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-17T17:46:38.376+0000] {processor.py:157} INFO - Started process (PID=59651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:46:38.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:46:38.381+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:46:38.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:46:38.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:46:38.425+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:46:38.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:46:38.439+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:46:38.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:46:38.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-17T17:47:08.707+0000] {processor.py:157} INFO - Started process (PID=59662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:47:08.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:47:08.713+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:47:08.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:47:08.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:47:08.758+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:47:08.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:47:08.772+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:47:08.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:47:08.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T17:47:39.021+0000] {processor.py:157} INFO - Started process (PID=59672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:47:39.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:47:39.027+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:47:39.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:47:39.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:47:39.064+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:47:39.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:47:39.083+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:47:39.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:47:39.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T17:48:09.409+0000] {processor.py:157} INFO - Started process (PID=59682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:48:09.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:48:09.412+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:48:09.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:48:09.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:48:09.447+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:48:09.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:48:09.460+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:48:09.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:48:09.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T17:48:39.771+0000] {processor.py:157} INFO - Started process (PID=59692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:48:39.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:48:39.776+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:48:39.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:48:39.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:48:39.821+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:48:39.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:48:39.832+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:48:39.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:48:39.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T17:49:10.174+0000] {processor.py:157} INFO - Started process (PID=59702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:49:10.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:49:10.179+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:49:10.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:49:10.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:49:10.216+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:49:10.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:49:10.233+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:49:10.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:49:10.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T17:49:40.530+0000] {processor.py:157} INFO - Started process (PID=59712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:49:40.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:49:40.535+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:49:40.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:49:40.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:49:40.575+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:49:40.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:49:40.591+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:49:40.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:49:40.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T17:50:10.902+0000] {processor.py:157} INFO - Started process (PID=59721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:50:10.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:50:10.910+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:50:10.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:50:10.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:50:10.968+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:50:10.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:50:10.983+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:50:10.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:50:10.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T17:50:41.270+0000] {processor.py:157} INFO - Started process (PID=59732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:50:41.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:50:41.278+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:50:41.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:50:41.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:50:41.353+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:50:41.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:50:41.372+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:50:41.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:50:41.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-17T17:51:11.644+0000] {processor.py:157} INFO - Started process (PID=59741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:51:11.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:51:11.650+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:51:11.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:51:11.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:51:11.694+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:51:11.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:51:11.716+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:51:11.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:51:11.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T17:51:41.938+0000] {processor.py:157} INFO - Started process (PID=59752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:51:41.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:51:41.944+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:51:41.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:51:41.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:51:41.989+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:51:41.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:51:42.003+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:51:42.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:51:42.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T17:52:12.354+0000] {processor.py:157} INFO - Started process (PID=59762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:52:12.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:52:12.360+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:52:12.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:52:12.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:52:12.402+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:52:12.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:52:12.424+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:52:12.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:52:12.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T17:52:42.736+0000] {processor.py:157} INFO - Started process (PID=59772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:52:42.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:52:42.740+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:52:42.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:52:42.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:52:42.762+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:52:42.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:52:42.772+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:52:42.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:52:42.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-17T17:53:13.090+0000] {processor.py:157} INFO - Started process (PID=59782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:53:13.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:53:13.094+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:53:13.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:53:13.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:53:13.156+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:53:13.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:53:13.172+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:53:13.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:53:13.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T17:53:43.462+0000] {processor.py:157} INFO - Started process (PID=59792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:53:43.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:53:43.466+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:53:43.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:53:43.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:53:43.503+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:53:43.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:53:43.517+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:53:43.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:53:43.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T17:54:13.887+0000] {processor.py:157} INFO - Started process (PID=59802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:54:13.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:54:13.893+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:54:13.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:54:13.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:54:13.967+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:54:13.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:54:13.983+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:54:13.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:54:13.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-17T17:54:44.165+0000] {processor.py:157} INFO - Started process (PID=59812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:54:44.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:54:44.171+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:54:44.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:54:44.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:54:44.195+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:54:44.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:54:44.205+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:54:44.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:54:44.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T17:55:14.513+0000] {processor.py:157} INFO - Started process (PID=59822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:55:14.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:55:14.517+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:55:14.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:55:14.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:55:14.561+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:55:14.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:55:14.575+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:55:14.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:55:14.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T17:55:44.802+0000] {processor.py:157} INFO - Started process (PID=59832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:55:44.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:55:44.810+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:55:44.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:55:44.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:55:44.835+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:55:44.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:55:44.848+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:55:44.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:55:44.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T17:56:15.200+0000] {processor.py:157} INFO - Started process (PID=59842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:56:15.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:56:15.205+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:56:15.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:56:15.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:56:15.249+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:56:15.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:56:15.263+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:56:15.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:56:15.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-17T17:56:45.541+0000] {processor.py:157} INFO - Started process (PID=59852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:56:45.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:56:45.546+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:56:45.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:56:45.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:56:45.583+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:56:45.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:56:45.597+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:56:45.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:56:45.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T17:57:15.850+0000] {processor.py:157} INFO - Started process (PID=59862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:57:15.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:57:15.853+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:57:15.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:57:15.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:57:15.879+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:57:15.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:57:15.889+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:57:15.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:57:15.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T17:57:46.271+0000] {processor.py:157} INFO - Started process (PID=59872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:57:46.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:57:46.279+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:57:46.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:57:46.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:57:46.342+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:57:46.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:57:46.357+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:57:46.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:57:46.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T17:58:18.648+0000] {processor.py:157} INFO - Started process (PID=59882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:58:18.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:58:18.663+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:58:18.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:58:18.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:58:18.763+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:58:18.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:58:18.790+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:58:18.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:58:18.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-08-17T17:58:52.438+0000] {processor.py:157} INFO - Started process (PID=59892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:58:52.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T17:58:52.442+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:58:52.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:58:52.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T17:58:52.503+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:58:52.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T17:58:52.526+0000] {logging_mixin.py:151} INFO - [2024-08-17T17:58:52.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T17:58:52.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T18:16:15.016+0000] {processor.py:157} INFO - Started process (PID=59904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:16:15.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:16:15.026+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:16:15.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:16:15.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:16:15.093+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:16:15.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:16:15.129+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:16:15.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:16:15.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-17T18:16:45.330+0000] {processor.py:157} INFO - Started process (PID=59914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:16:45.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:16:45.336+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:16:45.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:16:45.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:16:45.403+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:16:45.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:16:45.421+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:16:45.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:16:45.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-17T18:17:15.638+0000] {processor.py:157} INFO - Started process (PID=59924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:17:15.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:17:15.643+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:17:15.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:17:15.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:17:15.676+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:17:15.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:17:15.690+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:17:15.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:17:15.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T18:17:45.935+0000] {processor.py:157} INFO - Started process (PID=59934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:17:45.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:17:45.941+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:17:45.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:17:45.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:17:45.977+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:17:45.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:17:45.990+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:17:45.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:17:46.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T18:18:16.305+0000] {processor.py:157} INFO - Started process (PID=59944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:18:16.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:18:16.306+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:18:16.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:18:16.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:18:16.335+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:18:16.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:18:16.347+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:18:16.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:18:16.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T18:18:46.593+0000] {processor.py:157} INFO - Started process (PID=59954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:18:46.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:18:46.596+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:18:46.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:18:46.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:18:46.624+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:18:46.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:18:46.636+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:18:46.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:18:46.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T18:19:16.901+0000] {processor.py:157} INFO - Started process (PID=59963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:19:16.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:19:16.905+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:19:16.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:19:16.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:19:16.938+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:19:16.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:19:16.953+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:19:16.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:19:16.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T18:19:47.320+0000] {processor.py:157} INFO - Started process (PID=59974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:19:47.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:19:47.324+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:19:47.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:19:47.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:19:47.349+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:19:47.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:19:47.360+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:19:47.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:19:47.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T18:20:17.638+0000] {processor.py:157} INFO - Started process (PID=59984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:20:17.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:20:17.643+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:20:17.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:20:17.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:20:17.681+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:20:17.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:20:17.695+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:20:17.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:20:17.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T18:37:01.264+0000] {processor.py:157} INFO - Started process (PID=59996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:37:01.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:37:01.283+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:37:01.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:37:01.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:37:01.353+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:37:01.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:37:01.381+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:37:01.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:37:01.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-17T18:37:31.613+0000] {processor.py:157} INFO - Started process (PID=60006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:37:31.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:37:31.617+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:37:31.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:37:31.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:37:31.653+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:37:31.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:37:31.663+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:37:31.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:37:31.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T18:54:18.290+0000] {processor.py:157} INFO - Started process (PID=60016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:54:18.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:54:18.293+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:54:18.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:54:18.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:54:18.325+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:54:18.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:54:18.337+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:54:18.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:54:18.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T18:54:48.681+0000] {processor.py:157} INFO - Started process (PID=60026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:54:48.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:54:48.685+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:54:48.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:54:48.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:54:48.735+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:54:48.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:54:48.754+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:54:48.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:54:48.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T18:55:19.023+0000] {processor.py:157} INFO - Started process (PID=60036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:55:19.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:55:19.027+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:55:19.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:55:19.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:55:19.066+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:55:19.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:55:19.080+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:55:19.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:55:19.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T18:55:49.346+0000] {processor.py:157} INFO - Started process (PID=60046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:55:49.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:55:49.350+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:55:49.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:55:49.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:55:49.382+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:55:49.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:55:49.395+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:55:49.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:55:49.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T18:56:19.754+0000] {processor.py:157} INFO - Started process (PID=60056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:56:19.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:56:19.758+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:56:19.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:56:19.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:56:19.814+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:56:19.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:56:19.829+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:56:19.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:56:19.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T18:56:50.129+0000] {processor.py:157} INFO - Started process (PID=60066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:56:50.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T18:56:50.132+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:56:50.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:56:50.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T18:56:50.160+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:56:50.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T18:56:50.173+0000] {logging_mixin.py:151} INFO - [2024-08-17T18:56:50.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T18:56:50.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T19:12:58.866+0000] {processor.py:157} INFO - Started process (PID=60076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:12:58.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:12:58.876+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:12:58.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:12:58.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:12:58.935+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:12:58.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:12:58.968+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:12:58.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:12:58.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-17T19:13:29.319+0000] {processor.py:157} INFO - Started process (PID=60086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:13:29.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:13:29.337+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:13:29.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:13:29.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:13:29.378+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:13:29.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:13:29.396+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:13:29.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:13:29.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-17T19:31:29.464+0000] {processor.py:157} INFO - Started process (PID=60098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:31:29.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:31:29.468+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:31:29.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:31:29.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:31:29.497+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:31:29.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:31:29.509+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:31:29.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:31:29.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T19:47:11.868+0000] {processor.py:157} INFO - Started process (PID=60106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:47:11.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:47:11.878+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:47:11.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:47:11.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:47:11.969+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:47:11.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:47:12.025+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:47:12.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:47:12.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-17T19:47:42.221+0000] {processor.py:157} INFO - Started process (PID=60118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:47:42.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:47:42.225+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:47:42.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:47:42.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:47:42.276+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:47:42.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:47:42.292+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:47:42.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:47:42.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-17T19:48:12.534+0000] {processor.py:157} INFO - Started process (PID=60128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:48:12.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:48:12.538+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:48:12.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:48:12.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:48:12.564+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:48:12.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:48:12.576+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:48:12.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:48:12.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T19:48:42.924+0000] {processor.py:157} INFO - Started process (PID=60138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:48:42.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:48:42.928+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:48:42.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:48:42.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:48:42.960+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:48:42.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:48:42.973+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:48:42.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:48:42.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T19:49:13.338+0000] {processor.py:157} INFO - Started process (PID=60148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:49:13.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:49:13.342+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:49:13.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:49:13.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:49:13.378+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:49:13.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:49:13.393+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:49:13.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:49:13.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-17T19:59:37.841+0000] {processor.py:157} INFO - Started process (PID=60160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:59:37.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T19:59:37.846+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:59:37.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:59:37.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T19:59:37.902+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:59:37.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T19:59:37.926+0000] {logging_mixin.py:151} INFO - [2024-08-17T19:59:37.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T19:59:37.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T20:00:08.234+0000] {processor.py:157} INFO - Started process (PID=60170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:00:08.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:00:08.237+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:00:08.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:00:08.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:00:08.291+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:00:08.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:00:08.307+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:00:08.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:00:08.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T20:17:17.363+0000] {processor.py:157} INFO - Started process (PID=60180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:17:17.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:17:17.370+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:17:17.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:17:17.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:17:17.426+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:17:17.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:17:17.454+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:17:17.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:17:17.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-17T20:34:24.896+0000] {processor.py:157} INFO - Started process (PID=60189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:34:24.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:34:24.912+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:34:24.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:34:24.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:34:24.987+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:34:24.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:34:25.021+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:34:25.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:34:25.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-17T20:34:55.234+0000] {processor.py:157} INFO - Started process (PID=60198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:34:55.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:34:55.239+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:34:55.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:34:55.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:34:55.281+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:34:55.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:34:55.302+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:34:55.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:34:55.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-17T20:35:25.702+0000] {processor.py:157} INFO - Started process (PID=60210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:35:25.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:35:25.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:35:25.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:35:25.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:35:25.732+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:35:25.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:35:25.744+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:35:25.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:35:25.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T20:35:56.088+0000] {processor.py:157} INFO - Started process (PID=60220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:35:56.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:35:56.091+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:35:56.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:35:56.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:35:56.126+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:35:56.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:35:56.139+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:35:56.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:35:56.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T20:36:26.494+0000] {processor.py:157} INFO - Started process (PID=60230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:36:26.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:36:26.497+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:36:26.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:36:26.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:36:26.525+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:36:26.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:36:26.535+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:36:26.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:36:26.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T20:36:56.835+0000] {processor.py:157} INFO - Started process (PID=60240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:36:56.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:36:56.840+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:36:56.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:36:56.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:36:56.874+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:36:56.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:36:56.888+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:36:56.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:36:56.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T20:52:31.389+0000] {processor.py:157} INFO - Started process (PID=60250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:52:31.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:52:31.393+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:52:31.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:52:31.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:52:31.427+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:52:31.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:52:31.443+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:52:31.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:52:31.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T20:53:01.841+0000] {processor.py:157} INFO - Started process (PID=60260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:53:01.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:53:01.846+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:53:01.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:53:01.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:53:01.883+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:53:01.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:53:01.898+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:53:01.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:53:01.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T20:53:32.165+0000] {processor.py:157} INFO - Started process (PID=60270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:53:32.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:53:32.167+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:53:32.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:53:32.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:53:32.192+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:53:32.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:53:32.202+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:53:32.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:53:32.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-17T20:54:02.607+0000] {processor.py:157} INFO - Started process (PID=60280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:54:02.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:54:02.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:54:02.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:54:02.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:54:02.652+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:54:02.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:54:02.665+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:54:02.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:54:02.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T20:54:33.093+0000] {processor.py:157} INFO - Started process (PID=60290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:54:33.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T20:54:33.096+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:54:33.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:54:33.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T20:54:33.141+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:54:33.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T20:54:33.174+0000] {logging_mixin.py:151} INFO - [2024-08-17T20:54:33.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T20:54:33.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T21:00:40.520+0000] {processor.py:157} INFO - Started process (PID=60301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:00:40.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:00:40.525+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:00:40.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:00:40.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:00:40.568+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:00:40.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:00:40.600+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:00:40.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:00:40.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-17T21:01:10.836+0000] {processor.py:157} INFO - Started process (PID=60312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:01:10.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:01:10.840+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:01:10.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:01:10.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:01:10.880+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:01:10.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:01:10.894+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:01:10.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:01:10.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T21:06:43.298+0000] {processor.py:157} INFO - Started process (PID=60322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:06:43.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:06:43.304+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:06:43.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:06:43.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:06:43.353+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:06:43.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:06:43.377+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:06:43.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:06:43.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-17T21:07:13.684+0000] {processor.py:157} INFO - Started process (PID=60332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:07:13.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:07:13.689+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:07:13.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:07:13.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:07:13.722+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:07:13.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:07:13.735+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:07:13.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:07:13.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T21:07:44.011+0000] {processor.py:157} INFO - Started process (PID=60342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:07:44.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:07:44.014+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:07:44.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:07:44.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:07:44.064+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:07:44.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:07:44.076+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:07:44.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:07:44.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-17T21:08:14.283+0000] {processor.py:157} INFO - Started process (PID=60352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:08:14.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:08:14.285+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:08:14.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:08:14.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:08:14.312+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:08:14.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:08:14.323+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:08:14.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:08:14.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T21:08:44.668+0000] {processor.py:157} INFO - Started process (PID=60362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:08:44.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:08:44.670+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:08:44.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:08:44.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:08:44.696+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:08:44.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:08:44.708+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:08:44.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:08:44.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T21:09:15.034+0000] {processor.py:157} INFO - Started process (PID=60372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:09:15.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:09:15.036+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:09:15.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:09:15.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:09:15.066+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:09:15.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:09:15.078+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:09:15.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:09:15.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T21:09:45.398+0000] {processor.py:157} INFO - Started process (PID=60382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:09:45.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:09:45.403+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:09:45.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:09:45.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:09:45.437+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:09:45.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:09:45.452+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:09:45.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:09:45.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T21:10:15.849+0000] {processor.py:157} INFO - Started process (PID=60390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:10:15.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:10:15.858+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:10:15.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:10:15.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:10:15.938+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:10:15.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:10:15.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:10:15.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:10:15.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-17T21:10:46.342+0000] {processor.py:157} INFO - Started process (PID=60402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:10:46.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:10:46.346+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:10:46.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:10:46.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:10:46.373+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:10:46.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:10:46.384+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:10:46.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:10:46.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:11:16.748+0000] {processor.py:157} INFO - Started process (PID=60412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:11:16.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:11:16.766+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:11:16.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:11:16.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:11:16.820+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:11:16.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:11:16.833+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:11:16.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:11:16.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T21:11:47.097+0000] {processor.py:157} INFO - Started process (PID=60422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:11:47.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:11:47.104+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:11:47.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:11:47.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:11:47.143+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:11:47.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:11:47.159+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:11:47.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:11:47.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T21:12:17.541+0000] {processor.py:157} INFO - Started process (PID=60432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:12:17.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:12:17.544+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:12:17.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:12:17.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:12:17.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:12:17.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:12:17.636+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:12:17.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:12:17.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-17T21:12:47.847+0000] {processor.py:157} INFO - Started process (PID=60442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:12:47.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:12:47.852+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:12:47.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:12:47.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:12:47.878+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:12:47.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:12:47.889+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:12:47.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:12:47.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T21:13:18.189+0000] {processor.py:157} INFO - Started process (PID=60452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:13:18.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:13:18.192+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:13:18.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:13:18.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:13:18.228+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:13:18.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:13:18.242+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:13:18.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:13:18.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T21:13:48.555+0000] {processor.py:157} INFO - Started process (PID=60462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:13:48.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:13:48.562+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:13:48.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:13:48.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:13:48.587+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:13:48.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:13:48.597+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:13:48.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:13:48.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T21:14:18.915+0000] {processor.py:157} INFO - Started process (PID=60472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:14:18.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:14:18.918+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:14:18.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:14:18.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:14:18.945+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:14:18.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:14:18.957+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:14:18.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:14:18.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:14:49.249+0000] {processor.py:157} INFO - Started process (PID=60482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:14:49.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:14:49.252+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:14:49.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:14:49.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:14:49.280+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:14:49.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:14:49.291+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:14:49.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:14:49.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T21:15:19.696+0000] {processor.py:157} INFO - Started process (PID=60492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:15:19.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:15:19.702+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:15:19.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:15:19.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:15:19.746+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:15:19.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:15:19.760+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:15:19.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:15:19.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T21:15:50.130+0000] {processor.py:157} INFO - Started process (PID=60502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:15:50.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:15:50.137+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:15:50.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:15:50.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:15:50.192+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:15:50.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:15:50.208+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:15:50.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:15:50.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-17T21:16:20.601+0000] {processor.py:157} INFO - Started process (PID=60512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:16:20.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:16:20.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:16:20.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:16:20.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:16:20.665+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:16:20.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:16:20.681+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:16:20.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:16:20.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T21:16:50.992+0000] {processor.py:157} INFO - Started process (PID=60521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:16:50.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:16:50.998+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:16:50.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:16:51.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:16:51.052+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:16:51.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:16:51.067+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:16:51.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:16:51.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T21:17:21.270+0000] {processor.py:157} INFO - Started process (PID=60532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:17:21.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:17:21.272+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:17:21.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:17:21.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:17:21.298+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:17:21.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:17:21.310+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:17:21.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:17:21.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:17:51.677+0000] {processor.py:157} INFO - Started process (PID=60542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:17:51.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:17:51.680+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:17:51.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:17:51.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:17:51.708+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:17:51.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:17:51.720+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:17:51.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:17:51.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T21:18:22.061+0000] {processor.py:157} INFO - Started process (PID=60552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:18:22.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:18:22.070+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:18:22.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:18:22.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:18:22.109+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:18:22.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:18:22.124+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:18:22.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:18:22.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T21:18:52.342+0000] {processor.py:157} INFO - Started process (PID=60562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:18:52.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:18:52.344+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:18:52.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:18:52.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:18:52.374+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:18:52.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:18:52.383+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:18:52.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:18:52.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T21:19:22.696+0000] {processor.py:157} INFO - Started process (PID=60572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:19:22.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:19:22.698+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:19:22.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:19:22.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:19:22.725+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:19:22.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:19:22.736+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:19:22.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:19:22.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T21:19:52.998+0000] {processor.py:157} INFO - Started process (PID=60582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:19:53.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:19:53.002+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:19:53.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:19:53.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:19:53.027+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:19:53.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:19:53.037+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:19:53.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:19:53.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T21:20:23.270+0000] {processor.py:157} INFO - Started process (PID=60592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:20:23.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:20:23.274+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:20:23.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:20:23.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:20:23.300+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:20:23.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:20:23.310+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:20:23.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:20:23.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T21:20:53.627+0000] {processor.py:157} INFO - Started process (PID=60602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:20:53.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:20:53.631+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:20:53.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:20:53.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:20:53.670+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:20:53.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:20:53.684+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:20:53.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:20:53.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T21:21:24.037+0000] {processor.py:157} INFO - Started process (PID=60612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:21:24.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:21:24.039+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:21:24.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:21:24.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:21:24.065+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:21:24.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:21:24.078+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:21:24.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:21:24.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:21:54.405+0000] {processor.py:157} INFO - Started process (PID=60622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:21:54.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:21:54.409+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:21:54.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:21:54.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:21:54.435+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:21:54.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:21:54.446+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:21:54.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:21:54.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:22:24.805+0000] {processor.py:157} INFO - Started process (PID=60632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:22:24.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:22:24.809+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:22:24.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:22:24.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:22:24.838+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:22:24.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:22:24.848+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:22:24.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:22:24.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T21:22:55.229+0000] {processor.py:157} INFO - Started process (PID=60642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:22:55.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:22:55.233+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:22:55.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:22:55.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:22:55.275+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:22:55.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:22:55.288+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:22:55.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:22:55.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T21:23:25.595+0000] {processor.py:157} INFO - Started process (PID=60652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:23:25.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:23:25.599+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:23:25.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:23:25.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:23:25.624+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:23:25.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:23:25.634+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:23:25.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:23:25.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T21:23:56.000+0000] {processor.py:157} INFO - Started process (PID=60662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:23:56.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:23:56.003+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:23:56.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:23:56.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:23:56.029+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:23:56.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:23:56.040+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:23:56.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:23:56.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T21:24:26.446+0000] {processor.py:157} INFO - Started process (PID=60672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:24:26.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:24:26.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:24:26.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:24:26.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:24:26.477+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:24:26.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:24:26.488+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:24:26.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:24:26.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T21:24:56.901+0000] {processor.py:157} INFO - Started process (PID=60682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:24:56.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:24:56.907+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:24:56.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:24:56.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:24:56.971+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:24:56.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:24:56.986+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:24:56.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:24:56.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-17T21:25:27.327+0000] {processor.py:157} INFO - Started process (PID=60692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:25:27.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:25:27.329+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:25:27.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:25:27.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:25:27.356+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:25:27.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:25:27.367+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:25:27.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:25:27.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:25:57.728+0000] {processor.py:157} INFO - Started process (PID=60702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:25:57.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:25:57.732+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:25:57.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:25:57.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:25:57.760+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:25:57.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:25:57.770+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:25:57.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:25:57.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T21:26:28.113+0000] {processor.py:157} INFO - Started process (PID=60712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:26:28.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:26:28.118+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:26:28.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:26:28.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:26:28.158+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:26:28.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:26:28.173+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:26:28.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:26:28.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T21:26:58.464+0000] {processor.py:157} INFO - Started process (PID=60722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:26:58.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:26:58.466+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:26:58.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:26:58.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:26:58.488+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:26:58.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:26:58.499+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:26:58.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:26:58.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-17T21:27:28.885+0000] {processor.py:157} INFO - Started process (PID=60732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:27:28.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:27:28.888+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:27:28.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:27:28.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:27:28.916+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:27:28.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:27:28.930+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:27:28.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:27:28.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T21:27:59.293+0000] {processor.py:157} INFO - Started process (PID=60742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:27:59.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:27:59.297+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:27:59.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:27:59.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:27:59.335+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:27:59.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:27:59.349+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:27:59.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:27:59.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T21:28:29.664+0000] {processor.py:157} INFO - Started process (PID=60752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:28:29.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:28:29.666+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:28:29.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:28:29.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:28:29.703+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:28:29.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:28:29.712+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:28:29.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:28:29.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T21:29:00.199+0000] {processor.py:157} INFO - Started process (PID=60762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:29:00.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:29:00.202+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:29:00.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:29:00.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:29:00.235+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:29:00.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:29:00.247+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:29:00.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:29:00.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T21:29:30.576+0000] {processor.py:157} INFO - Started process (PID=60772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:29:30.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:29:30.581+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:29:30.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:29:30.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:29:30.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:29:30.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:29:30.626+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:29:30.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:29:30.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T21:30:01.001+0000] {processor.py:157} INFO - Started process (PID=60782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:30:01.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:30:01.004+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:30:01.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:30:01.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:30:01.029+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:30:01.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:30:01.041+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:30:01.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:30:01.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T21:30:31.445+0000] {processor.py:157} INFO - Started process (PID=60792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:30:31.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:30:31.452+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:30:31.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:30:31.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:30:31.493+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:30:31.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:30:31.516+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:30:31.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:30:31.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-17T21:31:01.834+0000] {processor.py:157} INFO - Started process (PID=60802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:31:01.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:31:01.838+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:31:01.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:31:01.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:31:01.864+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:31:01.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:31:01.874+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:31:01.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:31:01.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T21:31:32.174+0000] {processor.py:157} INFO - Started process (PID=60810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:31:32.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:31:32.178+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:31:32.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:31:32.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:31:32.213+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:31:32.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:31:32.227+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:31:32.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:31:32.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T21:32:02.572+0000] {processor.py:157} INFO - Started process (PID=60822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:32:02.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:32:02.575+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:32:02.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:32:02.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:32:02.608+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:32:02.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:32:02.621+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:32:02.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:32:02.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T21:32:32.887+0000] {processor.py:157} INFO - Started process (PID=60832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:32:32.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:32:32.891+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:32:32.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:32:32.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:32:32.923+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:32:32.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:32:32.933+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:32:32.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:32:32.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T21:33:03.404+0000] {processor.py:157} INFO - Started process (PID=60842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:33:03.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:33:03.407+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:33:03.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:33:03.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:33:03.436+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:33:03.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:33:03.449+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:33:03.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:33:03.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T21:33:33.769+0000] {processor.py:157} INFO - Started process (PID=60852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:33:33.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:33:33.772+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:33:33.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:33:33.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:33:33.806+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:33:33.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:33:33.819+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:33:33.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:33:33.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T21:34:04.253+0000] {processor.py:157} INFO - Started process (PID=60862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:34:04.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:34:04.256+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:34:04.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:34:04.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:34:04.285+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:34:04.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:34:04.295+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:34:04.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:34:04.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:34:34.655+0000] {processor.py:157} INFO - Started process (PID=60872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:34:34.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:34:34.658+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:34:34.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:34:34.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:34:34.683+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:34:34.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:34:34.697+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:34:34.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:34:34.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T21:35:05.026+0000] {processor.py:157} INFO - Started process (PID=60882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:35:05.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:35:05.031+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:35:05.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:35:05.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:35:05.063+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:35:05.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:35:05.074+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:35:05.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:35:05.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T21:35:35.497+0000] {processor.py:157} INFO - Started process (PID=60892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:35:35.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:35:35.499+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:35:35.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:35:35.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:35:35.532+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:35:35.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:35:35.549+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:35:35.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:35:35.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T21:36:05.910+0000] {processor.py:157} INFO - Started process (PID=60902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:36:05.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:36:05.913+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:36:05.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:36:05.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:36:05.940+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:36:05.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:36:05.951+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:36:05.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:36:05.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T21:36:36.274+0000] {processor.py:157} INFO - Started process (PID=60912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:36:36.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:36:36.278+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:36:36.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:36:36.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:36:36.341+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:36:36.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:36:36.356+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:36:36.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:36:36.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-17T21:37:06.652+0000] {processor.py:157} INFO - Started process (PID=60922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:37:06.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:37:06.661+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:37:06.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:37:06.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:37:06.695+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:37:06.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:37:06.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:37:06.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:37:06.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T21:37:36.999+0000] {processor.py:157} INFO - Started process (PID=60932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:37:37.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:37:37.005+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:37:37.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:37:37.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:37:37.048+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:37:37.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:37:37.062+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:37:37.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:37:37.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T21:38:07.459+0000] {processor.py:157} INFO - Started process (PID=60942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:38:07.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:38:07.463+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:38:07.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:38:07.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:38:07.489+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:38:07.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:38:07.501+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:38:07.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:38:07.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T21:38:37.846+0000] {processor.py:157} INFO - Started process (PID=60952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:38:37.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:38:37.849+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:38:37.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:38:37.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:38:37.877+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:38:37.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:38:37.888+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:38:37.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:38:37.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T21:39:08.202+0000] {processor.py:157} INFO - Started process (PID=60962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:39:08.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:39:08.207+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:39:08.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:39:08.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:39:08.243+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:39:08.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:39:08.256+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:39:08.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:39:08.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T21:39:38.558+0000] {processor.py:157} INFO - Started process (PID=60972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:39:38.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:39:38.561+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:39:38.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:39:38.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:39:38.589+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:39:38.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:39:38.601+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:39:38.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:39:38.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T21:40:09.089+0000] {processor.py:157} INFO - Started process (PID=60981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:40:09.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:40:09.094+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:40:09.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:40:09.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:40:09.156+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:40:09.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:40:09.172+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:40:09.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:40:09.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-17T21:40:39.491+0000] {processor.py:157} INFO - Started process (PID=60991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:40:39.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:40:39.504+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:40:39.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:40:39.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:40:39.545+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:40:39.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:40:39.570+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:40:39.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:40:39.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-17T21:41:09.913+0000] {processor.py:157} INFO - Started process (PID=61002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:41:09.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:41:09.916+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:41:09.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:41:09.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:41:09.942+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:41:09.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:41:09.952+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:41:09.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:41:09.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T21:41:40.364+0000] {processor.py:157} INFO - Started process (PID=61012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:41:40.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:41:40.369+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:41:40.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:41:40.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:41:40.439+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:41:40.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:41:40.455+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:41:40.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:41:40.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T21:42:10.862+0000] {processor.py:157} INFO - Started process (PID=61022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:42:10.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:42:10.868+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:42:10.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:42:10.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:42:10.903+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:42:10.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:42:10.918+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:42:10.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:42:10.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T21:42:41.150+0000] {processor.py:157} INFO - Started process (PID=61032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:42:41.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:42:41.152+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:42:41.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:42:41.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:42:41.181+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:42:41.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:42:41.193+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:42:41.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:42:41.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T21:43:11.429+0000] {processor.py:157} INFO - Started process (PID=61042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:43:11.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:43:11.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:43:11.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:43:11.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:43:11.509+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:43:11.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:43:11.523+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:43:11.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:43:11.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T21:43:41.711+0000] {processor.py:157} INFO - Started process (PID=61052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:43:41.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:43:41.713+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:43:41.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:43:41.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:43:41.742+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:43:41.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:43:41.752+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:43:41.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:43:41.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:44:12.236+0000] {processor.py:157} INFO - Started process (PID=61062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:44:12.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:44:12.240+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:44:12.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:44:12.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:44:12.277+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:44:12.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:44:12.290+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:44:12.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:44:12.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T21:44:42.608+0000] {processor.py:157} INFO - Started process (PID=61072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:44:42.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:44:42.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:44:42.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:44:42.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:44:42.642+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:44:42.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:44:42.653+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:44:42.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:44:42.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T21:45:13.089+0000] {processor.py:157} INFO - Started process (PID=61082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:45:13.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:45:13.093+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:45:13.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:45:13.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:45:13.120+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:45:13.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:45:13.131+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:45:13.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:45:13.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T21:45:43.398+0000] {processor.py:157} INFO - Started process (PID=61092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:45:43.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:45:43.401+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:45:43.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:45:43.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:45:43.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:45:43.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:45:43.453+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:45:43.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:45:43.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T21:46:13.748+0000] {processor.py:157} INFO - Started process (PID=61102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:46:13.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:46:13.751+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:46:13.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:46:13.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:46:13.789+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:46:13.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:46:13.809+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:46:13.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:46:13.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T21:46:44.112+0000] {processor.py:157} INFO - Started process (PID=61112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:46:44.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:46:44.115+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:46:44.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:46:44.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:46:44.144+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:46:44.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:46:44.156+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:46:44.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:46:44.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T21:47:14.521+0000] {processor.py:157} INFO - Started process (PID=61122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:47:14.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:47:14.526+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:47:14.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:47:14.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:47:14.573+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:47:14.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:47:14.589+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:47:14.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:47:14.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T21:47:44.925+0000] {processor.py:157} INFO - Started process (PID=61132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:47:44.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:47:44.927+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:47:44.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:47:44.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:47:44.952+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:47:44.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:47:44.965+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:47:44.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:47:44.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T21:48:15.388+0000] {processor.py:157} INFO - Started process (PID=61142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:48:15.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:48:15.402+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:48:15.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:48:15.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:48:15.441+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:48:15.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:48:15.457+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:48:15.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:48:15.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T21:48:45.723+0000] {processor.py:157} INFO - Started process (PID=61152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:48:45.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:48:45.729+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:48:45.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:48:45.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:48:45.753+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:48:45.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:48:45.765+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:48:45.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:48:45.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T21:49:16.149+0000] {processor.py:157} INFO - Started process (PID=61162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:49:16.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:49:16.151+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:49:16.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:49:16.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:49:16.187+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:49:16.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:49:16.199+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:49:16.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:49:16.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T21:49:46.490+0000] {processor.py:157} INFO - Started process (PID=61172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:49:46.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:49:46.502+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:49:46.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:49:46.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:49:46.558+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:49:46.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:49:46.573+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:49:46.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:49:46.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T21:50:16.918+0000] {processor.py:157} INFO - Started process (PID=61182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:50:16.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:50:16.923+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:50:16.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:50:16.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:50:16.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:50:16.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:50:16.976+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:50:16.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:50:16.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T21:50:47.293+0000] {processor.py:157} INFO - Started process (PID=61192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:50:47.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:50:47.298+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:50:47.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:50:47.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:50:47.323+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:50:47.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:50:47.333+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:50:47.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:50:47.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T21:51:17.807+0000] {processor.py:157} INFO - Started process (PID=61202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:51:17.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:51:17.816+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:51:17.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:51:17.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:51:17.890+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:51:17.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:51:17.908+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:51:17.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:51:17.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-17T21:51:48.280+0000] {processor.py:157} INFO - Started process (PID=61212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:51:48.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:51:48.287+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:51:48.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:51:48.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:51:48.374+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:51:48.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:51:48.400+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:51:48.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:51:48.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-17T21:52:18.660+0000] {processor.py:157} INFO - Started process (PID=61222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:52:18.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:52:18.677+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:52:18.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:52:18.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:52:18.759+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:52:18.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:52:18.783+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:52:18.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:52:18.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-17T21:52:49.136+0000] {processor.py:157} INFO - Started process (PID=61232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:52:49.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:52:49.141+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:52:49.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:52:49.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:52:49.193+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:52:49.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:52:49.212+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:52:49.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:52:49.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T21:53:19.549+0000] {processor.py:157} INFO - Started process (PID=61242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:53:19.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:53:19.552+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:53:19.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:53:19.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:53:19.588+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:53:19.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:53:19.602+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:53:19.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:53:19.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T21:53:49.876+0000] {processor.py:157} INFO - Started process (PID=61252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:53:49.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:53:49.899+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:53:49.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:53:49.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:53:49.948+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:53:49.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:53:49.963+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:53:49.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:53:49.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-17T21:54:20.207+0000] {processor.py:157} INFO - Started process (PID=61262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:54:20.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:54:20.211+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:54:20.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:54:20.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:54:20.243+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:54:20.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:54:20.255+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:54:20.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:54:20.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T21:54:50.629+0000] {processor.py:157} INFO - Started process (PID=61272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:54:50.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:54:50.636+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:54:50.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:54:50.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:54:50.679+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:54:50.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:54:50.706+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:54:50.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:54:50.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-17T21:55:20.877+0000] {processor.py:157} INFO - Started process (PID=61282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:55:20.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:55:20.879+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:55:20.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:55:20.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:55:20.904+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:55:20.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:55:20.914+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:55:20.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:55:20.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-17T21:55:51.181+0000] {processor.py:157} INFO - Started process (PID=61292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:55:51.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:55:51.185+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:55:51.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:55:51.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:55:51.222+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:55:51.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:55:51.235+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:55:51.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:55:51.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T21:56:21.573+0000] {processor.py:157} INFO - Started process (PID=61302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:56:21.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:56:21.575+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:56:21.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:56:21.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:56:21.604+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:56:21.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:56:21.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:56:21.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:56:21.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T21:56:51.900+0000] {processor.py:157} INFO - Started process (PID=61312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:56:51.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:56:51.904+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:56:51.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:56:51.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:56:51.932+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:56:51.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:56:51.944+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:56:51.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:56:51.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T21:57:22.277+0000] {processor.py:157} INFO - Started process (PID=61322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:57:22.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:57:22.283+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:57:22.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:57:22.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:57:22.349+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:57:22.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:57:22.366+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:57:22.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:57:22.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-17T21:57:52.616+0000] {processor.py:157} INFO - Started process (PID=61332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:57:52.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:57:52.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:57:52.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:57:52.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:57:52.648+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:57:52.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:57:52.658+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:57:52.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:57:52.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T21:58:22.981+0000] {processor.py:157} INFO - Started process (PID=61342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:58:22.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:58:22.984+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:58:22.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:58:22.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:58:23.012+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:58:23.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:58:23.020+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:58:23.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:58:23.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T21:58:53.324+0000] {processor.py:157} INFO - Started process (PID=61352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:58:53.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:58:53.332+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:58:53.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:58:53.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:58:53.394+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:58:53.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:58:53.410+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:58:53.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:58:53.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-17T21:59:23.680+0000] {processor.py:157} INFO - Started process (PID=61362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:59:23.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:59:23.684+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:59:23.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:59:23.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:59:23.710+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:59:23.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:59:23.720+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:59:23.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:59:23.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T21:59:53.994+0000] {processor.py:157} INFO - Started process (PID=61372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:59:53.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T21:59:53.998+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:59:53.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:59:54.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T21:59:54.028+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:59:54.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T21:59:54.039+0000] {logging_mixin.py:151} INFO - [2024-08-17T21:59:54.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T21:59:54.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:00:24.360+0000] {processor.py:157} INFO - Started process (PID=61382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:00:24.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:00:24.365+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:00:24.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:00:24.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:00:24.402+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:00:24.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:00:24.438+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:00:24.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:00:24.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-17T22:00:54.699+0000] {processor.py:157} INFO - Started process (PID=61392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:00:54.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:00:54.704+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:00:54.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:00:54.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:00:54.738+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:00:54.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:00:54.749+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:00:54.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:00:54.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T22:01:25.106+0000] {processor.py:157} INFO - Started process (PID=61402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:01:25.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:01:25.109+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:01:25.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:01:25.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:01:25.143+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:01:25.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:01:25.156+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:01:25.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:01:25.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T22:01:55.581+0000] {processor.py:157} INFO - Started process (PID=61412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:01:55.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:01:55.585+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:01:55.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:01:55.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:01:55.615+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:01:55.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:01:55.625+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:01:55.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:01:55.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:02:26.018+0000] {processor.py:157} INFO - Started process (PID=61422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:02:26.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:02:26.022+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:02:26.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:02:26.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:02:26.056+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:02:26.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:02:26.071+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:02:26.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:02:26.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T22:02:56.439+0000] {processor.py:157} INFO - Started process (PID=61432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:02:56.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:02:56.441+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:02:56.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:02:56.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:02:56.474+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:02:56.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:02:56.484+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:02:56.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:02:56.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T22:03:26.899+0000] {processor.py:157} INFO - Started process (PID=61442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:03:26.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:03:26.905+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:03:26.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:03:26.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:03:26.932+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:03:26.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:03:26.942+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:03:26.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:03:26.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:03:57.258+0000] {processor.py:157} INFO - Started process (PID=61452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:03:57.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:03:57.261+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:03:57.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:03:57.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:03:57.289+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:03:57.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:03:57.299+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:03:57.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:03:57.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:04:27.596+0000] {processor.py:157} INFO - Started process (PID=61462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:04:27.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:04:27.599+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:04:27.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:04:27.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:04:27.662+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:04:27.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:04:27.675+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:04:27.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:04:27.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-17T22:04:57.950+0000] {processor.py:157} INFO - Started process (PID=61472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:04:57.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:04:57.954+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:04:57.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:04:57.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:04:57.985+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:04:57.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:04:57.997+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:04:57.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:04:58.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T22:05:28.333+0000] {processor.py:157} INFO - Started process (PID=61482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:05:28.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:05:28.338+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:05:28.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:05:28.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:05:28.381+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:05:28.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:05:28.394+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:05:28.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:05:28.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T22:05:58.806+0000] {processor.py:157} INFO - Started process (PID=61492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:05:58.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:05:58.811+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:05:58.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:05:58.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:05:58.845+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:05:58.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:05:58.857+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:05:58.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:05:58.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T22:06:29.259+0000] {processor.py:157} INFO - Started process (PID=61502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:06:29.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:06:29.262+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:06:29.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:06:29.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:06:29.298+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:06:29.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:06:29.313+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:06:29.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:06:29.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T22:06:59.661+0000] {processor.py:157} INFO - Started process (PID=61512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:06:59.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:06:59.670+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:06:59.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:06:59.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:06:59.693+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:06:59.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:06:59.707+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:06:59.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:06:59.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T22:07:30.079+0000] {processor.py:157} INFO - Started process (PID=61522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:07:30.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:07:30.084+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:07:30.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:07:30.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:07:30.117+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:07:30.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:07:30.127+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:07:30.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:07:30.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T22:08:00.463+0000] {processor.py:157} INFO - Started process (PID=61532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:08:00.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:08:00.466+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:08:00.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:08:00.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:08:00.503+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:08:00.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:08:00.518+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:08:00.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:08:00.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T22:08:30.935+0000] {processor.py:157} INFO - Started process (PID=61542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:08:30.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:08:30.941+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:08:30.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:08:30.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:08:30.969+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:08:30.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:08:30.979+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:08:30.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:08:30.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:09:01.349+0000] {processor.py:157} INFO - Started process (PID=61552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:09:01.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:09:01.354+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:09:01.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:09:01.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:09:01.413+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:09:01.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:09:01.428+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:09:01.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:09:01.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-17T22:09:31.712+0000] {processor.py:157} INFO - Started process (PID=61562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:09:31.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:09:31.718+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:09:31.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:09:31.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:09:31.753+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:09:31.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:09:31.768+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:09:31.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:09:31.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T22:10:02.200+0000] {processor.py:157} INFO - Started process (PID=61572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:10:02.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:10:02.208+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:10:02.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:10:02.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:10:02.250+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:10:02.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:10:02.263+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:10:02.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:10:02.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T22:10:32.581+0000] {processor.py:157} INFO - Started process (PID=61582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:10:32.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:10:32.588+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:10:32.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:10:32.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:10:32.645+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:10:32.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:10:32.659+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:10:32.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:10:32.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-17T22:11:03.177+0000] {processor.py:157} INFO - Started process (PID=61591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:11:03.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:11:03.184+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:11:03.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:11:03.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:11:03.240+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:11:03.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:11:03.254+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:11:03.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:11:03.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T22:11:33.666+0000] {processor.py:157} INFO - Started process (PID=61602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:11:33.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:11:33.676+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:11:33.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:11:33.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:11:33.745+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:11:33.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:11:33.764+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:11:33.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:11:33.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-17T22:12:04.205+0000] {processor.py:157} INFO - Started process (PID=61612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:12:04.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:12:04.212+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:12:04.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:12:04.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:12:04.285+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:12:04.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:12:04.301+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:12:04.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:12:04.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-17T22:12:34.587+0000] {processor.py:157} INFO - Started process (PID=61622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:12:34.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:12:34.599+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:12:34.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:12:34.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:12:34.656+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:12:34.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:12:34.669+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:12:34.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:12:34.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-17T22:13:05.011+0000] {processor.py:157} INFO - Started process (PID=61632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:13:05.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:13:05.016+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:13:05.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:13:05.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:13:05.046+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:13:05.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:13:05.056+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:13:05.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:13:05.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T22:13:35.404+0000] {processor.py:157} INFO - Started process (PID=61642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:13:35.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:13:35.407+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:13:35.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:13:35.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:13:35.466+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:13:35.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:13:35.488+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:13:35.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:13:35.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-17T22:14:05.777+0000] {processor.py:157} INFO - Started process (PID=61652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:14:05.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:14:05.782+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:14:05.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:14:05.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:14:05.812+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:14:05.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:14:05.823+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:14:05.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:14:05.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T22:14:36.120+0000] {processor.py:157} INFO - Started process (PID=61662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:14:36.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:14:36.125+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:14:36.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:14:36.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:14:36.185+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:14:36.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:14:36.199+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:14:36.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:14:36.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-17T22:15:06.556+0000] {processor.py:157} INFO - Started process (PID=61672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:15:06.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:15:06.559+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:15:06.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:15:06.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:15:06.585+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:15:06.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:15:06.596+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:15:06.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:15:06.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T22:15:36.964+0000] {processor.py:157} INFO - Started process (PID=61682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:15:36.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:15:36.967+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:15:36.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:15:36.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:15:36.996+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:15:36.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:15:37.006+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:15:37.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:15:37.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:16:07.397+0000] {processor.py:157} INFO - Started process (PID=61692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:16:07.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:16:07.403+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:16:07.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:16:07.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:16:07.449+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:16:07.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:16:07.464+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:16:07.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:16:07.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T22:16:37.828+0000] {processor.py:157} INFO - Started process (PID=61702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:16:37.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:16:37.830+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:16:37.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:16:37.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:16:37.859+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:16:37.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:16:37.871+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:16:37.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:16:37.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:17:08.386+0000] {processor.py:157} INFO - Started process (PID=61712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:17:08.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:17:08.399+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:17:08.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:17:08.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:17:08.445+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:17:08.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:17:08.461+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:17:08.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:17:08.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-17T22:17:38.806+0000] {processor.py:157} INFO - Started process (PID=61722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:17:38.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:17:38.809+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:17:38.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:17:38.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:17:38.838+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:17:38.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:17:38.849+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:17:38.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:17:38.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:18:09.295+0000] {processor.py:157} INFO - Started process (PID=61732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:18:09.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:18:09.299+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:18:09.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:18:09.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:18:09.330+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:18:09.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:18:09.341+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:18:09.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:18:09.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T22:18:39.726+0000] {processor.py:157} INFO - Started process (PID=61742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:18:39.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:18:39.733+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:18:39.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:18:39.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:18:39.770+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:18:39.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:18:39.782+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:18:39.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:18:39.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T22:19:10.133+0000] {processor.py:157} INFO - Started process (PID=61752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:19:10.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:19:10.137+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:19:10.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:19:10.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:19:10.162+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:19:10.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:19:10.173+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:19:10.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:19:10.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T22:19:40.480+0000] {processor.py:157} INFO - Started process (PID=61762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:19:40.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:19:40.484+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:19:40.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:19:40.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:19:40.510+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:19:40.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:19:40.520+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:19:40.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:19:40.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T22:20:10.867+0000] {processor.py:157} INFO - Started process (PID=61772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:20:10.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:20:10.873+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:20:10.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:20:10.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:20:10.912+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:20:10.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:20:10.926+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:20:10.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:20:10.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T22:20:41.163+0000] {processor.py:157} INFO - Started process (PID=61782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:20:41.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:20:41.166+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:20:41.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:20:41.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:20:41.194+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:20:41.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:20:41.208+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:20:41.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:20:41.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T22:21:11.500+0000] {processor.py:157} INFO - Started process (PID=61792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:21:11.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:21:11.503+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:21:11.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:21:11.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:21:11.527+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:21:11.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:21:11.537+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:21:11.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:21:11.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-17T22:21:41.933+0000] {processor.py:157} INFO - Started process (PID=61802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:21:41.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:21:41.937+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:21:41.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:21:41.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:21:41.962+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:21:41.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:21:41.973+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:21:41.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:21:41.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:22:12.330+0000] {processor.py:157} INFO - Started process (PID=61812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:22:12.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:22:12.335+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:22:12.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:22:12.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:22:12.365+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:22:12.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:22:12.374+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:22:12.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:22:12.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T22:22:42.774+0000] {processor.py:157} INFO - Started process (PID=61822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:22:42.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:22:42.780+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:22:42.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:22:42.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:22:42.817+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:22:42.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:22:42.830+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:22:42.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:22:42.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T22:23:13.153+0000] {processor.py:157} INFO - Started process (PID=61832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:23:13.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:23:13.155+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:23:13.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:23:13.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:23:13.178+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:23:13.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:23:13.187+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:23:13.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:23:13.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-08-17T22:23:43.612+0000] {processor.py:157} INFO - Started process (PID=61842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:23:43.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:23:43.614+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:23:43.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:23:43.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:23:43.636+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:23:43.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:23:43.646+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:23:43.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:23:43.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-17T22:24:14.048+0000] {processor.py:157} INFO - Started process (PID=61852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:24:14.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:24:14.051+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:24:14.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:24:14.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:24:14.078+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:24:14.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:24:14.088+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:24:14.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:24:14.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T22:24:44.436+0000] {processor.py:157} INFO - Started process (PID=61862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:24:44.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:24:44.440+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:24:44.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:24:44.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:24:44.480+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:24:44.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:24:44.493+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:24:44.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:24:44.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T22:25:14.879+0000] {processor.py:157} INFO - Started process (PID=61872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:25:14.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:25:14.883+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:25:14.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:25:14.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:25:14.926+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:25:14.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:25:14.938+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:25:14.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:25:14.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T22:25:45.368+0000] {processor.py:157} INFO - Started process (PID=61882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:25:45.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:25:45.371+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:25:45.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:25:45.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:25:45.398+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:25:45.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:25:45.408+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:25:45.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:25:45.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T22:26:15.821+0000] {processor.py:157} INFO - Started process (PID=61892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:26:15.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:26:15.828+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:26:15.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:26:15.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:26:15.860+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:26:15.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:26:15.872+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:26:15.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:26:15.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T22:26:46.199+0000] {processor.py:157} INFO - Started process (PID=61902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:26:46.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:26:46.204+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:26:46.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:26:46.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:26:46.252+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:26:46.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:26:46.266+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:26:46.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:26:46.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T22:27:16.531+0000] {processor.py:157} INFO - Started process (PID=61912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:27:16.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:27:16.536+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:27:16.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:27:16.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:27:16.565+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:27:16.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:27:16.574+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:27:16.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:27:16.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:27:46.935+0000] {processor.py:157} INFO - Started process (PID=61922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:27:46.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:27:46.940+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:27:46.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:27:46.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:27:46.984+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:27:46.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:27:46.997+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:27:46.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:27:47.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T22:28:17.342+0000] {processor.py:157} INFO - Started process (PID=61932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:28:17.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:28:17.345+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:28:17.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:28:17.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:28:17.373+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:28:17.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:28:17.384+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:28:17.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:28:17.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:28:47.800+0000] {processor.py:157} INFO - Started process (PID=61942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:28:47.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:28:47.806+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:28:47.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:28:47.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:28:47.834+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:28:47.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:28:47.844+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:28:47.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:28:47.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:29:18.206+0000] {processor.py:157} INFO - Started process (PID=61952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:29:18.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:29:18.209+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:29:18.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:29:18.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:29:18.245+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:29:18.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:29:18.255+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:29:18.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:29:18.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T22:29:48.616+0000] {processor.py:157} INFO - Started process (PID=61962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:29:48.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:29:48.620+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:29:48.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:29:48.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:29:48.655+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:29:48.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:29:48.668+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:29:48.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:29:48.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T22:30:19.001+0000] {processor.py:157} INFO - Started process (PID=61972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:30:19.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:30:19.005+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:30:19.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:30:19.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:30:19.032+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:30:19.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:30:19.042+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:30:19.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:30:19.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T22:30:49.388+0000] {processor.py:157} INFO - Started process (PID=61982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:30:49.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:30:49.392+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:30:49.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:30:49.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:30:49.420+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:30:49.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:30:49.432+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:30:49.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:30:49.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:31:19.723+0000] {processor.py:157} INFO - Started process (PID=61992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:31:19.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:31:19.728+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:31:19.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:31:19.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:31:19.753+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:31:19.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:31:19.762+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:31:19.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:31:19.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T22:31:50.064+0000] {processor.py:157} INFO - Started process (PID=62002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:31:50.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:31:50.066+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:31:50.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:31:50.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:31:50.091+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:31:50.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:31:50.100+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:31:50.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:31:50.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-17T22:32:20.488+0000] {processor.py:157} INFO - Started process (PID=62012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:32:20.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:32:20.491+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:32:20.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:32:20.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:32:20.519+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:32:20.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:32:20.531+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:32:20.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:32:20.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:32:50.890+0000] {processor.py:157} INFO - Started process (PID=62022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:32:50.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:32:50.896+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:32:50.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:32:50.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:32:50.932+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:32:50.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:32:50.945+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:32:50.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:32:50.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T22:33:21.317+0000] {processor.py:157} INFO - Started process (PID=62032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:33:21.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:33:21.321+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:33:21.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:33:21.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:33:21.353+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:33:21.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:33:21.365+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:33:21.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:33:21.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T22:33:51.715+0000] {processor.py:157} INFO - Started process (PID=62042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:33:51.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:33:51.718+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:33:51.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:33:51.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:33:51.747+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:33:51.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:33:51.756+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:33:51.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:33:51.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T22:34:22.092+0000] {processor.py:157} INFO - Started process (PID=62052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:34:22.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:34:22.097+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:34:22.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:34:22.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:34:22.126+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:34:22.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:34:22.135+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:34:22.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:34:22.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T22:34:52.499+0000] {processor.py:157} INFO - Started process (PID=62062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:34:52.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:34:52.503+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:34:52.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:34:52.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:34:52.532+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:34:52.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:34:52.543+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:34:52.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:34:52.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:35:22.896+0000] {processor.py:157} INFO - Started process (PID=62072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:35:22.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:35:22.899+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:35:22.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:35:22.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:35:22.925+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:35:22.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:35:22.937+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:35:22.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:35:22.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T22:35:53.336+0000] {processor.py:157} INFO - Started process (PID=62082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:35:53.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:35:53.339+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:35:53.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:35:53.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:35:53.376+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:35:53.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:35:53.389+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:35:53.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:35:53.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T22:36:23.762+0000] {processor.py:157} INFO - Started process (PID=62092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:36:23.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:36:23.765+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:36:23.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:36:23.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:36:23.793+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:36:23.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:36:23.806+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:36:23.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:36:23.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T22:36:54.274+0000] {processor.py:157} INFO - Started process (PID=62102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:36:54.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:36:54.277+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:36:54.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:36:54.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:36:54.307+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:36:54.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:36:54.320+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:36:54.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:36:54.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T22:37:24.688+0000] {processor.py:157} INFO - Started process (PID=62112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:37:24.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:37:24.693+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:37:24.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:37:24.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:37:24.718+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:37:24.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:37:24.727+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:37:24.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:37:24.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T22:37:55.046+0000] {processor.py:157} INFO - Started process (PID=62122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:37:55.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:37:55.048+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:37:55.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:37:55.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:37:55.077+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:37:55.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:37:55.087+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:37:55.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:37:55.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:38:25.402+0000] {processor.py:157} INFO - Started process (PID=62132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:38:25.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:38:25.405+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:38:25.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:38:25.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:38:25.430+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:38:25.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:38:25.441+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:38:25.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:38:25.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T22:38:55.775+0000] {processor.py:157} INFO - Started process (PID=62142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:38:55.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:38:55.778+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:38:55.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:38:55.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:38:55.817+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:38:55.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:38:55.830+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:38:55.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:38:55.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T22:39:26.155+0000] {processor.py:157} INFO - Started process (PID=62152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:39:26.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:39:26.158+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:39:26.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:39:26.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:39:26.185+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:39:26.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:39:26.198+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:39:26.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:39:26.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T22:39:56.564+0000] {processor.py:157} INFO - Started process (PID=62162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:39:56.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:39:56.568+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:39:56.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:39:56.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:39:56.596+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:39:56.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:39:56.607+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:39:56.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:39:56.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:40:27.015+0000] {processor.py:157} INFO - Started process (PID=62172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:40:27.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:40:27.021+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:40:27.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:40:27.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:40:27.049+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:40:27.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:40:27.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:40:27.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:40:27.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T22:40:57.357+0000] {processor.py:157} INFO - Started process (PID=62182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:40:57.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:40:57.360+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:40:57.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:40:57.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:40:57.400+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:40:57.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:40:57.412+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:40:57.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:40:57.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T22:41:27.825+0000] {processor.py:157} INFO - Started process (PID=62192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:41:27.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:41:27.829+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:41:27.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:41:27.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:41:27.857+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:41:27.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:41:27.869+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:41:27.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:41:27.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:41:58.264+0000] {processor.py:157} INFO - Started process (PID=62202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:41:58.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:41:58.270+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:41:58.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:41:58.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:41:58.299+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:41:58.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:41:58.309+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:41:58.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:41:58.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:42:28.693+0000] {processor.py:157} INFO - Started process (PID=62212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:42:28.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:42:28.703+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:42:28.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:42:28.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:42:28.726+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:42:28.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:42:28.736+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:42:28.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:42:28.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T22:42:59.003+0000] {processor.py:157} INFO - Started process (PID=62222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:42:59.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:42:59.009+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:42:59.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:42:59.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:42:59.036+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:42:59.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:42:59.048+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:42:59.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:42:59.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:43:29.445+0000] {processor.py:157} INFO - Started process (PID=62232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:43:29.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:43:29.450+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:43:29.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:43:29.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:43:29.478+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:43:29.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:43:29.488+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:43:29.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:43:29.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:43:59.925+0000] {processor.py:157} INFO - Started process (PID=62242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:43:59.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:43:59.929+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:43:59.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:43:59.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:43:59.961+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:43:59.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:43:59.973+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:43:59.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:43:59.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T22:44:30.290+0000] {processor.py:157} INFO - Started process (PID=62252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:44:30.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:44:30.292+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:44:30.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:44:30.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:44:30.321+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:44:30.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:44:30.331+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:44:30.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:44:30.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:45:00.703+0000] {processor.py:157} INFO - Started process (PID=62262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:45:00.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:45:00.706+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:45:00.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:45:00.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:45:00.733+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:45:00.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:45:00.744+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:45:00.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:45:00.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T22:45:31.112+0000] {processor.py:157} INFO - Started process (PID=62272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:45:31.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:45:31.117+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:45:31.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:45:31.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:45:31.160+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:45:31.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:45:31.173+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:45:31.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:45:31.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T22:46:01.545+0000] {processor.py:157} INFO - Started process (PID=62282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:46:01.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:46:01.549+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:46:01.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:46:01.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:46:01.578+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:46:01.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:46:01.593+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:46:01.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:46:01.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T22:46:31.920+0000] {processor.py:157} INFO - Started process (PID=62292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:46:31.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:46:31.922+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:46:31.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:46:31.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:46:31.956+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:46:31.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:46:31.966+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:46:31.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:46:31.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:47:02.254+0000] {processor.py:157} INFO - Started process (PID=62302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:47:02.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:47:02.257+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:47:02.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:47:02.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:47:02.280+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:47:02.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:47:02.291+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:47:02.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:47:02.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-17T22:47:32.525+0000] {processor.py:157} INFO - Started process (PID=62312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:47:32.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:47:32.530+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:47:32.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:47:32.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:47:32.568+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:47:32.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:47:32.582+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:47:32.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:47:32.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T22:48:02.851+0000] {processor.py:157} INFO - Started process (PID=62322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:48:02.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:48:02.854+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:48:02.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:48:02.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:48:02.885+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:48:02.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:48:02.895+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:48:02.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:48:02.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:48:33.240+0000] {processor.py:157} INFO - Started process (PID=62332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:48:33.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:48:33.244+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:48:33.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:48:33.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:48:33.270+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:48:33.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:48:33.280+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:48:33.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:48:33.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T22:49:03.608+0000] {processor.py:157} INFO - Started process (PID=62342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:49:03.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:49:03.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:49:03.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:49:03.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:49:03.639+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:49:03.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:49:03.649+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:49:03.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:49:03.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T22:49:33.962+0000] {processor.py:157} INFO - Started process (PID=62352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:49:33.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:49:33.967+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:49:33.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:49:33.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:49:34.003+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:49:34.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:49:34.015+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:49:34.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:49:34.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T22:50:04.279+0000] {processor.py:157} INFO - Started process (PID=62362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:50:04.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:50:04.283+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:50:04.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:50:04.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:50:04.312+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:50:04.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:50:04.322+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:50:04.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:50:04.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:50:34.582+0000] {processor.py:157} INFO - Started process (PID=62372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:50:34.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:50:34.586+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:50:34.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:50:34.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:50:34.614+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:50:34.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:50:34.626+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:50:34.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:50:34.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T22:51:04.994+0000] {processor.py:157} INFO - Started process (PID=62382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:51:04.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:51:04.998+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:51:04.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:51:05.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:51:05.051+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:51:05.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:51:05.064+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:51:05.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:51:05.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T22:51:35.477+0000] {processor.py:157} INFO - Started process (PID=62392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:51:35.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:51:35.480+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:51:35.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:51:35.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:51:35.506+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:51:35.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:51:35.516+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:51:35.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:51:35.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T22:52:05.873+0000] {processor.py:157} INFO - Started process (PID=62402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:52:05.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:52:05.876+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:52:05.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:52:05.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:52:05.902+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:52:05.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:52:05.912+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:52:05.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:52:05.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T22:52:36.219+0000] {processor.py:157} INFO - Started process (PID=62412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:52:36.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:52:36.222+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:52:36.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:52:36.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:52:36.249+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:52:36.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:52:36.261+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:52:36.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:52:36.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T22:53:06.620+0000] {processor.py:157} INFO - Started process (PID=62422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:53:06.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:53:06.626+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:53:06.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:53:06.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:53:06.668+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:53:06.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:53:06.682+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:53:06.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:53:06.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T22:53:36.975+0000] {processor.py:157} INFO - Started process (PID=62432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:53:36.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:53:36.977+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:53:36.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:53:36.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:53:37.006+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:53:37.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:53:37.019+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:53:37.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:53:37.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T22:54:07.401+0000] {processor.py:157} INFO - Started process (PID=62442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:54:07.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:54:07.404+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:54:07.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:54:07.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:54:07.436+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:54:07.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:54:07.446+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:54:07.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:54:07.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T22:54:37.797+0000] {processor.py:157} INFO - Started process (PID=62452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:54:37.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:54:37.800+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:54:37.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:54:37.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:54:37.832+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:54:37.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:54:37.844+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:54:37.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:54:37.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T22:55:08.246+0000] {processor.py:157} INFO - Started process (PID=62462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:55:08.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:55:08.251+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:55:08.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:55:08.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:55:08.289+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:55:08.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:55:08.302+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:55:08.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:55:08.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T22:55:38.694+0000] {processor.py:157} INFO - Started process (PID=62472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:55:38.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:55:38.697+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:55:38.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:55:38.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:55:38.723+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:55:38.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:55:38.735+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:55:38.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:55:38.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:56:09.061+0000] {processor.py:157} INFO - Started process (PID=62482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:56:09.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:56:09.066+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:56:09.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:56:09.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:56:09.115+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:56:09.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:56:09.131+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:56:09.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:56:09.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T22:56:39.462+0000] {processor.py:157} INFO - Started process (PID=62492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:56:39.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:56:39.465+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:56:39.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:56:39.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:56:39.493+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:56:39.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:56:39.513+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:56:39.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:56:39.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T22:57:09.810+0000] {processor.py:157} INFO - Started process (PID=62502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:57:09.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:57:09.816+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:57:09.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:57:09.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:57:09.867+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:57:09.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:57:09.881+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:57:09.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:57:09.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-17T22:57:40.196+0000] {processor.py:157} INFO - Started process (PID=62512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:57:40.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:57:40.200+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:57:40.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:57:40.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:57:40.228+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:57:40.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:57:40.238+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:57:40.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:57:40.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T22:58:10.550+0000] {processor.py:157} INFO - Started process (PID=62522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:58:10.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:58:10.558+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:58:10.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:58:10.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:58:10.605+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:58:10.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:58:10.619+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:58:10.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:58:10.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T22:58:40.880+0000] {processor.py:157} INFO - Started process (PID=62532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:58:40.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:58:40.883+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:58:40.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:58:40.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:58:40.909+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:58:40.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:58:40.919+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:58:40.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:58:40.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T22:59:11.332+0000] {processor.py:157} INFO - Started process (PID=62542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:59:11.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:59:11.336+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:59:11.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:59:11.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:59:11.364+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:59:11.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:59:11.375+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:59:11.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:59:11.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T22:59:41.729+0000] {processor.py:157} INFO - Started process (PID=62552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:59:41.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T22:59:41.734+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:59:41.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:59:41.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T22:59:41.763+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:59:41.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T22:59:41.775+0000] {logging_mixin.py:151} INFO - [2024-08-17T22:59:41.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T22:59:41.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T23:00:12.116+0000] {processor.py:157} INFO - Started process (PID=62562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:00:12.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:00:12.123+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:00:12.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:00:12.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:00:12.165+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:00:12.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:00:12.178+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:00:12.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:00:12.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T23:00:42.539+0000] {processor.py:157} INFO - Started process (PID=62572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:00:42.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:00:42.543+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:00:42.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:00:42.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:00:42.571+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:00:42.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:00:42.581+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:00:42.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:00:42.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T23:01:12.892+0000] {processor.py:157} INFO - Started process (PID=62582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:01:12.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:01:12.897+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:01:12.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:01:12.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:01:12.935+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:01:12.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:01:12.948+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:01:12.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:01:12.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T23:01:43.268+0000] {processor.py:157} INFO - Started process (PID=62592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:01:43.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:01:43.271+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:01:43.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:01:43.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:01:43.301+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:01:43.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:01:43.311+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:01:43.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:01:43.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T23:02:13.664+0000] {processor.py:157} INFO - Started process (PID=62602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:02:13.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:02:13.666+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:02:13.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:02:13.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:02:13.694+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:02:13.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:02:13.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:02:13.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:02:13.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T23:02:44.020+0000] {processor.py:157} INFO - Started process (PID=62612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:02:44.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:02:44.024+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:02:44.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:02:44.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:02:44.062+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:02:44.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:02:44.077+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:02:44.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:02:44.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T23:03:14.460+0000] {processor.py:157} INFO - Started process (PID=62622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:03:14.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:03:14.463+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:03:14.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:03:14.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:03:14.495+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:03:14.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:03:14.509+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:03:14.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:03:14.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-17T23:03:44.813+0000] {processor.py:157} INFO - Started process (PID=62632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:03:44.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:03:44.816+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:03:44.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:03:44.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:03:44.848+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:03:44.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:03:44.861+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:03:44.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:03:44.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T23:04:15.229+0000] {processor.py:157} INFO - Started process (PID=62642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:04:15.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:04:15.232+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:04:15.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:04:15.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:04:15.267+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:04:15.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:04:15.282+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:04:15.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:04:15.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T23:04:45.592+0000] {processor.py:157} INFO - Started process (PID=62652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:04:45.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:04:45.595+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:04:45.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:04:45.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:04:45.627+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:04:45.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:04:45.638+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:04:45.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:04:45.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T23:05:15.990+0000] {processor.py:157} INFO - Started process (PID=62662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:05:15.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:05:15.993+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:05:15.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:05:16.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:05:16.024+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:05:16.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:05:16.035+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:05:16.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:05:16.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T23:05:46.396+0000] {processor.py:157} INFO - Started process (PID=62672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:05:46.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:05:46.402+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:05:46.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:05:46.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:05:46.435+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:05:46.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:05:46.446+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:05:46.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:05:46.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T23:06:16.858+0000] {processor.py:157} INFO - Started process (PID=62682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:06:16.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:06:16.863+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:06:16.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:06:16.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:06:16.891+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:06:16.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:06:16.904+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:06:16.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:06:16.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T23:06:47.282+0000] {processor.py:157} INFO - Started process (PID=62692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:06:47.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:06:47.285+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:06:47.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:06:47.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:06:47.314+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:06:47.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:06:47.325+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:06:47.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:06:47.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T23:07:17.639+0000] {processor.py:157} INFO - Started process (PID=62702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:07:17.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:07:17.643+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:07:17.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:07:17.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:07:17.673+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:07:17.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:07:17.683+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:07:17.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:07:17.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T23:07:48.007+0000] {processor.py:157} INFO - Started process (PID=62712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:07:48.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:07:48.012+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:07:48.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:07:48.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:07:48.047+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:07:48.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:07:48.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:07:48.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:07:48.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T23:08:18.463+0000] {processor.py:157} INFO - Started process (PID=62722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:08:18.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:08:18.466+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:08:18.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:08:18.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:08:18.495+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:08:18.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:08:18.508+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:08:18.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:08:18.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T23:08:48.943+0000] {processor.py:157} INFO - Started process (PID=62732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:08:48.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:08:48.948+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:08:48.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:08:48.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:08:48.976+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:08:48.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:08:48.989+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:08:48.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:08:48.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T23:09:19.371+0000] {processor.py:157} INFO - Started process (PID=62742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:09:19.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:09:19.376+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:09:19.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:09:19.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:09:19.421+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:09:19.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:09:19.432+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:09:19.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:09:19.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T23:09:49.740+0000] {processor.py:157} INFO - Started process (PID=62752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:09:49.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:09:49.742+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:09:49.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:09:49.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:09:49.772+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:09:49.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:09:49.785+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:09:49.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:09:49.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T23:10:20.162+0000] {processor.py:157} INFO - Started process (PID=62762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:10:20.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:10:20.165+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:10:20.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:10:20.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:10:20.194+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:10:20.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:10:20.207+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:10:20.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:10:20.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T23:10:50.538+0000] {processor.py:157} INFO - Started process (PID=62772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:10:50.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:10:50.543+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:10:50.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:10:50.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:10:50.571+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:10:50.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:10:50.582+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:10:50.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:10:50.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T23:11:20.937+0000] {processor.py:157} INFO - Started process (PID=62782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:11:20.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:11:20.943+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:11:20.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:11:20.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:11:20.978+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:11:20.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:11:20.990+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:11:20.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:11:20.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T23:11:51.264+0000] {processor.py:157} INFO - Started process (PID=62792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:11:51.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:11:51.268+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:11:51.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:11:51.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:11:51.300+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:11:51.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:11:51.312+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:11:51.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:11:51.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T23:12:21.552+0000] {processor.py:157} INFO - Started process (PID=62802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:12:21.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:12:21.554+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:12:21.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:12:21.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:12:21.581+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:12:21.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:12:21.592+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:12:21.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:12:21.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T23:12:51.900+0000] {processor.py:157} INFO - Started process (PID=62812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:12:51.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:12:51.904+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:12:51.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:12:51.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:12:51.942+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:12:51.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:12:51.956+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:12:51.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:12:51.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T23:13:22.341+0000] {processor.py:157} INFO - Started process (PID=62822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:13:22.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:13:22.345+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:13:22.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:13:22.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:13:22.375+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:13:22.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:13:22.386+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:13:22.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:13:22.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T23:13:52.711+0000] {processor.py:157} INFO - Started process (PID=62832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:13:52.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:13:52.714+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:13:52.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:13:52.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:13:52.741+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:13:52.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:13:52.752+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:13:52.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:13:52.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T23:14:23.107+0000] {processor.py:157} INFO - Started process (PID=62842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:14:23.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:14:23.111+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:14:23.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:14:23.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:14:23.142+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:14:23.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:14:23.155+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:14:23.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:14:23.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T23:14:53.526+0000] {processor.py:157} INFO - Started process (PID=62852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:14:53.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:14:53.529+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:14:53.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:14:53.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:14:53.566+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:14:53.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:14:53.576+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:14:53.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:14:53.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-17T23:15:23.986+0000] {processor.py:157} INFO - Started process (PID=62862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:15:23.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:15:23.989+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:15:23.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:15:24.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:15:24.020+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:15:24.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:15:24.034+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:15:24.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:15:24.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T23:15:54.386+0000] {processor.py:157} INFO - Started process (PID=62872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:15:54.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:15:54.390+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:15:54.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:15:54.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:15:54.423+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:15:54.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:15:54.433+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:15:54.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:15:54.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T23:16:24.775+0000] {processor.py:157} INFO - Started process (PID=62882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:16:24.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:16:24.779+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:16:24.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:16:24.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:16:24.809+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:16:24.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:16:24.822+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:16:24.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:16:24.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T23:16:55.124+0000] {processor.py:157} INFO - Started process (PID=62892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:16:55.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:16:55.128+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:16:55.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:16:55.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:16:55.158+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:16:55.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:16:55.171+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:16:55.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:16:55.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T23:17:25.567+0000] {processor.py:157} INFO - Started process (PID=62902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:17:25.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:17:25.572+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:17:25.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:17:25.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:17:25.601+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:17:25.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:17:25.612+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:17:25.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:17:25.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T23:17:55.984+0000] {processor.py:157} INFO - Started process (PID=62912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:17:55.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:17:55.989+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:17:55.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:17:56.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:17:56.039+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:17:56.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:17:56.052+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:17:56.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:17:56.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-17T23:18:26.435+0000] {processor.py:157} INFO - Started process (PID=62922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:18:26.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:18:26.440+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:18:26.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:18:26.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:18:26.475+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:18:26.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:18:26.487+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:18:26.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:18:26.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T23:18:56.813+0000] {processor.py:157} INFO - Started process (PID=62932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:18:56.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:18:56.820+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:18:56.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:18:56.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:18:56.854+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:18:56.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:18:56.869+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:18:56.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:18:56.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T23:19:27.177+0000] {processor.py:157} INFO - Started process (PID=62942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:19:27.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:19:27.182+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:19:27.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:19:27.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:19:27.234+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:19:27.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:19:27.246+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:19:27.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:19:27.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-17T23:19:57.552+0000] {processor.py:157} INFO - Started process (PID=62952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:19:57.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:19:57.556+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:19:57.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:19:57.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:19:57.587+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:19:57.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:19:57.602+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:19:57.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:19:57.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T23:20:27.917+0000] {processor.py:157} INFO - Started process (PID=62962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:20:27.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:20:27.920+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:20:27.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:20:27.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:20:27.960+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:20:27.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:20:27.974+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:20:27.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:20:27.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T23:20:58.198+0000] {processor.py:157} INFO - Started process (PID=62972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:20:58.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:20:58.200+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:20:58.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:20:58.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:20:58.230+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:20:58.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:20:58.239+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:20:58.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:20:58.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T23:21:28.612+0000] {processor.py:157} INFO - Started process (PID=62982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:21:28.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:21:28.616+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:21:28.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:21:28.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:21:28.644+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:21:28.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:21:28.655+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:21:28.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:21:28.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T23:21:59.003+0000] {processor.py:157} INFO - Started process (PID=62992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:21:59.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:21:59.007+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:21:59.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:21:59.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:21:59.045+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:21:59.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:21:59.057+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:21:59.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:21:59.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T23:22:29.398+0000] {processor.py:157} INFO - Started process (PID=63002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:22:29.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:22:29.401+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:22:29.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:22:29.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:22:29.427+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:22:29.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:22:29.437+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:22:29.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:22:29.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T23:22:59.806+0000] {processor.py:157} INFO - Started process (PID=63012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:22:59.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:22:59.810+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:22:59.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:22:59.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:22:59.839+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:22:59.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:22:59.851+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:22:59.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:22:59.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T23:23:30.171+0000] {processor.py:157} INFO - Started process (PID=63022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:23:30.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:23:30.176+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:23:30.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:23:30.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:23:30.216+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:23:30.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:23:30.228+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:23:30.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:23:30.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T23:24:00.512+0000] {processor.py:157} INFO - Started process (PID=63032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:24:00.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:24:00.521+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:24:00.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:24:00.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:24:00.546+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:24:00.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:24:00.555+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:24:00.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:24:00.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T23:24:30.942+0000] {processor.py:157} INFO - Started process (PID=63042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:24:30.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:24:30.945+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:24:30.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:24:30.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:24:30.972+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:24:30.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:24:30.983+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:24:30.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:24:30.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T23:25:01.316+0000] {processor.py:157} INFO - Started process (PID=63052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:25:01.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:25:01.320+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:25:01.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:25:01.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:25:01.359+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:25:01.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:25:01.372+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:25:01.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:25:01.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T23:25:31.661+0000] {processor.py:157} INFO - Started process (PID=63062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:25:31.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:25:31.665+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:25:31.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:25:31.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:25:31.705+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:25:31.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:25:31.717+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:25:31.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:25:31.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T23:26:02.013+0000] {processor.py:157} INFO - Started process (PID=63072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:26:02.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:26:02.029+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:26:02.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:26:02.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:26:02.073+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:26:02.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:26:02.085+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:26:02.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:26:02.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-17T23:26:32.396+0000] {processor.py:157} INFO - Started process (PID=63082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:26:32.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:26:32.400+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:26:32.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:26:32.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:26:32.432+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:26:32.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:26:32.444+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:26:32.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:26:32.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-17T23:27:02.865+0000] {processor.py:157} INFO - Started process (PID=63091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:27:02.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:27:02.871+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:27:02.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:27:02.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:27:02.940+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:27:02.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:27:02.959+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:27:02.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:27:02.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-17T23:27:33.252+0000] {processor.py:157} INFO - Started process (PID=63102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:27:33.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:27:33.260+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:27:33.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:27:33.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:27:33.306+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:27:33.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:27:33.321+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:27:33.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:27:33.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-17T23:28:03.575+0000] {processor.py:157} INFO - Started process (PID=63112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:28:03.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:28:03.579+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:28:03.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:28:03.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:28:03.604+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:28:03.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:28:03.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:28:03.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:28:03.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-17T23:28:34.063+0000] {processor.py:157} INFO - Started process (PID=63122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:28:34.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:28:34.069+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:28:34.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:28:34.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:28:34.109+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:28:34.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:28:34.123+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:28:34.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:28:34.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T23:29:04.408+0000] {processor.py:157} INFO - Started process (PID=63132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:29:04.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:29:04.410+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:29:04.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:29:04.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:29:04.431+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:29:04.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:29:04.444+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:29:04.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:29:04.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-17T23:29:34.827+0000] {processor.py:157} INFO - Started process (PID=63142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:29:34.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:29:34.832+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:29:34.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:29:34.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:29:34.871+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:29:34.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:29:34.885+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:29:34.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:29:34.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-17T23:30:05.260+0000] {processor.py:157} INFO - Started process (PID=63152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:30:05.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:30:05.264+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:30:05.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:30:05.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:30:05.314+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:30:05.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:30:05.332+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:30:05.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:30:05.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T23:30:35.534+0000] {processor.py:157} INFO - Started process (PID=63162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:30:35.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:30:35.538+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:30:35.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:30:35.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:30:35.568+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:30:35.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:30:35.578+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:30:35.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:30:35.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T23:31:05.942+0000] {processor.py:157} INFO - Started process (PID=63172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:31:05.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:31:05.955+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:31:05.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:31:05.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:31:06.000+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:31:05.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:31:06.014+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:31:06.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:31:06.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-17T23:31:36.238+0000] {processor.py:157} INFO - Started process (PID=63182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:31:36.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:31:36.240+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:31:36.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:31:36.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:31:36.267+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:31:36.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:31:36.280+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:31:36.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:31:36.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T23:32:06.670+0000] {processor.py:157} INFO - Started process (PID=63192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:32:06.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:32:06.674+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:32:06.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:32:06.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:32:06.716+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:32:06.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:32:06.730+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:32:06.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:32:06.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T23:32:37.200+0000] {processor.py:157} INFO - Started process (PID=63201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:32:37.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:32:37.206+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:32:37.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:32:37.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:32:37.234+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:32:37.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:32:37.249+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:32:37.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:32:37.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T23:33:07.575+0000] {processor.py:157} INFO - Started process (PID=63212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:33:07.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:33:07.577+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:33:07.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:33:07.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:33:07.604+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:33:07.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:33:07.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:33:07.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:33:07.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T23:33:37.954+0000] {processor.py:157} INFO - Started process (PID=63222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:33:37.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:33:37.958+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:33:37.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:33:37.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:33:38.001+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:33:38.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:33:38.017+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:33:38.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:33:38.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T23:34:08.354+0000] {processor.py:157} INFO - Started process (PID=63232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:34:08.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:34:08.363+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:34:08.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:34:08.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:34:08.397+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:34:08.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:34:08.407+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:34:08.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:34:08.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-17T23:34:38.750+0000] {processor.py:157} INFO - Started process (PID=63242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:34:38.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:34:38.753+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:34:38.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:34:38.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:34:38.781+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:34:38.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:34:38.792+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:34:38.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:34:38.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T23:35:09.152+0000] {processor.py:157} INFO - Started process (PID=63252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:35:09.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:35:09.155+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:35:09.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:35:09.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:35:09.194+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:35:09.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:35:09.208+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:35:09.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:35:09.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T23:35:39.585+0000] {processor.py:157} INFO - Started process (PID=63262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:35:39.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:35:39.589+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:35:39.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:35:39.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:35:39.619+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:35:39.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:35:39.629+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:35:39.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:35:39.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-17T23:36:09.996+0000] {processor.py:157} INFO - Started process (PID=63272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:36:09.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:36:09.998+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:36:09.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:36:10.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:36:10.025+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:36:10.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:36:10.035+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:36:10.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:36:10.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-17T23:36:40.419+0000] {processor.py:157} INFO - Started process (PID=63282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:36:40.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:36:40.424+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:36:40.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:36:40.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:36:40.455+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:36:40.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:36:40.465+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:36:40.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:36:40.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T23:37:10.896+0000] {processor.py:157} INFO - Started process (PID=63292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:37:10.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:37:10.901+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:37:10.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:37:10.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:37:10.938+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:37:10.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:37:10.952+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:37:10.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:37:10.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-17T23:37:41.236+0000] {processor.py:157} INFO - Started process (PID=63302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:37:41.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:37:41.239+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:37:41.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:37:41.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:37:41.267+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:37:41.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:37:41.278+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:37:41.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:37:41.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T23:38:11.738+0000] {processor.py:157} INFO - Started process (PID=63312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:38:11.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:38:11.742+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:38:11.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:38:11.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:38:11.782+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:38:11.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:38:11.796+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:38:11.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:38:11.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T23:38:42.225+0000] {processor.py:157} INFO - Started process (PID=63322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:38:42.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:38:42.229+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:38:42.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:38:42.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:38:42.256+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:38:42.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:38:42.267+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:38:42.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:38:42.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T23:39:12.687+0000] {processor.py:157} INFO - Started process (PID=63332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:39:12.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:39:12.692+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:39:12.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:39:12.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:39:12.737+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:39:12.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:39:12.750+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:39:12.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:39:12.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T23:39:43.064+0000] {processor.py:157} INFO - Started process (PID=63342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:39:43.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:39:43.068+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:39:43.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:39:43.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:39:43.097+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:39:43.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:39:43.107+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:39:43.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:39:43.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T23:40:13.544+0000] {processor.py:157} INFO - Started process (PID=63352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:40:13.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:40:13.550+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:40:13.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:40:13.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:40:13.589+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:40:13.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:40:13.602+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:40:13.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:40:13.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T23:40:43.931+0000] {processor.py:157} INFO - Started process (PID=63362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:40:43.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:40:43.933+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:40:43.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:40:43.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:40:43.966+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:40:43.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:40:43.978+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:40:43.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:40:43.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-17T23:41:14.234+0000] {processor.py:157} INFO - Started process (PID=63372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:41:14.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:41:14.238+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:41:14.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:41:14.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:41:14.274+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:41:14.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:41:14.288+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:41:14.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:41:14.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T23:41:44.623+0000] {processor.py:157} INFO - Started process (PID=63382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:41:44.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:41:44.629+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:41:44.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:41:44.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:41:44.657+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:41:44.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:41:44.668+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:41:44.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:41:44.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T23:42:14.981+0000] {processor.py:157} INFO - Started process (PID=63392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:42:14.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:42:14.983+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:42:14.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:42:14.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:42:15.016+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:42:15.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:42:15.032+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:42:15.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:42:15.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T23:42:45.446+0000] {processor.py:157} INFO - Started process (PID=63402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:42:45.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:42:45.449+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:42:45.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:42:45.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:42:45.499+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:42:45.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:42:45.520+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:42:45.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:42:45.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T23:43:15.917+0000] {processor.py:157} INFO - Started process (PID=63412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:43:15.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:43:15.920+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:43:15.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:43:15.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:43:15.961+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:43:15.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:43:15.972+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:43:15.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:43:15.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T23:43:46.350+0000] {processor.py:157} INFO - Started process (PID=63422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:43:46.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:43:46.356+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:43:46.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:43:46.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:43:46.393+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:43:46.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:43:46.405+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:43:46.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:43:46.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T23:44:16.730+0000] {processor.py:157} INFO - Started process (PID=63432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:44:16.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:44:16.735+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:44:16.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:44:16.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:44:16.777+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:44:16.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:44:16.787+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:44:16.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:44:16.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T23:44:47.127+0000] {processor.py:157} INFO - Started process (PID=63442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:44:47.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:44:47.130+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:44:47.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:44:47.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:44:47.159+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:44:47.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:44:47.172+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:44:47.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:44:47.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-17T23:45:17.484+0000] {processor.py:157} INFO - Started process (PID=63452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:45:17.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:45:17.491+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:45:17.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:45:17.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:45:17.530+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:45:17.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:45:17.544+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:45:17.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:45:17.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-17T23:45:47.824+0000] {processor.py:157} INFO - Started process (PID=63462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:45:47.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:45:47.827+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:45:47.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:45:47.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:45:47.856+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:45:47.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:45:47.868+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:45:47.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:45:47.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-17T23:46:18.272+0000] {processor.py:157} INFO - Started process (PID=63472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:46:18.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:46:18.275+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:46:18.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:46:18.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:46:18.302+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:46:18.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:46:18.313+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:46:18.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:46:18.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-17T23:46:48.730+0000] {processor.py:157} INFO - Started process (PID=63482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:46:48.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:46:48.740+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:46:48.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:46:48.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:46:48.783+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:46:48.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:46:48.796+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:46:48.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:46:48.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-17T23:47:19.099+0000] {processor.py:157} INFO - Started process (PID=63492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:47:19.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:47:19.101+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:47:19.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:47:19.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:47:19.130+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:47:19.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:47:19.141+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:47:19.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:47:19.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T23:47:49.498+0000] {processor.py:157} INFO - Started process (PID=63502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:47:49.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:47:49.504+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:47:49.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:47:49.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:47:49.541+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:47:49.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:47:49.555+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:47:49.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:47:49.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T23:48:19.866+0000] {processor.py:157} INFO - Started process (PID=63512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:48:19.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:48:19.870+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:48:19.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:48:19.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:48:19.895+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:48:19.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:48:19.905+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:48:19.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:48:19.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-17T23:48:50.237+0000] {processor.py:157} INFO - Started process (PID=63522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:48:50.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:48:50.240+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:48:50.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:48:50.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:48:50.268+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:48:50.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:48:50.279+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:48:50.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:48:50.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T23:49:20.664+0000] {processor.py:157} INFO - Started process (PID=63532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:49:20.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:49:20.666+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:49:20.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:49:20.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:49:20.694+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:49:20.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:49:20.708+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:49:20.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:49:20.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-17T23:49:51.121+0000] {processor.py:157} INFO - Started process (PID=63542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:49:51.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:49:51.126+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:49:51.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:49:51.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:49:51.166+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:49:51.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:49:51.179+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:49:51.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:49:51.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-17T23:50:21.463+0000] {processor.py:157} INFO - Started process (PID=63552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:50:21.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:50:21.467+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:50:21.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:50:21.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:50:21.508+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:50:21.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:50:21.519+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:50:21.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:50:21.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-17T23:50:51.990+0000] {processor.py:157} INFO - Started process (PID=63562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:50:51.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:50:51.993+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:50:51.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:50:52.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:50:52.027+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:50:52.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:50:52.040+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:50:52.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:50:52.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T23:51:22.375+0000] {processor.py:157} INFO - Started process (PID=63572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:51:22.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:51:22.379+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:51:22.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:51:22.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:51:22.423+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:51:22.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:51:22.433+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:51:22.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:51:22.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-17T23:51:52.741+0000] {processor.py:157} INFO - Started process (PID=63582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:51:52.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:51:52.743+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:51:52.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:51:52.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:51:52.769+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:51:52.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:51:52.781+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:51:52.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:51:52.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-17T23:52:23.162+0000] {processor.py:157} INFO - Started process (PID=63592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:52:23.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:52:23.165+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:52:23.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:52:23.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:52:23.198+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:52:23.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:52:23.214+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:52:23.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:52:23.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-17T23:52:53.569+0000] {processor.py:157} INFO - Started process (PID=63602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:52:53.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:52:53.573+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:52:53.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:52:53.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:52:53.605+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:52:53.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:52:53.617+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:52:53.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:52:53.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-17T23:53:23.981+0000] {processor.py:157} INFO - Started process (PID=63612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:53:23.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:53:23.990+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:53:23.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:53:24.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:53:24.022+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:53:24.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:53:24.033+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:53:24.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:53:24.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T23:53:54.460+0000] {processor.py:157} INFO - Started process (PID=63622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:53:54.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:53:54.462+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:53:54.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:53:54.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:53:54.492+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:53:54.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:53:54.503+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:53:54.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:53:54.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-17T23:54:24.854+0000] {processor.py:157} INFO - Started process (PID=63632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:54:24.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:54:24.858+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:54:24.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:54:24.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:54:24.892+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:54:24.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:54:24.905+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:54:24.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:54:24.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-17T23:54:55.199+0000] {processor.py:157} INFO - Started process (PID=63642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:54:55.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:54:55.203+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:54:55.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:54:55.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:54:55.235+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:54:55.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:54:55.245+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:54:55.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:54:55.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-17T23:55:25.610+0000] {processor.py:157} INFO - Started process (PID=63652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:55:25.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:55:25.613+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:55:25.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:55:25.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:55:25.648+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:55:25.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:55:25.663+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:55:25.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:55:25.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-17T23:55:56.051+0000] {processor.py:157} INFO - Started process (PID=63662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:55:56.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:55:56.060+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:55:56.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:55:56.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:55:56.094+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:55:56.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:55:56.107+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:55:56.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:55:56.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T23:56:26.482+0000] {processor.py:157} INFO - Started process (PID=63672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:56:26.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:56:26.486+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:56:26.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:56:26.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:56:26.527+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:56:26.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:56:26.541+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:56:26.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:56:26.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-17T23:56:56.780+0000] {processor.py:157} INFO - Started process (PID=63682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:56:56.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:56:56.788+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:56:56.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:56:56.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:56:56.832+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:56:56.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:56:56.846+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:56:56.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:56:56.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-17T23:57:27.238+0000] {processor.py:157} INFO - Started process (PID=63692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:57:27.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:57:27.260+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:57:27.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:57:27.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:57:27.302+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:57:27.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:57:27.316+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:57:27.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:57:27.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-17T23:57:57.613+0000] {processor.py:157} INFO - Started process (PID=63702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:57:57.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:57:57.619+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:57:57.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:57:57.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:57:57.645+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:57:57.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:57:57.656+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:57:57.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:57:57.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-17T23:58:28.021+0000] {processor.py:157} INFO - Started process (PID=63712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:58:28.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:58:28.025+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:58:28.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:58:28.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:58:28.064+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:58:28.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:58:28.079+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:58:28.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:58:28.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-17T23:58:58.419+0000] {processor.py:157} INFO - Started process (PID=63722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:58:58.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:58:58.421+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:58:58.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:58:58.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:58:58.454+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:58:58.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:58:58.466+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:58:58.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:58:58.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-17T23:59:28.873+0000] {processor.py:157} INFO - Started process (PID=63731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:59:28.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:59:28.884+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:59:28.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:59:28.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:59:28.934+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:59:28.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:59:28.948+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:59:28.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:59:28.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-17T23:59:59.350+0000] {processor.py:157} INFO - Started process (PID=63742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:59:59.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-17T23:59:59.353+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:59:59.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:59:59.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-17T23:59:59.385+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:59:59.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-17T23:59:59.397+0000] {logging_mixin.py:151} INFO - [2024-08-17T23:59:59.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-16T01:00:00+00:00, run_after=2024-08-17T01:00:00+00:00
[2024-08-17T23:59:59.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
