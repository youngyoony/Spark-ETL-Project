[2024-08-13T00:30:09.769+0000] {processor.py:157} INFO - Started process (PID=36900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:30:09.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:30:09.777+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:30:09.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:30:09.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:30:09.869+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:30:09.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:30:09.919+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:30:09.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:30:09.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.222 seconds
[2024-08-13T00:30:40.356+0000] {processor.py:157} INFO - Started process (PID=37503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:30:40.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:30:40.362+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:30:40.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:30:40.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:30:40.423+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:30:40.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:30:40.443+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:30:40.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:30:40.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-13T00:42:43.598+0000] {processor.py:157} INFO - Started process (PID=37515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:42:43.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:42:43.606+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:42:43.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:42:43.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:42:43.685+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:42:43.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:42:43.711+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:42:43.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:42:43.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-13T00:43:20.439+0000] {processor.py:157} INFO - Started process (PID=37693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:43:20.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:43:20.449+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:43:20.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:43:20.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:43:20.513+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:43:20.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:43:20.534+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:43:20.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:43:20.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-13T00:43:50.879+0000] {processor.py:157} INFO - Started process (PID=37703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:43:50.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:43:50.883+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:43:50.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:43:50.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:43:50.911+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:43:50.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:43:50.934+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:43:50.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:43:50.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-13T00:56:15.693+0000] {processor.py:157} INFO - Started process (PID=37715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:56:15.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:56:15.701+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:56:15.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:56:15.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:56:15.753+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:56:15.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:56:15.769+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:56:15.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:56:15.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-13T00:56:45.998+0000] {processor.py:157} INFO - Started process (PID=37725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:56:46.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:56:46.006+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:56:46.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:56:46.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:56:46.066+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:56:46.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:56:46.092+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:56:46.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:56:46.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-13T00:57:16.243+0000] {processor.py:157} INFO - Started process (PID=37735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:57:16.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:57:16.246+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:57:16.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:57:16.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:57:16.276+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:57:16.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:57:16.289+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:57:16.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:57:16.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-13T00:57:46.594+0000] {processor.py:157} INFO - Started process (PID=37745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:57:46.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:57:46.600+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:57:46.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:57:46.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:57:46.643+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:57:46.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:57:46.658+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:57:46.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:57:46.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-13T00:58:17.063+0000] {processor.py:157} INFO - Started process (PID=37755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:58:17.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:58:17.074+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:58:17.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:58:17.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:58:17.143+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:58:17.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:58:17.164+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:58:17.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:58:17.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-13T00:58:47.421+0000] {processor.py:157} INFO - Started process (PID=37765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:58:47.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:58:47.426+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:58:47.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:58:47.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:58:47.507+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:58:47.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:58:47.531+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:58:47.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:58:47.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-13T00:59:17.765+0000] {processor.py:157} INFO - Started process (PID=37775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:59:17.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:59:17.774+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:59:17.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:59:17.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:59:17.855+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:59:17.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:59:17.876+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:59:17.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:59:17.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-13T00:59:48.005+0000] {processor.py:157} INFO - Started process (PID=37785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:59:48.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T00:59:48.007+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:59:48.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:59:48.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T00:59:48.042+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:59:48.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T00:59:48.055+0000] {logging_mixin.py:151} INFO - [2024-08-13T00:59:48.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-13T00:59:48.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-13T01:00:18.328+0000] {processor.py:157} INFO - Started process (PID=37795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:00:18.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:00:18.337+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:00:18.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:00:18.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:00:18.400+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:00:18.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:00:18.418+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:00:18.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:00:18.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-13T01:00:48.795+0000] {processor.py:157} INFO - Started process (PID=37805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:00:48.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:00:48.806+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:00:48.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:00:48.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:00:48.869+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:00:48.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:00:48.893+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:00:48.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:00:48.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-13T01:01:19.117+0000] {processor.py:157} INFO - Started process (PID=37815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:01:19.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:01:19.128+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:01:19.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:01:19.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:01:19.200+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:01:19.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:01:19.219+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:01:19.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:01:19.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-13T01:01:49.381+0000] {processor.py:157} INFO - Started process (PID=37825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:01:49.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:01:49.390+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:01:49.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:01:49.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:01:49.420+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:01:49.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:01:49.433+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:01:49.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:01:49.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-13T01:02:19.697+0000] {processor.py:157} INFO - Started process (PID=37835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:02:19.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:02:19.706+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:02:19.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:02:19.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:02:19.780+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:02:19.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:02:19.800+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:02:19.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:02:19.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-13T01:02:50.179+0000] {processor.py:157} INFO - Started process (PID=37845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:02:50.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:02:50.183+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:02:50.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:02:50.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:02:50.240+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:02:50.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:02:50.264+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:02:50.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:02:50.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-13T01:03:20.466+0000] {processor.py:157} INFO - Started process (PID=37855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:03:20.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:03:20.469+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:03:20.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:03:20.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:03:20.504+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:03:20.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:03:20.517+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:03:20.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:03:20.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-13T01:03:50.723+0000] {processor.py:157} INFO - Started process (PID=37865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:03:50.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:03:50.725+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:03:50.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:03:50.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:03:50.755+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:03:50.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:03:50.768+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:03:50.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:03:50.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-13T01:04:20.988+0000] {processor.py:157} INFO - Started process (PID=37875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:04:20.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:04:20.992+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:04:20.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:04:21.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:04:21.037+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:04:21.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:04:21.054+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:04:21.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:04:21.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-13T01:04:51.331+0000] {processor.py:157} INFO - Started process (PID=37885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:04:51.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:04:51.339+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:04:51.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:04:51.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:04:51.424+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:04:51.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:04:51.445+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:04:51.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:04:51.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-13T01:05:21.642+0000] {processor.py:157} INFO - Started process (PID=37895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:05:21.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:05:21.649+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:05:21.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:05:21.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:05:21.720+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:05:21.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:05:21.740+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:05:21.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:05:21.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-13T01:05:52.039+0000] {processor.py:157} INFO - Started process (PID=37905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:05:52.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:05:52.041+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:05:52.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:05:52.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:05:52.078+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:05:52.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:05:52.093+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:05:52.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:05:52.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-13T01:06:22.390+0000] {processor.py:157} INFO - Started process (PID=37915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:06:22.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:06:22.398+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:06:22.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:06:22.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:06:22.442+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:06:22.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:06:22.455+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:06:22.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:06:22.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-13T01:06:52.803+0000] {processor.py:157} INFO - Started process (PID=37925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:06:52.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:06:52.812+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:06:52.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:06:52.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:06:52.897+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:06:52.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:06:52.925+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:06:52.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:06:52.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-13T01:07:23.182+0000] {processor.py:157} INFO - Started process (PID=37935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:07:23.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:07:23.190+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:07:23.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:07:23.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:07:23.230+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:07:23.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:07:23.243+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:07:23.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:07:23.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-13T01:07:53.494+0000] {processor.py:157} INFO - Started process (PID=37945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:07:53.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:07:53.498+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:07:53.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:07:53.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:07:53.531+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:07:53.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:07:53.543+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:07:53.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:07:53.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-13T01:08:23.911+0000] {processor.py:157} INFO - Started process (PID=37955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:08:23.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:08:23.920+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:08:23.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:08:23.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:08:23.985+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:08:23.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:08:24.004+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:08:24.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:08:24.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-13T01:08:54.348+0000] {processor.py:157} INFO - Started process (PID=37965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:08:54.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:08:54.356+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:08:54.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:08:54.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:08:54.432+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:08:54.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:08:54.451+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:08:54.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:08:54.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-13T01:09:24.606+0000] {processor.py:157} INFO - Started process (PID=37975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:09:24.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:09:24.614+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:09:24.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:09:24.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:09:24.646+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:09:24.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:09:24.656+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:09:24.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:09:24.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-13T01:09:55.050+0000] {processor.py:157} INFO - Started process (PID=37985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:09:55.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:09:55.057+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:09:55.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:09:55.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:09:55.139+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:09:55.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:09:55.161+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:09:55.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:09:55.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-13T01:10:25.314+0000] {processor.py:157} INFO - Started process (PID=37995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:10:25.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:10:25.318+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:10:25.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:10:25.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:10:25.349+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:10:25.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:10:25.362+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:10:25.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:10:25.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-13T01:10:55.730+0000] {processor.py:157} INFO - Started process (PID=38005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:10:55.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:10:55.745+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:10:55.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:10:55.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:10:55.821+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:10:55.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:10:55.848+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:10:55.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:10:55.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-13T01:11:26.005+0000] {processor.py:157} INFO - Started process (PID=38015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:11:26.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:11:26.007+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:11:26.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:11:26.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:11:26.043+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:11:26.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:11:26.056+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:11:26.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:11:26.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-13T01:11:56.326+0000] {processor.py:157} INFO - Started process (PID=38025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:11:56.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:11:56.329+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:11:56.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:11:56.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:11:56.361+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:11:56.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:11:56.375+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:11:56.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:11:56.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-13T01:12:26.590+0000] {processor.py:157} INFO - Started process (PID=38035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:12:26.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:12:26.593+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:12:26.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:12:26.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:12:26.637+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:12:26.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:12:26.652+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:12:26.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:12:26.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-13T01:12:56.825+0000] {processor.py:157} INFO - Started process (PID=38045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:12:56.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:12:56.828+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:12:56.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:12:56.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:12:56.860+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:12:56.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:12:56.875+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:12:56.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:12:56.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-13T01:13:27.069+0000] {processor.py:157} INFO - Started process (PID=38055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:13:27.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:13:27.074+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:13:27.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:13:27.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:13:27.109+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:13:27.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:13:27.123+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:13:27.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:13:27.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-13T01:13:57.285+0000] {processor.py:157} INFO - Started process (PID=38065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:13:57.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:13:57.293+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:13:57.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:13:57.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:13:57.323+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:13:57.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:13:57.335+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:13:57.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:13:57.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-13T01:14:27.633+0000] {processor.py:157} INFO - Started process (PID=38075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:14:27.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:14:27.636+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:14:27.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:14:27.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:14:27.672+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:14:27.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:14:27.686+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:14:27.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:14:27.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-13T01:14:57.886+0000] {processor.py:157} INFO - Started process (PID=38085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:14:57.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:14:57.891+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:14:57.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:14:57.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:14:57.935+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:14:57.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:14:57.951+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:14:57.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:14:57.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-13T01:15:28.153+0000] {processor.py:157} INFO - Started process (PID=38095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:15:28.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:15:28.159+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:15:28.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:15:28.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:15:28.209+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:15:28.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:15:28.223+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:15:28.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:15:28.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-13T01:15:58.442+0000] {processor.py:157} INFO - Started process (PID=38105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:15:58.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:15:58.445+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:15:58.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:15:58.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:15:58.478+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:15:58.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:15:58.490+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:15:58.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:15:58.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-13T01:16:28.796+0000] {processor.py:157} INFO - Started process (PID=38115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:16:28.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:16:28.798+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:16:28.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:16:28.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:16:28.830+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:16:28.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:16:28.843+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:16:28.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:16:28.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-13T01:16:59.056+0000] {processor.py:157} INFO - Started process (PID=38125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:16:59.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:16:59.059+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:16:59.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:16:59.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:16:59.094+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:16:59.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:16:59.108+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:16:59.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:16:59.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-13T01:17:29.359+0000] {processor.py:157} INFO - Started process (PID=38135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:17:29.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:17:29.364+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:17:29.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:17:29.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:17:29.406+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:17:29.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:17:29.422+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:17:29.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:17:29.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-13T01:17:59.700+0000] {processor.py:157} INFO - Started process (PID=38145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:17:59.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:17:59.703+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:17:59.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:17:59.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:17:59.738+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:17:59.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:17:59.753+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:17:59.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:17:59.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-13T01:18:30.015+0000] {processor.py:157} INFO - Started process (PID=38155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:18:30.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:18:30.026+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:18:30.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:18:30.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:18:30.057+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:18:30.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:18:30.067+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:18:30.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:18:30.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-13T01:19:00.316+0000] {processor.py:157} INFO - Started process (PID=38165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:19:00.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:19:00.321+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:19:00.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:19:00.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:19:00.424+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:19:00.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:19:00.446+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:19:00.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:19:00.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-13T01:19:30.582+0000] {processor.py:157} INFO - Started process (PID=38175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:19:30.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:19:30.587+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:19:30.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:19:30.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:19:30.623+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:19:30.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:19:30.638+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:19:30.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:19:30.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-13T01:20:00.827+0000] {processor.py:157} INFO - Started process (PID=38185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:20:00.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:20:00.834+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:20:00.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:20:00.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:20:00.869+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:20:00.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:20:00.881+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:20:00.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:20:00.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-13T01:20:31.156+0000] {processor.py:157} INFO - Started process (PID=38195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:20:31.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:20:31.163+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:20:31.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:20:31.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:20:31.200+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:20:31.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:20:31.211+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:20:31.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:20:31.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-13T01:21:01.525+0000] {processor.py:157} INFO - Started process (PID=38205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:21:01.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:21:01.530+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:21:01.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:21:01.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:21:01.584+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:21:01.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:21:01.600+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:21:01.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:21:01.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-13T01:21:31.788+0000] {processor.py:157} INFO - Started process (PID=38215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:21:31.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:21:31.792+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:21:31.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:21:31.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:21:31.826+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:21:31.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:21:31.840+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:21:31.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:21:31.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-13T01:22:02.067+0000] {processor.py:157} INFO - Started process (PID=38225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:22:02.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:22:02.077+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:22:02.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:22:02.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:22:02.105+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:22:02.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:22:02.119+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:22:02.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:22:02.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-13T01:22:32.380+0000] {processor.py:157} INFO - Started process (PID=38235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:22:32.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:22:32.383+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:22:32.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:22:32.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:22:32.421+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:22:32.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:22:32.435+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:22:32.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:22:32.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-13T01:23:02.711+0000] {processor.py:157} INFO - Started process (PID=38245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:23:02.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:23:02.715+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:23:02.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:23:02.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:23:02.762+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:23:02.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:23:02.779+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:23:02.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:23:02.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-13T01:23:33.158+0000] {processor.py:157} INFO - Started process (PID=38255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:23:33.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:23:33.178+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:23:33.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:23:33.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:23:33.230+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:23:33.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:23:33.267+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:23:33.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:23:33.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-13T01:24:04.014+0000] {processor.py:157} INFO - Started process (PID=38265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:24:04.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:24:04.020+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:24:04.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:24:04.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:24:04.091+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:24:04.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:24:04.112+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:24:04.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:24:04.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-13T01:24:34.314+0000] {processor.py:157} INFO - Started process (PID=38275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:24:34.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:24:34.318+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:24:34.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:24:34.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:24:34.367+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:24:34.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:24:34.386+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:24:34.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:24:34.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-13T01:25:04.573+0000] {processor.py:157} INFO - Started process (PID=38285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:25:04.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:25:04.576+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:25:04.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:25:04.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:25:04.615+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:25:04.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:25:04.630+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:25:04.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:25:04.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-13T01:25:34.882+0000] {processor.py:157} INFO - Started process (PID=38295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:25:34.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:25:34.888+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:25:34.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:25:34.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:25:34.943+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:25:34.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:25:34.960+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:25:34.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:25:34.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-13T01:26:05.144+0000] {processor.py:157} INFO - Started process (PID=38305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:26:05.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:26:05.148+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:26:05.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:26:05.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:26:05.199+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:26:05.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:26:05.221+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:26:05.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:26:05.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-13T01:26:35.517+0000] {processor.py:157} INFO - Started process (PID=38315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:26:35.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:26:35.520+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:26:35.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:26:35.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:26:35.553+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:26:35.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:26:35.567+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:26:35.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:26:35.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-13T01:27:05.794+0000] {processor.py:157} INFO - Started process (PID=38325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:27:05.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:27:05.798+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:27:05.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:27:05.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:27:05.831+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:27:05.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:27:05.843+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:27:05.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:27:05.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-13T01:27:36.059+0000] {processor.py:157} INFO - Started process (PID=38335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:27:36.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:27:36.062+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:27:36.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:27:36.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:27:36.097+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:27:36.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:27:36.109+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:27:36.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:27:36.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-13T01:28:06.324+0000] {processor.py:157} INFO - Started process (PID=38345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:28:06.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:28:06.331+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:28:06.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:28:06.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:28:06.368+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:28:06.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:28:06.381+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:28:06.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:28:06.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-13T01:28:36.571+0000] {processor.py:157} INFO - Started process (PID=38355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:28:36.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:28:36.582+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:28:36.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:28:36.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:28:36.631+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:28:36.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:28:36.648+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:28:36.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:28:36.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-13T01:29:06.935+0000] {processor.py:157} INFO - Started process (PID=38365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:29:06.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:29:06.939+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:29:06.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:29:06.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:29:06.973+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:29:06.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:29:06.984+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:29:06.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:29:06.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-13T01:29:37.287+0000] {processor.py:157} INFO - Started process (PID=38375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:29:37.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:29:37.292+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:29:37.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:29:37.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:29:37.327+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:29:37.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:29:37.341+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:29:37.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:29:37.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-13T01:30:07.587+0000] {processor.py:157} INFO - Started process (PID=38385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:30:07.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:30:07.595+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:30:07.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:30:07.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:30:07.666+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:30:07.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:30:07.683+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:30:07.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:30:07.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-13T01:30:37.877+0000] {processor.py:157} INFO - Started process (PID=38395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:30:37.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:30:37.881+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:30:37.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:30:37.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:30:37.917+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:30:37.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:30:37.931+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:30:37.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:30:37.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-13T01:31:08.176+0000] {processor.py:157} INFO - Started process (PID=38405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:31:08.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:31:08.187+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:31:08.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:31:08.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:31:08.251+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:31:08.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:31:08.294+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:31:08.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:31:08.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-13T01:31:38.404+0000] {processor.py:157} INFO - Started process (PID=38415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:31:38.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:31:38.407+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:31:38.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:31:38.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:31:38.441+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:31:38.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:31:38.453+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:31:38.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:31:38.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-13T01:32:08.673+0000] {processor.py:157} INFO - Started process (PID=38425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:32:08.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:32:08.679+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:32:08.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:32:08.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:32:08.716+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:32:08.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:32:08.733+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:32:08.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:32:08.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-13T01:32:38.937+0000] {processor.py:157} INFO - Started process (PID=38435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:32:38.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:32:38.941+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:32:38.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:32:38.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:32:38.975+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:32:38.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:32:38.988+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:32:38.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:32:38.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-13T01:33:09.203+0000] {processor.py:157} INFO - Started process (PID=38445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:33:09.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:33:09.207+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:33:09.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:33:09.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:33:09.243+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:33:09.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:33:09.258+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:33:09.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:33:09.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-13T01:33:39.458+0000] {processor.py:157} INFO - Started process (PID=38455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:33:39.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:33:39.465+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:33:39.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:33:39.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:33:39.507+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:33:39.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:33:39.522+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:33:39.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:33:39.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-13T01:34:09.797+0000] {processor.py:157} INFO - Started process (PID=38465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:34:09.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:34:09.804+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:34:09.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:34:09.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:34:09.841+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:34:09.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:34:09.858+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:34:09.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:34:09.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-13T01:34:40.043+0000] {processor.py:157} INFO - Started process (PID=38475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:34:40.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:34:40.055+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:34:40.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:34:40.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:34:40.088+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:34:40.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:34:40.103+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:34:40.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:34:40.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-13T01:35:10.673+0000] {processor.py:157} INFO - Started process (PID=38485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:35:10.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T01:35:10.678+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:35:10.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:35:10.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T01:35:10.734+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:35:10.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T01:35:10.750+0000] {logging_mixin.py:151} INFO - [2024-08-13T01:35:10.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T01:35:10.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-13T02:24:06.980+0000] {processor.py:157} INFO - Started process (PID=38495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T02:24:06.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T02:24:06.983+0000] {logging_mixin.py:151} INFO - [2024-08-13T02:24:06.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T02:24:06.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T02:24:07.004+0000] {logging_mixin.py:151} INFO - [2024-08-13T02:24:07.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T02:24:07.013+0000] {logging_mixin.py:151} INFO - [2024-08-13T02:24:07.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T02:24:07.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-08-13T02:24:37.364+0000] {processor.py:157} INFO - Started process (PID=38506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T02:24:37.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T02:24:37.369+0000] {logging_mixin.py:151} INFO - [2024-08-13T02:24:37.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T02:24:37.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T02:24:37.412+0000] {logging_mixin.py:151} INFO - [2024-08-13T02:24:37.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T02:24:37.426+0000] {logging_mixin.py:151} INFO - [2024-08-13T02:24:37.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T02:24:37.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-13T03:31:10.050+0000] {processor.py:157} INFO - Started process (PID=38519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T03:31:10.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T03:31:10.065+0000] {logging_mixin.py:151} INFO - [2024-08-13T03:31:10.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T03:31:10.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T03:31:10.108+0000] {logging_mixin.py:151} INFO - [2024-08-13T03:31:10.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T03:31:10.122+0000] {logging_mixin.py:151} INFO - [2024-08-13T03:31:10.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T03:31:10.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-13T03:36:15.195+0000] {processor.py:157} INFO - Started process (PID=38529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T03:36:15.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T03:36:15.207+0000] {logging_mixin.py:151} INFO - [2024-08-13T03:36:15.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T03:36:15.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T03:36:15.276+0000] {logging_mixin.py:151} INFO - [2024-08-13T03:36:15.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T03:36:15.320+0000] {logging_mixin.py:151} INFO - [2024-08-13T03:36:15.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T03:36:15.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-13T04:09:55.350+0000] {processor.py:157} INFO - Started process (PID=38539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:09:55.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T04:09:55.356+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:09:55.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:09:55.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:09:55.419+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:09:55.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T04:09:55.439+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:09:55.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T04:09:55.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-13T04:37:13.145+0000] {processor.py:157} INFO - Started process (PID=38549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:37:13.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T04:37:13.153+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:37:13.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:37:13.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:37:13.210+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:37:13.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T04:37:13.230+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:37:13.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T04:37:13.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-13T04:38:26.049+0000] {processor.py:157} INFO - Started process (PID=38560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:38:26.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T04:38:26.067+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:38:26.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:38:26.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:38:26.157+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:38:26.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T04:38:26.209+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:38:26.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T04:38:26.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-13T04:38:56.506+0000] {processor.py:157} INFO - Started process (PID=38571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:38:56.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T04:38:56.510+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:38:56.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:38:56.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:38:56.539+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:38:56.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T04:38:56.548+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:38:56.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T04:38:56.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-13T04:45:25.740+0000] {processor.py:157} INFO - Started process (PID=38580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:45:25.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T04:45:25.746+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:45:25.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:45:25.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:45:25.798+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:45:25.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T04:45:25.823+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:45:25.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T04:45:25.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-13T04:55:40.305+0000] {processor.py:157} INFO - Started process (PID=38591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:55:40.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T04:55:40.317+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:55:40.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:55:40.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:55:40.360+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:55:40.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T04:55:40.402+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:55:40.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T04:55:40.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-13T04:56:10.827+0000] {processor.py:157} INFO - Started process (PID=38601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:56:10.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T04:56:10.842+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:56:10.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:56:10.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T04:56:10.887+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:56:10.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T04:56:10.903+0000] {logging_mixin.py:151} INFO - [2024-08-13T04:56:10.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T04:56:10.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-13T05:14:06.959+0000] {processor.py:157} INFO - Started process (PID=38611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:14:06.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T05:14:06.964+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:14:06.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:14:06.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:14:07.009+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:14:07.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T05:14:07.029+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:14:07.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T05:14:07.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-13T05:14:37.342+0000] {processor.py:157} INFO - Started process (PID=38623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:14:37.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T05:14:37.348+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:14:37.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:14:37.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:14:37.400+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:14:37.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T05:14:37.419+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:14:37.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T05:14:37.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-13T05:38:07.786+0000] {processor.py:157} INFO - Started process (PID=38632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:38:07.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T05:38:07.793+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:38:07.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:38:07.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:38:07.855+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:38:07.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T05:38:07.883+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:38:07.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T05:38:07.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-13T05:38:38.223+0000] {processor.py:157} INFO - Started process (PID=38643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:38:38.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T05:38:38.236+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:38:38.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:38:38.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T05:38:38.283+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:38:38.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T05:38:38.307+0000] {logging_mixin.py:151} INFO - [2024-08-13T05:38:38.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T05:38:38.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-13T06:56:38.575+0000] {processor.py:157} INFO - Started process (PID=38655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T06:56:38.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T06:56:38.586+0000] {logging_mixin.py:151} INFO - [2024-08-13T06:56:38.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T06:56:38.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T06:56:38.690+0000] {logging_mixin.py:151} INFO - [2024-08-13T06:56:38.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T06:56:38.727+0000] {logging_mixin.py:151} INFO - [2024-08-13T06:56:38.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T06:56:38.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-08-13T06:57:09.104+0000] {processor.py:157} INFO - Started process (PID=38665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T06:57:09.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T06:57:09.108+0000] {logging_mixin.py:151} INFO - [2024-08-13T06:57:09.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T06:57:09.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T06:57:09.147+0000] {logging_mixin.py:151} INFO - [2024-08-13T06:57:09.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T06:57:09.168+0000] {logging_mixin.py:151} INFO - [2024-08-13T06:57:09.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T06:57:09.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-13T07:14:50.492+0000] {processor.py:157} INFO - Started process (PID=38674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T07:14:50.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T07:14:50.510+0000] {logging_mixin.py:151} INFO - [2024-08-13T07:14:50.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T07:14:50.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T07:14:50.574+0000] {logging_mixin.py:151} INFO - [2024-08-13T07:14:50.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T07:14:50.593+0000] {logging_mixin.py:151} INFO - [2024-08-13T07:14:50.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T07:14:50.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-13T07:15:20.783+0000] {processor.py:157} INFO - Started process (PID=38685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T07:15:20.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T07:15:20.788+0000] {logging_mixin.py:151} INFO - [2024-08-13T07:15:20.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T07:15:20.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T07:15:20.825+0000] {logging_mixin.py:151} INFO - [2024-08-13T07:15:20.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T07:15:20.838+0000] {logging_mixin.py:151} INFO - [2024-08-13T07:15:20.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T07:15:20.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-13T08:36:29.544+0000] {processor.py:157} INFO - Started process (PID=38696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T08:36:29.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T08:36:29.561+0000] {logging_mixin.py:151} INFO - [2024-08-13T08:36:29.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T08:36:29.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T08:36:29.640+0000] {logging_mixin.py:151} INFO - [2024-08-13T08:36:29.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T08:36:29.658+0000] {logging_mixin.py:151} INFO - [2024-08-13T08:36:29.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T08:36:29.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-13T09:35:21.205+0000] {processor.py:157} INFO - Started process (PID=38707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T09:35:21.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T09:35:21.212+0000] {logging_mixin.py:151} INFO - [2024-08-13T09:35:21.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T09:35:21.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T09:35:21.275+0000] {logging_mixin.py:151} INFO - [2024-08-13T09:35:21.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T09:35:21.307+0000] {logging_mixin.py:151} INFO - [2024-08-13T09:35:21.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T09:35:21.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-13T09:35:51.507+0000] {processor.py:157} INFO - Started process (PID=38717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T09:35:51.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T09:35:51.513+0000] {logging_mixin.py:151} INFO - [2024-08-13T09:35:51.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T09:35:51.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T09:35:51.568+0000] {logging_mixin.py:151} INFO - [2024-08-13T09:35:51.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T09:35:51.585+0000] {logging_mixin.py:151} INFO - [2024-08-13T09:35:51.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T09:35:51.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-13T10:01:22.248+0000] {processor.py:157} INFO - Started process (PID=38727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T10:01:22.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T10:01:22.251+0000] {logging_mixin.py:151} INFO - [2024-08-13T10:01:22.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T10:01:22.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T10:01:22.320+0000] {logging_mixin.py:151} INFO - [2024-08-13T10:01:22.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T10:01:22.352+0000] {logging_mixin.py:151} INFO - [2024-08-13T10:01:22.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T10:01:22.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-13T10:18:26.854+0000] {processor.py:157} INFO - Started process (PID=38739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T10:18:26.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T10:18:26.864+0000] {logging_mixin.py:151} INFO - [2024-08-13T10:18:26.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T10:18:26.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T10:18:26.933+0000] {logging_mixin.py:151} INFO - [2024-08-13T10:18:26.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T10:18:26.969+0000] {logging_mixin.py:151} INFO - [2024-08-13T10:18:26.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T10:18:27.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-13T11:56:21.272+0000] {processor.py:157} INFO - Started process (PID=38749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T11:56:21.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T11:56:21.279+0000] {logging_mixin.py:151} INFO - [2024-08-13T11:56:21.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T11:56:21.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T11:56:21.374+0000] {logging_mixin.py:151} INFO - [2024-08-13T11:56:21.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T11:56:21.406+0000] {logging_mixin.py:151} INFO - [2024-08-13T11:56:21.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T11:56:21.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-13T12:02:29.265+0000] {processor.py:157} INFO - Started process (PID=38759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:02:29.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:02:29.272+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:02:29.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:02:29.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:02:29.362+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:02:29.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:02:29.396+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:02:29.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:02:29.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-13T12:32:32.907+0000] {processor.py:157} INFO - Started process (PID=38769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:32:32.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:32:32.924+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:32:32.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:32:32.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:32:32.997+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:32:32.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:32:33.041+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:32:33.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:32:33.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-08-13T12:33:03.237+0000] {processor.py:157} INFO - Started process (PID=38779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:33:03.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:33:03.246+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:33:03.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:33:03.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:33:03.305+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:33:03.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:33:03.329+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:33:03.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:33:03.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-13T12:33:33.721+0000] {processor.py:157} INFO - Started process (PID=38789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:33:33.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:33:33.736+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:33:33.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:33:33.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:33:33.809+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:33:33.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:33:33.827+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:33:33.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:33:33.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-13T12:34:03.984+0000] {processor.py:157} INFO - Started process (PID=38799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:34:03.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:34:03.993+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:34:03.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:34:04.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:34:04.051+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:34:04.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:34:04.067+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:34:04.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:34:04.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-13T12:34:34.383+0000] {processor.py:157} INFO - Started process (PID=38809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:34:34.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:34:34.390+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:34:34.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:34:34.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:34:34.442+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:34:34.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:34:34.462+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:34:34.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:34:34.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-13T12:35:04.667+0000] {processor.py:157} INFO - Started process (PID=38819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:35:04.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:35:04.676+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:35:04.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:35:04.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:35:04.710+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:35:04.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:35:04.721+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:35:04.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:35:04.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-13T12:35:35.054+0000] {processor.py:157} INFO - Started process (PID=38829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:35:35.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:35:35.060+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:35:35.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:35:35.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:35:35.108+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:35:35.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:35:35.134+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:35:35.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:35:35.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-13T12:36:05.357+0000] {processor.py:157} INFO - Started process (PID=38839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:36:05.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:36:05.360+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:36:05.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:36:05.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:36:05.388+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:36:05.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:36:05.398+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:36:05.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:36:05.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-13T12:36:35.706+0000] {processor.py:157} INFO - Started process (PID=38849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:36:35.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:36:35.711+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:36:35.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:36:35.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:36:35.746+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:36:35.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:36:35.758+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:36:35.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:36:35.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-13T12:37:06.067+0000] {processor.py:157} INFO - Started process (PID=38859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:37:06.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:37:06.071+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:37:06.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:37:06.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:37:06.102+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:37:06.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:37:06.116+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:37:06.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:37:06.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-13T12:37:36.656+0000] {processor.py:157} INFO - Started process (PID=38868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:37:36.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T12:37:36.665+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:37:36.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:37:36.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T12:37:36.717+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:37:36.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T12:37:36.734+0000] {logging_mixin.py:151} INFO - [2024-08-13T12:37:36.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T12:37:36.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-13T13:28:42.909+0000] {processor.py:157} INFO - Started process (PID=38878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:28:42.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:28:42.933+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:28:42.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:28:42.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:28:43.037+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:28:43.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:28:43.096+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:28:43.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:28:43.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.267 seconds
[2024-08-13T13:29:13.312+0000] {processor.py:157} INFO - Started process (PID=38889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:29:13.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:29:13.320+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:29:13.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:29:13.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:29:13.379+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:29:13.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:29:13.393+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:29:13.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:29:13.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-13T13:38:23.734+0000] {processor.py:157} INFO - Started process (PID=38899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:38:23.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:38:23.741+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:38:23.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:38:23.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:38:23.816+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:38:23.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:38:23.856+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:38:23.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:38:23.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-13T13:38:54.055+0000] {processor.py:157} INFO - Started process (PID=38909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:38:54.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:38:54.064+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:38:54.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:38:54.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:38:54.117+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:38:54.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:38:54.138+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:38:54.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:38:54.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-13T13:39:24.456+0000] {processor.py:157} INFO - Started process (PID=38919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:39:24.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:39:24.464+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:39:24.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:39:24.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:39:24.511+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:39:24.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:39:24.526+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:39:24.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:39:24.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-13T13:39:54.781+0000] {processor.py:157} INFO - Started process (PID=38928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:39:54.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:39:54.789+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:39:54.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:39:54.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:39:54.851+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:39:54.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:39:54.870+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:39:54.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:39:54.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-13T13:40:25.190+0000] {processor.py:157} INFO - Started process (PID=38939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:40:25.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:40:25.204+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:40:25.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:40:25.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:40:25.274+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:40:25.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:40:25.292+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:40:25.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:40:25.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-13T13:40:55.542+0000] {processor.py:157} INFO - Started process (PID=38948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:40:55.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:40:55.546+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:40:55.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:40:55.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:40:55.607+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:40:55.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:40:55.624+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:40:55.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:40:55.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-13T13:41:25.833+0000] {processor.py:157} INFO - Started process (PID=38959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:41:25.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:41:25.836+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:41:25.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:41:25.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:41:25.885+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:41:25.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:41:25.900+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:41:25.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:41:25.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-13T13:41:56.203+0000] {processor.py:157} INFO - Started process (PID=38969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:41:56.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:41:56.214+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:41:56.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:41:56.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:41:56.276+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:41:56.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:41:56.292+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:41:56.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:41:56.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-13T13:42:26.653+0000] {processor.py:157} INFO - Started process (PID=38979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:42:26.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:42:26.679+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:42:26.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:42:26.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:42:26.775+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:42:26.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:42:26.801+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:42:26.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:42:26.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-08-13T13:42:56.938+0000] {processor.py:157} INFO - Started process (PID=38989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:42:56.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:42:56.946+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:42:56.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:42:56.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:42:57.039+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:42:57.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:42:57.059+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:42:57.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:42:57.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-13T13:43:27.381+0000] {processor.py:157} INFO - Started process (PID=38999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:43:27.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:43:27.388+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:43:27.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:43:27.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:43:27.455+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:43:27.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:43:27.470+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:43:27.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:43:27.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-13T13:43:57.737+0000] {processor.py:157} INFO - Started process (PID=39009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:43:57.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:43:57.753+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:43:57.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:43:57.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:43:57.812+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:43:57.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:43:57.827+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:43:57.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:43:57.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-13T13:59:48.345+0000] {processor.py:157} INFO - Started process (PID=39021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:59:48.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T13:59:48.376+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:59:48.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:59:48.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T13:59:48.504+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:59:48.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T13:59:48.542+0000] {logging_mixin.py:151} INFO - [2024-08-13T13:59:48.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T13:59:48.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.262 seconds
[2024-08-13T14:35:04.693+0000] {processor.py:157} INFO - Started process (PID=39031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:35:04.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T14:35:04.703+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:35:04.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:35:04.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:35:04.757+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:35:04.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T14:35:04.772+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:35:04.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T14:35:04.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-13T14:35:35.083+0000] {processor.py:157} INFO - Started process (PID=39040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:35:35.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T14:35:35.107+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:35:35.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:35:35.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:35:35.158+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:35:35.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T14:35:35.174+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:35:35.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T14:35:35.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-13T14:38:54.587+0000] {processor.py:157} INFO - Started process (PID=39051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:38:54.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T14:38:54.595+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:38:54.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:38:54.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T14:38:54.636+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:38:54.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T14:38:54.651+0000] {logging_mixin.py:151} INFO - [2024-08-13T14:38:54.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T14:38:54.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-13T15:27:38.446+0000] {processor.py:157} INFO - Started process (PID=39063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:27:38.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T15:27:38.468+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:27:38.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:27:38.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:27:38.525+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:27:38.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T15:27:38.548+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:27:38.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T15:27:38.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-13T15:28:08.745+0000] {processor.py:157} INFO - Started process (PID=39072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:28:08.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T15:28:08.760+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:28:08.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:28:08.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:28:08.824+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:28:08.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T15:28:08.838+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:28:08.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T15:28:08.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-13T15:30:16.239+0000] {processor.py:157} INFO - Started process (PID=39082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:30:16.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T15:30:16.255+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:30:16.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:30:16.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:30:16.367+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:30:16.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T15:30:16.403+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:30:16.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T15:30:16.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-13T15:30:46.589+0000] {processor.py:157} INFO - Started process (PID=39092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:30:46.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T15:30:46.596+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:30:46.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:30:46.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:30:46.669+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:30:46.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T15:30:46.682+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:30:46.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T15:30:46.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-13T15:33:19.013+0000] {processor.py:157} INFO - Started process (PID=39104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:33:19.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T15:33:19.020+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:33:19.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:33:19.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:33:19.100+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:33:19.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T15:33:19.129+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:33:19.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T15:33:19.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-08-13T15:34:02.254+0000] {processor.py:157} INFO - Started process (PID=39115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:34:02.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T15:34:02.273+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:34:02.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:34:02.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:34:02.325+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:34:02.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T15:34:02.351+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:34:02.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T15:34:02.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-13T15:34:32.633+0000] {processor.py:157} INFO - Started process (PID=39125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:34:32.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T15:34:32.636+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:34:32.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:34:32.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:34:32.669+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:34:32.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T15:34:32.682+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:34:32.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T15:34:32.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-13T15:45:38.012+0000] {processor.py:157} INFO - Started process (PID=39134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:45:38.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T15:45:38.023+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:45:38.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:45:38.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T15:45:38.072+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:45:38.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T15:45:38.090+0000] {logging_mixin.py:151} INFO - [2024-08-13T15:45:38.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T15:45:38.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-13T16:19:31.141+0000] {processor.py:157} INFO - Started process (PID=39145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:19:31.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T16:19:31.148+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:19:31.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:19:31.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:19:31.209+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:19:31.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T16:19:31.235+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:19:31.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T16:19:31.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-13T16:37:08.555+0000] {processor.py:157} INFO - Started process (PID=39156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:37:08.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T16:37:08.561+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:37:08.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:37:08.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:37:08.612+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:37:08.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T16:37:08.628+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:37:08.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T16:37:08.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-13T16:46:45.563+0000] {processor.py:157} INFO - Started process (PID=39167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:46:45.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T16:46:45.571+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:46:45.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:46:45.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T16:46:45.633+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:46:45.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T16:46:45.661+0000] {logging_mixin.py:151} INFO - [2024-08-13T16:46:45.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T16:46:45.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-13T17:37:40.508+0000] {processor.py:157} INFO - Started process (PID=39179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T17:37:40.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T17:37:40.515+0000] {logging_mixin.py:151} INFO - [2024-08-13T17:37:40.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T17:37:40.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T17:37:40.572+0000] {logging_mixin.py:151} INFO - [2024-08-13T17:37:40.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T17:37:40.586+0000] {logging_mixin.py:151} INFO - [2024-08-13T17:37:40.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T17:37:40.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-13T17:47:43.533+0000] {processor.py:157} INFO - Started process (PID=39188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T17:47:43.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T17:47:43.540+0000] {logging_mixin.py:151} INFO - [2024-08-13T17:47:43.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T17:47:43.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T17:47:43.607+0000] {logging_mixin.py:151} INFO - [2024-08-13T17:47:43.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T17:47:43.634+0000] {logging_mixin.py:151} INFO - [2024-08-13T17:47:43.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T17:47:43.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-13T18:22:27.563+0000] {processor.py:157} INFO - Started process (PID=39199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:22:27.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T18:22:27.572+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:22:27.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:22:27.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:22:27.646+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:22:27.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T18:22:27.660+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:22:27.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T18:22:27.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-13T18:40:38.667+0000] {processor.py:157} INFO - Started process (PID=39209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:40:38.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T18:40:38.676+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:40:38.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:40:38.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:40:38.768+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:40:38.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T18:40:38.804+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:40:38.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T18:40:38.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-13T18:48:24.635+0000] {processor.py:157} INFO - Started process (PID=39219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:48:24.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T18:48:24.648+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:48:24.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:48:24.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:48:24.743+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:48:24.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T18:48:24.781+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:48:24.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T18:48:24.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-13T18:48:55.075+0000] {processor.py:157} INFO - Started process (PID=39229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:48:55.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T18:48:55.082+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:48:55.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:48:55.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T18:48:55.138+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:48:55.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T18:48:55.168+0000] {logging_mixin.py:151} INFO - [2024-08-13T18:48:55.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T18:48:55.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-13T19:42:25.381+0000] {processor.py:157} INFO - Started process (PID=39239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:42:25.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T19:42:25.388+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:42:25.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:42:25.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:42:25.473+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:42:25.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T19:42:25.511+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:42:25.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T19:42:25.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-13T19:42:55.789+0000] {processor.py:157} INFO - Started process (PID=39250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:42:55.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T19:42:55.795+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:42:55.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:42:55.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:42:55.845+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:42:55.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T19:42:55.868+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:42:55.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T19:42:55.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-13T19:49:34.971+0000] {processor.py:157} INFO - Started process (PID=39260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:49:34.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T19:49:34.982+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:49:34.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:49:35.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:49:35.038+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:49:35.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T19:49:35.101+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:49:35.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T19:49:35.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-13T19:50:05.512+0000] {processor.py:157} INFO - Started process (PID=39270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:50:05.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T19:50:05.520+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:50:05.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:50:05.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T19:50:05.561+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:50:05.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T19:50:05.576+0000] {logging_mixin.py:151} INFO - [2024-08-13T19:50:05.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T19:50:05.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-13T20:50:31.620+0000] {processor.py:157} INFO - Started process (PID=39282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T20:50:31.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T20:50:31.628+0000] {logging_mixin.py:151} INFO - [2024-08-13T20:50:31.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T20:50:31.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T20:50:31.679+0000] {logging_mixin.py:151} INFO - [2024-08-13T20:50:31.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T20:50:31.692+0000] {logging_mixin.py:151} INFO - [2024-08-13T20:50:31.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T20:50:31.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-13T20:51:02.033+0000] {processor.py:157} INFO - Started process (PID=39292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T20:51:02.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T20:51:02.038+0000] {logging_mixin.py:151} INFO - [2024-08-13T20:51:02.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T20:51:02.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T20:51:02.082+0000] {logging_mixin.py:151} INFO - [2024-08-13T20:51:02.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T20:51:02.096+0000] {logging_mixin.py:151} INFO - [2024-08-13T20:51:02.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T20:51:02.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-13T21:09:38.020+0000] {processor.py:157} INFO - Started process (PID=39302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:09:38.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T21:09:38.041+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:09:38.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:09:38.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:09:38.124+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:09:38.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T21:09:38.176+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:09:38.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T21:09:38.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-13T21:11:55.424+0000] {processor.py:157} INFO - Started process (PID=39312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:11:55.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T21:11:55.434+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:11:55.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:11:55.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:11:55.551+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:11:55.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T21:11:55.591+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:11:55.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T21:11:55.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-13T21:12:25.862+0000] {processor.py:157} INFO - Started process (PID=39322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:12:25.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T21:12:25.873+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:12:25.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:12:25.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:12:25.948+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:12:25.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T21:12:25.962+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:12:25.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T21:12:25.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-13T21:22:12.998+0000] {processor.py:157} INFO - Started process (PID=39334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:22:13.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T21:22:13.010+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:22:13.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:22:13.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:22:13.078+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:22:13.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T21:22:13.101+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:22:13.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T21:22:13.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-13T21:22:43.346+0000] {processor.py:157} INFO - Started process (PID=39343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:22:43.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T21:22:43.352+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:22:43.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:22:43.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:22:43.416+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:22:43.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T21:22:43.433+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:22:43.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T21:22:43.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-13T21:51:43.797+0000] {processor.py:157} INFO - Started process (PID=39352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:51:43.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T21:51:43.803+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:51:43.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:51:43.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T21:51:43.857+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:51:43.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T21:51:43.877+0000] {logging_mixin.py:151} INFO - [2024-08-13T21:51:43.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T21:51:43.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-13T22:26:35.846+0000] {processor.py:157} INFO - Started process (PID=39365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:26:35.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T22:26:35.853+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:26:35.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:26:35.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:26:35.920+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:26:35.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T22:26:35.944+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:26:35.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T22:26:35.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-13T22:27:06.314+0000] {processor.py:157} INFO - Started process (PID=39376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:27:06.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T22:27:06.319+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:27:06.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:27:06.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:27:06.363+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:27:06.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T22:27:06.377+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:27:06.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T22:27:06.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-13T22:28:10.777+0000] {processor.py:157} INFO - Started process (PID=39386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:28:10.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T22:28:10.782+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:28:10.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:28:10.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:28:10.812+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:28:10.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T22:28:10.824+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:28:10.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T22:28:10.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-13T22:28:41.067+0000] {processor.py:157} INFO - Started process (PID=39396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:28:41.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T22:28:41.077+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:28:41.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:28:41.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:28:41.124+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:28:41.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T22:28:41.139+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:28:41.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T22:28:41.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-13T22:52:43.103+0000] {processor.py:157} INFO - Started process (PID=39405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:52:43.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T22:52:43.111+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:52:43.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:52:43.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:52:43.184+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:52:43.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T22:52:43.216+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:52:43.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T22:52:43.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-13T22:58:08.203+0000] {processor.py:157} INFO - Started process (PID=39416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:58:08.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T22:58:08.216+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:58:08.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:58:08.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:58:08.294+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:58:08.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T22:58:08.331+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:58:08.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T22:58:08.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-13T22:58:38.545+0000] {processor.py:157} INFO - Started process (PID=39426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:58:38.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T22:58:38.553+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:58:38.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:58:38.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T22:58:38.611+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:58:38.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T22:58:38.633+0000] {logging_mixin.py:151} INFO - [2024-08-13T22:58:38.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T22:58:38.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-13T23:28:28.555+0000] {processor.py:157} INFO - Started process (PID=39438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:28:28.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T23:28:28.560+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:28:28.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:28:28.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:28:28.614+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:28:28.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T23:28:28.646+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:28:28.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T23:28:28.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-13T23:28:59.007+0000] {processor.py:157} INFO - Started process (PID=39448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:28:59.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T23:28:59.012+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:28:59.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:28:59.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:28:59.088+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:28:59.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T23:28:59.111+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:28:59.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T23:28:59.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-13T23:41:02.745+0000] {processor.py:157} INFO - Started process (PID=39457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:41:02.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T23:41:02.752+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:41:02.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:41:02.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:41:02.824+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:41:02.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T23:41:02.880+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:41:02.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T23:41:02.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-13T23:53:31.336+0000] {processor.py:157} INFO - Started process (PID=39467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:53:31.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T23:53:31.347+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:53:31.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:53:31.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:53:31.451+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:53:31.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T23:53:31.483+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:53:31.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T23:53:31.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-13T23:54:01.709+0000] {processor.py:157} INFO - Started process (PID=39476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:54:01.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-13T23:54:01.716+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:54:01.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:54:01.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-13T23:54:01.778+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:54:01.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-13T23:54:01.807+0000] {logging_mixin.py:151} INFO - [2024-08-13T23:54:01.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-12T01:00:00+00:00, run_after=2024-08-13T01:00:00+00:00
[2024-08-13T23:54:01.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
