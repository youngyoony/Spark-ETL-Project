[2024-07-10T00:09:04.086+0000] {processor.py:157} INFO - Started process (PID=7572) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T00:09:04.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T00:09:04.087+0000] {logging_mixin.py:151} INFO - [2024-07-10T00:09:04.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T00:09:04.092+0000] {logging_mixin.py:151} INFO - [2024-07-10T00:09:04.091+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T00:09:04.092+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T00:09:04.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T00:46:15.510+0000] {processor.py:157} INFO - Started process (PID=7587) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T00:46:15.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T00:46:15.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T00:46:15.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T00:46:15.516+0000] {logging_mixin.py:151} INFO - [2024-07-10T00:46:15.515+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T00:46:15.516+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T00:46:15.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T01:02:01.986+0000] {processor.py:157} INFO - Started process (PID=7602) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:02:01.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T01:02:01.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:02:01.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:02:01.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:02:01.992+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T01:02:01.993+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:02:02.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T01:16:27.324+0000] {processor.py:157} INFO - Started process (PID=7617) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:16:27.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T01:16:27.326+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:16:27.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:16:27.330+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:16:27.329+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T01:16:27.330+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:16:27.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T01:17:28.039+0000] {processor.py:157} INFO - Started process (PID=7634) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:17:28.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T01:17:28.040+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:17:28.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:17:28.045+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:17:28.044+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T01:17:28.045+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:17:28.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T01:17:58.486+0000] {processor.py:157} INFO - Started process (PID=7649) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:17:58.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T01:17:58.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:17:58.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:17:58.491+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:17:58.490+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T01:17:58.492+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:17:58.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T01:47:13.108+0000] {processor.py:157} INFO - Started process (PID=7664) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:47:13.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T01:47:13.110+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:47:13.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:47:13.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:47:13.115+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T01:47:13.116+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:47:13.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T01:47:43.514+0000] {processor.py:157} INFO - Started process (PID=7679) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:47:43.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T01:47:43.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:47:43.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:47:43.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T01:47:43.527+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T01:47:43.528+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T01:47:43.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T02:48:10.935+0000] {processor.py:157} INFO - Started process (PID=7695) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T02:48:10.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T02:48:10.936+0000] {logging_mixin.py:151} INFO - [2024-07-10T02:48:10.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T02:48:10.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T02:48:10.940+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T02:48:10.941+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T02:48:10.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T02:48:41.429+0000] {processor.py:157} INFO - Started process (PID=7711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T02:48:41.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T02:48:41.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T02:48:41.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T02:48:41.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T02:48:41.433+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T02:48:41.435+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T02:48:41.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T03:49:04.196+0000] {processor.py:157} INFO - Started process (PID=7726) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T03:49:04.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T03:49:04.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T03:49:04.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T03:49:04.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T03:49:04.204+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T03:49:04.205+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T03:49:04.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T03:49:34.656+0000] {processor.py:157} INFO - Started process (PID=7741) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T03:49:34.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T03:49:34.658+0000] {logging_mixin.py:151} INFO - [2024-07-10T03:49:34.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T03:49:34.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T03:49:34.661+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T03:49:34.662+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T03:49:34.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T04:42:51.009+0000] {processor.py:157} INFO - Started process (PID=7756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:42:51.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T04:42:51.011+0000] {logging_mixin.py:151} INFO - [2024-07-10T04:42:51.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:42:51.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T04:42:51.014+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T04:42:51.016+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:42:51.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T04:43:21.403+0000] {processor.py:157} INFO - Started process (PID=7771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:43:21.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T04:43:21.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T04:43:21.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:43:21.409+0000] {logging_mixin.py:151} INFO - [2024-07-10T04:43:21.408+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T04:43:21.410+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:43:21.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T04:50:13.982+0000] {processor.py:157} INFO - Started process (PID=7786) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:50:13.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T04:50:13.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T04:50:13.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:50:13.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T04:50:13.987+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T04:50:13.988+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:50:13.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T04:50:44.403+0000] {processor.py:157} INFO - Started process (PID=7803) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:50:44.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T04:50:44.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T04:50:44.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:50:44.409+0000] {logging_mixin.py:151} INFO - [2024-07-10T04:50:44.409+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T04:50:44.410+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T04:50:44.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T05:30:21.375+0000] {processor.py:157} INFO - Started process (PID=7818) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:30:21.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T05:30:21.376+0000] {logging_mixin.py:151} INFO - [2024-07-10T05:30:21.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:30:21.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T05:30:21.380+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T05:30:21.381+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:30:21.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T05:47:10.505+0000] {processor.py:157} INFO - Started process (PID=7833) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:47:10.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T05:47:10.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T05:47:10.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:47:10.511+0000] {logging_mixin.py:151} INFO - [2024-07-10T05:47:10.510+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T05:47:10.511+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:47:10.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T05:51:24.567+0000] {processor.py:157} INFO - Started process (PID=7850) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:51:24.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T05:51:24.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T05:51:24.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:51:24.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T05:51:24.573+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T05:51:24.574+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T05:51:24.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:06:20.099+0000] {processor.py:157} INFO - Started process (PID=7865) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:06:20.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:06:20.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:06:20.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:06:20.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:06:20.104+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:06:20.105+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:06:20.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T06:06:50.527+0000] {processor.py:157} INFO - Started process (PID=7880) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:06:50.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:06:50.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:06:50.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:06:50.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:06:50.532+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:06:50.533+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:06:50.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:23:26.640+0000] {processor.py:157} INFO - Started process (PID=7895) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:23:26.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:23:26.642+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:23:26.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:23:26.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:23:26.648+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:23:26.650+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:23:26.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T06:23:57.099+0000] {processor.py:157} INFO - Started process (PID=7910) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:23:57.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:23:57.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:23:57.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:23:57.109+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:23:57.107+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:23:57.109+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:23:57.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T06:24:27.514+0000] {processor.py:157} INFO - Started process (PID=7925) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:24:27.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:24:27.516+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:24:27.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:24:27.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:24:27.522+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:24:27.524+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:24:27.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T06:24:57.835+0000] {processor.py:157} INFO - Started process (PID=7940) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:24:57.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:24:57.836+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:24:57.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:24:57.841+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:24:57.840+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:24:57.842+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:24:57.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T06:25:28.338+0000] {processor.py:157} INFO - Started process (PID=7955) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:25:28.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:25:28.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:25:28.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:25:28.347+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:25:28.346+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:25:28.347+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:25:28.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T06:25:58.723+0000] {processor.py:157} INFO - Started process (PID=7970) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:25:58.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:25:58.724+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:25:58.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:25:58.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:25:58.727+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:25:58.728+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:25:58.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:26:29.129+0000] {processor.py:157} INFO - Started process (PID=7985) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:26:29.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:26:29.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:26:29.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:26:29.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:26:29.134+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:26:29.135+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:26:29.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:26:59.516+0000] {processor.py:157} INFO - Started process (PID=8000) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:26:59.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:26:59.517+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:26:59.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:26:59.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:26:59.521+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:26:59.522+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:26:59.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:27:29.932+0000] {processor.py:157} INFO - Started process (PID=8015) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:27:29.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:27:29.933+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:27:29.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:27:29.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:27:29.937+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:27:29.938+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:27:29.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:28:00.302+0000] {processor.py:157} INFO - Started process (PID=8030) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:28:00.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:28:00.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:28:00.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:28:00.308+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:28:00.307+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:28:00.308+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:28:00.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:28:30.663+0000] {processor.py:157} INFO - Started process (PID=8045) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:28:30.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:28:30.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:28:30.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:28:30.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:28:30.668+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:28:30.669+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:28:30.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:29:01.026+0000] {processor.py:157} INFO - Started process (PID=8060) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:29:01.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:29:01.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:29:01.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:29:01.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:29:01.031+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:29:01.032+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:29:01.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:29:31.435+0000] {processor.py:157} INFO - Started process (PID=8075) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:29:31.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:29:31.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:29:31.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:29:31.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:29:31.440+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:29:31.441+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:29:31.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:30:01.847+0000] {processor.py:157} INFO - Started process (PID=8090) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:30:01.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:30:01.848+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:30:01.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:30:01.853+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:30:01.852+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:30:01.853+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:30:01.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:30:32.272+0000] {processor.py:157} INFO - Started process (PID=8105) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:30:32.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:30:32.274+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:30:32.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:30:32.278+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:30:32.277+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:30:32.278+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:30:32.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:31:02.709+0000] {processor.py:157} INFO - Started process (PID=8120) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:31:02.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:31:02.711+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:31:02.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:31:02.715+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:31:02.714+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:31:02.715+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:31:02.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:31:33.185+0000] {processor.py:157} INFO - Started process (PID=8135) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:31:33.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:31:33.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:31:33.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:31:33.191+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:31:33.190+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:31:33.191+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:31:33.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:32:03.602+0000] {processor.py:157} INFO - Started process (PID=8150) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:32:03.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:32:03.603+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:32:03.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:32:03.608+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:32:03.607+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:32:03.608+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:32:03.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T06:32:34.002+0000] {processor.py:157} INFO - Started process (PID=8165) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:32:34.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:32:34.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:32:34.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:32:34.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:32:34.007+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:32:34.008+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:32:34.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:33:04.416+0000] {processor.py:157} INFO - Started process (PID=8180) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:33:04.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:33:04.417+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:33:04.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:33:04.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:33:04.421+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:33:04.422+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:33:04.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:33:34.873+0000] {processor.py:157} INFO - Started process (PID=8195) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:33:34.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:33:34.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:33:34.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:33:34.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:33:34.879+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:33:34.880+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:33:34.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T06:34:05.269+0000] {processor.py:157} INFO - Started process (PID=8210) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:34:05.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:34:05.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:34:05.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:34:05.274+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:34:05.273+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:34:05.274+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:34:05.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:34:35.637+0000] {processor.py:157} INFO - Started process (PID=8225) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:34:35.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:34:35.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:34:35.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:34:35.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:34:35.642+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:34:35.643+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:34:35.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:35:06.085+0000] {processor.py:157} INFO - Started process (PID=8240) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:35:06.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:35:06.086+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:35:06.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:35:06.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:35:06.090+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:35:06.091+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:35:06.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:35:36.546+0000] {processor.py:157} INFO - Started process (PID=8255) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:35:36.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:35:36.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:35:36.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:35:36.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:35:36.551+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:35:36.552+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:35:36.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:36:07.052+0000] {processor.py:157} INFO - Started process (PID=8270) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:36:07.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:36:07.054+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:36:07.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:36:07.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:36:07.057+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:36:07.058+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:36:07.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:36:37.560+0000] {processor.py:157} INFO - Started process (PID=8285) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:36:37.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:36:37.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:36:37.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:36:37.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:36:37.565+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:36:37.566+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:36:37.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:37:07.970+0000] {processor.py:157} INFO - Started process (PID=8300) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:37:07.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:37:07.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:37:07.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:37:07.976+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:37:07.975+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:37:07.976+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:37:07.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:37:38.483+0000] {processor.py:157} INFO - Started process (PID=8315) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:37:38.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:37:38.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:37:38.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:37:38.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:37:38.488+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:37:38.489+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:37:38.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:38:08.959+0000] {processor.py:157} INFO - Started process (PID=8330) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:38:08.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:38:08.961+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:38:08.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:38:08.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:38:08.964+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:38:08.965+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:38:08.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:38:39.480+0000] {processor.py:157} INFO - Started process (PID=8345) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:38:39.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:38:39.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:38:39.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:38:39.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:38:39.485+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:38:39.486+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:38:39.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:39:10.005+0000] {processor.py:157} INFO - Started process (PID=8360) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:39:10.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:39:10.006+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:39:10.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:39:10.010+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:39:10.009+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:39:10.011+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:39:10.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:39:40.483+0000] {processor.py:157} INFO - Started process (PID=8375) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:39:40.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:39:40.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:39:40.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:39:40.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:39:40.488+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:39:40.489+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:39:40.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:40:10.963+0000] {processor.py:157} INFO - Started process (PID=8390) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:40:10.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:40:10.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:40:10.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:40:10.969+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:40:10.968+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:40:10.969+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:40:10.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:40:41.428+0000] {processor.py:157} INFO - Started process (PID=8405) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:40:41.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:40:41.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:40:41.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:40:41.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:40:41.432+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:40:41.434+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:40:41.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T06:41:11.885+0000] {processor.py:157} INFO - Started process (PID=8420) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:41:11.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:41:11.886+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:41:11.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:41:11.891+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:41:11.890+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:41:11.891+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:41:11.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T06:41:42.336+0000] {processor.py:157} INFO - Started process (PID=8435) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:41:42.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:41:42.337+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:41:42.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:41:42.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:41:42.341+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:41:42.342+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:41:42.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:42:12.776+0000] {processor.py:157} INFO - Started process (PID=8450) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:42:12.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:42:12.777+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:42:12.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:42:12.781+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:42:12.780+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:42:12.781+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:42:12.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:42:43.238+0000] {processor.py:157} INFO - Started process (PID=8465) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:42:43.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:42:43.240+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:42:43.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:42:43.244+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:42:43.243+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:42:43.244+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:42:43.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T06:43:13.722+0000] {processor.py:157} INFO - Started process (PID=8480) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:43:13.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:43:13.723+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:43:13.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:43:13.727+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:43:13.726+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:43:13.727+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:43:13.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:43:44.182+0000] {processor.py:157} INFO - Started process (PID=8495) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:43:44.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:43:44.183+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:43:44.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:43:44.188+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:43:44.187+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:43:44.188+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:43:44.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:44:14.642+0000] {processor.py:157} INFO - Started process (PID=8510) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:44:14.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:44:14.644+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:44:14.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:44:14.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:44:14.647+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:44:14.648+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:44:14.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:44:45.050+0000] {processor.py:157} INFO - Started process (PID=8525) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:44:45.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:44:45.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:44:45.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:44:45.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:44:45.055+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:44:45.056+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:44:45.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:45:15.364+0000] {processor.py:157} INFO - Started process (PID=8540) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:45:15.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:45:15.365+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:45:15.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:45:15.370+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:45:15.369+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:45:15.370+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:45:15.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:45:45.719+0000] {processor.py:157} INFO - Started process (PID=8555) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:45:45.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:45:45.720+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:45:45.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:45:45.725+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:45:45.724+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:45:45.725+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:45:45.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:46:16.088+0000] {processor.py:157} INFO - Started process (PID=8570) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:46:16.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:46:16.090+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:46:16.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:46:16.094+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:46:16.093+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:46:16.094+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:46:16.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:46:46.441+0000] {processor.py:157} INFO - Started process (PID=8585) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:46:46.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:46:46.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:46:46.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:46:46.447+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:46:46.446+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:46:46.447+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:46:46.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:47:16.915+0000] {processor.py:157} INFO - Started process (PID=8600) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:47:16.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:47:16.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:47:16.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:47:16.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:47:16.920+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:47:16.921+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:47:16.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:47:47.429+0000] {processor.py:157} INFO - Started process (PID=8615) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:47:47.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:47:47.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:47:47.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:47:47.435+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:47:47.434+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:47:47.436+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:47:47.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:48:17.834+0000] {processor.py:157} INFO - Started process (PID=8630) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:48:17.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:48:17.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:48:17.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:48:17.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:48:17.839+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:48:17.840+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:48:17.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T06:48:48.343+0000] {processor.py:157} INFO - Started process (PID=8645) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:48:48.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:48:48.344+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:48:48.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:48:48.349+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:48:48.348+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:48:48.349+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:48:48.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:49:18.768+0000] {processor.py:157} INFO - Started process (PID=8660) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:49:18.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:49:18.769+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:49:18.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:49:18.773+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:49:18.773+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:49:18.774+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:49:18.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:49:49.252+0000] {processor.py:157} INFO - Started process (PID=8675) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:49:49.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:49:49.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:49:49.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:49:49.258+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:49:49.257+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:49:49.258+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:49:49.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:50:19.739+0000] {processor.py:157} INFO - Started process (PID=8690) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:50:19.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:50:19.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:50:19.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:50:19.745+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:50:19.744+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:50:19.745+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:50:19.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:50:50.212+0000] {processor.py:157} INFO - Started process (PID=8705) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:50:50.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:50:50.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:50:50.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:50:50.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:50:50.217+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:50:50.218+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:50:50.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:51:20.667+0000] {processor.py:157} INFO - Started process (PID=8720) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:51:20.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:51:20.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:51:20.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:51:20.674+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:51:20.673+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:51:20.674+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:51:20.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:51:51.157+0000] {processor.py:157} INFO - Started process (PID=8735) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:51:51.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:51:51.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:51:51.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:51:51.163+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:51:51.162+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:51:51.163+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:51:51.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:52:21.654+0000] {processor.py:157} INFO - Started process (PID=8750) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:52:21.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:52:21.656+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:52:21.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:52:21.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:52:21.659+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:52:21.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:52:21.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:52:52.128+0000] {processor.py:157} INFO - Started process (PID=8765) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:52:52.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:52:52.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:52:52.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:52:52.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:52:52.133+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:52:52.134+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:52:52.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:53:22.613+0000] {processor.py:157} INFO - Started process (PID=8780) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:53:22.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:53:22.615+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:53:22.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:53:22.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:53:22.618+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:53:22.619+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:53:22.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:53:53.063+0000] {processor.py:157} INFO - Started process (PID=8795) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:53:53.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:53:53.064+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:53:53.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:53:53.069+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:53:53.068+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:53:53.069+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:53:53.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:54:23.523+0000] {processor.py:157} INFO - Started process (PID=8810) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:54:23.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:54:23.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:54:23.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:54:23.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:54:23.528+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:54:23.529+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:54:23.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:54:53.981+0000] {processor.py:157} INFO - Started process (PID=8825) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:54:53.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:54:53.982+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:54:53.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:54:53.986+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:54:53.986+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:54:53.987+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:54:53.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T06:55:24.446+0000] {processor.py:157} INFO - Started process (PID=8840) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:55:24.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:55:24.447+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:55:24.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:55:24.452+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:55:24.451+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:55:24.452+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:55:24.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:55:54.872+0000] {processor.py:157} INFO - Started process (PID=8855) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:55:54.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:55:54.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:55:54.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:55:54.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:55:54.877+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:55:54.878+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:55:54.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:56:25.324+0000] {processor.py:157} INFO - Started process (PID=8870) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:56:25.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:56:25.325+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:56:25.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:56:25.330+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:56:25.329+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:56:25.330+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:56:25.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:56:55.794+0000] {processor.py:157} INFO - Started process (PID=8885) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:56:55.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:56:55.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:56:55.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:56:55.800+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:56:55.799+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:56:55.800+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:56:55.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:57:26.230+0000] {processor.py:157} INFO - Started process (PID=8900) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:57:26.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:57:26.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:57:26.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:57:26.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:57:26.235+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:57:26.236+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:57:26.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:57:56.690+0000] {processor.py:157} INFO - Started process (PID=8915) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:57:56.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:57:56.692+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:57:56.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:57:56.696+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:57:56.695+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:57:56.696+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:57:56.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:58:27.113+0000] {processor.py:157} INFO - Started process (PID=8930) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:58:27.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:58:27.115+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:58:27.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:58:27.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:58:27.118+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:58:27.119+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:58:27.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:58:57.478+0000] {processor.py:157} INFO - Started process (PID=8945) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:58:57.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:58:57.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:58:57.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:58:57.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:58:57.483+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:58:57.485+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:58:57.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:59:27.857+0000] {processor.py:157} INFO - Started process (PID=8960) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:59:27.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:59:27.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:59:27.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:59:27.863+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:59:27.862+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:59:27.863+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:59:27.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T06:59:58.241+0000] {processor.py:157} INFO - Started process (PID=8975) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:59:58.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T06:59:58.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:59:58.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:59:58.247+0000] {logging_mixin.py:151} INFO - [2024-07-10T06:59:58.246+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T06:59:58.247+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T06:59:58.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:00:28.699+0000] {processor.py:157} INFO - Started process (PID=8990) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:00:28.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:00:28.700+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:00:28.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:00:28.704+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:00:28.703+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:00:28.705+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:00:28.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:00:59.071+0000] {processor.py:157} INFO - Started process (PID=9005) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:00:59.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:00:59.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:00:59.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:00:59.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:00:59.075+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:00:59.076+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:00:59.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:01:29.425+0000] {processor.py:157} INFO - Started process (PID=9020) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:01:29.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:01:29.426+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:01:29.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:01:29.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:01:29.430+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:01:29.431+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:01:29.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:01:59.785+0000] {processor.py:157} INFO - Started process (PID=9035) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:01:59.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:01:59.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:01:59.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:01:59.791+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:01:59.790+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:01:59.791+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:01:59.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:02:30.183+0000] {processor.py:157} INFO - Started process (PID=9050) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:02:30.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:02:30.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:02:30.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:02:30.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:02:30.188+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:02:30.189+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:02:30.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:03:00.538+0000] {processor.py:157} INFO - Started process (PID=9065) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:03:00.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:03:00.539+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:03:00.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:03:00.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:03:00.543+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:03:00.544+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:03:00.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:03:30.876+0000] {processor.py:157} INFO - Started process (PID=9080) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:03:30.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:03:30.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:03:30.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:03:30.882+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:03:30.881+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:03:30.882+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:03:30.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:04:01.224+0000] {processor.py:157} INFO - Started process (PID=9095) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:04:01.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:04:01.225+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:04:01.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:04:01.230+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:04:01.229+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:04:01.230+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:04:01.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:04:31.589+0000] {processor.py:157} INFO - Started process (PID=9110) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:04:31.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:04:31.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:04:31.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:04:31.595+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:04:31.594+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:04:31.595+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:04:31.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:05:02.012+0000] {processor.py:157} INFO - Started process (PID=9125) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:05:02.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:05:02.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:05:02.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:05:02.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:05:02.017+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:05:02.018+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:05:02.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:05:32.389+0000] {processor.py:157} INFO - Started process (PID=9140) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:05:32.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:05:32.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:05:32.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:05:32.395+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:05:32.394+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:05:32.395+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:05:32.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:06:02.811+0000] {processor.py:157} INFO - Started process (PID=9155) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:06:02.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:06:02.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:06:02.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:06:02.817+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:06:02.816+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:06:02.817+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:06:02.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:06:33.218+0000] {processor.py:157} INFO - Started process (PID=9170) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:06:33.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:06:33.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:06:33.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:06:33.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:06:33.223+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:06:33.224+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:06:33.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:07:03.589+0000] {processor.py:157} INFO - Started process (PID=9185) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:07:03.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:07:03.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:07:03.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:07:03.595+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:07:03.594+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:07:03.595+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:07:03.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:07:33.953+0000] {processor.py:157} INFO - Started process (PID=9200) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:07:33.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:07:33.954+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:07:33.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:07:33.959+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:07:33.958+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:07:33.959+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:07:33.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:08:04.337+0000] {processor.py:157} INFO - Started process (PID=9215) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:08:04.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:08:04.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:08:04.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:08:04.343+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:08:04.343+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:08:04.344+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:08:04.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:08:34.727+0000] {processor.py:157} INFO - Started process (PID=9230) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:08:34.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:08:34.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:08:34.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:08:34.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:08:34.732+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:08:34.733+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:08:34.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:09:05.159+0000] {processor.py:157} INFO - Started process (PID=9245) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:09:05.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:09:05.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:09:05.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:09:05.165+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:09:05.164+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:09:05.165+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:09:05.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:09:35.555+0000] {processor.py:157} INFO - Started process (PID=9260) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:09:35.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:09:35.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:09:35.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:09:35.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:09:35.560+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:09:35.561+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:09:35.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:10:05.945+0000] {processor.py:157} INFO - Started process (PID=9275) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:10:05.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:10:05.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:10:05.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:10:05.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:10:05.950+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:10:05.952+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:10:05.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:10:36.422+0000] {processor.py:157} INFO - Started process (PID=9290) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:10:36.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:10:36.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:10:36.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:10:36.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:10:36.427+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:10:36.428+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:10:36.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:11:06.937+0000] {processor.py:157} INFO - Started process (PID=9305) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:11:06.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:11:06.939+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:11:06.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:11:06.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:11:06.945+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:11:06.949+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:11:06.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T07:11:37.293+0000] {processor.py:157} INFO - Started process (PID=9320) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:11:37.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:11:37.295+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:11:37.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:11:37.300+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:11:37.299+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:11:37.300+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:11:37.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T07:12:07.658+0000] {processor.py:157} INFO - Started process (PID=9335) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:12:07.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:12:07.659+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:12:07.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:12:07.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:12:07.663+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:12:07.664+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:12:07.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:12:38.087+0000] {processor.py:157} INFO - Started process (PID=9350) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:12:38.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:12:38.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:12:38.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:12:38.093+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:12:38.092+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:12:38.093+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:12:38.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:13:08.493+0000] {processor.py:157} INFO - Started process (PID=9365) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:13:08.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:13:08.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:13:08.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:13:08.499+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:13:08.498+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:13:08.499+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:13:08.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:13:38.883+0000] {processor.py:157} INFO - Started process (PID=9380) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:13:38.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:13:38.884+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:13:38.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:13:38.889+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:13:38.888+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:13:38.889+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:13:38.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:14:09.269+0000] {processor.py:157} INFO - Started process (PID=9395) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:14:09.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:14:09.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:14:09.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:14:09.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:14:09.274+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:14:09.275+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:14:09.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:14:39.647+0000] {processor.py:157} INFO - Started process (PID=9410) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:14:39.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:14:39.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:14:39.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:14:39.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:14:39.653+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:14:39.654+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:14:39.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:15:10.020+0000] {processor.py:157} INFO - Started process (PID=9425) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:15:10.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:15:10.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:15:10.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:15:10.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:15:10.024+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:15:10.026+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:15:10.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:15:40.446+0000] {processor.py:157} INFO - Started process (PID=9440) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:15:40.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:15:40.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:15:40.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:15:40.452+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:15:40.451+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:15:40.452+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:15:40.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:16:10.837+0000] {processor.py:157} INFO - Started process (PID=9455) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:16:10.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:16:10.838+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:16:10.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:16:10.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:16:10.842+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:16:10.843+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:16:10.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:16:41.243+0000] {processor.py:157} INFO - Started process (PID=9470) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:16:41.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:16:41.244+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:16:41.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:16:41.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:16:41.248+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:16:41.249+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:16:41.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:17:11.716+0000] {processor.py:157} INFO - Started process (PID=9485) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:17:11.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:17:11.718+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:17:11.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:17:11.723+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:17:11.722+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:17:11.723+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:17:11.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:17:42.158+0000] {processor.py:157} INFO - Started process (PID=9500) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:17:42.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:17:42.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:17:42.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:17:42.163+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:17:42.162+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:17:42.164+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:17:42.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:18:12.685+0000] {processor.py:157} INFO - Started process (PID=9515) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:18:12.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:18:12.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:18:12.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:18:12.690+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:18:12.690+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:18:12.691+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:18:12.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:18:43.162+0000] {processor.py:157} INFO - Started process (PID=9530) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:18:43.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:18:43.164+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:18:43.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:18:43.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:18:43.167+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:18:43.168+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:18:43.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:19:13.654+0000] {processor.py:157} INFO - Started process (PID=9545) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:19:13.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:19:13.656+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:19:13.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:19:13.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:19:13.659+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:19:13.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:19:13.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:19:44.122+0000] {processor.py:157} INFO - Started process (PID=9560) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:19:44.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:19:44.124+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:19:44.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:19:44.128+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:19:44.127+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:19:44.128+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:19:44.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:20:14.517+0000] {processor.py:157} INFO - Started process (PID=9575) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:20:14.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:20:14.518+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:20:14.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:20:14.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:20:14.521+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:20:14.522+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:20:14.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:20:44.978+0000] {processor.py:157} INFO - Started process (PID=9590) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:20:44.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:20:44.980+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:20:44.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:20:44.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:20:44.983+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:20:44.984+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:20:44.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:21:15.487+0000] {processor.py:157} INFO - Started process (PID=9605) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:21:15.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:21:15.488+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:21:15.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:21:15.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:21:15.492+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:21:15.493+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:21:15.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:21:45.966+0000] {processor.py:157} INFO - Started process (PID=9620) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:21:45.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:21:45.967+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:21:45.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:21:45.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:21:45.971+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:21:45.972+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:21:45.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:22:16.442+0000] {processor.py:157} INFO - Started process (PID=9635) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:22:16.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:22:16.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:22:16.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:22:16.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:22:16.447+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:22:16.448+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:22:16.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:22:46.843+0000] {processor.py:157} INFO - Started process (PID=9650) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:22:46.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:22:46.844+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:22:46.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:22:46.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:22:46.848+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:22:46.849+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:22:46.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:23:17.276+0000] {processor.py:157} INFO - Started process (PID=9665) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:23:17.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:23:17.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:23:17.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:23:17.282+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:23:17.281+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:23:17.282+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:23:17.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:23:47.732+0000] {processor.py:157} INFO - Started process (PID=9680) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:23:47.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:23:47.734+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:23:47.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:23:47.739+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:23:47.738+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:23:47.739+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:23:47.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:24:18.115+0000] {processor.py:157} INFO - Started process (PID=9695) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:24:18.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:24:18.117+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:24:18.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:24:18.121+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:24:18.120+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:24:18.121+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:24:18.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:24:48.495+0000] {processor.py:157} INFO - Started process (PID=9710) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:24:48.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:24:48.496+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:24:48.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:24:48.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:24:48.500+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:24:48.501+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:24:48.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:25:18.892+0000] {processor.py:157} INFO - Started process (PID=9725) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:25:18.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:25:18.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:25:18.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:25:18.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:25:18.897+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:25:18.898+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:25:18.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:25:49.288+0000] {processor.py:157} INFO - Started process (PID=9740) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:25:49.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:25:49.289+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:25:49.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:25:49.294+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:25:49.293+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:25:49.294+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:25:49.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:26:19.674+0000] {processor.py:157} INFO - Started process (PID=9755) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:26:19.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:26:19.676+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:26:19.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:26:19.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:26:19.679+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:26:19.680+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:26:19.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:26:50.056+0000] {processor.py:157} INFO - Started process (PID=9770) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:26:50.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:26:50.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:26:50.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:26:50.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:26:50.061+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:26:50.062+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:26:50.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:27:20.476+0000] {processor.py:157} INFO - Started process (PID=9785) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:27:20.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:27:20.477+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:27:20.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:27:20.482+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:27:20.481+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:27:20.482+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:27:20.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:27:50.887+0000] {processor.py:157} INFO - Started process (PID=9800) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:27:50.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:27:50.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:27:50.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:27:50.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:27:50.892+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:27:50.893+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:27:50.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:28:21.265+0000] {processor.py:157} INFO - Started process (PID=9815) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:28:21.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:28:21.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:28:21.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:28:21.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:28:21.270+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:28:21.271+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:28:21.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:28:51.684+0000] {processor.py:157} INFO - Started process (PID=9830) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:28:51.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:28:51.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:28:51.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:28:51.690+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:28:51.689+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:28:51.690+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:28:51.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:29:22.090+0000] {processor.py:157} INFO - Started process (PID=9845) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:29:22.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:29:22.092+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:29:22.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:29:22.097+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:29:22.096+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:29:22.097+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:29:22.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:29:52.463+0000] {processor.py:157} INFO - Started process (PID=9860) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:29:52.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:29:52.464+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:29:52.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:29:52.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:29:52.468+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:29:52.469+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:29:52.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:30:22.840+0000] {processor.py:157} INFO - Started process (PID=9875) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:30:22.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:30:22.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:30:22.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:30:22.847+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:30:22.846+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:30:22.847+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:30:22.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:30:53.245+0000] {processor.py:157} INFO - Started process (PID=9890) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:30:53.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:30:53.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:30:53.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:30:53.251+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:30:53.250+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:30:53.251+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:30:53.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:31:23.664+0000] {processor.py:157} INFO - Started process (PID=9905) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:31:23.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:31:23.666+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:31:23.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:31:23.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:31:23.670+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:31:23.671+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:31:23.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:31:54.051+0000] {processor.py:157} INFO - Started process (PID=9920) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:31:54.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:31:54.053+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:31:54.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:31:54.060+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:31:54.059+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:31:54.060+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:31:54.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T07:32:24.473+0000] {processor.py:157} INFO - Started process (PID=9935) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:32:24.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:32:24.475+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:32:24.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:32:24.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:32:24.478+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:32:24.480+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:32:24.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:32:54.887+0000] {processor.py:157} INFO - Started process (PID=9950) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:32:54.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:32:54.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:32:54.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:32:54.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:32:54.892+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:32:54.894+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:32:54.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:33:25.278+0000] {processor.py:157} INFO - Started process (PID=9965) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:33:25.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:33:25.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:33:25.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:33:25.287+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:33:25.286+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:33:25.287+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:33:25.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T07:33:55.680+0000] {processor.py:157} INFO - Started process (PID=9980) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:33:55.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:33:55.682+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:33:55.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:33:55.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:33:55.685+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:33:55.687+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:33:55.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T07:34:26.103+0000] {processor.py:157} INFO - Started process (PID=9995) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:34:26.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:34:26.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:34:26.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:34:26.109+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:34:26.108+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:34:26.109+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:34:26.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:34:56.505+0000] {processor.py:157} INFO - Started process (PID=10010) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:34:56.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:34:56.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:34:56.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:34:56.511+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:34:56.510+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:34:56.511+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:34:56.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:35:26.927+0000] {processor.py:157} INFO - Started process (PID=10025) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:35:26.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:35:26.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:35:26.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:35:26.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:35:26.933+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:35:26.934+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:35:26.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:35:57.306+0000] {processor.py:157} INFO - Started process (PID=10040) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:35:57.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:35:57.308+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:35:57.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:35:57.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:35:57.312+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:35:57.313+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:35:57.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T07:36:27.782+0000] {processor.py:157} INFO - Started process (PID=10055) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:36:27.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:36:27.784+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:36:27.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:36:27.789+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:36:27.788+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:36:27.789+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:36:27.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:36:58.164+0000] {processor.py:157} INFO - Started process (PID=10070) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:36:58.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:36:58.165+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:36:58.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:36:58.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:36:58.169+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:36:58.170+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:36:58.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:37:28.535+0000] {processor.py:157} INFO - Started process (PID=10085) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:37:28.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:37:28.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:37:28.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:37:28.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:37:28.540+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:37:28.541+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:37:28.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:37:58.891+0000] {processor.py:157} INFO - Started process (PID=10100) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:37:58.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:37:58.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:37:58.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:37:58.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:37:58.896+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:37:58.897+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:37:58.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:38:29.287+0000] {processor.py:157} INFO - Started process (PID=10115) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:38:29.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:38:29.289+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:38:29.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:38:29.294+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:38:29.293+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:38:29.294+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:38:29.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:38:59.716+0000] {processor.py:157} INFO - Started process (PID=10130) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:38:59.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:38:59.717+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:38:59.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:38:59.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:38:59.720+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:38:59.722+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:38:59.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:39:30.093+0000] {processor.py:157} INFO - Started process (PID=10145) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:39:30.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:39:30.094+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:39:30.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:39:30.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:39:30.098+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:39:30.099+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:39:30.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:40:00.435+0000] {processor.py:157} INFO - Started process (PID=10160) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:40:00.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:40:00.437+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:40:00.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:40:00.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:40:00.440+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:40:00.441+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:40:00.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:40:30.738+0000] {processor.py:157} INFO - Started process (PID=10175) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:40:30.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:40:30.740+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:40:30.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:40:30.744+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:40:30.743+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:40:30.744+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:40:30.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:41:01.101+0000] {processor.py:157} INFO - Started process (PID=10190) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:41:01.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:41:01.102+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:41:01.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:41:01.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:41:01.106+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:41:01.107+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:41:01.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:41:31.495+0000] {processor.py:157} INFO - Started process (PID=10205) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:41:31.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:41:31.496+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:41:31.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:41:31.500+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:41:31.500+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:41:31.501+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:41:31.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:42:01.864+0000] {processor.py:157} INFO - Started process (PID=10220) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:42:01.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:42:01.866+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:42:01.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:42:01.870+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:42:01.869+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:42:01.870+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:42:01.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:42:32.178+0000] {processor.py:157} INFO - Started process (PID=10235) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:42:32.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:42:32.179+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:42:32.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:42:32.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:42:32.183+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:42:32.184+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:42:32.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:43:02.514+0000] {processor.py:157} INFO - Started process (PID=10250) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:43:02.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:43:02.515+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:43:02.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:43:02.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:43:02.519+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:43:02.520+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:43:02.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:43:32.856+0000] {processor.py:157} INFO - Started process (PID=10265) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:43:32.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:43:32.857+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:43:32.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:43:32.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:43:32.861+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:43:32.862+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:43:32.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:44:03.223+0000] {processor.py:157} INFO - Started process (PID=10280) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:44:03.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:44:03.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:44:03.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:44:03.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:44:03.228+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:44:03.229+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:44:03.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:44:33.618+0000] {processor.py:157} INFO - Started process (PID=10295) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:44:33.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:44:33.620+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:44:33.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:44:33.624+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:44:33.623+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:44:33.624+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:44:33.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:45:04.007+0000] {processor.py:157} INFO - Started process (PID=10310) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:45:04.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:45:04.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:45:04.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:45:04.013+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:45:04.012+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:45:04.013+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:45:04.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:45:34.440+0000] {processor.py:157} INFO - Started process (PID=10325) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:45:34.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:45:34.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:45:34.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:45:34.446+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:45:34.445+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:45:34.446+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:45:34.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:46:04.887+0000] {processor.py:157} INFO - Started process (PID=10340) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:46:04.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:46:04.889+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:46:04.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:46:04.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:46:04.892+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:46:04.893+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:46:04.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:46:35.337+0000] {processor.py:157} INFO - Started process (PID=10355) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:46:35.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:46:35.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:46:35.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:46:35.343+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:46:35.342+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:46:35.343+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:46:35.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:47:05.813+0000] {processor.py:157} INFO - Started process (PID=10370) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:47:05.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:47:05.815+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:47:05.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:47:05.819+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:47:05.818+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:47:05.819+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:47:05.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:47:36.248+0000] {processor.py:157} INFO - Started process (PID=10385) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:47:36.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:47:36.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:47:36.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:47:36.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:47:36.253+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:47:36.254+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:47:36.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:48:06.704+0000] {processor.py:157} INFO - Started process (PID=10400) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:48:06.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:48:06.705+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:48:06.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:48:06.710+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:48:06.709+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:48:06.710+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:48:06.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:48:37.133+0000] {processor.py:157} INFO - Started process (PID=10415) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:48:37.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:48:37.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:48:37.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:48:37.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:48:37.138+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:48:37.139+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:48:37.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:49:07.526+0000] {processor.py:157} INFO - Started process (PID=10430) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:49:07.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:49:07.527+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:49:07.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:49:07.532+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:49:07.531+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:49:07.532+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:49:07.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:49:38.021+0000] {processor.py:157} INFO - Started process (PID=10445) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:49:38.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:49:38.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:49:38.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:49:38.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:49:38.026+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:49:38.027+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:49:38.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:50:08.488+0000] {processor.py:157} INFO - Started process (PID=10460) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:50:08.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:50:08.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:50:08.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:50:08.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:50:08.493+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:50:08.494+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:50:08.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:50:38.899+0000] {processor.py:157} INFO - Started process (PID=10475) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:50:38.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:50:38.900+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:50:38.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:50:38.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:50:38.904+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:50:38.905+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:50:38.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:51:09.357+0000] {processor.py:157} INFO - Started process (PID=10490) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:51:09.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:51:09.358+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:51:09.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:51:09.363+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:51:09.362+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:51:09.363+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:51:09.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:51:39.800+0000] {processor.py:157} INFO - Started process (PID=10505) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:51:39.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:51:39.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:51:39.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:51:39.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:51:39.805+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:51:39.807+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:51:39.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:52:10.243+0000] {processor.py:157} INFO - Started process (PID=10520) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:52:10.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:52:10.244+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:52:10.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:52:10.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:52:10.248+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:52:10.249+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:52:10.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:52:40.695+0000] {processor.py:157} INFO - Started process (PID=10535) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:52:40.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:52:40.696+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:52:40.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:52:40.700+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:52:40.699+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:52:40.701+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:52:40.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:53:11.198+0000] {processor.py:157} INFO - Started process (PID=10550) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:53:11.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:53:11.199+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:53:11.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:53:11.204+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:53:11.203+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:53:11.204+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:53:11.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:53:41.600+0000] {processor.py:157} INFO - Started process (PID=10565) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:53:41.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:53:41.602+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:53:41.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:53:41.606+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:53:41.605+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:53:41.606+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:53:41.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:54:12.004+0000] {processor.py:157} INFO - Started process (PID=10580) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:54:12.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:54:12.006+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:54:12.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:54:12.010+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:54:12.009+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:54:12.010+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:54:12.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:54:42.410+0000] {processor.py:157} INFO - Started process (PID=10595) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:54:42.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:54:42.412+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:54:42.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:54:42.416+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:54:42.415+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:54:42.417+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:54:42.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:55:12.837+0000] {processor.py:157} INFO - Started process (PID=10610) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:55:12.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:55:12.838+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:55:12.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:55:12.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:55:12.842+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:55:12.843+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:55:12.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T07:55:43.247+0000] {processor.py:157} INFO - Started process (PID=10625) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:55:43.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:55:43.248+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:55:43.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:55:43.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:55:43.252+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:55:43.254+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:55:43.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:56:13.615+0000] {processor.py:157} INFO - Started process (PID=10640) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:56:13.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:56:13.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:56:13.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:56:13.621+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:56:13.620+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:56:13.621+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:56:13.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.030 seconds
[2024-07-10T07:56:43.949+0000] {processor.py:157} INFO - Started process (PID=10655) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:56:43.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:56:43.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:56:43.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:56:43.954+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:56:43.953+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:56:43.955+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:56:43.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:57:14.316+0000] {processor.py:157} INFO - Started process (PID=10670) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:57:14.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:57:14.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:57:14.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:57:14.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:57:14.321+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:57:14.322+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:57:14.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:57:44.687+0000] {processor.py:157} INFO - Started process (PID=10685) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:57:44.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:57:44.688+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:57:44.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:57:44.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:57:44.692+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:57:44.693+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:57:44.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:58:15.076+0000] {processor.py:157} INFO - Started process (PID=10700) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:58:15.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:58:15.077+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:58:15.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:58:15.082+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:58:15.081+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:58:15.082+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:58:15.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T07:58:45.492+0000] {processor.py:157} INFO - Started process (PID=10715) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:58:45.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:58:45.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:58:45.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:58:45.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:58:45.497+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:58:45.498+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:58:45.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:59:15.880+0000] {processor.py:157} INFO - Started process (PID=10730) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:59:15.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:59:15.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:59:15.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:59:15.885+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:59:15.884+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:59:15.886+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:59:15.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T07:59:46.289+0000] {processor.py:157} INFO - Started process (PID=10745) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:59:46.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T07:59:46.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:59:46.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:59:46.296+0000] {logging_mixin.py:151} INFO - [2024-07-10T07:59:46.294+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T07:59:46.296+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T07:59:46.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T08:00:16.643+0000] {processor.py:157} INFO - Started process (PID=10760) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:00:16.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:00:16.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:00:16.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:00:16.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:00:16.649+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:00:16.650+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:00:16.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:00:46.967+0000] {processor.py:157} INFO - Started process (PID=10775) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:00:46.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:00:46.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:00:46.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:00:46.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:00:46.971+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:00:46.972+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:00:46.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T08:01:17.330+0000] {processor.py:157} INFO - Started process (PID=10790) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:01:17.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:01:17.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:01:17.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:01:17.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:01:17.335+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:01:17.336+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:01:17.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:01:47.680+0000] {processor.py:157} INFO - Started process (PID=10805) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:01:47.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:01:47.682+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:01:47.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:01:47.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:01:47.685+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:01:47.686+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:01:47.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:02:18.100+0000] {processor.py:157} INFO - Started process (PID=10820) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:02:18.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:02:18.102+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:02:18.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:02:18.107+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:02:18.106+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:02:18.107+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:02:18.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:02:48.557+0000] {processor.py:157} INFO - Started process (PID=10835) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:02:48.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:02:48.559+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:02:48.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:02:48.564+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:02:48.563+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:02:48.564+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:02:48.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T08:03:18.967+0000] {processor.py:157} INFO - Started process (PID=10850) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:03:18.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:03:18.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:03:18.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:03:18.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:03:18.972+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:03:18.973+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:03:18.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:03:49.385+0000] {processor.py:157} INFO - Started process (PID=10865) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:03:49.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:03:49.386+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:03:49.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:03:49.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:03:49.390+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:03:49.392+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:03:49.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:04:19.687+0000] {processor.py:157} INFO - Started process (PID=10880) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:04:19.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:04:19.688+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:04:19.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:04:19.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:04:19.692+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:04:19.693+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:04:19.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:04:50.124+0000] {processor.py:157} INFO - Started process (PID=10895) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:04:50.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:04:50.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:04:50.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:04:50.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:04:50.129+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:04:50.130+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:04:50.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:05:20.522+0000] {processor.py:157} INFO - Started process (PID=10910) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:05:20.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:05:20.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:05:20.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:05:20.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:05:20.527+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:05:20.528+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:05:20.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:05:50.886+0000] {processor.py:157} INFO - Started process (PID=10925) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:05:50.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:05:50.887+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:05:50.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:05:50.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:05:50.891+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:05:50.892+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:05:50.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:06:21.269+0000] {processor.py:157} INFO - Started process (PID=10940) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:06:21.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:06:21.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:06:21.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:06:21.274+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:06:21.274+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:06:21.275+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:06:21.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:06:51.695+0000] {processor.py:157} INFO - Started process (PID=10955) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:06:51.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:06:51.697+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:06:51.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:06:51.702+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:06:51.701+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:06:51.702+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:06:51.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:07:22.068+0000] {processor.py:157} INFO - Started process (PID=10970) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:07:22.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:07:22.070+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:07:22.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:07:22.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:07:22.073+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:07:22.074+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:07:22.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T08:07:52.400+0000] {processor.py:157} INFO - Started process (PID=10985) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:07:52.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:07:52.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:07:52.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:07:52.406+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:07:52.405+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:07:52.406+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:07:52.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:08:22.820+0000] {processor.py:157} INFO - Started process (PID=11000) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:08:22.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:08:22.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:08:22.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:08:22.827+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:08:22.826+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:08:22.827+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:08:22.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:08:53.251+0000] {processor.py:157} INFO - Started process (PID=11015) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:08:53.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:08:53.253+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:08:53.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:08:53.257+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:08:53.256+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:08:53.257+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:08:53.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:09:23.614+0000] {processor.py:157} INFO - Started process (PID=11030) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:09:23.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:09:23.615+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:09:23.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:09:23.621+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:09:23.619+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:09:23.621+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:09:23.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:09:53.987+0000] {processor.py:157} INFO - Started process (PID=11045) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:09:53.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:09:53.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:09:53.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:09:53.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:09:53.992+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:09:53.993+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:09:54.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T08:10:24.403+0000] {processor.py:157} INFO - Started process (PID=11060) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:10:24.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:10:24.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:10:24.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:10:24.409+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:10:24.408+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:10:24.409+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:10:24.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:10:54.819+0000] {processor.py:157} INFO - Started process (PID=11075) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:10:54.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:10:54.820+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:10:54.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:10:54.824+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:10:54.823+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:10:54.824+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:10:54.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:11:25.182+0000] {processor.py:157} INFO - Started process (PID=11090) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:11:25.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:11:25.183+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:11:25.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:11:25.188+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:11:25.187+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:11:25.188+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:11:25.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:11:55.541+0000] {processor.py:157} INFO - Started process (PID=11105) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:11:55.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:11:55.543+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:11:55.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:11:55.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:11:55.547+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:11:55.548+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:11:55.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:12:25.891+0000] {processor.py:157} INFO - Started process (PID=11120) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:12:25.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:12:25.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:12:25.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:12:25.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:12:25.896+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:12:25.897+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:12:25.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T08:12:56.326+0000] {processor.py:157} INFO - Started process (PID=11135) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:12:56.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:12:56.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:12:56.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:12:56.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:12:56.331+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:12:56.332+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:12:56.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:13:26.789+0000] {processor.py:157} INFO - Started process (PID=11150) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:13:26.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:13:26.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:13:26.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:13:26.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:13:26.794+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:13:26.795+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:13:26.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:13:57.229+0000] {processor.py:157} INFO - Started process (PID=11165) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:13:57.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:13:57.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:13:57.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:13:57.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:13:57.234+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:13:57.236+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:13:57.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:14:27.651+0000] {processor.py:157} INFO - Started process (PID=11180) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:14:27.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:14:27.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:14:27.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:14:27.658+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:14:27.657+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:14:27.658+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:14:27.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T08:14:58.017+0000] {processor.py:157} INFO - Started process (PID=11195) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:14:58.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:14:58.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:14:58.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:14:58.023+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:14:58.022+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:14:58.023+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:14:58.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:15:28.468+0000] {processor.py:157} INFO - Started process (PID=11210) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:15:28.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:15:28.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:15:28.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:15:28.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:15:28.474+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:15:28.476+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:15:28.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T08:15:58.891+0000] {processor.py:157} INFO - Started process (PID=11225) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:15:58.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:15:58.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:15:58.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:15:58.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:15:58.897+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:15:58.898+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:15:58.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T08:16:29.278+0000] {processor.py:157} INFO - Started process (PID=11240) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:16:29.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:16:29.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:16:29.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:16:29.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:16:29.284+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:16:29.286+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:16:29.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T08:16:59.729+0000] {processor.py:157} INFO - Started process (PID=11255) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:16:59.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:16:59.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:16:59.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:16:59.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:16:59.736+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:16:59.738+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:16:59.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T08:17:30.138+0000] {processor.py:157} INFO - Started process (PID=11270) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:17:30.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:17:30.140+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:17:30.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:17:30.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:17:30.143+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:17:30.144+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:17:30.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:18:00.504+0000] {processor.py:157} INFO - Started process (PID=11285) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:18:00.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:18:00.505+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:18:00.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:18:00.511+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:18:00.510+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:18:00.512+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:18:00.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T08:18:30.914+0000] {processor.py:157} INFO - Started process (PID=11300) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:18:30.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:18:30.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:18:30.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:18:30.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:18:30.919+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:18:30.920+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:18:30.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:19:01.351+0000] {processor.py:157} INFO - Started process (PID=11315) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:19:01.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:19:01.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:19:01.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:19:01.357+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:19:01.355+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:19:01.357+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:19:01.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:19:31.769+0000] {processor.py:157} INFO - Started process (PID=11330) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:19:31.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:19:31.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:19:31.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:19:31.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:19:31.776+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:19:31.778+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:19:31.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T08:20:02.098+0000] {processor.py:157} INFO - Started process (PID=11345) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:20:02.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:20:02.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:20:02.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:20:02.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:20:02.104+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:20:02.105+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:20:02.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T08:20:32.536+0000] {processor.py:157} INFO - Started process (PID=11360) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:20:32.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:20:32.537+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:20:32.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:20:32.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:20:32.542+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:20:32.550+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:20:32.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T08:21:02.971+0000] {processor.py:157} INFO - Started process (PID=11375) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:21:02.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:21:02.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:21:02.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:21:02.979+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:21:02.978+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:21:02.980+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:21:02.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T08:21:33.337+0000] {processor.py:157} INFO - Started process (PID=11390) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:21:33.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:21:33.338+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:21:33.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:21:33.343+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:21:33.342+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:21:33.343+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:21:33.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:22:03.720+0000] {processor.py:157} INFO - Started process (PID=11405) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:22:03.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:22:03.721+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:22:03.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:22:03.725+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:22:03.724+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:22:03.726+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:22:03.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:22:34.109+0000] {processor.py:157} INFO - Started process (PID=11420) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:22:34.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:22:34.110+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:22:34.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:22:34.115+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:22:34.114+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:22:34.115+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:22:34.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:23:04.479+0000] {processor.py:157} INFO - Started process (PID=11435) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:23:04.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:23:04.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:23:04.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:23:04.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:23:04.483+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:23:04.484+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:23:04.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:23:34.850+0000] {processor.py:157} INFO - Started process (PID=11450) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:23:34.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:23:34.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:23:34.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:23:34.857+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:23:34.856+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:23:34.857+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:23:34.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T08:24:05.227+0000] {processor.py:157} INFO - Started process (PID=11465) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:24:05.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:24:05.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:24:05.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:24:05.233+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:24:05.232+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:24:05.233+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:24:05.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:24:35.600+0000] {processor.py:157} INFO - Started process (PID=11480) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:24:35.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:24:35.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:24:35.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:24:35.607+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:24:35.606+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:24:35.607+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:24:35.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:25:05.946+0000] {processor.py:157} INFO - Started process (PID=11495) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:25:05.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:25:05.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:25:05.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:25:05.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:25:05.952+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:25:05.953+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:25:05.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:25:36.326+0000] {processor.py:157} INFO - Started process (PID=11510) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:25:36.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:25:36.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:25:36.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:25:36.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:25:36.331+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:25:36.332+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:25:36.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:26:06.712+0000] {processor.py:157} INFO - Started process (PID=11525) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:26:06.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:26:06.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:26:06.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:26:06.718+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:26:06.717+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:26:06.718+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:26:06.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:26:37.108+0000] {processor.py:157} INFO - Started process (PID=11540) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:26:37.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:26:37.109+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:26:37.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:26:37.114+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:26:37.113+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:26:37.114+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:26:37.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:27:07.492+0000] {processor.py:157} INFO - Started process (PID=11555) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:27:07.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:27:07.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:27:07.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:27:07.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:27:07.497+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:27:07.499+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:27:07.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:27:37.848+0000] {processor.py:157} INFO - Started process (PID=11570) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:27:37.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:27:37.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:27:37.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:27:37.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:27:37.853+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:27:37.854+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:27:37.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:28:08.440+0000] {processor.py:157} INFO - Started process (PID=11585) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:28:08.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:28:08.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:28:08.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:28:08.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:28:08.449+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:28:08.454+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:28:08.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T08:28:38.837+0000] {processor.py:157} INFO - Started process (PID=11600) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:28:38.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:28:38.838+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:28:38.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:28:38.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:28:38.842+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:28:38.843+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:28:38.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:29:09.246+0000] {processor.py:157} INFO - Started process (PID=11615) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:29:09.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:29:09.248+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:29:09.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:29:09.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:29:09.252+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:29:09.253+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:29:09.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:29:39.633+0000] {processor.py:157} INFO - Started process (PID=11630) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:29:39.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:29:39.634+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:29:39.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:29:39.639+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:29:39.638+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:29:39.639+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:29:39.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:30:10.003+0000] {processor.py:157} INFO - Started process (PID=11645) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:30:10.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:30:10.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:30:10.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:30:10.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:30:10.008+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:30:10.009+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:30:10.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:30:40.357+0000] {processor.py:157} INFO - Started process (PID=11660) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:30:40.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:30:40.358+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:30:40.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:30:40.363+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:30:40.362+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:30:40.363+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:30:40.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T08:31:10.713+0000] {processor.py:157} INFO - Started process (PID=11675) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:31:10.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:31:10.715+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:31:10.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:31:10.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:31:10.718+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:31:10.719+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:31:10.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T08:31:41.060+0000] {processor.py:157} INFO - Started process (PID=11690) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:31:41.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:31:41.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:31:41.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:31:41.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:31:41.065+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:31:41.067+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:31:41.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:32:11.417+0000] {processor.py:157} INFO - Started process (PID=11705) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:32:11.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:32:11.418+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:32:11.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:32:11.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:32:11.422+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:32:11.423+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:32:11.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:32:41.812+0000] {processor.py:157} INFO - Started process (PID=11720) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:32:41.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:32:41.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:32:41.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:32:41.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:32:41.817+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:32:41.818+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:32:41.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:33:12.214+0000] {processor.py:157} INFO - Started process (PID=11735) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:33:12.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:33:12.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:33:12.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:33:12.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:33:12.220+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:33:12.221+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:33:12.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:33:42.610+0000] {processor.py:157} INFO - Started process (PID=11750) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:33:42.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:33:42.612+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:33:42.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:33:42.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:33:42.616+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:33:42.617+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:33:42.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:34:12.992+0000] {processor.py:157} INFO - Started process (PID=11765) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:34:12.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:34:12.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:34:12.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:34:12.998+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:34:12.997+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:34:12.999+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:34:13.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:34:43.385+0000] {processor.py:157} INFO - Started process (PID=11780) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:34:43.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:34:43.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:34:43.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:34:43.392+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:34:43.391+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:34:43.392+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:34:43.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:35:13.748+0000] {processor.py:157} INFO - Started process (PID=11795) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:35:13.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:35:13.750+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:35:13.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:35:13.754+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:35:13.753+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:35:13.754+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:35:13.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:35:44.126+0000] {processor.py:157} INFO - Started process (PID=11810) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:35:44.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:35:44.128+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:35:44.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:35:44.132+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:35:44.131+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:35:44.132+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:35:44.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:36:14.506+0000] {processor.py:157} INFO - Started process (PID=11825) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:36:14.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:36:14.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:36:14.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:36:14.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:36:14.512+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:36:14.513+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:36:14.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:36:44.913+0000] {processor.py:157} INFO - Started process (PID=11840) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:36:44.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:36:44.915+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:36:44.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:36:44.919+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:36:44.918+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:36:44.919+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:36:44.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:37:15.289+0000] {processor.py:157} INFO - Started process (PID=11855) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:37:15.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:37:15.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:37:15.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:37:15.295+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:37:15.294+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:37:15.295+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:37:15.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:37:45.669+0000] {processor.py:157} INFO - Started process (PID=11870) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:37:45.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:37:45.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:37:45.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:37:45.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:37:45.674+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:37:45.675+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:37:45.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:38:16.057+0000] {processor.py:157} INFO - Started process (PID=11885) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:38:16.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:38:16.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:38:16.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:38:16.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:38:16.061+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:38:16.062+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:38:16.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:38:46.478+0000] {processor.py:157} INFO - Started process (PID=11900) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:38:46.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:38:46.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:38:46.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:38:46.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:38:46.483+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:38:46.484+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:38:46.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:39:16.908+0000] {processor.py:157} INFO - Started process (PID=11915) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:39:16.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:39:16.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:39:16.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:39:16.914+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:39:16.913+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:39:16.914+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:39:16.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:39:47.274+0000] {processor.py:157} INFO - Started process (PID=11930) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:39:47.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:39:47.276+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:39:47.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:39:47.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:39:47.279+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:39:47.280+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:39:47.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:40:17.679+0000] {processor.py:157} INFO - Started process (PID=11945) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:40:17.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:40:17.682+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:40:17.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:40:17.690+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:40:17.688+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:40:17.691+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:40:17.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.032 seconds
[2024-07-10T08:40:48.097+0000] {processor.py:157} INFO - Started process (PID=11960) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:40:48.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:40:48.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:40:48.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:40:48.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:40:48.102+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:40:48.104+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:40:48.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:41:18.461+0000] {processor.py:157} INFO - Started process (PID=11975) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:41:18.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:41:18.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:41:18.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:41:18.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:41:18.466+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:41:18.467+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:41:18.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:41:48.879+0000] {processor.py:157} INFO - Started process (PID=11990) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:41:48.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:41:48.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:41:48.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:41:48.889+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:41:48.885+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:41:48.889+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:41:48.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T08:42:19.270+0000] {processor.py:157} INFO - Started process (PID=12005) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:42:19.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:42:19.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:42:19.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:42:19.276+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:42:19.275+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:42:19.277+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:42:19.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:42:49.633+0000] {processor.py:157} INFO - Started process (PID=12020) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:42:49.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:42:49.635+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:42:49.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:42:49.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:42:49.639+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:42:49.640+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:42:49.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:43:19.979+0000] {processor.py:157} INFO - Started process (PID=12035) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:43:19.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:43:19.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:43:19.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:43:19.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:43:19.984+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:43:19.985+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:43:19.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:43:50.398+0000] {processor.py:157} INFO - Started process (PID=12050) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:43:50.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:43:50.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:43:50.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:43:50.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:43:50.403+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:43:50.404+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:43:50.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:44:20.783+0000] {processor.py:157} INFO - Started process (PID=12065) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:44:20.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:44:20.784+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:44:20.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:44:20.789+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:44:20.788+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:44:20.789+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:44:20.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:44:51.180+0000] {processor.py:157} INFO - Started process (PID=12080) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:44:51.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:44:51.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:44:51.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:44:51.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:44:51.185+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:44:51.186+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:44:51.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:45:21.591+0000] {processor.py:157} INFO - Started process (PID=12095) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:45:21.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:45:21.593+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:45:21.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:45:21.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:45:21.597+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:45:21.598+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:45:21.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:45:52.042+0000] {processor.py:157} INFO - Started process (PID=12110) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:45:52.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:45:52.044+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:45:52.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:45:52.049+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:45:52.048+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:45:52.050+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:45:52.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T08:46:22.479+0000] {processor.py:157} INFO - Started process (PID=12125) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:46:22.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:46:22.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:46:22.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:46:22.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:46:22.484+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:46:22.486+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:46:22.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:46:52.830+0000] {processor.py:157} INFO - Started process (PID=12140) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:46:52.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:46:52.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:46:52.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:46:52.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:46:52.836+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:46:52.837+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:46:52.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:47:23.113+0000] {processor.py:157} INFO - Started process (PID=12155) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:47:23.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:47:23.115+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:47:23.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:47:23.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:47:23.118+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:47:23.120+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:47:23.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T08:47:53.572+0000] {processor.py:157} INFO - Started process (PID=12170) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:47:53.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:47:53.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:47:53.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:47:53.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:47:53.577+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:47:53.578+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:47:53.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:48:23.975+0000] {processor.py:157} INFO - Started process (PID=12185) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:48:23.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:48:23.976+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:48:23.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:48:23.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:48:23.980+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:48:23.981+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:48:23.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:48:54.430+0000] {processor.py:157} INFO - Started process (PID=12200) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:48:54.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:48:54.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:48:54.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:48:54.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:48:54.439+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:48:54.441+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:48:54.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.027 seconds
[2024-07-10T08:49:24.820+0000] {processor.py:157} INFO - Started process (PID=12215) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:49:24.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:49:24.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:49:24.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:49:24.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:49:24.827+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:49:24.828+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:49:24.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T08:49:55.184+0000] {processor.py:157} INFO - Started process (PID=12230) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:49:55.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:49:55.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:49:55.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:49:55.193+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:49:55.192+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:49:55.193+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:49:55.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T08:50:25.551+0000] {processor.py:157} INFO - Started process (PID=12245) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:50:25.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:50:25.553+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:50:25.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:50:25.558+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:50:25.557+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:50:25.558+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:50:25.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:50:55.966+0000] {processor.py:157} INFO - Started process (PID=12260) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:50:55.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:50:55.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:50:55.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:50:55.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:50:55.971+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:50:55.972+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:50:55.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:51:26.425+0000] {processor.py:157} INFO - Started process (PID=12275) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:51:26.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:51:26.426+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:51:26.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:51:26.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:51:26.430+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:51:26.432+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:51:26.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:51:56.801+0000] {processor.py:157} INFO - Started process (PID=12290) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:51:56.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:51:56.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:51:56.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:51:56.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:51:56.807+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:51:56.808+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:51:56.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T08:52:27.271+0000] {processor.py:157} INFO - Started process (PID=12305) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:52:27.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:52:27.273+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:52:27.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:52:27.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:52:27.278+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:52:27.280+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:52:27.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T08:52:57.666+0000] {processor.py:157} INFO - Started process (PID=12320) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:52:57.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:52:57.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:52:57.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:52:57.679+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:52:57.677+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:52:57.679+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:52:57.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.032 seconds
[2024-07-10T08:53:28.142+0000] {processor.py:157} INFO - Started process (PID=12335) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:53:28.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:53:28.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:53:28.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:53:28.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:53:28.149+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:53:28.151+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:53:28.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T08:53:58.527+0000] {processor.py:157} INFO - Started process (PID=12350) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:53:58.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:53:58.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:53:58.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:53:58.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:53:58.535+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:53:58.536+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:53:58.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T08:54:28.965+0000] {processor.py:157} INFO - Started process (PID=12365) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:54:28.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:54:28.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:54:28.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:54:28.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:54:28.974+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:54:28.976+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:54:28.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T08:54:59.406+0000] {processor.py:157} INFO - Started process (PID=12380) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:54:59.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:54:59.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:54:59.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:54:59.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:54:59.412+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:54:59.414+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:54:59.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T08:55:29.804+0000] {processor.py:157} INFO - Started process (PID=12395) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:55:29.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:55:29.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:55:29.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:55:29.812+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:55:29.811+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:55:29.813+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:55:29.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T08:56:00.214+0000] {processor.py:157} INFO - Started process (PID=12410) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:56:00.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:56:00.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:56:00.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:56:00.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:56:00.222+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:56:00.223+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:56:00.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T08:56:30.633+0000] {processor.py:157} INFO - Started process (PID=12425) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:56:30.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:56:30.636+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:56:30.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:56:30.642+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:56:30.641+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:56:30.643+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:56:30.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T08:57:00.985+0000] {processor.py:157} INFO - Started process (PID=12440) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:57:00.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:57:00.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:57:00.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:57:00.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:57:00.992+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:57:00.994+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:57:01.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T08:57:31.405+0000] {processor.py:157} INFO - Started process (PID=12455) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:57:31.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:57:31.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:57:31.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:57:31.412+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:57:31.411+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:57:31.412+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:57:31.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:58:01.796+0000] {processor.py:157} INFO - Started process (PID=12470) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:58:01.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:58:01.797+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:58:01.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:58:01.801+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:58:01.800+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:58:01.802+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:58:01.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T08:58:32.221+0000] {processor.py:157} INFO - Started process (PID=12485) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:58:32.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:58:32.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:58:32.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:58:32.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:58:32.228+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:58:32.229+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:58:32.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:59:02.627+0000] {processor.py:157} INFO - Started process (PID=12500) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:59:02.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:59:02.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:59:02.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:59:02.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:59:02.632+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:59:02.633+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:59:02.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T08:59:33.019+0000] {processor.py:157} INFO - Started process (PID=12515) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:59:33.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T08:59:33.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:59:33.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:59:33.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T08:59:33.024+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T08:59:33.026+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T08:59:33.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:00:03.408+0000] {processor.py:157} INFO - Started process (PID=12530) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:00:03.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:00:03.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:00:03.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:00:03.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:00:03.414+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:00:03.415+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:00:03.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:00:33.778+0000] {processor.py:157} INFO - Started process (PID=12545) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:00:33.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:00:33.780+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:00:33.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:00:33.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:00:33.784+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:00:33.786+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:00:33.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T09:01:04.183+0000] {processor.py:157} INFO - Started process (PID=12560) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:01:04.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:01:04.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:01:04.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:01:04.188+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:01:04.188+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:01:04.189+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:01:04.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:01:34.582+0000] {processor.py:157} INFO - Started process (PID=12575) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:01:34.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:01:34.584+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:01:34.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:01:34.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:01:34.588+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:01:34.589+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:01:34.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:02:05.020+0000] {processor.py:157} INFO - Started process (PID=12590) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:02:05.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:02:05.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:02:05.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:02:05.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:02:05.026+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:02:05.027+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:02:05.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:02:35.421+0000] {processor.py:157} INFO - Started process (PID=12605) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:02:35.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:02:35.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:02:35.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:02:35.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:02:35.426+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:02:35.427+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:02:35.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:03:05.797+0000] {processor.py:157} INFO - Started process (PID=12620) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:03:05.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:03:05.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:03:05.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:03:05.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:03:05.802+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:03:05.803+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:03:05.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:03:36.158+0000] {processor.py:157} INFO - Started process (PID=12635) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:03:36.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:03:36.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:03:36.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:03:36.164+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:03:36.163+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:03:36.164+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:03:36.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:04:06.527+0000] {processor.py:157} INFO - Started process (PID=12650) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:04:06.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:04:06.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:04:06.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:04:06.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:04:06.533+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:04:06.535+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:04:06.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T09:04:36.893+0000] {processor.py:157} INFO - Started process (PID=12665) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:04:36.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:04:36.894+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:04:36.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:04:36.899+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:04:36.898+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:04:36.899+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:04:36.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:05:07.279+0000] {processor.py:157} INFO - Started process (PID=12680) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:05:07.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:05:07.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:05:07.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:05:07.284+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:05:07.284+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:05:07.285+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:05:07.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:05:37.640+0000] {processor.py:157} INFO - Started process (PID=12695) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:05:37.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:05:37.642+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:05:37.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:05:37.646+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:05:37.645+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:05:37.646+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:05:37.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:06:07.987+0000] {processor.py:157} INFO - Started process (PID=12710) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:06:07.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:06:07.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:06:07.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:06:07.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:06:07.992+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:06:07.993+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:06:08.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T09:06:38.363+0000] {processor.py:157} INFO - Started process (PID=12725) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:06:38.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:06:38.365+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:06:38.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:06:38.369+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:06:38.368+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:06:38.370+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:06:38.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:07:08.760+0000] {processor.py:157} INFO - Started process (PID=12740) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:07:08.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:07:08.761+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:07:08.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:07:08.766+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:07:08.765+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:07:08.766+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:07:08.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:07:39.165+0000] {processor.py:157} INFO - Started process (PID=12755) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:07:39.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:07:39.167+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:07:39.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:07:39.171+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:07:39.170+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:07:39.171+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:07:39.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:08:09.632+0000] {processor.py:157} INFO - Started process (PID=12770) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:08:09.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:08:09.634+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:08:09.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:08:09.639+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:08:09.638+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:08:09.639+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:08:09.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:08:40.066+0000] {processor.py:157} INFO - Started process (PID=12785) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:08:40.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:08:40.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:08:40.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:08:40.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:08:40.071+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:08:40.072+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:08:40.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:09:10.538+0000] {processor.py:157} INFO - Started process (PID=12800) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:09:10.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:09:10.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:09:10.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:09:10.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:09:10.543+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:09:10.544+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:09:10.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:09:40.999+0000] {processor.py:157} INFO - Started process (PID=12815) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:09:41.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:09:41.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:09:41.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:09:41.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:09:41.004+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:09:41.005+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:09:41.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:10:11.452+0000] {processor.py:157} INFO - Started process (PID=12830) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:10:11.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:10:11.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:10:11.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:10:11.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:10:11.458+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:10:11.459+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:10:11.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:10:41.871+0000] {processor.py:157} INFO - Started process (PID=12845) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:10:41.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:10:41.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:10:41.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:10:41.877+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:10:41.876+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:10:41.877+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:10:41.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:11:12.274+0000] {processor.py:157} INFO - Started process (PID=12860) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:11:12.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:11:12.276+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:11:12.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:11:12.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:11:12.279+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:11:12.280+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:11:12.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:11:42.771+0000] {processor.py:157} INFO - Started process (PID=12875) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:11:42.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:11:42.772+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:11:42.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:11:42.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:11:42.777+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:11:42.779+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:11:42.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:12:13.128+0000] {processor.py:157} INFO - Started process (PID=12890) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:12:13.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:12:13.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:12:13.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:12:13.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:12:13.134+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:12:13.135+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:12:13.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:12:43.538+0000] {processor.py:157} INFO - Started process (PID=12905) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:12:43.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:12:43.539+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:12:43.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:12:43.543+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:12:43.542+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:12:43.543+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:12:43.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:13:13.969+0000] {processor.py:157} INFO - Started process (PID=12920) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:13:13.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:13:13.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:13:13.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:13:13.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:13:13.974+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:13:13.975+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:13:13.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:13:44.429+0000] {processor.py:157} INFO - Started process (PID=12935) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:13:44.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:13:44.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:13:44.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:13:44.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:13:44.434+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:13:44.435+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:13:44.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:14:15.017+0000] {processor.py:157} INFO - Started process (PID=12950) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:14:15.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:14:15.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:14:15.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:14:15.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:14:15.027+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:14:15.028+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:14:15.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T09:14:45.465+0000] {processor.py:157} INFO - Started process (PID=12965) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:14:45.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:14:45.466+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:14:45.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:14:45.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:14:45.470+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:14:45.471+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:14:45.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:15:15.976+0000] {processor.py:157} INFO - Started process (PID=12980) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:15:15.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:15:15.978+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:15:15.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:15:15.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:15:15.983+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:15:15.985+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:15:15.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T09:15:46.332+0000] {processor.py:157} INFO - Started process (PID=12995) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:15:46.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:15:46.334+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:15:46.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:15:46.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:15:46.338+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:15:46.340+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:15:46.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T09:16:16.734+0000] {processor.py:157} INFO - Started process (PID=13010) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:16:16.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:16:16.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:16:16.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:16:16.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:16:16.740+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:16:16.741+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:16:16.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:16:47.253+0000] {processor.py:157} INFO - Started process (PID=13025) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:16:47.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:16:47.257+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:16:47.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:16:47.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:16:47.263+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:16:47.266+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:16:47.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.027 seconds
[2024-07-10T09:17:17.654+0000] {processor.py:157} INFO - Started process (PID=13040) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:17:17.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:17:17.656+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:17:17.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:17:17.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:17:17.662+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:17:17.664+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:17:17.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T09:17:48.012+0000] {processor.py:157} INFO - Started process (PID=13055) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:17:48.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:17:48.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:17:48.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:17:48.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:17:48.019+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:17:48.021+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:17:48.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T09:18:18.373+0000] {processor.py:157} INFO - Started process (PID=13070) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:18:18.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:18:18.375+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:18:18.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:18:18.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:18:18.380+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:18:18.381+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:18:18.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T09:18:48.861+0000] {processor.py:157} INFO - Started process (PID=13085) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:18:48.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:18:48.863+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:18:48.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:18:48.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:18:48.870+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:18:48.872+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:18:48.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T09:19:19.291+0000] {processor.py:157} INFO - Started process (PID=13100) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:19:19.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:19:19.294+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:19:19.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:19:19.304+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:19:19.302+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:19:19.304+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:19:19.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.033 seconds
[2024-07-10T09:19:49.824+0000] {processor.py:157} INFO - Started process (PID=13115) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:19:49.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:19:49.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:19:49.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:19:49.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:19:49.834+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:19:49.836+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:19:49.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T09:20:20.208+0000] {processor.py:157} INFO - Started process (PID=13130) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:20:20.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:20:20.212+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:20:20.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:20:20.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:20:20.218+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:20:20.220+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:20:20.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.028 seconds
[2024-07-10T09:20:50.617+0000] {processor.py:157} INFO - Started process (PID=13145) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:20:50.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:20:50.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:20:50.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:20:50.627+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:20:50.625+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:20:50.627+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:20:50.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T09:21:21.129+0000] {processor.py:157} INFO - Started process (PID=13160) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:21:21.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:21:21.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:21:21.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:21:21.137+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:21:21.136+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:21:21.138+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:21:21.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T09:21:51.647+0000] {processor.py:157} INFO - Started process (PID=13175) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:21:51.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:21:51.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:21:51.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:21:51.657+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:21:51.655+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:21:51.657+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:21:51.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T09:22:22.050+0000] {processor.py:157} INFO - Started process (PID=13190) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:22:22.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:22:22.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:22:22.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:22:22.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:22:22.056+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:22:22.058+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:22:22.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T09:22:52.473+0000] {processor.py:157} INFO - Started process (PID=13205) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:22:52.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:22:52.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:22:52.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:22:52.510+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:22:52.502+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:22:52.511+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:22:52.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.065 seconds
[2024-07-10T09:23:22.951+0000] {processor.py:157} INFO - Started process (PID=13220) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:23:22.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:23:22.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:23:22.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:23:22.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:23:22.957+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:23:22.958+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:23:22.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:23:53.459+0000] {processor.py:157} INFO - Started process (PID=13235) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:23:53.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:23:53.463+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:23:53.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:23:53.470+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:23:53.468+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:23:53.470+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:23:53.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T09:24:23.955+0000] {processor.py:157} INFO - Started process (PID=13250) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:24:23.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:24:23.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:24:23.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:24:23.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:24:23.962+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:24:23.964+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:24:23.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T09:24:54.394+0000] {processor.py:157} INFO - Started process (PID=13265) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:24:54.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:24:54.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:24:54.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:24:54.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:24:54.401+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:24:54.402+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:24:54.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T09:25:24.901+0000] {processor.py:157} INFO - Started process (PID=13280) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:25:24.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:25:24.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:25:24.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:25:24.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:25:24.909+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:25:24.911+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:25:24.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T09:25:55.337+0000] {processor.py:157} INFO - Started process (PID=13295) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:25:55.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:25:55.338+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:25:55.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:25:55.343+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:25:55.342+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:25:55.343+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:25:55.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:26:25.863+0000] {processor.py:157} INFO - Started process (PID=13310) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:26:25.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:26:25.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:26:25.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:26:25.870+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:26:25.869+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:26:25.871+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:26:25.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T09:26:56.358+0000] {processor.py:157} INFO - Started process (PID=13325) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:26:56.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:26:56.360+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:26:56.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:26:56.368+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:26:56.366+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:26:56.368+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:26:56.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T09:27:26.890+0000] {processor.py:157} INFO - Started process (PID=13340) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:27:26.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:27:26.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:27:26.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:27:26.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:27:26.897+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:27:26.898+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:27:26.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T09:27:57.412+0000] {processor.py:157} INFO - Started process (PID=13355) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:27:57.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:27:57.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:27:57.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:27:57.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:27:57.421+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:27:57.423+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:27:57.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.028 seconds
[2024-07-10T09:28:27.772+0000] {processor.py:157} INFO - Started process (PID=13370) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:28:27.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:28:27.774+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:28:27.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:28:27.780+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:28:27.779+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:28:27.780+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:28:27.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:28:58.277+0000] {processor.py:157} INFO - Started process (PID=13385) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:28:58.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:28:58.279+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:28:58.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:28:58.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:28:58.284+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:28:58.285+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:28:58.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T09:29:28.684+0000] {processor.py:157} INFO - Started process (PID=13400) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:29:28.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:29:28.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:29:28.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:29:28.692+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:29:28.691+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:29:28.693+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:29:28.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T09:29:59.175+0000] {processor.py:157} INFO - Started process (PID=13415) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:29:59.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:29:59.178+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:29:59.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:29:59.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:29:59.183+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:29:59.184+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:29:59.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:30:29.576+0000] {processor.py:157} INFO - Started process (PID=13430) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:30:29.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:30:29.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:30:29.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:30:29.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:30:29.582+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:30:29.583+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:30:29.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T09:31:00.036+0000] {processor.py:157} INFO - Started process (PID=13445) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:31:00.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:31:00.038+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:31:00.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:31:00.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:31:00.042+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:31:00.043+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:31:00.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T09:31:30.700+0000] {processor.py:157} INFO - Started process (PID=13460) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:31:30.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:31:30.703+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:31:30.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:31:30.710+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:31:30.708+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:31:30.710+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:31:30.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T09:32:01.091+0000] {processor.py:157} INFO - Started process (PID=13475) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:32:01.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:32:01.093+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:32:01.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:32:01.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:32:01.097+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:32:01.098+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:32:01.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T09:32:31.456+0000] {processor.py:157} INFO - Started process (PID=13490) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:32:31.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:32:31.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:32:31.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:32:31.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:32:31.461+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:32:31.462+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:32:31.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:33:01.789+0000] {processor.py:157} INFO - Started process (PID=13505) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:33:01.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:33:01.791+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:33:01.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:33:01.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:33:01.795+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:33:01.796+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:33:01.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:33:32.206+0000] {processor.py:157} INFO - Started process (PID=13520) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:33:32.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:33:32.208+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:33:32.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:33:32.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:33:32.215+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:33:32.217+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:33:32.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T09:34:02.673+0000] {processor.py:157} INFO - Started process (PID=13535) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:34:02.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:34:02.674+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:34:02.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:34:02.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:34:02.679+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:34:02.681+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:34:02.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T09:34:33.077+0000] {processor.py:157} INFO - Started process (PID=13550) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:34:33.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:34:33.078+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:34:33.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:34:33.084+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:34:33.083+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:34:33.084+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:34:33.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T09:35:03.425+0000] {processor.py:157} INFO - Started process (PID=13565) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:35:03.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:35:03.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:35:03.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:35:03.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:35:03.431+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:35:03.433+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:35:03.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T09:35:33.926+0000] {processor.py:157} INFO - Started process (PID=13580) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:35:33.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:35:33.928+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:35:33.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:35:33.937+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:35:33.935+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:35:33.937+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:35:33.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.027 seconds
[2024-07-10T09:36:04.348+0000] {processor.py:157} INFO - Started process (PID=13595) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:36:04.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:36:04.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:36:04.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:36:04.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:36:04.359+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:36:04.362+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:36:04.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.031 seconds
[2024-07-10T09:36:34.781+0000] {processor.py:157} INFO - Started process (PID=13610) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:36:34.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:36:34.783+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:36:34.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:36:34.788+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:36:34.787+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:36:34.788+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:36:34.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:37:05.269+0000] {processor.py:157} INFO - Started process (PID=13625) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:37:05.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:37:05.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:37:05.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:37:05.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:37:05.278+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:37:05.281+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:37:05.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.028 seconds
[2024-07-10T09:37:35.731+0000] {processor.py:157} INFO - Started process (PID=13640) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:37:35.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:37:35.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:37:35.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:37:35.739+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:37:35.738+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:37:35.739+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:37:35.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T09:38:06.080+0000] {processor.py:157} INFO - Started process (PID=13655) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:38:06.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:38:06.082+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:38:06.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:38:06.087+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:38:06.086+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:38:06.087+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:38:06.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T09:38:36.469+0000] {processor.py:157} INFO - Started process (PID=13670) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:38:36.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:38:36.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:38:36.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:38:36.478+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:38:36.477+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:38:36.478+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:38:36.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:39:06.880+0000] {processor.py:157} INFO - Started process (PID=13685) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:39:06.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:39:06.884+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:39:06.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:39:06.891+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:39:06.890+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:39:06.892+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:39:06.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T09:39:37.290+0000] {processor.py:157} INFO - Started process (PID=13700) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:39:37.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:39:37.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:39:37.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:39:37.296+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:39:37.295+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:39:37.296+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:39:37.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:40:07.650+0000] {processor.py:157} INFO - Started process (PID=13715) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:40:07.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:40:07.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:40:07.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:40:07.656+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:40:07.655+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:40:07.657+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:40:07.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:40:37.947+0000] {processor.py:157} INFO - Started process (PID=13730) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:40:37.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:40:37.949+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:40:37.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:40:37.954+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:40:37.953+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:40:37.954+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:40:37.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:41:08.320+0000] {processor.py:157} INFO - Started process (PID=13745) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:41:08.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:41:08.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:41:08.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:41:08.326+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:41:08.325+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:41:08.326+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:41:08.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:41:38.732+0000] {processor.py:157} INFO - Started process (PID=13760) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:41:38.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:41:38.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:41:38.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:41:38.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:41:38.737+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:41:38.738+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:41:38.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:42:09.095+0000] {processor.py:157} INFO - Started process (PID=13775) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:42:09.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:42:09.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:42:09.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:42:09.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:42:09.100+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:42:09.101+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:42:09.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:42:39.533+0000] {processor.py:157} INFO - Started process (PID=13790) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:42:39.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:42:39.535+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:42:39.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:42:39.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:42:39.539+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:42:39.540+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:42:39.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:43:09.995+0000] {processor.py:157} INFO - Started process (PID=13805) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:43:09.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:43:09.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:43:09.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:43:10.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:43:10.000+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:43:10.002+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:43:10.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:43:40.392+0000] {processor.py:157} INFO - Started process (PID=13820) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:43:40.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:43:40.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:43:40.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:43:40.398+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:43:40.397+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:43:40.398+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:43:40.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:44:10.802+0000] {processor.py:157} INFO - Started process (PID=13835) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:44:10.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:44:10.804+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:44:10.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:44:10.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:44:10.808+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:44:10.809+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:44:10.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:44:41.222+0000] {processor.py:157} INFO - Started process (PID=13850) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:44:41.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:44:41.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:44:41.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:44:41.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:44:41.227+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:44:41.228+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:44:41.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:45:11.670+0000] {processor.py:157} INFO - Started process (PID=13865) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:45:11.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:45:11.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:45:11.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:45:11.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:45:11.674+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:45:11.675+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:45:11.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:45:42.093+0000] {processor.py:157} INFO - Started process (PID=13880) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:45:42.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:45:42.094+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:45:42.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:45:42.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:45:42.098+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:45:42.099+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:45:42.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:46:12.534+0000] {processor.py:157} INFO - Started process (PID=13895) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:46:12.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:46:12.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:46:12.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:46:12.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:46:12.539+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:46:12.540+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:46:12.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:46:43.152+0000] {processor.py:157} INFO - Started process (PID=13910) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:46:43.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:46:43.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:46:43.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:46:43.162+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:46:43.160+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:46:43.162+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:46:43.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T09:47:13.539+0000] {processor.py:157} INFO - Started process (PID=13925) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:47:13.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:47:13.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:47:13.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:47:13.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:47:13.546+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:47:13.548+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:47:13.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:47:43.942+0000] {processor.py:157} INFO - Started process (PID=13940) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:47:43.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:47:43.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:47:43.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:47:43.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:47:43.949+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:47:43.950+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:47:43.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:48:14.327+0000] {processor.py:157} INFO - Started process (PID=13955) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:48:14.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:48:14.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:48:14.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:48:14.335+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:48:14.334+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:48:14.335+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:48:14.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T09:48:44.731+0000] {processor.py:157} INFO - Started process (PID=13970) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:48:44.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:48:44.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:48:44.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:48:44.739+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:48:44.738+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:48:44.739+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:48:44.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T09:49:15.157+0000] {processor.py:157} INFO - Started process (PID=13985) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:49:15.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:49:15.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:49:15.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:49:15.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:49:15.165+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:49:15.167+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:49:15.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:49:45.653+0000] {processor.py:157} INFO - Started process (PID=14000) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:49:45.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:49:45.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:49:45.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:49:45.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:49:45.661+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:49:45.664+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:49:45.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T09:50:16.015+0000] {processor.py:157} INFO - Started process (PID=14015) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:50:16.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:50:16.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:50:16.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:50:16.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:50:16.023+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:50:16.025+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:50:16.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T09:50:46.407+0000] {processor.py:157} INFO - Started process (PID=14030) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:50:46.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:50:46.409+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:50:46.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:50:46.416+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:50:46.415+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:50:46.416+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:50:46.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T09:51:16.821+0000] {processor.py:157} INFO - Started process (PID=14045) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:51:16.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:51:16.824+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:51:16.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:51:16.831+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:51:16.829+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:51:16.831+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:51:16.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:51:47.198+0000] {processor.py:157} INFO - Started process (PID=14060) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:51:47.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:51:47.201+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:51:47.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:51:47.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:51:47.206+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:51:47.207+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:51:47.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T09:52:17.595+0000] {processor.py:157} INFO - Started process (PID=14075) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:52:17.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:52:17.597+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:52:17.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:52:17.603+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:52:17.602+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:52:17.604+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:52:17.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:52:47.961+0000] {processor.py:157} INFO - Started process (PID=14090) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:52:47.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:52:47.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:52:47.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:52:47.969+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:52:47.968+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:52:47.969+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:52:47.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T09:53:18.351+0000] {processor.py:157} INFO - Started process (PID=14105) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:53:18.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:53:18.354+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:53:18.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:53:18.361+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:53:18.360+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:53:18.361+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:53:18.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T09:53:48.778+0000] {processor.py:157} INFO - Started process (PID=14120) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:53:48.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:53:48.781+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:53:48.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:53:48.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:53:48.785+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:53:48.786+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:53:48.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T09:54:19.156+0000] {processor.py:157} INFO - Started process (PID=14135) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:54:19.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:54:19.158+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:54:19.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:54:19.165+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:54:19.164+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:54:19.165+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:54:19.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:54:49.524+0000] {processor.py:157} INFO - Started process (PID=14150) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:54:49.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:54:49.526+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:54:49.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:54:49.532+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:54:49.531+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:54:49.532+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:54:49.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T09:55:19.932+0000] {processor.py:157} INFO - Started process (PID=14165) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:55:19.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:55:19.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:55:19.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:55:19.940+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:55:19.939+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:55:19.941+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:55:19.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T09:55:50.276+0000] {processor.py:157} INFO - Started process (PID=14180) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:55:50.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:55:50.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:55:50.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:55:50.283+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:55:50.281+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:55:50.283+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:55:50.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:56:20.598+0000] {processor.py:157} INFO - Started process (PID=14195) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:56:20.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:56:20.599+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:56:20.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:56:20.604+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:56:20.603+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:56:20.604+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:56:20.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T09:56:50.977+0000] {processor.py:157} INFO - Started process (PID=14210) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:56:50.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:56:50.979+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:56:50.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:56:50.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:56:50.983+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:56:50.984+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:56:50.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T09:57:21.354+0000] {processor.py:157} INFO - Started process (PID=14225) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:57:21.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:57:21.355+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:57:21.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:57:21.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:57:21.358+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:57:21.359+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:57:21.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.014 seconds
[2024-07-10T09:57:51.688+0000] {processor.py:157} INFO - Started process (PID=14240) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:57:51.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:57:51.690+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:57:51.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:57:51.695+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:57:51.694+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:57:51.695+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:57:51.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T09:58:22.078+0000] {processor.py:157} INFO - Started process (PID=14255) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:58:22.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:58:22.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:58:22.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:58:22.085+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:58:22.084+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:58:22.085+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:58:22.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:58:52.495+0000] {processor.py:157} INFO - Started process (PID=14275) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:58:52.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:58:52.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:58:52.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:58:52.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:58:52.504+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:58:52.506+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:58:52.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T09:59:22.876+0000] {processor.py:157} INFO - Started process (PID=14295) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:59:22.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:59:22.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:59:22.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:59:22.883+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:59:22.882+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:59:22.883+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:59:22.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T09:59:53.361+0000] {processor.py:157} INFO - Started process (PID=14318) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:59:53.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T09:59:53.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:59:53.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:59:53.372+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:59:53.371+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T09:59:53.373+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T09:59:53.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.029 seconds
[2024-07-10T10:00:23.803+0000] {processor.py:157} INFO - Started process (PID=14338) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:00:23.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:00:23.804+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:23.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:00:23.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:23.809+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:00:23.811+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:00:23.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T10:00:54.236+0000] {processor.py:157} INFO - Started process (PID=14365) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:00:54.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:00:54.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:54.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:00:54.243+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:54.242+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:00:54.243+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:00:54.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T10:01:24.613+0000] {processor.py:157} INFO - Started process (PID=14385) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:01:24.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:01:24.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:01:24.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:01:24.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:01:24.618+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:01:24.619+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:01:24.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T10:01:54.963+0000] {processor.py:157} INFO - Started process (PID=14405) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:01:54.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:01:54.964+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:01:54.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:01:54.970+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:01:54.969+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:01:54.970+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:01:54.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T10:02:25.346+0000] {processor.py:157} INFO - Started process (PID=14425) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:02:25.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:02:25.348+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:02:25.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:02:25.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:02:25.351+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:02:25.352+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:02:25.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.015 seconds
[2024-07-10T10:02:55.739+0000] {processor.py:157} INFO - Started process (PID=14445) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:02:55.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:02:55.740+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:02:55.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:02:55.745+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:02:55.744+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:02:55.745+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:02:55.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T10:03:26.128+0000] {processor.py:157} INFO - Started process (PID=14465) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:03:26.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:03:26.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:03:26.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:03:26.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:03:26.133+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:03:26.134+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:03:26.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.016 seconds
[2024-07-10T10:03:56.556+0000] {processor.py:157} INFO - Started process (PID=14485) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:03:56.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:03:56.558+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:03:56.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:03:56.563+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:03:56.562+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:03:56.564+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:03:56.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.017 seconds
[2024-07-10T10:04:26.847+0000] {processor.py:157} INFO - Started process (PID=14503) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:04:26.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:04:26.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:04:26.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:04:26.856+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:04:26.855+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:04:26.856+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:04:26.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T10:04:57.213+0000] {processor.py:157} INFO - Started process (PID=14523) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:04:57.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:04:57.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:04:57.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:04:57.225+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:04:57.224+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:04:57.226+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:04:57.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.027 seconds
[2024-07-10T10:05:27.598+0000] {processor.py:157} INFO - Started process (PID=14543) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:05:27.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:05:27.600+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:05:27.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:05:27.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:05:27.608+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:05:27.610+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:05:27.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T10:05:57.987+0000] {processor.py:157} INFO - Started process (PID=14563) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:05:57.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:05:57.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:05:57.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:05:58.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:05:58.000+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:05:58.004+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:05:58.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.029 seconds
[2024-07-10T10:06:28.400+0000] {processor.py:157} INFO - Started process (PID=14583) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:06:28.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:06:28.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:06:28.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:06:28.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:06:28.409+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:06:28.411+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:06:28.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T10:06:58.803+0000] {processor.py:157} INFO - Started process (PID=14603) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:06:58.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:06:58.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:06:58.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:06:58.819+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:06:58.817+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:06:58.819+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:06:58.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.030 seconds
[2024-07-10T10:07:29.222+0000] {processor.py:157} INFO - Started process (PID=14623) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:07:29.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:07:29.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:07:29.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:07:29.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:07:29.230+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:07:29.232+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:07:29.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:07:59.590+0000] {processor.py:157} INFO - Started process (PID=14643) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:07:59.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:07:59.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:07:59.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:07:59.600+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:07:59.598+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:07:59.600+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:07:59.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:08:29.990+0000] {processor.py:157} INFO - Started process (PID=14663) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:08:29.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:08:29.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:08:29.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:08:30.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:08:29.999+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:08:30.001+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:08:30.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:09:00.350+0000] {processor.py:157} INFO - Started process (PID=14683) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:09:00.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:09:00.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:09:00.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:09:00.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:09:00.358+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:09:00.360+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:09:00.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:09:30.694+0000] {processor.py:157} INFO - Started process (PID=14703) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:09:30.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:09:30.697+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:09:30.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:09:30.704+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:09:30.703+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:09:30.705+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:09:30.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:10:01.069+0000] {processor.py:157} INFO - Started process (PID=14723) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:10:01.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:10:01.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:10:01.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:10:01.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:10:01.078+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:10:01.080+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:10:01.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.026 seconds
[2024-07-10T10:10:31.482+0000] {processor.py:157} INFO - Started process (PID=14743) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:10:31.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:10:31.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:10:31.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:10:31.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:10:31.491+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:10:31.493+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:10:31.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:11:01.876+0000] {processor.py:157} INFO - Started process (PID=14763) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:11:01.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:11:01.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:11:01.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:11:01.885+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:11:01.884+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:11:01.886+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:11:01.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:11:32.254+0000] {processor.py:157} INFO - Started process (PID=14783) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:11:32.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:11:32.257+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:11:32.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:11:32.265+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:11:32.263+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:11:32.265+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:11:32.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:12:02.610+0000] {processor.py:157} INFO - Started process (PID=14803) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:12:02.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:12:02.612+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:12:02.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:12:02.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:12:02.618+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:12:02.620+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:12:02.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:12:32.995+0000] {processor.py:157} INFO - Started process (PID=14823) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:12:32.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:12:32.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:12:32.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:12:33.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:12:33.004+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:12:33.005+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:12:33.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:13:03.416+0000] {processor.py:157} INFO - Started process (PID=14843) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:13:03.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:13:03.418+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:13:03.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:13:03.426+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:13:03.424+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:13:03.426+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:13:03.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:13:33.832+0000] {processor.py:157} INFO - Started process (PID=14863) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:13:33.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:13:33.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:13:33.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:13:33.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:13:33.840+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:13:33.842+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:13:33.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:14:04.268+0000] {processor.py:157} INFO - Started process (PID=14883) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:14:04.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:14:04.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:14:04.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:14:04.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:14:04.278+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:14:04.280+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:14:04.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.029 seconds
[2024-07-10T10:14:34.671+0000] {processor.py:157} INFO - Started process (PID=14903) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:14:34.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:14:34.673+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:14:34.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:14:34.681+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:14:34.680+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:14:34.682+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:14:34.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:15:05.042+0000] {processor.py:157} INFO - Started process (PID=14923) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:15:05.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:15:05.045+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:15:05.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:15:05.053+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:15:05.051+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:15:05.053+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:15:05.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T10:15:35.407+0000] {processor.py:157} INFO - Started process (PID=14943) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:15:35.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:15:35.409+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:15:35.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:15:35.416+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:15:35.414+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:15:35.416+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:15:35.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:16:05.803+0000] {processor.py:157} INFO - Started process (PID=14963) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:16:05.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:16:05.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:16:05.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:16:05.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:16:05.812+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:16:05.814+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:16:05.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:16:36.151+0000] {processor.py:157} INFO - Started process (PID=14983) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:16:36.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:16:36.153+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:16:36.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:16:36.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:16:36.158+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:16:36.160+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:16:36.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T10:17:06.550+0000] {processor.py:157} INFO - Started process (PID=15003) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:17:06.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:17:06.552+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:17:06.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:17:06.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:17:06.558+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:17:06.560+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:17:06.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:17:36.941+0000] {processor.py:157} INFO - Started process (PID=15023) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:17:36.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:17:36.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:17:36.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:17:36.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:17:36.949+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:17:36.952+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:17:36.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:18:07.317+0000] {processor.py:157} INFO - Started process (PID=15043) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:18:07.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:18:07.319+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:18:07.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:18:07.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:18:07.325+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:18:07.327+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:18:07.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:18:37.709+0000] {processor.py:157} INFO - Started process (PID=15063) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:18:37.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:18:37.711+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:18:37.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:18:37.718+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:18:37.716+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:18:37.718+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:18:37.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T10:19:08.115+0000] {processor.py:157} INFO - Started process (PID=15083) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:19:08.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:19:08.117+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:19:08.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:19:08.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:19:08.123+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:19:08.125+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:19:08.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:19:38.534+0000] {processor.py:157} INFO - Started process (PID=15103) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:19:38.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:19:38.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:19:38.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:19:38.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:19:38.542+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:19:38.544+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:19:38.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:20:08.924+0000] {processor.py:157} INFO - Started process (PID=15123) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:20:08.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:20:08.927+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:20:08.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:20:08.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:20:08.933+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:20:08.934+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:20:08.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:20:39.323+0000] {processor.py:157} INFO - Started process (PID=15143) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:20:39.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:20:39.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:20:39.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:20:39.334+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:20:39.332+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:20:39.334+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:20:39.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T10:21:09.748+0000] {processor.py:157} INFO - Started process (PID=15163) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:21:09.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:21:09.750+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:21:09.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:21:09.757+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:21:09.756+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:21:09.758+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:21:09.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:21:40.154+0000] {processor.py:157} INFO - Started process (PID=15183) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:21:40.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:21:40.156+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:21:40.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:21:40.164+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:21:40.162+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:21:40.164+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:21:40.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:22:10.512+0000] {processor.py:157} INFO - Started process (PID=15203) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:22:10.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:22:10.514+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:22:10.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:22:10.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:22:10.520+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:22:10.521+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:22:10.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T10:22:40.882+0000] {processor.py:157} INFO - Started process (PID=15223) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:22:40.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:22:40.884+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:22:40.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:22:40.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:22:40.891+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:22:40.893+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:22:40.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T10:23:11.257+0000] {processor.py:157} INFO - Started process (PID=15243) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:23:11.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:23:11.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:23:11.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:23:11.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:23:11.265+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:23:11.266+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:23:11.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:23:41.615+0000] {processor.py:157} INFO - Started process (PID=15263) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:23:41.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:23:41.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:23:41.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:23:41.625+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:23:41.623+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:23:41.625+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:23:41.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:24:11.987+0000] {processor.py:157} INFO - Started process (PID=15283) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:24:11.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:24:11.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:24:11.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:24:11.998+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:24:11.996+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:24:11.998+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:24:12.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T10:24:42.328+0000] {processor.py:157} INFO - Started process (PID=15303) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:24:42.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:24:42.330+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:24:42.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:24:42.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:24:42.335+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:24:42.336+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:24:42.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T10:25:12.708+0000] {processor.py:157} INFO - Started process (PID=15323) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:25:12.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:25:12.712+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:25:12.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:25:12.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:25:12.729+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:25:12.734+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:25:12.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T10:25:43.075+0000] {processor.py:157} INFO - Started process (PID=15343) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:25:43.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:25:43.078+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:25:43.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:25:43.087+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:25:43.086+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:25:43.088+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:25:43.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.030 seconds
[2024-07-10T10:26:13.410+0000] {processor.py:157} INFO - Started process (PID=15363) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:26:13.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:26:13.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:26:13.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:26:13.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:26:13.421+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:26:13.424+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:26:13.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.031 seconds
[2024-07-10T10:26:43.738+0000] {processor.py:157} INFO - Started process (PID=15383) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:26:43.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:26:43.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:26:43.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:26:43.752+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:26:43.750+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:26:43.752+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:26:43.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.031 seconds
[2024-07-10T10:27:14.076+0000] {processor.py:157} INFO - Started process (PID=15403) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:27:14.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:27:14.079+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:27:14.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:27:14.087+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:27:14.085+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:27:14.087+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:27:14.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T10:27:44.431+0000] {processor.py:157} INFO - Started process (PID=15423) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:27:44.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:27:44.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:27:44.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:27:44.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:27:44.440+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:27:44.442+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:27:44.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T10:28:14.760+0000] {processor.py:157} INFO - Started process (PID=15443) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:28:14.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:28:14.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:28:14.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:28:14.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:28:14.769+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:28:14.771+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:28:14.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.025 seconds
[2024-07-10T10:28:45.113+0000] {processor.py:157} INFO - Started process (PID=15463) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:28:45.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:28:45.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:28:45.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:28:45.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:28:45.121+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:28:45.123+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:28:45.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:29:15.514+0000] {processor.py:157} INFO - Started process (PID=15483) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:29:15.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:29:15.516+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:29:15.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:29:15.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:29:15.522+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:29:15.524+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:29:15.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.021 seconds
[2024-07-10T10:29:45.904+0000] {processor.py:157} INFO - Started process (PID=15503) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:29:45.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:29:45.906+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:29:45.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:29:45.914+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:29:45.912+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:29:45.914+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:29:45.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.022 seconds
[2024-07-10T10:30:16.306+0000] {processor.py:157} INFO - Started process (PID=15523) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:30:16.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:30:16.311+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:30:16.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:30:16.335+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:30:16.331+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:30:16.335+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:30:16.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T10:30:46.730+0000] {processor.py:157} INFO - Started process (PID=15543) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:30:46.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:30:46.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:30:46.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:30:46.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:30:46.750+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:30:46.753+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:30:46.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T10:31:17.129+0000] {processor.py:157} INFO - Started process (PID=15563) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:31:17.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:31:17.132+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:31:17.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:31:17.141+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:31:17.139+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:31:17.141+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:31:17.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.031 seconds
[2024-07-10T10:31:47.500+0000] {processor.py:157} INFO - Started process (PID=15583) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:31:47.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:31:47.505+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:31:47.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:31:47.515+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:31:47.513+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:31:47.515+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:31:47.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.032 seconds
[2024-07-10T10:32:17.908+0000] {processor.py:157} INFO - Started process (PID=15603) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:32:17.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:32:17.914+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:32:17.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:32:17.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:32:17.932+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:32:17.935+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:32:17.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T10:32:48.352+0000] {processor.py:157} INFO - Started process (PID=15623) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:32:48.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:32:48.355+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:32:48.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:32:48.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:32:48.363+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:32:48.365+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:32:48.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.031 seconds
[2024-07-10T10:33:18.738+0000] {processor.py:157} INFO - Started process (PID=15643) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:33:18.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:33:18.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:33:18.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:33:18.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:33:18.749+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:33:18.752+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:33:18.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.029 seconds
[2024-07-10T10:33:49.152+0000] {processor.py:157} INFO - Started process (PID=15663) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:33:49.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:33:49.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:33:49.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:33:49.171+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:33:49.169+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:33:49.172+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:33:49.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.039 seconds
[2024-07-10T10:34:11.171+0000] {processor.py:157} INFO - Started process (PID=194) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:34:11.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:34:11.172+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:34:11.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:34:11.178+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:34:11.177+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:34:11.178+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:34:11.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.018 seconds
[2024-07-10T10:34:41.647+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:34:41.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:34:41.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:34:41.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:34:41.658+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:34:41.656+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:34:41.658+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:34:41.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.023 seconds
[2024-07-10T10:35:12.085+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:35:12.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:35:12.087+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:35:12.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:35:12.094+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:35:12.093+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:35:12.094+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:35:12.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.019 seconds
[2024-07-10T10:35:42.484+0000] {processor.py:157} INFO - Started process (PID=254) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:35:42.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:35:42.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:35:42.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:35:42.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:35:42.491+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:35:42.493+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:35:42.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.024 seconds
[2024-07-10T10:36:12.870+0000] {processor.py:157} INFO - Started process (PID=276) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:12.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:36:12.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:12.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:12.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:12.878+0000] {dagbag.py:446} ERROR - Failed to bag_dag: /opt/airflow/dags/data-pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 88, in validate
    croniter(self._expression)
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 183, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(expr_format, hash_id=hash_id)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 807, in expand
    return cls._expand(expr_format, hash_id=hash_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/croniter/croniter.py", line 770, in _expand
    raise CroniterBadCronError(
croniter.croniter.CroniterBadCronError: [0 30 * * *] is not acceptable, out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    dag.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 711, in validate
    self.timetable.validate()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/timetables/_cron.py", line 90, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [0 30 * * *] is not acceptable, out of range
[2024-07-10T10:36:12.879+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:12.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.020 seconds
[2024-07-10T10:36:17.922+0000] {processor.py:157} INFO - Started process (PID=281) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:17.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:36:17.925+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:17.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:17.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:18.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:18.005+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-10T10:36:18.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:18.009+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-10T10:36:18.012+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:18.012+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-10T10:36:18.012+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:18.012+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:github-archive-pipeline' as access control is unset.
[2024-07-10T10:36:18.013+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:18.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:36:18.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:18.017+0000] {dag.py:2937} INFO - Creating ORM DAG for github-archive-pipeline
[2024-07-10T10:36:18.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:18.022+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:36:18.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.110 seconds
[2024-07-10T10:36:48.286+0000] {processor.py:157} INFO - Started process (PID=306) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:48.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:36:48.289+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:48.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:48.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:36:48.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:48.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:36:48.325+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:48.325+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:36:48.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T10:37:18.775+0000] {processor.py:157} INFO - Started process (PID=326) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:37:18.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:37:18.780+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:18.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:37:18.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:37:18.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:18.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:37:18.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:18.842+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:37:18.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.082 seconds
[2024-07-10T10:37:49.107+0000] {processor.py:157} INFO - Started process (PID=346) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:37:49.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:37:49.110+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:49.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:37:49.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:37:49.142+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:49.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:37:49.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:49.155+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:37:49.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T10:38:19.517+0000] {processor.py:157} INFO - Started process (PID=366) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:38:19.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:38:19.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:19.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:38:19.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:38:19.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:19.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:38:19.567+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:19.566+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:38:19.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.062 seconds
[2024-07-10T10:38:49.880+0000] {processor.py:157} INFO - Started process (PID=386) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:38:49.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:38:49.883+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:49.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:38:49.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:38:49.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:49.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:38:49.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:49.920+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:38:49.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T10:39:20.205+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:39:20.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:39:20.208+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:20.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:39:20.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:39:20.238+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:20.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:39:20.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:20.249+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:39:20.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T10:39:50.599+0000] {processor.py:157} INFO - Started process (PID=426) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:39:50.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:39:50.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:50.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:39:50.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:39:50.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:50.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:39:50.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:50.638+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:39:50.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T10:40:20.995+0000] {processor.py:157} INFO - Started process (PID=446) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:40:20.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:40:20.998+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:20.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:40:21.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:40:21.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:21.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:40:21.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:21.043+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:40:21.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T10:40:51.388+0000] {processor.py:157} INFO - Started process (PID=466) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:40:51.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:40:51.392+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:51.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:40:51.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:40:51.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:51.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:40:51.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:51.443+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:40:51.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.066 seconds
[2024-07-10T10:41:21.774+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:41:21.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:41:21.781+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:21.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:41:21.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:41:21.812+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:21.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:41:21.824+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:21.824+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:41:21.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T10:41:52.149+0000] {processor.py:157} INFO - Started process (PID=506) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:41:52.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:41:52.152+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:52.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:41:52.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:41:52.179+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:52.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:41:52.191+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:52.190+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:41:52.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T10:42:22.484+0000] {processor.py:157} INFO - Started process (PID=526) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:42:22.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:42:22.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:22.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:42:22.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:42:22.509+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:22.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:42:22.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:22.520+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:42:22.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T10:42:52.855+0000] {processor.py:157} INFO - Started process (PID=546) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:42:52.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:42:52.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:52.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:42:52.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:42:52.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:52.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:42:52.900+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:52.900+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:42:52.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T10:43:23.229+0000] {processor.py:157} INFO - Started process (PID=566) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:43:23.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:43:23.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:23.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:43:23.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:43:23.265+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:23.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:43:23.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:23.277+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:43:23.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T10:43:53.628+0000] {processor.py:157} INFO - Started process (PID=586) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:43:53.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:43:53.630+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:53.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:43:53.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:43:53.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:53.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:43:53.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:53.655+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:43:53.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.036 seconds
[2024-07-10T10:44:24.028+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:44:24.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:44:24.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:24.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:44:24.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:44:24.060+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:24.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:44:24.069+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:24.069+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:44:24.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T10:44:54.434+0000] {processor.py:157} INFO - Started process (PID=626) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:44:54.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:44:54.437+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:54.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:44:54.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:44:54.461+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:54.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:44:54.470+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:54.470+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:44:54.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T10:45:24.866+0000] {processor.py:157} INFO - Started process (PID=646) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:45:24.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:45:24.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:24.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:45:24.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:45:24.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:24.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:45:24.907+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:24.907+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:45:24.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T10:45:55.221+0000] {processor.py:157} INFO - Started process (PID=666) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:45:55.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:45:55.226+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:55.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:45:55.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:45:55.251+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:55.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:45:55.261+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:55.261+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:45:55.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T10:46:25.635+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:46:25.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:46:25.639+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:25.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:46:25.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:46:25.667+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:25.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:46:25.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:25.677+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:46:25.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T10:46:56.036+0000] {processor.py:157} INFO - Started process (PID=706) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:46:56.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:46:56.039+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:56.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:46:56.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:46:56.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:56.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:46:56.075+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:56.075+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:46:56.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T10:47:26.449+0000] {processor.py:157} INFO - Started process (PID=726) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:47:26.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:47:26.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:26.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:47:26.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:47:26.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:26.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:47:26.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:26.490+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:47:26.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T10:47:56.832+0000] {processor.py:157} INFO - Started process (PID=746) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:47:56.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:47:56.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:56.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:47:56.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:47:56.865+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:56.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:47:56.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:56.874+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:47:56.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T10:48:27.203+0000] {processor.py:157} INFO - Started process (PID=766) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:48:27.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:48:27.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:27.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:48:27.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:48:27.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:27.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:48:27.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:27.241+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:48:27.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T10:48:57.570+0000] {processor.py:157} INFO - Started process (PID=786) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:48:57.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:48:57.572+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:57.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:48:57.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:48:57.595+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:57.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:48:57.605+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:57.605+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:48:57.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T10:49:27.924+0000] {processor.py:157} INFO - Started process (PID=806) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:49:27.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:49:27.926+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:49:27.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:49:27.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:49:27.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:49:27.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:49:27.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:49:27.965+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:49:27.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T10:49:58.272+0000] {processor.py:157} INFO - Started process (PID=826) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:49:58.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:49:58.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:49:58.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:49:58.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:49:58.300+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:49:58.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:49:58.309+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:49:58.309+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:49:58.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T10:50:28.670+0000] {processor.py:157} INFO - Started process (PID=846) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:50:28.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:50:28.673+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:28.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:50:28.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:50:28.703+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:28.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:50:28.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:28.713+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:50:28.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T10:50:59.092+0000] {processor.py:157} INFO - Started process (PID=866) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:50:59.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:50:59.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:59.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:50:59.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:50:59.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:59.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:50:59.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:59.130+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:50:59.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T10:51:29.475+0000] {processor.py:157} INFO - Started process (PID=886) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:51:29.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:51:29.478+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:29.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:51:29.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:51:29.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:29.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:51:29.516+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:29.516+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:51:29.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T10:51:59.886+0000] {processor.py:157} INFO - Started process (PID=906) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:51:59.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:51:59.890+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:59.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:51:59.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:51:59.935+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:59.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:51:59.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:59.948+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:51:59.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.074 seconds
[2024-07-10T10:52:30.292+0000] {processor.py:157} INFO - Started process (PID=926) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:52:30.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:52:30.295+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:52:30.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:52:30.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:52:30.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:52:30.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:52:30.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:52:30.329+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:52:30.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T10:53:00.665+0000] {processor.py:157} INFO - Started process (PID=946) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:53:00.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:53:00.667+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:00.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:53:00.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:53:00.692+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:00.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:53:00.701+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:00.701+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:53:00.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T10:53:31.087+0000] {processor.py:157} INFO - Started process (PID=966) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:53:31.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:53:31.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:31.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:53:31.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:53:31.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:31.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:53:31.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:31.129+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:53:31.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T10:54:01.514+0000] {processor.py:157} INFO - Started process (PID=986) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:54:01.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:54:01.518+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:01.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:54:01.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:54:01.542+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:01.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:54:01.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:01.551+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:54:01.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T10:54:32.013+0000] {processor.py:157} INFO - Started process (PID=1006) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:54:32.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:54:32.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:32.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:54:32.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:54:32.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:32.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:54:32.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:32.057+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:54:32.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T10:55:02.410+0000] {processor.py:157} INFO - Started process (PID=1026) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:55:02.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:55:02.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:02.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:55:02.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:55:02.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:02.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:55:02.460+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:02.460+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:55:02.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.064 seconds
[2024-07-10T10:55:32.850+0000] {processor.py:157} INFO - Started process (PID=1046) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:55:32.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:55:32.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:32.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:55:32.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:55:32.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:32.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:55:32.890+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:32.890+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:55:32.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T10:56:03.239+0000] {processor.py:157} INFO - Started process (PID=1066) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:56:03.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:56:03.243+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:03.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:56:03.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:56:03.273+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:03.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:56:03.284+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:03.284+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:56:03.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T10:56:33.640+0000] {processor.py:157} INFO - Started process (PID=1086) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:56:33.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:56:33.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:33.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:56:33.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:56:33.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:33.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:56:33.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:33.680+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:56:33.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T10:57:04.028+0000] {processor.py:157} INFO - Started process (PID=1106) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:57:04.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:57:04.031+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:04.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:57:04.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:57:04.060+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:04.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:57:04.069+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:04.069+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:57:04.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T10:57:34.426+0000] {processor.py:157} INFO - Started process (PID=1131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:57:34.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:57:34.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:34.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:57:34.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:57:34.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:34.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:57:34.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:34.468+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:57:34.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T10:58:04.856+0000] {processor.py:157} INFO - Started process (PID=1151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:58:04.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:58:04.860+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:04.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:58:04.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:58:04.891+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:04.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:58:04.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:04.902+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:58:04.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T10:58:35.233+0000] {processor.py:157} INFO - Started process (PID=1176) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:58:35.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:58:35.236+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:35.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:58:35.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:58:35.262+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:35.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:58:35.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:35.272+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:58:35.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T10:59:05.719+0000] {processor.py:157} INFO - Started process (PID=1206) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:59:05.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:59:05.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:05.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:59:05.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:59:05.749+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:05.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:59:05.759+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:05.759+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:59:05.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T10:59:36.145+0000] {processor.py:157} INFO - Started process (PID=1226) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:59:36.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T10:59:36.149+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:36.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:59:36.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T10:59:36.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:36.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:59:36.187+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:36.186+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:59:36.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T11:00:06.544+0000] {processor.py:157} INFO - Started process (PID=1246) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:00:06.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:00:06.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:06.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:00:06.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:00:06.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:06.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:00:06.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:06.590+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:00:06.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T11:00:37.021+0000] {processor.py:157} INFO - Started process (PID=1266) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:00:37.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:00:37.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:37.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:00:37.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:00:37.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:37.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:00:37.068+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:37.068+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:00:37.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T11:01:07.389+0000] {processor.py:157} INFO - Started process (PID=1286) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:01:07.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:01:07.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:07.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:01:07.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:01:07.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:07.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:01:07.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:07.432+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:01:07.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T11:01:37.815+0000] {processor.py:157} INFO - Started process (PID=1306) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:01:37.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:01:37.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:37.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:01:37.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:01:37.845+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:37.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:01:37.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:37.854+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:01:37.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:02:08.242+0000] {processor.py:157} INFO - Started process (PID=1326) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:02:08.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:02:08.243+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:08.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:02:08.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:02:08.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:08.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:02:08.290+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:08.290+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:02:08.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T11:02:38.657+0000] {processor.py:157} INFO - Started process (PID=1346) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:02:38.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:02:38.659+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:38.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:02:38.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:02:38.695+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:38.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:02:38.704+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:38.704+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:02:38.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T11:03:09.076+0000] {processor.py:157} INFO - Started process (PID=1366) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:03:09.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:03:09.078+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:09.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:03:09.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:03:09.111+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:09.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:03:09.121+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:09.121+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:03:09.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T11:03:39.502+0000] {processor.py:157} INFO - Started process (PID=1386) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:03:39.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:03:39.504+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:39.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:03:39.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:03:39.538+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:39.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:03:39.549+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:39.549+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:03:39.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T11:04:09.948+0000] {processor.py:157} INFO - Started process (PID=1406) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:04:09.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:04:09.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:09.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:04:09.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:04:09.978+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:09.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:04:09.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:09.988+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:04:09.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T11:04:40.362+0000] {processor.py:157} INFO - Started process (PID=1426) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:04:40.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:04:40.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:40.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:04:40.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:04:40.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:40.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:04:40.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:40.399+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:04:40.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T11:05:10.781+0000] {processor.py:157} INFO - Started process (PID=1446) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:05:10.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:05:10.782+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:10.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:05:10.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:05:10.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:10.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:05:10.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:10.821+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:05:10.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T11:05:41.157+0000] {processor.py:157} INFO - Started process (PID=1466) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:05:41.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:05:41.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:41.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:05:41.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:05:41.187+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:41.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:05:41.197+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:41.197+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:05:41.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T11:06:11.562+0000] {processor.py:157} INFO - Started process (PID=1486) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:06:11.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:06:11.564+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:11.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:06:11.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:06:11.595+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:11.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:06:11.607+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:11.607+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:06:11.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T11:06:41.960+0000] {processor.py:157} INFO - Started process (PID=1506) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:06:41.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:06:41.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:41.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:06:41.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:06:41.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:41.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:06:42.002+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:42.002+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:06:42.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T11:07:12.377+0000] {processor.py:157} INFO - Started process (PID=1526) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:07:12.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:07:12.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:12.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:07:12.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:07:12.406+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:12.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:07:12.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:12.415+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:07:12.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T11:07:42.757+0000] {processor.py:157} INFO - Started process (PID=1546) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:07:42.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:07:42.760+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:42.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:07:42.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:07:42.797+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:42.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:07:42.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:42.813+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:07:42.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.074 seconds
[2024-07-10T11:08:13.158+0000] {processor.py:157} INFO - Started process (PID=1571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:08:13.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:08:13.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:13.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:08:13.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:08:13.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:13.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:08:13.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:13.198+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:08:13.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T11:08:43.552+0000] {processor.py:157} INFO - Started process (PID=1591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:08:43.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:08:43.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:43.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:08:43.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:08:43.579+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:43.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:08:43.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:43.588+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:08:43.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T11:09:13.998+0000] {processor.py:157} INFO - Started process (PID=1616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:09:13.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:09:14.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:14.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:09:14.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:09:14.031+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:14.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:09:14.042+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:14.042+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:09:14.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T11:09:44.389+0000] {processor.py:157} INFO - Started process (PID=1636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:09:44.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:09:44.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:44.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:09:44.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:09:44.420+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:44.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:09:44.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:44.429+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:09:44.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T11:10:14.853+0000] {processor.py:157} INFO - Started process (PID=1656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:10:14.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:10:14.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:14.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:10:14.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:10:14.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:14.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:10:14.882+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:14.882+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:10:14.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.037 seconds
[2024-07-10T11:10:45.277+0000] {processor.py:157} INFO - Started process (PID=1676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:10:45.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:10:45.278+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:45.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:10:45.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:10:45.308+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:45.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:10:45.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:45.319+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:10:45.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T11:11:13.561+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:11:13.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:11:13.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:13.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:11:13.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:11:13.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:13.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:11:13.600+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:13.600+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:11:13.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:11:44.010+0000] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:11:44.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:11:44.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:44.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:11:44.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:11:44.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:44.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:11:44.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:44.095+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:11:44.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.106 seconds
[2024-07-10T11:12:14.477+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:12:14.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:12:14.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:14.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:12:14.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:12:14.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:14.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:12:14.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:14.512+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:12:14.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T11:12:44.957+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:12:44.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:12:44.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:44.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:12:45.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:12:45.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:45.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:12:45.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:45.036+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:12:45.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.090 seconds
[2024-07-10T11:13:15.484+0000] {processor.py:157} INFO - Started process (PID=266) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:13:15.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:13:15.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:15.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:13:15.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:13:15.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:15.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:13:15.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:15.531+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:13:15.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T11:13:45.898+0000] {processor.py:157} INFO - Started process (PID=286) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:13:45.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:13:45.900+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:45.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:13:45.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:13:45.923+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:45.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:13:45.932+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:45.932+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:13:45.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T11:14:16.318+0000] {processor.py:157} INFO - Started process (PID=306) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:14:16.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:14:16.324+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:16.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:14:16.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:14:16.386+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:16.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:14:16.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:16.399+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:14:16.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.092 seconds
[2024-07-10T11:14:46.806+0000] {processor.py:157} INFO - Started process (PID=326) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:14:46.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:14:46.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:46.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:14:46.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:14:46.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:46.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:14:46.845+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:46.845+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:14:46.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:15:17.240+0000] {processor.py:157} INFO - Started process (PID=346) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:15:17.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:15:17.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:17.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:15:17.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:15:17.267+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:17.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:15:17.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:17.277+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:15:17.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T11:15:47.700+0000] {processor.py:157} INFO - Started process (PID=366) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:15:47.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:15:47.723+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:47.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:15:47.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:15:47.789+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:47.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:15:47.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:47.826+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:15:47.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.154 seconds
[2024-07-10T11:16:18.306+0000] {processor.py:157} INFO - Started process (PID=386) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:16:18.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:16:18.309+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:18.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:16:18.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:16:18.343+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:18.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:16:18.354+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:18.354+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:16:18.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T11:16:48.786+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:16:48.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:16:48.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:48.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:16:48.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:16:48.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:48.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:16:48.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:48.867+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:16:48.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.093 seconds
[2024-07-10T11:17:19.247+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:17:19.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:17:19.251+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:19.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:17:19.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:17:19.278+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:19.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:17:19.288+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:19.288+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:17:19.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T11:17:49.719+0000] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:17:49.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:17:49.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:49.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:17:49.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:17:49.754+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:49.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:17:49.765+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:49.765+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:17:49.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T11:18:20.111+0000] {processor.py:157} INFO - Started process (PID=471) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:18:20.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:18:20.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:20.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:18:20.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:18:20.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:20.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:18:20.145+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:20.144+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:18:20.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T11:18:50.517+0000] {processor.py:157} INFO - Started process (PID=491) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:18:50.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:18:50.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:50.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:18:50.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:18:50.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:50.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:18:50.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:50.557+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:18:50.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T11:19:20.922+0000] {processor.py:157} INFO - Started process (PID=511) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:19:20.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:19:20.928+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:20.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:19:20.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:19:20.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:20.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:19:20.979+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:20.979+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:19:20.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.069 seconds
[2024-07-10T11:19:51.347+0000] {processor.py:157} INFO - Started process (PID=531) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:19:51.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:19:51.350+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:51.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:19:51.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:19:51.374+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:51.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:19:51.384+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:51.384+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:19:51.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:20:21.772+0000] {processor.py:157} INFO - Started process (PID=551) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:20:21.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:20:21.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:21.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:20:21.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:20:21.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:21.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:20:21.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:21.808+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:20:21.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T11:20:52.190+0000] {processor.py:157} INFO - Started process (PID=571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:20:52.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:20:52.193+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:52.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:20:52.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:20:52.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:52.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:20:52.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:52.228+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:20:52.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:21:22.644+0000] {processor.py:157} INFO - Started process (PID=591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:21:22.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:21:22.647+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:22.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:21:22.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:21:22.672+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:22.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:21:22.682+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:22.682+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:21:22.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T11:21:53.058+0000] {processor.py:157} INFO - Started process (PID=611) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:21:53.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:21:53.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:53.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:21:53.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:21:53.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:53.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:21:53.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:53.102+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:21:53.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T11:22:23.460+0000] {processor.py:157} INFO - Started process (PID=631) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:22:23.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:22:23.463+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:23.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:22:23.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:22:23.553+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:23.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:22:23.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:23.570+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:22:23.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.123 seconds
[2024-07-10T11:22:53.869+0000] {processor.py:157} INFO - Started process (PID=651) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:22:53.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:22:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:53.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:22:53.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:22:53.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:53.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:22:53.915+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:53.915+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:22:53.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T11:23:24.257+0000] {processor.py:157} INFO - Started process (PID=671) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:23:24.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:23:24.261+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:24.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:23:24.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:23:24.310+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:24.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:23:24.326+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:24.326+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:23:24.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.082 seconds
[2024-07-10T11:23:54.754+0000] {processor.py:157} INFO - Started process (PID=691) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:23:54.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:23:54.765+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:54.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:23:54.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:23:54.900+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:54.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:23:54.926+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:54.926+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:23:54.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.201 seconds
[2024-07-10T11:24:25.360+0000] {processor.py:157} INFO - Started process (PID=711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:24:25.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:24:25.365+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:25.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:24:25.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:24:25.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:25.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:24:25.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:25.415+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:24:25.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.073 seconds
[2024-07-10T11:24:55.830+0000] {processor.py:157} INFO - Started process (PID=731) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:24:55.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:24:55.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:55.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:24:55.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:24:55.880+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:55.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:24:55.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:55.894+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:24:55.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.079 seconds
[2024-07-10T11:25:26.266+0000] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:25:26.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:25:26.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:26.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:25:26.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:25:26.304+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:26.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:25:26.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:26.317+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:25:26.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.063 seconds
[2024-07-10T11:25:56.679+0000] {processor.py:157} INFO - Started process (PID=771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:25:56.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:25:56.684+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:56.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:25:56.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:25:56.729+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:56.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:25:56.745+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:56.745+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:25:56.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.082 seconds
[2024-07-10T11:26:27.146+0000] {processor.py:157} INFO - Started process (PID=791) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:26:27.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:26:27.149+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:27.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:26:27.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:26:27.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:27.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:26:27.195+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:27.195+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:26:27.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T11:26:57.550+0000] {processor.py:157} INFO - Started process (PID=811) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:26:57.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:26:57.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:57.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:26:57.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:26:57.579+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:57.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:26:57.589+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:57.589+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:26:57.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T11:27:28.012+0000] {processor.py:157} INFO - Started process (PID=831) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:27:28.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:27:28.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:28.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:27:28.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:27:28.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:28.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:27:28.118+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:28.118+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:27:28.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.123 seconds
[2024-07-10T11:27:58.542+0000] {processor.py:157} INFO - Started process (PID=851) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:27:58.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:27:58.546+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:58.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:27:58.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:27:58.594+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:58.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:27:58.608+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:58.608+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:27:58.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.079 seconds
[2024-07-10T11:28:28.986+0000] {processor.py:157} INFO - Started process (PID=871) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:28:28.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:28:28.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:28.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:28:29.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:28:29.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:29.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:28:29.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:29.041+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:28:29.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.068 seconds
[2024-07-10T11:28:59.389+0000] {processor.py:157} INFO - Started process (PID=891) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:28:59.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:28:59.392+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:59.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:28:59.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:28:59.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:59.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:28:59.424+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:59.424+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:28:59.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T11:29:29.822+0000] {processor.py:157} INFO - Started process (PID=911) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:29:29.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:29:29.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:29.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:29:29.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:29:29.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:29.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:29:29.877+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:29.877+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:29:29.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.072 seconds
[2024-07-10T11:30:00.280+0000] {processor.py:157} INFO - Started process (PID=931) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:30:00.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:30:00.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:00.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:30:00.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:30:00.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:00.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:30:00.337+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:00.337+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:30:00.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.070 seconds
[2024-07-10T11:30:30.747+0000] {processor.py:157} INFO - Started process (PID=951) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:30:30.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:30:30.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:30.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:30:30.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:30:30.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:30.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:30:30.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:30.809+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:30:30.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.074 seconds
[2024-07-10T11:31:01.148+0000] {processor.py:157} INFO - Started process (PID=971) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:31:01.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:31:01.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:01.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:31:01.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:31:01.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:01.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:31:01.187+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:01.187+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:31:01.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T11:31:31.567+0000] {processor.py:157} INFO - Started process (PID=991) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:31:31.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:31:31.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:31.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:31:31.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:31:31.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:31.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:31:31.624+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:31.624+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:31:31.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.071 seconds
[2024-07-10T11:32:01.988+0000] {processor.py:157} INFO - Started process (PID=1011) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:32:01.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:32:01.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:01.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:32:02.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:32:02.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:02.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:32:02.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:02.029+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:32:02.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T11:32:32.385+0000] {processor.py:157} INFO - Started process (PID=1031) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:32:32.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:32:32.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:32.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:32:32.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:32:32.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:32.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:32:32.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:32.431+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:32:32.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T11:33:02.775+0000] {processor.py:157} INFO - Started process (PID=1051) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:33:02.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:33:02.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:02.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:33:02.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:33:02.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:02.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:33:02.812+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:02.812+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:33:02.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T11:33:33.191+0000] {processor.py:157} INFO - Started process (PID=1071) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:33:33.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:33:33.194+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:33.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:33:33.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:33:33.230+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:33.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:33:33.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:33.241+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:33:33.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.062 seconds
[2024-07-10T11:34:03.555+0000] {processor.py:157} INFO - Started process (PID=1091) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:34:03.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:34:03.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:03.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:34:03.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:34:03.587+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:03.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:34:03.600+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:03.599+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:34:03.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T11:34:33.943+0000] {processor.py:157} INFO - Started process (PID=1111) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:34:33.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:34:33.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:33.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:34:33.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:34:33.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:33.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:34:33.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:33.996+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:34:34.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.067 seconds
[2024-07-10T11:35:04.351+0000] {processor.py:157} INFO - Started process (PID=1131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:35:04.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:35:04.354+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:04.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:35:04.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:35:04.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:04.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:35:04.389+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:04.389+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:35:04.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T11:35:34.739+0000] {processor.py:157} INFO - Started process (PID=1151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:35:34.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:35:34.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:34.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:35:34.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:35:34.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:34.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:35:34.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:34.786+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:35:34.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T11:36:05.153+0000] {processor.py:157} INFO - Started process (PID=1171) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:36:05.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:36:05.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:05.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:36:05.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:36:05.202+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:05.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:36:05.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:05.217+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:36:05.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.079 seconds
[2024-07-10T11:36:35.579+0000] {processor.py:157} INFO - Started process (PID=1191) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:36:35.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:36:35.582+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:35.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:36:35.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:36:35.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:35.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:36:35.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:35.622+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:36:35.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T11:37:05.998+0000] {processor.py:157} INFO - Started process (PID=1211) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:37:05.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:37:06.003+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:06.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:37:06.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:37:06.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:06.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:37:06.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:06.056+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:37:06.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.072 seconds
[2024-07-10T11:37:36.348+0000] {processor.py:157} INFO - Started process (PID=1231) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:37:36.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:37:36.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:36.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:37:36.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:37:36.383+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:36.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:37:36.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:36.399+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:37:36.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.064 seconds
[2024-07-10T11:38:06.789+0000] {processor.py:157} INFO - Started process (PID=1251) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:38:06.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:38:06.793+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:06.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:38:06.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:38:06.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:06.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:38:06.836+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:06.836+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:38:06.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T11:38:37.226+0000] {processor.py:157} INFO - Started process (PID=1271) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:38:37.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:38:37.230+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:37.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:38:37.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:38:37.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:37.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:38:37.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:37.270+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:38:37.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T11:39:07.646+0000] {processor.py:157} INFO - Started process (PID=1291) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:39:07.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:39:07.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:07.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:39:07.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:39:07.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:07.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:39:07.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:07.686+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:39:07.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T11:39:38.058+0000] {processor.py:157} INFO - Started process (PID=1311) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:39:38.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:39:38.061+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:38.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:39:38.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:39:38.092+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:38.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:39:38.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:38.104+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:39:38.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T11:40:08.482+0000] {processor.py:157} INFO - Started process (PID=1331) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:40:08.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:40:08.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:08.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:40:08.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:40:08.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:08.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:40:08.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:08.534+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:40:08.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.066 seconds
[2024-07-10T11:40:38.900+0000] {processor.py:157} INFO - Started process (PID=1351) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:40:38.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:40:38.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:38.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:40:38.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:40:38.926+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:38.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:40:38.936+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:38.936+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:40:38.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T11:41:09.266+0000] {processor.py:157} INFO - Started process (PID=1371) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:41:09.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:41:09.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:09.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:41:09.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:41:09.296+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:09.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:41:09.307+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:09.306+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:41:09.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T11:41:39.709+0000] {processor.py:157} INFO - Started process (PID=1391) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:41:39.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:41:39.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:39.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:41:39.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:41:39.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:39.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:41:39.765+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:39.765+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:41:39.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.069 seconds
[2024-07-10T11:42:10.130+0000] {processor.py:157} INFO - Started process (PID=1411) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:42:10.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:42:10.137+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:10.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:42:10.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:42:10.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:10.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:42:10.212+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:10.212+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:42:10.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.095 seconds
[2024-07-10T11:42:40.586+0000] {processor.py:157} INFO - Started process (PID=1431) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:42:40.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:42:40.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:40.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:42:40.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:42:40.618+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:40.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:42:40.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:40.628+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:42:40.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T11:43:10.959+0000] {processor.py:157} INFO - Started process (PID=1451) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:43:10.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:43:10.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:10.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:43:10.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:43:10.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:10.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:43:11.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:10.999+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:43:11.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T11:43:41.375+0000] {processor.py:157} INFO - Started process (PID=1471) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:43:41.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:43:41.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:41.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:43:41.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:43:41.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:41.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:43:41.417+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:41.417+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:43:41.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T11:44:11.802+0000] {processor.py:157} INFO - Started process (PID=1491) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:44:11.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:44:11.807+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:11.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:44:11.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:44:11.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:11.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:44:11.868+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:11.868+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:44:11.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.080 seconds
[2024-07-10T11:44:42.254+0000] {processor.py:157} INFO - Started process (PID=1511) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:44:42.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:44:42.257+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:42.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:44:42.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:44:42.283+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:42.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:44:42.293+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:42.292+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:44:42.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T11:45:12.657+0000] {processor.py:157} INFO - Started process (PID=1531) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:45:12.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:45:12.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:12.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:45:12.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:45:12.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:12.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:45:12.695+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:12.695+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:45:12.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:45:43.038+0000] {processor.py:157} INFO - Started process (PID=1551) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:45:43.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:45:43.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:43.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:45:43.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:45:43.065+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:43.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:45:43.075+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:43.075+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:45:43.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:46:13.441+0000] {processor.py:157} INFO - Started process (PID=1571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:46:13.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:46:13.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:13.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:46:13.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:46:13.477+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:13.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:46:13.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:13.489+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:46:13.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T11:46:43.827+0000] {processor.py:157} INFO - Started process (PID=1591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:46:43.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:46:43.831+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:43.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:46:43.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:46:43.863+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:43.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:46:43.876+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:43.875+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:46:43.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.062 seconds
[2024-07-10T11:47:14.227+0000] {processor.py:157} INFO - Started process (PID=1611) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:47:14.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:47:14.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:14.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:47:14.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:47:14.278+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:14.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:47:14.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:14.299+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:47:14.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.091 seconds
[2024-07-10T11:47:44.704+0000] {processor.py:157} INFO - Started process (PID=1631) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:47:44.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:47:44.709+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:44.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:47:44.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:47:44.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:44.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:47:44.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:44.753+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:47:44.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T11:48:15.115+0000] {processor.py:157} INFO - Started process (PID=1651) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:48:15.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:48:15.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:15.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:48:15.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:48:15.152+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:15.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:48:15.165+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:15.165+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:48:15.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T11:48:45.499+0000] {processor.py:157} INFO - Started process (PID=1671) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:48:45.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:48:45.504+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:45.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:48:45.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:48:45.537+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:45.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:48:45.550+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:45.550+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:48:45.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.063 seconds
[2024-07-10T11:49:15.881+0000] {processor.py:157} INFO - Started process (PID=1691) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:49:15.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:49:15.885+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:15.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:49:15.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:49:15.910+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:15.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:49:15.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:15.920+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:49:15.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T11:49:46.271+0000] {processor.py:157} INFO - Started process (PID=1711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:49:46.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:49:46.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:46.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:49:46.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:49:46.300+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:46.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:49:46.310+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:46.310+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:49:46.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T11:50:16.641+0000] {processor.py:157} INFO - Started process (PID=1731) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:50:16.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:50:16.644+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:16.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:50:16.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:50:16.668+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:16.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:50:16.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:16.677+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:50:16.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T11:50:47.038+0000] {processor.py:157} INFO - Started process (PID=1751) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:50:47.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:50:47.042+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:47.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:50:47.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:50:47.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:47.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:50:47.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:47.076+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:50:47.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:51:17.430+0000] {processor.py:157} INFO - Started process (PID=1771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:51:17.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:51:17.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:17.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:51:17.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:51:17.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:17.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:51:17.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:17.462+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:51:17.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T11:51:47.835+0000] {processor.py:157} INFO - Started process (PID=1791) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:51:47.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:51:47.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:47.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:51:47.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:51:47.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:47.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:51:47.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:47.874+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:51:47.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T11:52:18.208+0000] {processor.py:157} INFO - Started process (PID=1811) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:52:18.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:52:18.210+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:18.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:52:18.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:52:18.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:18.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:52:18.245+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:18.245+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:52:18.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T11:52:48.584+0000] {processor.py:157} INFO - Started process (PID=1831) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:52:48.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:52:48.587+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:48.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:52:48.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:52:48.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:48.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:52:48.620+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:48.620+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:52:48.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T11:53:18.947+0000] {processor.py:157} INFO - Started process (PID=1851) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:53:18.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:53:18.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:18.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:53:18.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:53:18.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:18.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:53:18.982+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:18.982+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:53:18.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T11:53:49.318+0000] {processor.py:157} INFO - Started process (PID=1871) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:53:49.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:53:49.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:49.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:53:49.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:53:49.343+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:49.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:53:49.353+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:49.352+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:53:49.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T11:54:19.736+0000] {processor.py:157} INFO - Started process (PID=1891) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:54:19.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:54:19.740+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:19.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:54:19.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:54:19.773+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:19.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:54:19.784+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:19.784+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:54:19.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T11:54:50.195+0000] {processor.py:157} INFO - Started process (PID=1911) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:54:50.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:54:50.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:50.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:54:50.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:54:50.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:50.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:54:50.234+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:50.234+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:54:50.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T11:55:20.575+0000] {processor.py:157} INFO - Started process (PID=1931) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:55:20.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:55:20.579+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:20.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:55:20.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:55:20.603+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:20.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:55:20.613+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:20.613+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:55:20.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:55:50.967+0000] {processor.py:157} INFO - Started process (PID=1951) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:55:50.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:55:50.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:50.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:55:50.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:55:51.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:51.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:55:51.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:51.017+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:55:51.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T11:56:21.381+0000] {processor.py:157} INFO - Started process (PID=1971) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:56:21.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:56:21.384+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:21.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:56:21.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:56:21.406+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:21.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:56:21.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:21.415+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:56:21.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T11:56:51.766+0000] {processor.py:157} INFO - Started process (PID=1991) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:56:51.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:56:51.770+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:51.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:56:51.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:56:51.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:51.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:56:51.807+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:51.807+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:56:51.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T11:57:22.168+0000] {processor.py:157} INFO - Started process (PID=2011) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:57:22.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:57:22.171+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:22.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:57:22.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:57:22.195+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:22.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:57:22.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:22.205+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:57:22.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T11:57:52.537+0000] {processor.py:157} INFO - Started process (PID=2031) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:57:52.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:57:52.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:52.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:57:52.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:57:52.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:52.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:57:52.575+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:52.575+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:57:52.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:58:22.970+0000] {processor.py:157} INFO - Started process (PID=2051) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:58:22.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:58:22.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:22.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:58:22.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:58:22.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:22.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:58:23.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:23.008+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:58:23.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:58:53.377+0000] {processor.py:157} INFO - Started process (PID=2071) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:58:53.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:58:53.380+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:53.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:58:53.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:58:53.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:53.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:58:53.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:53.415+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:58:53.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T11:59:23.790+0000] {processor.py:157} INFO - Started process (PID=2091) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:59:23.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:59:23.792+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:23.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:59:23.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:59:23.817+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:23.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:59:23.827+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:23.827+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:59:23.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T11:59:54.229+0000] {processor.py:157} INFO - Started process (PID=2111) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:59:54.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T11:59:54.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:54.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:59:54.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T11:59:54.256+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:54.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:59:54.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:54.265+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:59:54.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:00:24.611+0000] {processor.py:157} INFO - Started process (PID=2131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:00:24.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:00:24.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:24.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:00:24.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:00:24.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:24.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:00:24.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:24.648+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:00:24.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:00:54.976+0000] {processor.py:157} INFO - Started process (PID=2151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:00:54.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:00:54.979+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:54.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:00:54.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:00:55.003+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:55.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:00:55.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:55.013+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:00:55.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:01:25.450+0000] {processor.py:157} INFO - Started process (PID=2171) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:01:25.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:01:25.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:25.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:01:25.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:01:25.478+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:25.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:01:25.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:25.487+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:01:25.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:01:55.960+0000] {processor.py:157} INFO - Started process (PID=2191) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:01:55.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:01:55.964+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:55.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:01:55.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:01:55.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:55.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:01:55.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:55.997+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:01:56.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:02:26.406+0000] {processor.py:157} INFO - Started process (PID=2211) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:02:26.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:02:26.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:26.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:02:26.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:02:26.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:26.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:02:26.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:26.443+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:02:26.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:02:56.914+0000] {processor.py:157} INFO - Started process (PID=2231) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:02:56.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:02:56.918+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:56.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:02:56.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:02:56.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:56.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:02:56.957+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:56.957+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:02:56.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T12:03:27.333+0000] {processor.py:157} INFO - Started process (PID=2251) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:03:27.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:03:27.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:27.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:03:27.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:03:27.361+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:27.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:03:27.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:27.371+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:03:27.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:03:57.775+0000] {processor.py:157} INFO - Started process (PID=2271) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:03:57.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:03:57.777+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:57.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:03:57.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:03:57.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:57.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:03:57.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:57.808+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:03:57.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T12:04:28.223+0000] {processor.py:157} INFO - Started process (PID=2291) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:04:28.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:04:28.226+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:28.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:04:28.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:04:28.253+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:28.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:04:28.263+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:28.263+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:04:28.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T12:04:58.664+0000] {processor.py:157} INFO - Started process (PID=2311) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:04:58.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:04:58.667+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:58.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:04:58.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:04:58.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:58.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:04:58.705+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:58.704+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:04:58.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T12:05:29.090+0000] {processor.py:157} INFO - Started process (PID=2331) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:05:29.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:05:29.093+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:29.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:05:29.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:05:29.118+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:29.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:05:29.128+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:29.128+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:05:29.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:05:59.509+0000] {processor.py:157} INFO - Started process (PID=2351) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:05:59.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:05:59.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:59.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:05:59.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:05:59.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:59.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:05:59.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:59.547+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:05:59.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:06:29.906+0000] {processor.py:157} INFO - Started process (PID=2371) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:06:29.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:06:29.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:29.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:06:29.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:06:29.936+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:29.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:06:29.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:29.945+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:06:29.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T12:07:00.325+0000] {processor.py:157} INFO - Started process (PID=2391) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:07:00.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:07:00.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:00.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:07:00.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:07:00.368+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:00.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:07:00.380+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:00.380+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:07:00.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.067 seconds
[2024-07-10T12:07:30.777+0000] {processor.py:157} INFO - Started process (PID=2411) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:07:30.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:07:30.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:30.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:07:30.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:07:30.804+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:30.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:07:30.814+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:30.814+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:07:30.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:08:01.183+0000] {processor.py:157} INFO - Started process (PID=2431) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:08:01.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:08:01.185+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:01.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:08:01.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:08:01.212+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:01.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:08:01.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:01.221+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:08:01.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:08:31.610+0000] {processor.py:157} INFO - Started process (PID=2451) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:08:31.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:08:31.612+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:31.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:08:31.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:08:31.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:31.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:08:31.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:31.649+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:08:31.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:09:01.984+0000] {processor.py:157} INFO - Started process (PID=2471) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:09:01.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:09:01.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:01.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:09:02.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:09:02.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:02.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:09:02.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:02.024+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:09:02.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:09:32.399+0000] {processor.py:157} INFO - Started process (PID=2491) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:09:32.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:09:32.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:32.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:09:32.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:09:32.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:32.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:09:32.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:32.442+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:09:32.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T12:10:02.830+0000] {processor.py:157} INFO - Started process (PID=2511) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:10:02.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:10:02.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:02.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:10:02.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:10:02.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:02.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:10:02.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:02.873+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:10:02.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T12:10:33.270+0000] {processor.py:157} INFO - Started process (PID=2531) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:10:33.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:10:33.273+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:33.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:10:33.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:10:33.304+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:33.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:10:33.315+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:33.315+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:10:33.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T12:11:03.678+0000] {processor.py:157} INFO - Started process (PID=2551) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:11:03.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:11:03.681+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:03.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:11:03.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:11:03.706+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:03.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:11:03.715+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:03.715+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:11:03.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:11:34.120+0000] {processor.py:157} INFO - Started process (PID=2571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:11:34.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:11:34.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:34.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:11:34.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:11:34.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:34.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:11:34.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:34.155+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:11:34.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T12:12:04.482+0000] {processor.py:157} INFO - Started process (PID=2591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:12:04.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:12:04.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:04.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:12:04.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:12:04.511+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:04.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:12:04.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:04.522+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:12:04.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T12:12:34.935+0000] {processor.py:157} INFO - Started process (PID=2611) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:12:34.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:12:34.939+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:34.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:12:34.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:12:34.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:34.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:12:35.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:35.014+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:12:35.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.092 seconds
[2024-07-10T12:13:05.462+0000] {processor.py:157} INFO - Started process (PID=2631) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:13:05.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:13:05.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:05.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:13:05.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:13:05.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:05.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:13:05.535+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:05.535+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:13:05.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.092 seconds
[2024-07-10T12:13:35.911+0000] {processor.py:157} INFO - Started process (PID=2651) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:13:35.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:13:35.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:35.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:13:35.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:13:35.937+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:35.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:13:35.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:35.948+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:13:35.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:14:06.317+0000] {processor.py:157} INFO - Started process (PID=2671) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:14:06.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:14:06.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:06.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:14:06.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:14:06.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:06.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:14:06.378+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:06.378+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:14:06.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.074 seconds
[2024-07-10T12:14:36.732+0000] {processor.py:157} INFO - Started process (PID=2691) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:14:36.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:14:36.735+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:36.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:14:36.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:14:36.761+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:36.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:14:36.772+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:36.772+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:14:36.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T12:15:07.031+0000] {processor.py:157} INFO - Started process (PID=2711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:15:07.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:15:07.034+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:07.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:15:07.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:15:07.063+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:07.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:15:07.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:07.074+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:15:07.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T12:15:37.359+0000] {processor.py:157} INFO - Started process (PID=2731) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:15:37.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:15:37.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:37.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:15:37.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:15:37.392+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:37.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:15:37.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:37.404+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:15:37.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T12:16:07.782+0000] {processor.py:157} INFO - Started process (PID=2751) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:16:07.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:16:07.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:07.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:16:07.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:16:07.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:07.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:16:07.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:07.835+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:16:07.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.066 seconds
[2024-07-10T12:16:38.150+0000] {processor.py:157} INFO - Started process (PID=2771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:16:38.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:16:38.152+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:38.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:16:38.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:16:38.172+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:38.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:16:38.182+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:38.182+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:16:38.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T12:17:08.561+0000] {processor.py:157} INFO - Started process (PID=2791) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:17:08.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:17:08.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:08.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:17:08.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:17:08.600+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:08.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:17:08.618+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:08.618+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:17:08.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.075 seconds
[2024-07-10T12:17:38.989+0000] {processor.py:157} INFO - Started process (PID=2811) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:17:38.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:17:38.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:38.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:17:39.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:17:39.013+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:39.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:17:39.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:39.025+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:17:39.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:18:09.399+0000] {processor.py:157} INFO - Started process (PID=2831) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:18:09.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:18:09.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:09.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:18:09.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:18:09.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:09.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:18:09.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:09.454+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:18:09.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.069 seconds
[2024-07-10T12:18:39.802+0000] {processor.py:157} INFO - Started process (PID=2851) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:18:39.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:18:39.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:39.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:18:39.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:18:39.838+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:39.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:18:39.851+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:39.851+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:18:39.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.063 seconds
[2024-07-10T12:19:10.185+0000] {processor.py:157} INFO - Started process (PID=2871) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:19:10.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:19:10.187+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:10.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:19:10.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:19:10.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:10.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:19:10.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:10.230+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:19:10.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T12:19:40.609+0000] {processor.py:157} INFO - Started process (PID=2891) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:19:40.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:19:40.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:40.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:19:40.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:19:40.659+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:40.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:19:40.672+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:40.672+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:19:40.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.077 seconds
[2024-07-10T12:20:11.062+0000] {processor.py:157} INFO - Started process (PID=2911) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:20:11.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:20:11.064+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:11.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:20:11.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:20:11.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:11.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:20:11.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:11.099+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:20:11.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:20:41.436+0000] {processor.py:157} INFO - Started process (PID=2931) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:20:41.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:20:41.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:41.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:20:41.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:20:41.464+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:41.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:20:41.474+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:41.474+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:20:41.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:21:11.835+0000] {processor.py:157} INFO - Started process (PID=2951) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:21:11.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:21:11.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:11.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:21:11.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:21:11.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:11.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:21:11.875+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:11.875+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:21:11.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T12:21:42.334+0000] {processor.py:157} INFO - Started process (PID=2971) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:21:42.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:21:42.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:42.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:21:42.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:21:42.383+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:42.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:21:42.396+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:42.396+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:21:42.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.076 seconds
[2024-07-10T12:22:12.793+0000] {processor.py:157} INFO - Started process (PID=2991) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:22:12.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:22:12.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:12.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:22:12.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:22:12.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:12.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:22:12.885+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:12.885+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:22:12.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.110 seconds
[2024-07-10T12:22:43.289+0000] {processor.py:157} INFO - Started process (PID=3011) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:22:43.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:22:43.293+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:43.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:22:43.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:22:43.323+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:43.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:22:43.333+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:43.333+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:22:43.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T12:23:13.671+0000] {processor.py:157} INFO - Started process (PID=3031) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:23:13.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:23:13.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:13.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:23:13.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:23:13.707+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:13.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:23:13.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:13.719+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:23:13.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T12:23:44.053+0000] {processor.py:157} INFO - Started process (PID=3051) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:23:44.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:23:44.055+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:44.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:23:44.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:23:44.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:44.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:23:44.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:44.090+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:23:44.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:24:14.468+0000] {processor.py:157} INFO - Started process (PID=3071) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:24:14.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:24:14.473+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:14.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:24:14.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:24:14.511+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:14.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:24:14.525+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:14.525+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:24:14.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.071 seconds
[2024-07-10T12:24:44.930+0000] {processor.py:157} INFO - Started process (PID=3091) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:24:44.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:24:44.933+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:44.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:24:44.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:24:44.959+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:44.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:24:44.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:44.971+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:24:44.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T12:25:15.365+0000] {processor.py:157} INFO - Started process (PID=3111) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:25:15.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:25:15.368+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:15.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:25:15.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:25:15.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:15.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:25:15.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:15.404+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:25:15.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T12:25:45.803+0000] {processor.py:157} INFO - Started process (PID=3131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:25:45.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:25:45.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:45.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:25:45.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:25:45.830+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:45.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:25:45.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:45.839+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:25:45.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:26:16.232+0000] {processor.py:157} INFO - Started process (PID=3151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:26:16.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:26:16.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:16.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:26:16.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:26:16.260+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:16.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:26:16.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:16.270+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:26:16.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:26:46.666+0000] {processor.py:157} INFO - Started process (PID=3171) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:26:46.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:26:46.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:46.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:26:46.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:26:46.697+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:46.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:26:46.708+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:46.708+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:26:46.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T12:27:17.080+0000] {processor.py:157} INFO - Started process (PID=3191) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:27:17.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:27:17.083+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:17.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:27:17.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:27:17.108+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:17.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:27:17.118+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:17.118+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:27:17.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:27:47.486+0000] {processor.py:157} INFO - Started process (PID=3211) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:27:47.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:27:47.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:47.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:27:47.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:27:47.515+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:47.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:27:47.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:47.524+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:27:47.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:28:17.880+0000] {processor.py:157} INFO - Started process (PID=3231) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:28:17.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:28:17.886+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:17.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:28:17.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:28:17.932+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:17.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:28:17.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:17.962+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:28:17.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.103 seconds
[2024-07-10T12:28:48.348+0000] {processor.py:157} INFO - Started process (PID=3251) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:28:48.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:28:48.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:48.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:28:48.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:28:48.375+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:48.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:28:48.385+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:48.385+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:28:48.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:29:18.735+0000] {processor.py:157} INFO - Started process (PID=3271) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:29:18.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:29:18.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:18.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:29:18.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:29:18.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:18.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:29:18.772+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:18.772+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:29:18.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:29:49.166+0000] {processor.py:157} INFO - Started process (PID=3291) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:29:49.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:29:49.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:49.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:29:49.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:29:49.195+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:49.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:29:49.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:49.205+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:29:49.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T12:30:19.550+0000] {processor.py:157} INFO - Started process (PID=3311) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:30:19.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:30:19.553+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:19.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:30:19.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:30:19.579+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:19.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:30:19.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:19.588+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:30:19.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T12:30:49.970+0000] {processor.py:157} INFO - Started process (PID=3331) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:30:49.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:30:49.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:49.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:30:49.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:30:50.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:50.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:30:50.016+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:50.016+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:30:50.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T12:31:20.406+0000] {processor.py:157} INFO - Started process (PID=3351) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:31:20.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:31:20.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:20.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:31:20.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:31:20.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:20.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:31:20.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:20.438+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:31:20.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T12:31:50.776+0000] {processor.py:157} INFO - Started process (PID=3371) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:31:50.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:31:50.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:50.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:31:50.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:31:50.805+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:50.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:31:50.815+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:50.815+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:31:50.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:32:21.190+0000] {processor.py:157} INFO - Started process (PID=3391) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:32:21.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:32:21.193+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:21.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:32:21.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:32:21.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:21.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:32:21.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:21.235+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:32:21.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T12:32:51.632+0000] {processor.py:157} INFO - Started process (PID=3411) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:32:51.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:32:51.635+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:51.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:32:51.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:32:51.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:51.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:32:51.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:51.671+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:32:51.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:33:22.076+0000] {processor.py:157} INFO - Started process (PID=3431) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:33:22.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:33:22.079+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:22.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:33:22.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:33:22.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:22.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:33:22.115+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:22.114+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:33:22.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:33:52.440+0000] {processor.py:157} INFO - Started process (PID=3451) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:33:52.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:33:52.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:52.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:33:52.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:33:52.466+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:52.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:33:52.475+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:52.475+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:33:52.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T12:34:22.780+0000] {processor.py:157} INFO - Started process (PID=3471) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:34:22.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:34:22.784+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:22.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:34:22.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:34:22.815+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:22.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:34:22.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:22.826+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:34:22.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T12:34:53.177+0000] {processor.py:157} INFO - Started process (PID=3491) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:34:53.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:34:53.180+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:53.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:34:53.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:34:53.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:53.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:34:53.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:53.215+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:34:53.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T12:35:23.583+0000] {processor.py:157} INFO - Started process (PID=3511) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:35:23.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:35:23.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:23.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:35:23.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:35:23.611+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:23.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:35:23.621+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:23.621+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:35:23.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:35:53.948+0000] {processor.py:157} INFO - Started process (PID=3531) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:35:53.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:35:53.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:53.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:35:53.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:35:53.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:53.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:35:53.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:53.985+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:35:53.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:36:24.372+0000] {processor.py:157} INFO - Started process (PID=3551) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:36:24.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:36:24.374+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:24.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:36:24.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:36:24.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:24.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:36:24.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:24.407+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:36:24.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T12:36:54.745+0000] {processor.py:157} INFO - Started process (PID=3571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:36:54.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:36:54.748+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:54.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:36:54.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:36:54.772+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:54.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:36:54.782+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:54.782+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:36:54.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:37:25.133+0000] {processor.py:157} INFO - Started process (PID=3591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:37:25.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:37:25.136+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:25.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:37:25.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:37:25.161+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:25.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:37:25.171+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:25.171+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:37:25.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:37:55.525+0000] {processor.py:157} INFO - Started process (PID=3611) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:37:55.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:37:55.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:55.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:37:55.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:37:55.552+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:55.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:37:55.562+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:55.562+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:37:55.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:38:25.885+0000] {processor.py:157} INFO - Started process (PID=3631) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:38:25.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:38:25.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:25.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:38:25.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:38:25.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:25.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:38:25.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:25.921+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:38:25.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:38:56.284+0000] {processor.py:157} INFO - Started process (PID=3651) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:38:56.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:38:56.287+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:56.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:38:56.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:38:56.311+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:56.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:38:56.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:56.320+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:38:56.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:39:26.690+0000] {processor.py:157} INFO - Started process (PID=3671) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:39:26.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:39:26.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:26.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:39:26.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:39:26.718+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:26.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:39:26.727+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:26.727+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:39:26.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:39:57.069+0000] {processor.py:157} INFO - Started process (PID=3691) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:39:57.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:39:57.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:57.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:39:57.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:39:57.097+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:57.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:39:57.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:57.106+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:39:57.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:40:27.471+0000] {processor.py:157} INFO - Started process (PID=3711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:40:27.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:40:27.474+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:27.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:40:27.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:40:27.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:27.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:40:27.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:27.508+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:40:27.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:40:57.871+0000] {processor.py:157} INFO - Started process (PID=3731) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:40:57.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:40:57.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:57.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:40:57.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:40:57.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:57.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:40:57.908+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:57.907+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:40:57.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:41:28.249+0000] {processor.py:157} INFO - Started process (PID=3751) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:41:28.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:41:28.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:28.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:41:28.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:41:28.276+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:28.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:41:28.286+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:28.286+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:41:28.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:41:58.626+0000] {processor.py:157} INFO - Started process (PID=3771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:41:58.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:41:58.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:58.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:41:58.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:41:58.654+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:58.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:41:58.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:58.664+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:41:58.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:42:29.048+0000] {processor.py:157} INFO - Started process (PID=3791) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:42:29.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:42:29.050+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:29.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:42:29.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:42:29.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:29.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:42:29.083+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:29.083+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:42:29.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T12:42:59.533+0000] {processor.py:157} INFO - Started process (PID=3811) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:42:59.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:42:59.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:59.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:42:59.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:42:59.559+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:59.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:42:59.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:59.569+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:42:59.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T12:43:29.996+0000] {processor.py:157} INFO - Started process (PID=3831) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:43:29.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:43:29.998+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:29.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:43:30.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:43:30.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:30.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:43:30.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:30.031+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:43:30.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T12:44:00.476+0000] {processor.py:157} INFO - Started process (PID=3851) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:44:00.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:44:00.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:00.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:44:00.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:44:00.503+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:00.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:44:00.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:00.513+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:44:00.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:44:30.840+0000] {processor.py:157} INFO - Started process (PID=3871) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:44:30.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:44:30.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:30.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:44:30.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:44:30.863+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:30.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:44:30.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:30.872+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:44:30.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T12:45:01.209+0000] {processor.py:157} INFO - Started process (PID=3891) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:45:01.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:45:01.212+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:01.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:45:01.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:45:01.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:01.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:45:01.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:01.246+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:45:01.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:45:31.694+0000] {processor.py:157} INFO - Started process (PID=3911) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:45:31.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:45:31.698+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:31.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:45:31.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:45:31.723+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:31.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:45:31.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:31.732+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:45:31.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:46:02.089+0000] {processor.py:157} INFO - Started process (PID=3931) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:46:02.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:46:02.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:02.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:46:02.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:46:02.109+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:02.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:46:02.117+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:02.117+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:46:02.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.035 seconds
[2024-07-10T12:46:32.530+0000] {processor.py:157} INFO - Started process (PID=3951) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:46:32.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:46:32.532+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:32.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:46:32.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:46:32.555+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:32.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:46:32.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:32.565+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:46:32.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T12:47:03.011+0000] {processor.py:157} INFO - Started process (PID=3971) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:47:03.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:47:03.013+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:03.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:47:03.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:47:03.038+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:03.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:47:03.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:03.048+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:47:03.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:47:33.423+0000] {processor.py:157} INFO - Started process (PID=3991) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:47:33.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:47:33.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:33.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:47:33.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:47:33.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:33.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:47:33.458+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:33.458+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:47:33.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T12:48:03.926+0000] {processor.py:157} INFO - Started process (PID=4011) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:48:03.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:48:03.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:03.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:48:03.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:48:03.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:03.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:48:03.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:03.963+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:48:03.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:48:34.394+0000] {processor.py:157} INFO - Started process (PID=4031) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:48:34.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:48:34.396+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:34.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:48:34.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:48:34.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:34.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:48:34.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:34.431+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:48:34.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:49:04.928+0000] {processor.py:157} INFO - Started process (PID=4051) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:49:04.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:49:04.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:04.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:49:04.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:49:04.954+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:04.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:49:04.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:04.963+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:49:04.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T12:49:35.409+0000] {processor.py:157} INFO - Started process (PID=4071) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:49:35.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:49:35.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:35.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:49:35.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:49:35.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:35.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:49:35.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:35.454+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:49:35.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T12:50:05.826+0000] {processor.py:157} INFO - Started process (PID=4091) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:50:05.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:50:05.831+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:05.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:50:05.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:50:05.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:05.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:50:05.877+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:05.877+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:50:05.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.064 seconds
[2024-07-10T12:50:36.273+0000] {processor.py:157} INFO - Started process (PID=4111) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:50:36.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:50:36.276+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:36.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:50:36.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:50:36.300+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:36.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:50:36.310+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:36.310+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:50:36.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:51:06.678+0000] {processor.py:157} INFO - Started process (PID=4131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:51:06.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:51:06.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:06.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:51:06.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:51:06.698+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:06.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:51:06.706+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:06.706+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:51:06.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.037 seconds
[2024-07-10T12:51:37.102+0000] {processor.py:157} INFO - Started process (PID=4151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:51:37.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:51:37.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:37.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:51:37.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:51:37.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:37.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:51:37.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:37.139+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:51:37.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:52:07.485+0000] {processor.py:157} INFO - Started process (PID=4171) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:52:07.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:52:07.488+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:07.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:52:07.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:52:07.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:07.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:52:07.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:07.522+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:52:07.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:52:37.878+0000] {processor.py:157} INFO - Started process (PID=4191) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:52:37.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:52:37.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:37.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:52:37.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:52:37.906+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:37.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:52:37.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:37.916+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:52:37.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:53:08.241+0000] {processor.py:157} INFO - Started process (PID=4211) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:53:08.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:53:08.243+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:08.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:53:08.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:53:08.267+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:08.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:53:08.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:08.277+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:53:08.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:53:38.574+0000] {processor.py:157} INFO - Started process (PID=4231) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:53:38.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:53:38.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:38.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:53:38.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:53:38.603+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:38.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:53:38.612+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:38.612+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:53:38.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:54:08.988+0000] {processor.py:157} INFO - Started process (PID=4251) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:54:08.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:54:08.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:08.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:54:09.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:54:09.016+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:09.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:54:09.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:09.026+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:54:09.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:54:39.391+0000] {processor.py:157} INFO - Started process (PID=4271) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:54:39.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:54:39.395+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:39.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:54:39.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:54:39.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:39.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:54:39.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:39.429+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:54:39.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T12:55:09.854+0000] {processor.py:157} INFO - Started process (PID=4291) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:55:09.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:55:09.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:09.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:55:09.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:55:09.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:09.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:55:09.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:09.911+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:55:09.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.069 seconds
[2024-07-10T12:55:40.282+0000] {processor.py:157} INFO - Started process (PID=4311) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:55:40.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:55:40.286+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:40.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:55:40.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:55:40.311+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:40.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:55:40.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:40.321+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:55:40.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T12:56:10.636+0000] {processor.py:157} INFO - Started process (PID=4331) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:56:10.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:56:10.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:10.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:56:10.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:56:10.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:10.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:56:10.672+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:10.672+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:56:10.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:56:41.038+0000] {processor.py:157} INFO - Started process (PID=4351) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:56:41.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:56:41.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:41.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:56:41.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:56:41.065+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:41.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:56:41.075+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:41.075+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:56:41.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:57:11.447+0000] {processor.py:157} INFO - Started process (PID=4371) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:57:11.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:57:11.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:11.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:57:11.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:57:11.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:11.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:57:11.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:11.485+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:57:11.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:57:41.827+0000] {processor.py:157} INFO - Started process (PID=4391) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:57:41.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:57:41.831+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:41.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:57:41.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:57:41.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:41.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:57:41.868+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:41.868+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:57:41.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T12:58:12.254+0000] {processor.py:157} INFO - Started process (PID=4411) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:58:12.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:58:12.258+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:12.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:58:12.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:58:12.282+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:12.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:58:12.292+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:12.292+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:58:12.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T12:58:42.658+0000] {processor.py:157} INFO - Started process (PID=4431) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:58:42.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:58:42.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:42.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:58:42.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:58:42.684+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:42.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:58:42.694+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:42.694+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:58:42.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T12:59:13.053+0000] {processor.py:157} INFO - Started process (PID=4451) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:59:13.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:59:13.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:13.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:59:13.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:59:13.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:13.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:59:13.090+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:13.090+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:59:13.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T12:59:43.439+0000] {processor.py:157} INFO - Started process (PID=4471) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:59:43.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T12:59:43.444+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:43.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:59:43.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T12:59:43.475+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:43.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:59:43.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:43.487+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:59:43.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T13:00:13.810+0000] {processor.py:157} INFO - Started process (PID=4491) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:00:13.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:00:13.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:13.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:00:13.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:00:13.838+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:13.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:00:13.848+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:13.848+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:00:13.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:00:44.225+0000] {processor.py:157} INFO - Started process (PID=4511) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:00:44.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:00:44.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:44.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:00:44.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:00:44.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:44.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:00:44.264+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:44.264+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:00:44.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:01:14.604+0000] {processor.py:157} INFO - Started process (PID=4531) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:01:14.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:01:14.607+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:14.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:01:14.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:01:14.630+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:14.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:01:14.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:14.640+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:01:14.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T13:01:45.031+0000] {processor.py:157} INFO - Started process (PID=4551) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:01:45.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:01:45.034+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:45.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:01:45.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:01:45.059+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:45.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:01:45.069+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:45.069+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:01:45.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:02:15.441+0000] {processor.py:157} INFO - Started process (PID=4571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:02:15.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:02:15.444+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:15.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:02:15.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:02:15.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:15.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:02:15.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:15.476+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:02:15.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T13:02:45.850+0000] {processor.py:157} INFO - Started process (PID=4591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:02:45.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:02:45.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:45.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:02:45.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:02:45.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:45.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:02:45.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:45.888+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:02:45.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:03:16.263+0000] {processor.py:157} INFO - Started process (PID=4611) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:03:16.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:03:16.267+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:16.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:03:16.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:03:16.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:16.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:03:16.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:16.301+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:03:16.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:03:46.675+0000] {processor.py:157} INFO - Started process (PID=4631) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:03:46.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:03:46.678+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:46.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:03:46.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:03:46.700+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:46.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:03:46.709+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:46.709+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:03:46.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T13:04:17.081+0000] {processor.py:157} INFO - Started process (PID=4651) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:04:17.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:04:17.084+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:17.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:04:17.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:04:17.108+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:17.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:04:17.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:17.119+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:04:17.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:04:47.466+0000] {processor.py:157} INFO - Started process (PID=4671) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:04:47.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:04:47.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:47.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:04:47.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:04:47.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:47.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:04:47.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:47.501+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:04:47.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:05:17.875+0000] {processor.py:157} INFO - Started process (PID=4691) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:05:17.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:05:17.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:17.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:05:17.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:05:17.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:17.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:05:17.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:17.911+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:05:17.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T13:05:48.349+0000] {processor.py:157} INFO - Started process (PID=4711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:05:48.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:05:48.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:48.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:05:48.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:05:48.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:48.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:05:48.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:48.386+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:05:48.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:06:18.775+0000] {processor.py:157} INFO - Started process (PID=4731) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:06:18.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:06:18.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:18.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:06:18.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:06:18.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:18.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:06:18.812+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:18.812+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:06:18.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:06:49.227+0000] {processor.py:157} INFO - Started process (PID=4751) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:06:49.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:06:49.230+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:49.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:06:49.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:06:49.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:49.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:06:49.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:49.266+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:06:49.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:07:19.628+0000] {processor.py:157} INFO - Started process (PID=4771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:07:19.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:07:19.632+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:19.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:07:19.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:07:19.657+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:19.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:07:19.667+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:19.667+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:07:19.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T13:07:49.985+0000] {processor.py:157} INFO - Started process (PID=4791) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:07:49.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:07:49.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:49.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:07:49.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:07:50.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:50.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:07:50.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:50.024+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:07:50.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:08:20.348+0000] {processor.py:157} INFO - Started process (PID=4811) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:08:20.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:08:20.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:20.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:08:20.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:08:20.374+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:20.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:08:20.384+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:20.384+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:08:20.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:08:50.756+0000] {processor.py:157} INFO - Started process (PID=4831) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:08:50.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:08:50.759+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:50.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:08:50.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:08:50.783+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:50.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:08:50.793+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:50.793+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:08:50.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:09:21.140+0000] {processor.py:157} INFO - Started process (PID=4851) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:09:21.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:09:21.143+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:21.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:09:21.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:09:21.165+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:21.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:09:21.175+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:21.175+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:09:21.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T13:09:51.528+0000] {processor.py:157} INFO - Started process (PID=4871) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:09:51.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:09:51.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:51.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:09:51.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:09:51.555+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:51.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:09:51.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:51.565+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:09:51.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:10:21.938+0000] {processor.py:157} INFO - Started process (PID=4891) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:10:21.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:10:21.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:21.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:10:21.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:10:21.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:21.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:10:21.976+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:21.976+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:10:21.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:10:52.379+0000] {processor.py:157} INFO - Started process (PID=4911) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:10:52.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:10:52.382+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:52.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:10:52.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:10:52.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:52.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:10:52.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:52.422+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:10:52.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T13:11:22.809+0000] {processor.py:157} INFO - Started process (PID=4931) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:11:22.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:11:22.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:22.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:11:22.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:11:22.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:22.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:11:22.847+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:22.847+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:11:22.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:11:53.234+0000] {processor.py:157} INFO - Started process (PID=4951) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:11:53.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:11:53.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:53.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:11:53.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:11:53.262+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:53.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:11:53.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:53.272+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:11:53.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:12:23.640+0000] {processor.py:157} INFO - Started process (PID=4971) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:12:23.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:12:23.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:23.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:12:23.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:12:23.667+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:23.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:12:23.678+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:23.678+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:12:23.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:12:53.997+0000] {processor.py:157} INFO - Started process (PID=4991) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:12:53.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:12:53.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:53.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:12:54.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:12:54.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:54.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:12:54.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:54.028+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:12:54.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.039 seconds
[2024-07-10T13:13:24.388+0000] {processor.py:157} INFO - Started process (PID=5011) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:13:24.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:13:24.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:24.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:13:24.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:13:24.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:24.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:13:24.424+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:24.424+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:13:24.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:13:54.793+0000] {processor.py:157} INFO - Started process (PID=5031) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:13:54.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:13:54.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:54.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:13:54.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:13:54.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:54.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:13:54.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:54.833+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:13:54.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T13:14:25.219+0000] {processor.py:157} INFO - Started process (PID=5051) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:14:25.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:14:25.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:25.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:14:25.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:14:25.245+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:25.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:14:25.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:25.255+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:14:25.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:14:55.619+0000] {processor.py:157} INFO - Started process (PID=5071) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:14:55.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:14:55.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:55.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:14:55.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:14:55.647+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:55.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:14:55.657+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:55.657+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:14:55.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:15:26.036+0000] {processor.py:157} INFO - Started process (PID=5091) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:15:26.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:15:26.040+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:26.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:15:26.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:15:26.065+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:26.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:15:26.075+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:26.075+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:15:26.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:15:56.425+0000] {processor.py:157} INFO - Started process (PID=5111) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:15:56.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:15:56.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:56.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:15:56.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:15:56.452+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:56.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:15:56.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:56.462+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:15:56.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:16:26.794+0000] {processor.py:157} INFO - Started process (PID=5131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:16:26.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:16:26.797+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:26.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:16:26.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:16:26.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:26.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:16:26.831+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:26.831+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:16:26.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:16:57.151+0000] {processor.py:157} INFO - Started process (PID=5151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:16:57.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:16:57.153+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:57.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:16:57.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:16:57.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:57.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:16:57.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:57.186+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:16:57.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T13:17:27.619+0000] {processor.py:157} INFO - Started process (PID=5171) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:17:27.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:17:27.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:27.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:17:27.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:17:27.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:27.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:17:27.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:27.660+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:17:27.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T13:17:58.079+0000] {processor.py:157} INFO - Started process (PID=5191) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:17:58.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:17:58.082+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:58.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:17:58.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:17:58.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:58.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:17:58.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:58.116+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:17:58.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:18:28.456+0000] {processor.py:157} INFO - Started process (PID=5211) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:18:28.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:18:28.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:28.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:18:28.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:18:28.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:28.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:18:28.491+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:28.491+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:18:28.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T13:18:58.945+0000] {processor.py:157} INFO - Started process (PID=5231) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:18:58.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:18:58.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:58.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:18:58.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:18:58.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:58.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:18:58.982+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:58.982+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:18:58.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:19:29.382+0000] {processor.py:157} INFO - Started process (PID=5251) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:19:29.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:19:29.386+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:29.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:19:29.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:19:29.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:29.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:19:29.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:29.419+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:19:29.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T13:19:59.846+0000] {processor.py:157} INFO - Started process (PID=5271) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:19:59.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:19:59.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:59.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:19:59.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:19:59.880+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:59.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:19:59.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:59.892+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:19:59.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T13:20:30.301+0000] {processor.py:157} INFO - Started process (PID=5291) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:20:30.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:20:30.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:30.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:20:30.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:20:30.324+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:30.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:20:30.333+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:30.333+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:20:30.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T13:21:00.728+0000] {processor.py:157} INFO - Started process (PID=5311) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:21:00.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:21:00.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:00.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:21:00.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:21:00.757+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:00.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:21:00.766+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:00.766+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:21:00.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:21:31.170+0000] {processor.py:157} INFO - Started process (PID=5331) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:21:31.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:21:31.173+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:31.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:21:31.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:21:31.197+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:31.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:21:31.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:31.206+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:21:31.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:22:01.557+0000] {processor.py:157} INFO - Started process (PID=5351) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:22:01.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:22:01.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:01.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:22:01.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:22:01.584+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:01.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:22:01.593+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:01.593+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:22:01.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:22:31.944+0000] {processor.py:157} INFO - Started process (PID=5371) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:22:31.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:22:31.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:31.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:22:31.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:22:31.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:31.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:22:31.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:31.981+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:22:31.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:23:02.371+0000] {processor.py:157} INFO - Started process (PID=5391) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:23:02.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:23:02.375+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:02.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:23:02.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:23:02.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:02.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:23:02.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:02.410+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:23:02.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:23:32.794+0000] {processor.py:157} INFO - Started process (PID=5411) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:23:32.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:23:32.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:32.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:23:32.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:23:32.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:32.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:23:32.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:32.833+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:23:32.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:24:03.243+0000] {processor.py:157} INFO - Started process (PID=5431) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:24:03.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:24:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:03.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:24:03.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:24:03.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:03.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:24:03.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:03.280+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:24:03.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:24:33.651+0000] {processor.py:157} INFO - Started process (PID=5451) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:24:33.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:24:33.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:33.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:24:33.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:24:33.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:33.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:24:33.688+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:33.688+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:24:33.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:25:04.081+0000] {processor.py:157} INFO - Started process (PID=5471) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:25:04.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:25:04.083+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:04.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:25:04.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:25:04.108+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:04.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:25:04.118+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:04.118+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:25:04.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:25:34.456+0000] {processor.py:157} INFO - Started process (PID=5491) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:25:34.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:25:34.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:34.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:25:34.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:25:34.483+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:34.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:25:34.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:34.493+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:25:34.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:26:04.863+0000] {processor.py:157} INFO - Started process (PID=5511) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:26:04.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:26:04.866+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:04.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:26:04.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:26:04.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:04.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:26:04.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:04.903+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:26:04.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T13:26:35.311+0000] {processor.py:157} INFO - Started process (PID=5531) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:26:35.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:26:35.315+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:35.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:26:35.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:26:35.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:35.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:26:35.348+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:35.348+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:26:35.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:27:05.682+0000] {processor.py:157} INFO - Started process (PID=5551) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:27:05.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:27:05.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:05.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:27:05.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:27:05.708+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:05.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:27:05.718+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:05.718+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:27:05.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:27:36.117+0000] {processor.py:157} INFO - Started process (PID=5571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:27:36.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:27:36.121+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:36.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:27:36.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:27:36.145+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:36.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:27:36.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:36.155+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:27:36.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T13:28:06.495+0000] {processor.py:157} INFO - Started process (PID=5591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:28:06.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:28:06.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:06.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:28:06.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:28:06.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:06.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:28:06.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:06.530+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:28:06.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T13:28:36.844+0000] {processor.py:157} INFO - Started process (PID=5611) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:28:36.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:28:36.846+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:36.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:28:36.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:28:36.868+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:36.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:28:36.877+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:36.877+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:28:36.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T13:29:07.217+0000] {processor.py:157} INFO - Started process (PID=5631) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:29:07.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:29:07.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:07.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:29:07.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:29:07.244+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:07.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:29:07.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:07.254+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:29:07.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:29:37.614+0000] {processor.py:157} INFO - Started process (PID=5651) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:29:37.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:29:37.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:37.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:29:37.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:29:37.642+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:37.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:29:37.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:37.652+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:29:37.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:30:08.012+0000] {processor.py:157} INFO - Started process (PID=5671) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:30:08.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:30:08.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:08.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:30:08.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:30:08.039+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:08.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:30:08.050+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:08.049+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:30:08.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:30:38.452+0000] {processor.py:157} INFO - Started process (PID=5691) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:30:38.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:30:38.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:38.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:30:38.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:30:38.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:38.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:30:38.491+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:38.491+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:30:38.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T13:31:08.831+0000] {processor.py:157} INFO - Started process (PID=5711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:31:08.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:31:08.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:08.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:31:08.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:31:08.859+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:08.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:31:08.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:08.869+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:31:08.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:31:39.263+0000] {processor.py:157} INFO - Started process (PID=5731) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:31:39.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:31:39.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:39.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:31:39.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:31:39.289+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:39.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:31:39.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:39.299+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:31:39.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:32:09.619+0000] {processor.py:157} INFO - Started process (PID=5751) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:32:09.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:32:09.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:09.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:32:09.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:32:09.644+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:09.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:32:09.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:09.653+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:32:09.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T13:32:40.015+0000] {processor.py:157} INFO - Started process (PID=5771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:32:40.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:32:40.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:40.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:32:40.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:32:40.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:40.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:32:40.052+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:40.052+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:32:40.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:33:10.443+0000] {processor.py:157} INFO - Started process (PID=5791) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:33:10.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:33:10.446+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:10.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:33:10.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:33:10.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:10.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:33:10.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:10.481+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:33:10.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:33:40.830+0000] {processor.py:157} INFO - Started process (PID=5811) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:33:40.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:33:40.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:40.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:33:40.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:33:40.857+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:40.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:33:40.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:40.867+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:33:40.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:34:11.339+0000] {processor.py:157} INFO - Started process (PID=5831) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:34:11.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:34:11.344+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:11.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:34:11.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:34:11.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:11.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:34:11.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:11.388+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:34:11.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.062 seconds
[2024-07-10T13:34:41.776+0000] {processor.py:157} INFO - Started process (PID=5851) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:34:41.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:34:41.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:41.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:34:41.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:34:41.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:41.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:34:41.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:41.813+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:34:41.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:35:12.176+0000] {processor.py:157} INFO - Started process (PID=5871) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:35:12.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:35:12.179+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:12.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:35:12.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:35:12.204+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:12.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:35:12.213+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:12.213+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:35:12.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:35:42.590+0000] {processor.py:157} INFO - Started process (PID=5891) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:35:42.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:35:42.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:42.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:35:42.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:35:42.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:42.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:35:42.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:42.628+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:35:42.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:36:12.988+0000] {processor.py:157} INFO - Started process (PID=5911) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:36:12.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:36:12.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:12.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:36:13.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:36:13.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:13.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:36:13.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:13.025+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:36:13.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:36:43.432+0000] {processor.py:157} INFO - Started process (PID=5931) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:36:43.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:36:43.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:43.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:36:43.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:36:43.460+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:43.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:36:43.470+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:43.470+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:36:43.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:37:13.846+0000] {processor.py:157} INFO - Started process (PID=5951) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:37:13.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:37:13.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:13.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:37:13.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:37:13.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:13.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:37:13.883+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:13.883+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:37:13.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:37:44.249+0000] {processor.py:157} INFO - Started process (PID=5971) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:37:44.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:37:44.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:44.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:37:44.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:37:44.276+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:44.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:37:44.286+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:44.286+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:37:44.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:38:14.653+0000] {processor.py:157} INFO - Started process (PID=5991) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:38:14.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:38:14.656+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:14.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:38:14.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:38:14.682+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:14.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:38:14.692+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:14.692+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:38:14.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T13:38:45.029+0000] {processor.py:157} INFO - Started process (PID=6011) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:38:45.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:38:45.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:45.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:38:45.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:38:45.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:45.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:38:45.068+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:45.068+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:38:45.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:39:15.522+0000] {processor.py:157} INFO - Started process (PID=6031) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:39:15.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:39:15.526+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:15.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:39:15.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:39:15.550+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:15.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:39:15.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:15.560+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:39:15.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:39:45.942+0000] {processor.py:157} INFO - Started process (PID=6051) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:39:45.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:39:45.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:45.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:39:45.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:39:45.967+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:45.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:39:45.977+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:45.977+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:39:45.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T13:40:16.377+0000] {processor.py:157} INFO - Started process (PID=6071) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:40:16.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:40:16.380+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:16.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:40:16.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:40:16.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:16.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:40:16.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:16.415+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:40:16.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:40:46.773+0000] {processor.py:157} INFO - Started process (PID=6091) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:40:46.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:40:46.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:46.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:40:46.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:40:46.799+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:46.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:40:46.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:46.809+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:40:46.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T13:41:17.168+0000] {processor.py:157} INFO - Started process (PID=6111) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:41:17.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:41:17.171+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:17.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:41:17.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:41:17.195+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:17.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:41:17.204+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:17.204+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:41:17.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:41:47.592+0000] {processor.py:157} INFO - Started process (PID=6131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:41:47.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:41:47.595+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:47.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:41:47.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:41:47.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:47.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:41:47.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:47.629+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:41:47.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:42:17.985+0000] {processor.py:157} INFO - Started process (PID=6151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:42:17.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:42:17.989+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:17.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:42:17.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:42:18.013+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:18.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:42:18.023+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:18.023+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:42:18.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:42:48.392+0000] {processor.py:157} INFO - Started process (PID=6171) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:42:48.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:42:48.395+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:48.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:42:48.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:42:48.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:48.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:42:48.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:48.429+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:42:48.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:43:18.806+0000] {processor.py:157} INFO - Started process (PID=6191) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:43:18.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:43:18.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:18.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:43:18.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:43:18.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:18.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:43:18.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:18.843+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:43:18.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:43:49.214+0000] {processor.py:157} INFO - Started process (PID=6211) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:43:49.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:43:49.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:49.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:43:49.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:43:49.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:49.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:43:49.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:49.246+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:43:49.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T13:44:19.569+0000] {processor.py:157} INFO - Started process (PID=6231) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:44:19.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:44:19.572+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:19.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:44:19.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:44:19.597+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:19.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:44:19.607+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:19.607+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:44:19.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:44:49.981+0000] {processor.py:157} INFO - Started process (PID=6251) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:44:49.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:44:49.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:49.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:44:49.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:44:50.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:50.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:44:50.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:50.019+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:44:50.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:45:20.412+0000] {processor.py:157} INFO - Started process (PID=6271) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:45:20.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:45:20.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:20.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:45:20.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:45:20.437+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:20.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:45:20.447+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:20.447+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:45:20.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T13:45:50.859+0000] {processor.py:157} INFO - Started process (PID=6291) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:45:50.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:45:50.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:50.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:45:50.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:45:50.896+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:50.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:45:50.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:50.904+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:45:50.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T13:46:21.293+0000] {processor.py:157} INFO - Started process (PID=6311) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:46:21.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:46:21.296+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:21.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:46:21.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:46:21.324+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:21.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:46:21.334+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:21.334+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:46:21.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T13:46:51.709+0000] {processor.py:157} INFO - Started process (PID=6331) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:46:51.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:46:51.712+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:51.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:46:51.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:46:51.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:51.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:46:51.748+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:51.748+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:46:51.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:47:22.055+0000] {processor.py:157} INFO - Started process (PID=6351) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:47:22.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:47:22.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:22.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:47:22.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:47:22.081+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:22.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:47:22.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:22.091+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:47:22.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:47:52.402+0000] {processor.py:157} INFO - Started process (PID=6371) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:47:52.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:47:52.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:52.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:47:52.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:47:52.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:52.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:47:52.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:52.438+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:47:52.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T13:48:22.875+0000] {processor.py:157} INFO - Started process (PID=6391) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:48:22.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:48:22.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:22.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:48:22.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:48:22.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:22.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:48:22.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:22.913+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:48:22.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:48:53.398+0000] {processor.py:157} INFO - Started process (PID=6411) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:48:53.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:48:53.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:53.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:48:53.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:48:53.426+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:53.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:48:53.435+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:53.435+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:48:53.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:49:23.836+0000] {processor.py:157} INFO - Started process (PID=6431) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:49:23.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:49:23.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:23.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:49:23.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:49:23.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:23.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:49:23.885+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:23.885+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:49:23.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T13:49:54.263+0000] {processor.py:157} INFO - Started process (PID=6451) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:49:54.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:49:54.267+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:54.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:49:54.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:49:54.292+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:54.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:49:54.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:54.301+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:49:54.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:50:24.646+0000] {processor.py:157} INFO - Started process (PID=6471) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:50:24.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:50:24.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:24.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:50:24.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:50:24.674+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:24.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:50:24.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:24.685+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:50:24.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T13:50:55.088+0000] {processor.py:157} INFO - Started process (PID=6491) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:50:55.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:50:55.092+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:55.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:50:55.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:50:55.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:55.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:50:55.126+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:55.126+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:50:55.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:51:25.503+0000] {processor.py:157} INFO - Started process (PID=6511) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:51:25.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:51:25.507+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:25.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:51:25.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:51:25.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:25.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:51:25.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:25.540+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:51:25.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:51:55.910+0000] {processor.py:157} INFO - Started process (PID=6531) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:51:55.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:51:55.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:55.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:51:55.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:51:55.937+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:55.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:51:55.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:55.947+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:51:55.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:52:26.327+0000] {processor.py:157} INFO - Started process (PID=6551) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:52:26.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:52:26.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:26.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:52:26.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:52:26.354+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:26.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:52:26.363+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:26.363+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:52:26.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T13:52:56.741+0000] {processor.py:157} INFO - Started process (PID=6571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:52:56.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:52:56.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:56.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:52:56.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:52:56.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:56.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:52:56.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:56.785+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:52:56.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T13:53:27.141+0000] {processor.py:157} INFO - Started process (PID=6591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:53:27.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:53:27.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:27.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:53:27.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:53:27.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:27.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:53:27.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:27.181+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:53:27.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T13:53:57.548+0000] {processor.py:157} INFO - Started process (PID=6611) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:53:57.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:53:57.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:57.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:53:57.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:53:57.580+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:57.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:53:57.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:57.591+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:53:57.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T13:54:27.960+0000] {processor.py:157} INFO - Started process (PID=6631) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:54:27.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:54:27.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:27.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:54:27.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:54:27.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:27.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:54:28.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:28.008+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:54:28.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.062 seconds
[2024-07-10T13:54:58.397+0000] {processor.py:157} INFO - Started process (PID=6651) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:54:58.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:54:58.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:58.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:54:58.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:54:58.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:58.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:54:58.435+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:58.434+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:54:58.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:55:28.796+0000] {processor.py:157} INFO - Started process (PID=6671) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:55:28.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:55:28.799+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:28.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:55:28.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:55:28.824+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:28.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:55:28.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:28.834+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:55:28.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:55:59.189+0000] {processor.py:157} INFO - Started process (PID=6691) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:55:59.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:55:59.192+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:59.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:55:59.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:55:59.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:59.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:55:59.227+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:59.227+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:55:59.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:56:29.565+0000] {processor.py:157} INFO - Started process (PID=6711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:56:29.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:56:29.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:29.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:56:29.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:56:29.597+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:29.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:56:29.606+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:29.606+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:56:29.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T13:56:59.965+0000] {processor.py:157} INFO - Started process (PID=6731) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:56:59.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:56:59.969+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:59.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:56:59.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:56:59.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:59.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:57:00.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:00.004+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:57:00.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T13:57:30.371+0000] {processor.py:157} INFO - Started process (PID=6751) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:57:30.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:57:30.374+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:30.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:57:30.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:57:30.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:30.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:57:30.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:30.408+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:57:30.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T13:58:00.772+0000] {processor.py:157} INFO - Started process (PID=6771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:58:00.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:58:00.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:00.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:58:00.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:58:00.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:00.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:58:00.812+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:00.812+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:58:00.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T13:58:31.152+0000] {processor.py:157} INFO - Started process (PID=6791) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:58:31.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:58:31.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:31.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:58:31.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:58:31.180+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:31.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:58:31.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:31.189+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:58:31.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T13:59:01.561+0000] {processor.py:157} INFO - Started process (PID=6811) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:59:01.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:59:01.564+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:01.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:59:01.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:59:01.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:01.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:59:01.604+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:01.604+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:59:01.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T13:59:31.939+0000] {processor.py:157} INFO - Started process (PID=6831) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:59:31.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T13:59:31.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:31.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:59:31.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T13:59:31.970+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:31.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:59:31.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:31.981+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:59:31.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T14:00:02.361+0000] {processor.py:157} INFO - Started process (PID=6851) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:00:02.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:00:02.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:02.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:00:02.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:00:02.389+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:02.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:00:02.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:02.399+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:00:02.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:00:32.775+0000] {processor.py:157} INFO - Started process (PID=6871) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:00:32.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:00:32.780+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:32.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:00:32.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:00:32.805+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:32.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:00:32.814+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:32.814+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:00:32.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T14:01:03.188+0000] {processor.py:157} INFO - Started process (PID=6891) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:01:03.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:01:03.197+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:03.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:01:03.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:01:03.222+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:03.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:01:03.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:03.231+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:01:03.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T14:01:33.599+0000] {processor.py:157} INFO - Started process (PID=6911) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:01:33.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:01:33.602+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:33.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:01:33.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:01:33.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:33.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:01:33.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:33.640+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:01:33.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T14:02:03.988+0000] {processor.py:157} INFO - Started process (PID=6931) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:02:03.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:02:03.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:03.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:02:04.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:02:04.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:04.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:02:04.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:04.027+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:02:04.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:02:34.404+0000] {processor.py:157} INFO - Started process (PID=6951) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:02:34.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:02:34.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:34.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:02:34.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:02:34.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:34.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:02:34.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:34.441+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:02:34.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T14:03:04.767+0000] {processor.py:157} INFO - Started process (PID=6971) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:03:04.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:03:04.770+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:04.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:03:04.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:03:04.792+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:04.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:03:04.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:04.802+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:03:04.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T14:03:35.199+0000] {processor.py:157} INFO - Started process (PID=6991) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:03:35.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:03:35.202+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:35.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:03:35.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:03:35.230+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:35.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:03:35.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:35.241+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:03:35.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T14:04:05.674+0000] {processor.py:157} INFO - Started process (PID=7011) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:04:05.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:04:05.678+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:05.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:04:05.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:04:05.707+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:05.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:04:05.717+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:05.717+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:04:05.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T14:04:36.069+0000] {processor.py:157} INFO - Started process (PID=7031) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:04:36.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:04:36.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:36.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:04:36.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:04:36.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:36.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:04:36.108+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:36.108+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:04:36.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:05:06.511+0000] {processor.py:157} INFO - Started process (PID=7051) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:05:06.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:05:06.514+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:06.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:05:06.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:05:06.538+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:06.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:05:06.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:06.548+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:05:06.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T14:05:36.914+0000] {processor.py:157} INFO - Started process (PID=7071) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:05:36.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:05:36.917+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:36.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:05:36.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:05:36.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:36.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:05:36.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:36.951+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:05:36.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T14:06:07.261+0000] {processor.py:157} INFO - Started process (PID=7091) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:06:07.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:06:07.264+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:07.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:06:07.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:06:07.287+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:07.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:06:07.296+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:07.296+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:06:07.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T14:06:37.709+0000] {processor.py:157} INFO - Started process (PID=7111) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:06:37.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:06:37.711+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:37.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:06:37.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:06:37.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:37.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:06:37.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:37.746+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:06:37.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:07:08.117+0000] {processor.py:157} INFO - Started process (PID=7131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:07:08.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:07:08.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:08.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:07:08.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:07:08.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:08.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:07:08.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:08.159+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:07:08.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T14:07:38.565+0000] {processor.py:157} INFO - Started process (PID=7151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:07:38.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:07:38.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:38.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:07:38.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:07:38.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:38.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:07:38.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:38.609+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:07:38.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T14:08:09.011+0000] {processor.py:157} INFO - Started process (PID=7171) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:08:09.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:08:09.016+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:09.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:08:09.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:08:09.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:09.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:08:09.054+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:09.054+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:08:09.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T14:08:39.411+0000] {processor.py:157} INFO - Started process (PID=7191) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:08:39.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:08:39.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:39.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:08:39.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:08:39.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:39.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:08:39.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:39.450+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:08:39.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:09:09.830+0000] {processor.py:157} INFO - Started process (PID=7211) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:09:09.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:09:09.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:09.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:09:09.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:09:09.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:09.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:09:09.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:09.873+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:09:09.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T14:09:40.243+0000] {processor.py:157} INFO - Started process (PID=7231) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:09:40.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:09:40.247+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:40.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:09:40.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:09:40.273+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:40.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:09:40.283+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:40.283+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:09:40.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T14:10:10.660+0000] {processor.py:157} INFO - Started process (PID=7251) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:10:10.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:10:10.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:10.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:10:10.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:10:10.706+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:10.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:10:10.717+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:10.717+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:10:10.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.069 seconds
[2024-07-10T14:10:41.212+0000] {processor.py:157} INFO - Started process (PID=7271) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:10:41.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:10:41.222+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:41.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:10:41.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:10:41.257+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:41.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:10:41.268+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:41.268+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:10:41.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.070 seconds
[2024-07-10T14:11:11.672+0000] {processor.py:157} INFO - Started process (PID=7291) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:11:11.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:11:11.676+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:11.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:11:11.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:11:11.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:11.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:11:11.726+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:11.726+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:11:11.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.067 seconds
[2024-07-10T14:11:42.136+0000] {processor.py:157} INFO - Started process (PID=7311) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:11:42.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:11:42.140+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:42.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:11:42.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:11:42.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:42.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:11:42.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:42.177+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:11:42.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T14:12:12.566+0000] {processor.py:157} INFO - Started process (PID=7331) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:12:12.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:12:12.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:12.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:12:12.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:12:12.594+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:12.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:12:12.603+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:12.603+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:12:12.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:12:43.001+0000] {processor.py:157} INFO - Started process (PID=7351) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:12:43.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:12:43.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:43.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:12:43.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:12:43.042+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:43.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:12:43.054+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:43.054+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:12:43.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.065 seconds
[2024-07-10T14:13:13.430+0000] {processor.py:157} INFO - Started process (PID=7371) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:13:13.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:13:13.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:13.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:13:13.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:13:13.461+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:13.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:13:13.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:13.471+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:13:13.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T14:13:43.863+0000] {processor.py:157} INFO - Started process (PID=7391) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:13:43.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:13:43.866+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:43.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:13:43.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:13:43.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:43.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:13:43.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:43.904+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:13:43.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T14:14:14.218+0000] {processor.py:157} INFO - Started process (PID=7411) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:14:14.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:14:14.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:14.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:14:14.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:14:14.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:14.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:14:14.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:14.252+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:14:14.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T14:14:44.649+0000] {processor.py:157} INFO - Started process (PID=7431) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:14:44.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:14:44.654+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:44.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:14:44.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:14:44.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:44.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:14:44.690+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:44.690+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:14:44.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T14:15:15.081+0000] {processor.py:157} INFO - Started process (PID=7451) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:15:15.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:15:15.085+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:15.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:15:15.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:15:15.110+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:15.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:15:15.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:15.119+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:15:15.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:15:45.490+0000] {processor.py:157} INFO - Started process (PID=7471) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:15:45.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:15:45.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:45.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:15:45.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:15:45.518+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:45.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:15:45.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:45.528+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:15:45.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:16:15.917+0000] {processor.py:157} INFO - Started process (PID=7491) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:16:15.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:16:15.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:15.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:16:15.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:16:15.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:15.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:16:15.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:15.956+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:16:15.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:16:46.381+0000] {processor.py:157} INFO - Started process (PID=7511) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:16:46.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:16:46.384+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:46.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:16:46.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:16:46.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:46.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:16:46.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:46.424+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:16:46.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T14:17:16.805+0000] {processor.py:157} INFO - Started process (PID=7531) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:17:16.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:17:16.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:16.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:17:16.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:17:16.841+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:16.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:17:16.851+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:16.851+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:17:16.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T14:17:47.218+0000] {processor.py:157} INFO - Started process (PID=7551) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:17:47.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:17:47.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:47.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:17:47.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:17:47.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:47.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:17:47.256+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:47.256+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:17:47.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:18:17.621+0000] {processor.py:157} INFO - Started process (PID=7571) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:18:17.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:18:17.624+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:17.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:18:17.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:18:17.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:17.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:18:17.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:17.662+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:18:17.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T14:18:48.047+0000] {processor.py:157} INFO - Started process (PID=7591) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:18:48.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:18:48.050+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:48.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:18:48.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:18:48.075+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:48.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:18:48.085+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:48.085+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:18:48.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:19:18.402+0000] {processor.py:157} INFO - Started process (PID=7611) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:19:18.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:19:18.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:18.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:19:18.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:19:18.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:18.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:19:18.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:18.440+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:19:18.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:19:48.832+0000] {processor.py:157} INFO - Started process (PID=7631) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:19:48.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:19:48.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:48.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:19:48.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:19:48.866+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:48.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:19:48.876+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:48.876+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:19:48.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T14:20:19.260+0000] {processor.py:157} INFO - Started process (PID=7651) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:20:19.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:20:19.264+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:19.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:20:19.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:20:19.290+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:19.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:20:19.300+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:19.300+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:20:19.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:20:49.657+0000] {processor.py:157} INFO - Started process (PID=7671) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:20:49.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:20:49.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:49.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:20:49.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:20:49.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:49.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:20:49.696+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:49.696+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:20:49.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:21:20.056+0000] {processor.py:157} INFO - Started process (PID=7691) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:21:20.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:21:20.060+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:20.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:21:20.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:21:20.088+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:20.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:21:20.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:20.098+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:21:20.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T14:21:50.486+0000] {processor.py:157} INFO - Started process (PID=7711) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:21:50.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:21:50.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:50.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:21:50.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:21:50.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:50.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:21:50.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:50.522+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:21:50.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T14:22:20.920+0000] {processor.py:157} INFO - Started process (PID=7731) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:22:20.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:22:20.923+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:20.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:22:20.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:22:20.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:20.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:22:20.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:20.966+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:22:20.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T14:22:51.381+0000] {processor.py:157} INFO - Started process (PID=7751) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:22:51.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:22:51.384+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:51.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:22:51.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:22:51.409+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:51.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:22:51.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:51.419+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:22:51.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:23:21.747+0000] {processor.py:157} INFO - Started process (PID=7771) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:23:21.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:23:21.750+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:21.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:23:21.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:23:21.774+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:21.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:23:21.784+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:21.784+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:23:21.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T14:23:52.148+0000] {processor.py:157} INFO - Started process (PID=7791) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:23:52.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:23:52.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:52.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:23:52.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:23:52.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:52.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:23:52.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:52.186+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:23:52.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:24:22.551+0000] {processor.py:157} INFO - Started process (PID=7811) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:24:22.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:24:22.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:22.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:24:22.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:24:22.580+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:22.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:24:22.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:22.591+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:24:22.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:24:52.986+0000] {processor.py:157} INFO - Started process (PID=7831) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:24:52.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:24:52.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:52.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:24:53.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:24:53.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:53.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:24:53.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:53.033+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:24:53.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T14:25:23.414+0000] {processor.py:157} INFO - Started process (PID=7851) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:25:23.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:25:23.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:23.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:25:23.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:25:23.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:23.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:25:23.456+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:23.456+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:25:23.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T14:25:53.830+0000] {processor.py:157} INFO - Started process (PID=7871) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:25:53.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:25:53.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:53.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:25:53.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:25:53.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:53.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:25:53.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:53.867+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:25:53.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:26:24.196+0000] {processor.py:157} INFO - Started process (PID=7891) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:26:24.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:26:24.199+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:24.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:26:24.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:26:24.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:24.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:26:24.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:24.232+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:26:24.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T14:26:54.595+0000] {processor.py:157} INFO - Started process (PID=7911) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:26:54.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:26:54.599+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:54.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:26:54.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:26:54.627+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:54.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:26:54.637+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:54.637+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:26:54.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T14:27:24.987+0000] {processor.py:157} INFO - Started process (PID=7931) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:27:24.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:27:24.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:24.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:27:24.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:27:25.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:25.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:27:25.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:25.024+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:27:25.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:27:55.389+0000] {processor.py:157} INFO - Started process (PID=7951) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:27:55.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:27:55.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:55.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:27:55.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:27:55.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:55.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:27:55.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:55.425+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:27:55.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T14:28:25.797+0000] {processor.py:157} INFO - Started process (PID=7971) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:28:25.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:28:25.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:25.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:28:25.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:28:25.845+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:25.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:28:25.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:25.860+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:28:25.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.081 seconds
[2024-07-10T14:28:56.269+0000] {processor.py:157} INFO - Started process (PID=7991) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:28:56.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:28:56.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:56.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:28:56.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:28:56.298+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:56.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:28:56.308+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:56.307+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:28:56.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:29:26.658+0000] {processor.py:157} INFO - Started process (PID=8011) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:29:26.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:29:26.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:26.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:29:26.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:29:26.682+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:26.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:29:26.691+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:26.690+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:29:26.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T14:29:57.032+0000] {processor.py:157} INFO - Started process (PID=8031) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:29:57.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:29:57.037+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:57.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:29:57.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:29:57.069+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:57.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:29:57.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:57.080+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:29:57.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.060 seconds
[2024-07-10T14:30:27.476+0000] {processor.py:157} INFO - Started process (PID=8051) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:30:27.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:30:27.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:27.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:30:27.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:30:27.504+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:27.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:30:27.514+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:27.514+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:30:27.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:30:57.869+0000] {processor.py:157} INFO - Started process (PID=8071) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:30:57.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:30:57.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:57.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:30:57.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:30:57.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:57.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:30:57.907+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:57.907+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:30:57.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:31:28.241+0000] {processor.py:157} INFO - Started process (PID=8091) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:31:28.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:31:28.245+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:28.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:31:28.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:31:28.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:28.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:31:28.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:28.280+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:31:28.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:31:58.688+0000] {processor.py:157} INFO - Started process (PID=8111) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:31:58.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:31:58.692+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:58.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:31:58.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:31:58.725+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:58.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:31:58.735+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:58.735+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:31:58.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T14:32:29.093+0000] {processor.py:157} INFO - Started process (PID=8131) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:32:29.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:32:29.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:29.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:32:29.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:32:29.122+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:29.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:32:29.133+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:29.133+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:32:29.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:32:59.451+0000] {processor.py:157} INFO - Started process (PID=8151) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:32:59.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:32:59.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:59.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:32:59.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:32:59.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:59.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:32:59.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:59.489+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:32:59.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:33:29.810+0000] {processor.py:157} INFO - Started process (PID=8171) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:33:29.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:33:29.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:29.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:33:29.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:33:29.838+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:29.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:33:29.848+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:29.848+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:33:29.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:34:00.205+0000] {processor.py:157} INFO - Started process (PID=8191) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:34:00.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:34:00.210+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:00.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:34:00.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:34:00.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:00.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:34:00.247+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:00.247+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:34:00.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T14:34:30.613+0000] {processor.py:157} INFO - Started process (PID=8211) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:34:30.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:34:30.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:30.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:34:30.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:34:30.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:30.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:34:30.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:30.653+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:34:30.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:35:01.024+0000] {processor.py:157} INFO - Started process (PID=8231) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:35:01.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:35:01.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:01.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:35:01.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:35:01.053+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:01.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:35:01.063+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:01.063+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:35:01.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:35:31.447+0000] {processor.py:157} INFO - Started process (PID=8251) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:35:31.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:35:31.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:31.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:35:31.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:35:31.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:31.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:35:31.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:31.485+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:35:31.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:36:01.872+0000] {processor.py:157} INFO - Started process (PID=8271) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:36:01.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:36:01.875+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:01.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:36:01.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:36:01.899+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:01.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:36:01.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:01.909+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:36:01.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T14:36:32.321+0000] {processor.py:157} INFO - Started process (PID=8291) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:36:32.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:36:32.324+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:32.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:36:32.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:36:32.349+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:32.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:36:32.360+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:32.360+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:36:32.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T14:37:02.760+0000] {processor.py:157} INFO - Started process (PID=8311) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:37:02.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:37:02.764+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:02.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:37:02.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:37:02.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:02.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:37:02.805+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:02.805+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:37:02.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T14:37:33.165+0000] {processor.py:157} INFO - Started process (PID=8331) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:37:33.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:37:33.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:33.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:37:33.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:37:33.194+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:33.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:37:33.204+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:33.204+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:37:33.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T14:38:03.612+0000] {processor.py:157} INFO - Started process (PID=8351) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:38:03.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:38:03.616+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:03.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:38:03.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:38:03.641+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:03.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:38:03.651+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:03.651+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:38:03.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T14:38:34.075+0000] {processor.py:157} INFO - Started process (PID=8371) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:38:34.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:38:34.081+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:34.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:38:34.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:38:34.127+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:34.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:38:34.143+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:34.143+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:38:34.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.083 seconds
[2024-07-10T14:39:28.827+0000] {processor.py:157} INFO - Started process (PID=8396) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:39:28.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:39:28.829+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:39:28.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:39:28.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:39:28.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:39:28.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:39:28.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:39:28.861+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:39:28.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T14:43:31.748+0000] {processor.py:157} INFO - Started process (PID=8416) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:43:31.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:43:31.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:43:31.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:43:31.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:43:31.788+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:43:31.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:43:31.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:43:31.823+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:43:31.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.110 seconds
[2024-07-10T14:44:02.333+0000] {processor.py:157} INFO - Started process (PID=8436) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:44:02.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T14:44:02.337+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:44:02.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:44:02.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T14:44:02.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:44:02.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:44:02.373+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:44:02.373+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:44:02.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T15:00:39.329+0000] {processor.py:157} INFO - Started process (PID=8455) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:00:39.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:00:39.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:00:39.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:00:39.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:00:39.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:00:39.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:00:39.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:00:39.410+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:00:39.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.099 seconds
[2024-07-10T15:01:09.870+0000] {processor.py:157} INFO - Started process (PID=8476) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:01:09.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:01:09.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:09.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:01:09.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:01:09.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:09.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:01:09.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:09.913+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:01:09.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T15:01:40.388+0000] {processor.py:157} INFO - Started process (PID=8496) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:01:40.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:01:40.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:40.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:01:40.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:01:40.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:40.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:01:40.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:40.433+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:01:40.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T15:02:10.907+0000] {processor.py:157} INFO - Started process (PID=8516) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:02:10.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:02:10.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:10.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:02:10.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:02:10.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:10.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:02:10.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:10.941+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:02:10.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:02:41.403+0000] {processor.py:157} INFO - Started process (PID=8536) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:02:41.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:02:41.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:41.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:02:41.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:02:41.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:41.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:02:41.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:41.431+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:02:41.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.036 seconds
[2024-07-10T15:03:11.886+0000] {processor.py:157} INFO - Started process (PID=8556) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:03:11.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:03:11.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:11.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:03:11.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:03:11.910+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:11.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:03:11.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:11.920+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:03:11.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:03:42.351+0000] {processor.py:157} INFO - Started process (PID=8576) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:03:42.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:03:42.353+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:42.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:03:42.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:03:42.375+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:42.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:03:42.385+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:42.385+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:03:42.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:04:12.875+0000] {processor.py:157} INFO - Started process (PID=8596) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:04:12.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:04:12.877+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:12.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:04:12.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:04:12.899+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:12.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:04:12.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:12.909+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:04:12.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:04:43.404+0000] {processor.py:157} INFO - Started process (PID=8616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:04:43.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:04:43.406+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:43.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:04:43.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:04:43.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:43.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:04:43.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:43.438+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:04:43.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:05:13.828+0000] {processor.py:157} INFO - Started process (PID=8636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:05:13.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:05:13.831+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:13.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:05:13.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:05:13.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:13.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:05:13.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:13.862+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:05:13.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:05:44.397+0000] {processor.py:157} INFO - Started process (PID=8656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:05:44.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:05:44.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:44.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:05:44.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:05:44.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:44.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:05:44.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:44.431+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:05:44.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:06:14.834+0000] {processor.py:157} INFO - Started process (PID=8676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:06:14.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:06:14.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:14.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:06:14.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:06:14.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:14.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:06:14.870+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:14.870+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:06:14.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:06:45.342+0000] {processor.py:157} INFO - Started process (PID=8696) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:06:45.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:06:45.344+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:45.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:06:45.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:06:45.366+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:45.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:06:45.376+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:45.376+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:06:45.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:07:15.784+0000] {processor.py:157} INFO - Started process (PID=8716) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:07:15.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:07:15.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:15.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:07:15.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:07:15.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:15.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:07:15.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:15.821+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:07:15.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T15:07:46.144+0000] {processor.py:157} INFO - Started process (PID=8736) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:07:46.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:07:46.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:46.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:07:46.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:07:46.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:46.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:07:46.180+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:46.180+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:07:46.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T15:08:16.594+0000] {processor.py:157} INFO - Started process (PID=8756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:08:16.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:08:16.596+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:16.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:08:16.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:08:16.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:16.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:08:16.632+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:16.632+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:08:16.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T15:08:47.045+0000] {processor.py:157} INFO - Started process (PID=8776) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:08:47.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:08:47.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:47.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:08:47.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:08:47.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:47.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:08:47.082+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:47.082+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:08:47.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T15:09:17.495+0000] {processor.py:157} INFO - Started process (PID=8796) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:09:17.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:09:17.497+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:17.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:09:17.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:09:17.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:17.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:09:17.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:17.531+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:09:17.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T15:09:47.954+0000] {processor.py:157} INFO - Started process (PID=8815) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:09:47.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:09:47.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:47.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:09:47.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:09:47.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:47.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:09:48.012+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:48.011+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:09:48.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.070 seconds
[2024-07-10T15:10:18.455+0000] {processor.py:157} INFO - Started process (PID=8836) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:10:18.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:10:18.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:18.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:10:18.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:10:18.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:18.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:10:18.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:18.489+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:10:18.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:10:48.968+0000] {processor.py:157} INFO - Started process (PID=8856) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:10:48.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:10:48.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:48.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:10:48.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:10:48.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:48.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:10:49.002+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:49.002+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:10:49.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T15:11:19.484+0000] {processor.py:157} INFO - Started process (PID=8876) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:11:19.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:11:19.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:19.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:11:19.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:11:19.509+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:19.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:11:19.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:19.519+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:11:19.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:11:49.993+0000] {processor.py:157} INFO - Started process (PID=8896) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:11:49.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:11:49.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:49.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:11:50.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:11:50.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:50.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:11:50.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:50.027+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:11:50.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:12:20.519+0000] {processor.py:157} INFO - Started process (PID=8916) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:12:20.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:12:20.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:20.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:12:20.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:12:20.542+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:20.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:12:20.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:20.551+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:12:20.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T15:12:50.986+0000] {processor.py:157} INFO - Started process (PID=8936) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:12:50.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:12:50.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:50.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:12:50.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:12:51.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:51.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:12:51.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:51.018+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:12:51.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T15:13:21.538+0000] {processor.py:157} INFO - Started process (PID=8956) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:13:21.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:13:21.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:21.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:13:21.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:13:21.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:21.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:13:21.571+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:21.571+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:13:21.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:13:52.104+0000] {processor.py:157} INFO - Started process (PID=8976) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:13:52.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:13:52.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:52.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:13:52.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:13:52.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:52.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:13:52.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:52.139+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:13:52.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:14:22.619+0000] {processor.py:157} INFO - Started process (PID=8996) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:14:22.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:14:22.621+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:22.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:14:22.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:14:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:14:22.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:22.653+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:14:22.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:14:53.172+0000] {processor.py:157} INFO - Started process (PID=9016) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:14:53.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:14:53.174+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:53.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:14:53.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:14:53.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:53.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:14:53.208+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:53.208+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:14:53.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T15:15:23.710+0000] {processor.py:157} INFO - Started process (PID=9036) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:15:23.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:15:23.712+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:23.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:15:23.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:15:23.734+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:23.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:15:23.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:23.743+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:15:23.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:15:54.279+0000] {processor.py:157} INFO - Started process (PID=9056) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:15:54.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:15:54.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:54.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:15:54.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:15:54.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:54.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:15:54.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:54.313+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:15:54.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:16:24.782+0000] {processor.py:157} INFO - Started process (PID=9076) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:16:24.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:16:24.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:24.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:16:24.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:16:24.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:24.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:16:24.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:24.821+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:16:24.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T15:16:55.352+0000] {processor.py:157} INFO - Started process (PID=9096) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:16:55.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:16:55.355+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:55.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:16:55.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:16:55.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:55.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:16:55.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:55.399+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:16:55.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T15:17:25.914+0000] {processor.py:157} INFO - Started process (PID=9116) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:17:25.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:17:25.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:25.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:17:25.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:17:25.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:25.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:17:25.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:25.948+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:17:25.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:17:56.423+0000] {processor.py:157} INFO - Started process (PID=9136) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:17:56.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:17:56.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:56.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:17:56.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:17:56.447+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:56.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:17:56.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:56.457+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:17:56.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:18:26.911+0000] {processor.py:157} INFO - Started process (PID=9156) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:18:26.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:18:26.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:26.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:18:26.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:18:26.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:26.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:18:26.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:26.943+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:18:26.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:18:57.394+0000] {processor.py:157} INFO - Started process (PID=9176) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:18:57.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:18:57.396+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:57.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:18:57.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:18:57.417+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:57.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:18:57.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:57.427+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:18:57.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:19:27.949+0000] {processor.py:157} INFO - Started process (PID=9196) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:19:27.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:19:27.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:27.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:19:27.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:19:27.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:27.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:19:27.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:27.981+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:19:27.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T15:19:58.468+0000] {processor.py:157} INFO - Started process (PID=9216) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:19:58.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:19:58.470+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:58.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:19:58.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:19:58.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:58.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:19:58.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:58.502+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:19:58.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:20:28.959+0000] {processor.py:157} INFO - Started process (PID=9236) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:20:28.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:20:28.961+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:28.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:20:28.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:20:28.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:28.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:20:28.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:28.992+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:20:28.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:20:59.506+0000] {processor.py:157} INFO - Started process (PID=9256) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:20:59.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:20:59.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:59.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:20:59.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:20:59.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:59.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:20:59.539+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:59.538+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:20:59.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:21:30.025+0000] {processor.py:157} INFO - Started process (PID=9276) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:21:30.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:21:30.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:21:30.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:21:30.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:21:30.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:21:30.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:21:30.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:21:30.057+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:21:30.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T15:22:00.547+0000] {processor.py:157} INFO - Started process (PID=9296) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:22:00.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:22:00.549+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:00.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:22:00.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:22:00.571+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:00.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:22:00.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:00.581+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:22:00.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:22:31.061+0000] {processor.py:157} INFO - Started process (PID=9316) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:22:31.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:22:31.063+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:31.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:22:31.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:22:31.088+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:31.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:22:31.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:31.099+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:22:31.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T15:23:01.521+0000] {processor.py:157} INFO - Started process (PID=9336) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:23:01.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:23:01.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:01.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:23:01.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:23:01.545+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:01.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:23:01.555+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:01.555+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:23:01.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T15:23:32.034+0000] {processor.py:157} INFO - Started process (PID=9356) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:23:32.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:23:32.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:32.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:23:32.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:23:32.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:32.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:23:32.069+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:32.069+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:23:32.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T15:24:02.552+0000] {processor.py:157} INFO - Started process (PID=9376) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:24:02.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:24:02.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:02.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:24:02.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:24:02.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:02.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:24:02.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:02.585+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:24:02.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:24:33.044+0000] {processor.py:157} INFO - Started process (PID=9396) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:24:33.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:24:33.046+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:33.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:24:33.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:24:33.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:33.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:24:33.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:33.076+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:24:33.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T15:25:03.563+0000] {processor.py:157} INFO - Started process (PID=9416) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:25:03.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:25:03.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:03.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:25:03.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:25:03.589+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:03.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:25:03.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:03.598+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:25:03.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T15:25:34.057+0000] {processor.py:157} INFO - Started process (PID=9436) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:25:34.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:25:34.060+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:34.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:25:34.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:25:34.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:34.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:25:34.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:34.101+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:25:34.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T15:26:04.577+0000] {processor.py:157} INFO - Started process (PID=9456) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:26:04.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:26:04.579+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:04.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:26:04.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:26:04.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:04.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:26:04.611+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:04.611+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:26:04.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:26:35.088+0000] {processor.py:157} INFO - Started process (PID=9476) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:26:35.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:26:35.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:35.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:26:35.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:26:35.112+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:35.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:26:35.122+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:35.122+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:26:35.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:27:05.553+0000] {processor.py:157} INFO - Started process (PID=9496) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:27:05.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:27:05.555+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:05.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:27:05.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:27:05.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:05.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:27:05.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:05.586+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:27:05.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:27:35.949+0000] {processor.py:157} INFO - Started process (PID=9516) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:27:35.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:27:35.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:35.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:27:35.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:27:35.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:35.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:27:35.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:35.982+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:27:35.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:28:06.431+0000] {processor.py:157} INFO - Started process (PID=9536) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:28:06.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:28:06.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:06.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:28:06.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:28:06.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:06.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:28:06.464+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:06.464+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:28:06.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:28:36.826+0000] {processor.py:157} INFO - Started process (PID=9556) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:28:36.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:28:36.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:36.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:28:36.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:28:36.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:36.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:28:36.860+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:36.860+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:28:36.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:29:07.244+0000] {processor.py:157} INFO - Started process (PID=9576) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:29:07.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:29:07.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:07.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:29:07.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:29:07.269+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:07.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:29:07.279+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:07.279+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:29:07.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T15:29:37.707+0000] {processor.py:157} INFO - Started process (PID=9596) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:29:37.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:29:37.710+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:37.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:29:37.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:29:37.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:37.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:29:37.742+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:37.742+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:29:37.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:30:08.128+0000] {processor.py:157} INFO - Started process (PID=9616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:30:08.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:30:08.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:08.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:30:08.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:30:08.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:08.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:30:08.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:08.160+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:30:08.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T15:30:38.628+0000] {processor.py:157} INFO - Started process (PID=9636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:30:38.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:30:38.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:38.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:30:38.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:30:38.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:38.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:30:38.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:38.664+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:30:38.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T15:31:09.177+0000] {processor.py:157} INFO - Started process (PID=9656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:31:09.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:31:09.180+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:09.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:31:09.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:31:09.201+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:09.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:31:09.212+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:09.212+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:31:09.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:31:39.752+0000] {processor.py:157} INFO - Started process (PID=9676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:31:39.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:31:39.754+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:39.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:31:39.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:31:39.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:39.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:31:39.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:39.786+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:31:39.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:32:10.217+0000] {processor.py:157} INFO - Started process (PID=9696) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:32:10.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:32:10.219+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:10.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:32:10.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:32:10.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:10.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:32:10.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:10.252+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:32:10.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:32:40.732+0000] {processor.py:157} INFO - Started process (PID=9716) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:32:40.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:32:40.735+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:40.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:32:40.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:32:40.757+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:40.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:32:40.767+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:40.767+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:32:40.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:33:11.250+0000] {processor.py:157} INFO - Started process (PID=9736) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:33:11.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:33:11.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:11.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:33:11.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:33:11.274+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:11.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:33:11.284+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:11.284+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:33:11.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:33:41.774+0000] {processor.py:157} INFO - Started process (PID=9756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:33:41.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:33:41.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:41.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:33:41.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:33:41.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:41.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:33:41.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:41.808+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:33:41.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:34:12.237+0000] {processor.py:157} INFO - Started process (PID=9776) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:34:12.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:34:12.239+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:12.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:34:12.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:34:12.261+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:12.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:34:12.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:12.271+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:34:12.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:34:42.775+0000] {processor.py:157} INFO - Started process (PID=9796) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:34:42.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:34:42.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:42.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:34:42.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:34:42.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:42.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:34:42.814+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:42.814+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:34:42.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T15:35:13.296+0000] {processor.py:157} INFO - Started process (PID=9816) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:35:13.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:35:13.298+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:13.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:35:13.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:35:13.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:13.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:35:13.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:13.329+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:35:13.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:35:43.822+0000] {processor.py:157} INFO - Started process (PID=9836) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:35:43.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:35:43.824+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:43.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:35:43.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:35:43.845+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:43.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:35:43.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:43.854+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:35:43.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:36:14.358+0000] {processor.py:157} INFO - Started process (PID=9856) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:36:14.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:36:14.360+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:14.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:36:14.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:36:14.380+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:14.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:36:14.389+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:14.389+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:36:14.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T15:36:44.859+0000] {processor.py:157} INFO - Started process (PID=9876) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:36:44.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:36:44.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:44.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:36:44.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:36:44.883+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:44.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:36:44.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:44.892+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:36:44.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:37:15.371+0000] {processor.py:157} INFO - Started process (PID=9896) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:37:15.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:37:15.373+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:15.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:37:15.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:37:15.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:15.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:37:15.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:15.404+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:37:15.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:37:45.873+0000] {processor.py:157} INFO - Started process (PID=9916) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:37:45.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:37:45.876+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:45.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:37:45.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:37:45.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:45.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:37:45.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:45.913+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:37:45.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T15:38:16.370+0000] {processor.py:157} INFO - Started process (PID=9936) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:38:16.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:38:16.372+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:16.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:38:16.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:38:16.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:16.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:38:16.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:16.404+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:38:16.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:38:46.916+0000] {processor.py:157} INFO - Started process (PID=9956) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:38:46.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:38:46.919+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:46.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:38:46.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:38:46.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:46.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:38:46.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:46.962+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:38:46.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T15:39:17.444+0000] {processor.py:157} INFO - Started process (PID=9976) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:39:17.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:39:17.446+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:17.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:39:17.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:39:17.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:17.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:39:17.478+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:17.478+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:39:17.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:39:47.985+0000] {processor.py:157} INFO - Started process (PID=9996) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:39:47.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:39:47.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:47.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:39:47.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:39:48.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:48.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:39:48.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:48.017+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:39:48.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:40:18.454+0000] {processor.py:157} INFO - Started process (PID=10016) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:40:18.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:40:18.458+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:18.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:40:18.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:40:18.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:18.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:40:18.488+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:18.488+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:40:18.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:40:48.853+0000] {processor.py:157} INFO - Started process (PID=10036) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:40:48.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:40:48.856+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:48.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:40:48.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:40:48.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:48.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:40:48.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:48.888+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:40:48.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:41:19.283+0000] {processor.py:157} INFO - Started process (PID=10056) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:41:19.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:41:19.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:19.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:41:19.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:41:19.306+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:19.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:41:19.316+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:19.316+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:41:19.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:41:49.762+0000] {processor.py:157} INFO - Started process (PID=10076) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:41:49.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:41:49.765+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:49.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:41:49.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:41:49.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:49.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:41:49.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:49.795+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:41:49.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:42:20.287+0000] {processor.py:157} INFO - Started process (PID=10096) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:42:20.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:42:20.289+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:20.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:42:20.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:42:20.310+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:20.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:42:20.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:20.320+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:42:20.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:42:50.746+0000] {processor.py:157} INFO - Started process (PID=10116) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:42:50.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:42:50.748+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:50.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:42:50.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:42:50.769+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:50.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:42:50.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:50.779+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:42:50.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:43:21.251+0000] {processor.py:157} INFO - Started process (PID=10136) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:43:21.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:43:21.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:21.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:43:21.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:43:21.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:21.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:43:21.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:21.281+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:43:21.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.038 seconds
[2024-07-10T15:43:51.769+0000] {processor.py:157} INFO - Started process (PID=10156) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:43:51.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:43:51.770+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:51.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:43:51.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:43:51.792+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:51.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:43:51.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:51.802+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:43:51.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:44:22.317+0000] {processor.py:157} INFO - Started process (PID=10176) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:44:22.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:44:22.319+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:22.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:44:22.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:44:22.341+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:22.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:44:22.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:22.350+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:44:22.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:44:52.831+0000] {processor.py:157} INFO - Started process (PID=10196) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:44:52.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:44:52.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:52.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:44:52.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:44:52.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:52.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:44:52.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:52.864+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:44:52.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:45:23.287+0000] {processor.py:157} INFO - Started process (PID=10216) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:45:23.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:45:23.290+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:23.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:45:23.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:45:23.311+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:23.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:45:23.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:23.321+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:45:23.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:45:53.838+0000] {processor.py:157} INFO - Started process (PID=10236) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:45:53.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:45:53.840+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:53.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:45:53.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:45:53.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:53.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:45:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:53.872+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:45:53.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:46:24.319+0000] {processor.py:157} INFO - Started process (PID=10256) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:46:24.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:46:24.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:24.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:46:24.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:46:24.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:24.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:46:24.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:24.352+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:46:24.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:46:54.813+0000] {processor.py:157} INFO - Started process (PID=10276) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:46:54.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:46:54.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:54.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:46:54.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:46:54.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:54.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:46:54.847+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:54.847+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:46:54.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:47:25.403+0000] {processor.py:157} INFO - Started process (PID=10296) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:47:25.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:47:25.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:25.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:47:25.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:47:25.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:25.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:47:25.437+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:25.437+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:47:25.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:47:55.932+0000] {processor.py:157} INFO - Started process (PID=10316) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:47:55.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:47:55.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:55.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:47:55.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:47:55.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:55.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:47:55.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:55.966+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:47:55.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:48:26.411+0000] {processor.py:157} INFO - Started process (PID=10336) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:48:26.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:48:26.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:26.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:48:26.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:48:26.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:26.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:48:26.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:26.445+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:48:26.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:48:56.813+0000] {processor.py:157} INFO - Started process (PID=10356) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:48:56.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:48:56.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:56.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:48:56.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:48:56.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:56.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:48:56.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:56.849+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:48:56.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T15:49:27.294+0000] {processor.py:157} INFO - Started process (PID=10376) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:49:27.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:49:27.297+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:27.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:49:27.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:49:27.322+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:27.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:49:27.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:27.331+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:49:27.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T15:49:57.742+0000] {processor.py:157} INFO - Started process (PID=10396) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:49:57.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:49:57.744+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:57.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:49:57.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:49:57.768+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:57.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:49:57.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:57.778+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:49:57.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T15:50:28.090+0000] {processor.py:157} INFO - Started process (PID=10416) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:50:28.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:50:28.092+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:28.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:50:28.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:50:28.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:28.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:50:28.126+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:28.126+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:50:28.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T15:50:58.528+0000] {processor.py:157} INFO - Started process (PID=10436) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:50:58.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:50:58.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:58.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:50:58.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:50:58.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:58.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:50:58.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:58.561+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:50:58.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:51:28.912+0000] {processor.py:157} INFO - Started process (PID=10456) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:51:28.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:51:28.914+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:28.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:51:28.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:51:28.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:28.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:51:28.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:28.944+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:51:28.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T15:51:59.369+0000] {processor.py:157} INFO - Started process (PID=10476) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:51:59.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:51:59.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:59.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:51:59.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:51:59.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:59.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:51:59.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:59.403+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:51:59.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:52:29.871+0000] {processor.py:157} INFO - Started process (PID=10496) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:52:29.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:52:29.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:52:29.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:52:29.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:52:29.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:52:29.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:52:29.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:52:29.905+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:52:29.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:53:00.315+0000] {processor.py:157} INFO - Started process (PID=10516) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:53:00.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:53:00.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:00.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:53:00.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:53:00.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:00.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:53:00.349+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:00.349+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:53:00.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:53:30.739+0000] {processor.py:157} INFO - Started process (PID=10536) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:53:30.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:53:30.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:30.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:53:30.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:53:30.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:30.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:53:30.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:30.771+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:53:30.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T15:54:01.211+0000] {processor.py:157} INFO - Started process (PID=10556) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:54:01.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:54:01.213+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:01.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:54:01.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:54:01.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:01.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:54:01.245+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:01.245+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:54:01.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:54:31.756+0000] {processor.py:157} INFO - Started process (PID=10576) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:54:31.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:54:31.758+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:31.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:54:31.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:54:31.781+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:31.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:54:31.791+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:31.791+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:54:31.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:55:02.290+0000] {processor.py:157} INFO - Started process (PID=10596) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:55:02.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:55:02.293+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:02.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:55:02.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:55:02.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:02.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:55:02.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:02.327+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:55:02.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T15:55:32.817+0000] {processor.py:157} INFO - Started process (PID=10616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:55:32.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:55:32.820+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:32.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:55:32.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:55:32.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:32.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:55:32.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:32.851+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:55:32.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:56:03.348+0000] {processor.py:157} INFO - Started process (PID=10636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:56:03.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:56:03.350+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:03.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:56:03.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:56:03.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:03.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:56:03.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:03.381+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:56:03.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:56:33.857+0000] {processor.py:157} INFO - Started process (PID=10656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:56:33.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:56:33.860+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:33.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:56:33.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:56:33.891+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:33.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:56:33.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:33.903+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:56:33.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T15:57:04.366+0000] {processor.py:157} INFO - Started process (PID=10676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:57:04.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:57:04.368+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:04.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:57:04.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:57:04.390+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:04.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:57:04.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:04.400+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:57:04.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T15:57:34.940+0000] {processor.py:157} INFO - Started process (PID=10696) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:57:34.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:57:34.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:34.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:57:34.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:57:34.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:34.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:57:34.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:34.973+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:57:34.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:58:05.467+0000] {processor.py:157} INFO - Started process (PID=10716) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:58:05.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:58:05.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:05.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:58:05.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:58:05.491+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:05.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:58:05.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:05.501+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:58:05.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:58:36.024+0000] {processor.py:157} INFO - Started process (PID=10736) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:58:36.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:58:36.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:36.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:58:36.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:58:36.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:36.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:58:36.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:36.058+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:58:36.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T15:59:06.556+0000] {processor.py:157} INFO - Started process (PID=10756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:59:06.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:59:06.558+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:06.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:59:06.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:59:06.580+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:06.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:59:06.589+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:06.589+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:59:06.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T15:59:37.033+0000] {processor.py:157} INFO - Started process (PID=10776) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:59:37.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T15:59:37.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:37.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:59:37.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T15:59:37.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:37.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:59:37.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:37.066+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:59:37.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:00:07.566+0000] {processor.py:157} INFO - Started process (PID=10796) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:00:07.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:00:07.568+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:07.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:00:07.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:00:07.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:07.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:00:07.599+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:07.599+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:00:07.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:00:38.087+0000] {processor.py:157} INFO - Started process (PID=10816) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:00:38.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:00:38.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:38.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:00:38.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:00:38.111+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:38.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:00:38.121+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:38.121+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:00:38.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:01:08.598+0000] {processor.py:157} INFO - Started process (PID=10836) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:01:08.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:01:08.600+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:08.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:01:08.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:01:08.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:08.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:01:08.632+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:08.631+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:01:08.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:01:39.102+0000] {processor.py:157} INFO - Started process (PID=10856) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:01:39.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:01:39.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:39.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:01:39.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:01:39.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:39.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:01:39.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:39.134+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:01:39.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T16:02:09.552+0000] {processor.py:157} INFO - Started process (PID=10876) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:02:09.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:02:09.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:09.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:02:09.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:02:09.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:09.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:02:09.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:09.585+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:02:09.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T16:02:40.093+0000] {processor.py:157} INFO - Started process (PID=10896) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:02:40.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:02:40.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:40.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:02:40.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:02:40.118+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:40.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:02:40.128+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:40.128+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:02:40.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:03:10.581+0000] {processor.py:157} INFO - Started process (PID=10916) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:03:10.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:03:10.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:10.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:03:10.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:03:10.604+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:10.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:03:10.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:10.614+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:03:10.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:03:41.122+0000] {processor.py:157} INFO - Started process (PID=10936) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:03:41.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:03:41.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:41.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:03:41.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:03:41.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:41.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:03:41.156+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:41.156+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:03:41.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:04:11.606+0000] {processor.py:157} INFO - Started process (PID=10956) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:04:11.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:04:11.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:11.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:04:11.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:04:11.630+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:11.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:04:11.639+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:11.639+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:04:11.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:04:42.141+0000] {processor.py:157} INFO - Started process (PID=10976) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:04:42.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:04:42.143+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:42.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:04:42.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:04:42.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:42.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:04:42.176+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:42.176+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:04:42.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:05:12.628+0000] {processor.py:157} INFO - Started process (PID=10996) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:05:12.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:05:12.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:12.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:05:12.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:05:12.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:12.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:05:12.665+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:12.665+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:05:12.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T16:05:43.054+0000] {processor.py:157} INFO - Started process (PID=11016) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:05:43.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:05:43.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:43.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:05:43.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:05:43.078+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:43.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:05:43.087+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:43.087+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:05:43.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:06:13.562+0000] {processor.py:157} INFO - Started process (PID=11036) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:06:13.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:06:13.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:13.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:06:13.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:06:13.599+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:13.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:06:13.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:13.610+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:06:13.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T16:06:44.074+0000] {processor.py:157} INFO - Started process (PID=11056) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:06:44.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:06:44.077+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:44.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:06:44.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:06:44.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:44.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:06:44.110+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:44.110+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:06:44.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T16:07:14.559+0000] {processor.py:157} INFO - Started process (PID=11076) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:07:14.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:07:14.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:14.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:07:14.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:07:14.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:14.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:07:14.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:14.592+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:07:14.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:07:45.082+0000] {processor.py:157} INFO - Started process (PID=11096) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:07:45.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:07:45.085+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:45.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:07:45.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:07:45.107+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:45.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:07:45.117+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:45.117+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:07:45.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:08:15.585+0000] {processor.py:157} INFO - Started process (PID=11116) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:08:15.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:08:15.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:15.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:08:15.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:08:15.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:15.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:08:15.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:15.619+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:08:15.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:08:45.991+0000] {processor.py:157} INFO - Started process (PID=11136) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:08:45.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:08:45.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:45.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:08:46.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:08:46.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:46.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:08:46.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:46.025+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:08:46.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:09:16.515+0000] {processor.py:157} INFO - Started process (PID=11154) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:09:16.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:09:16.518+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:16.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:09:16.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:09:16.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:16.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:09:16.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:16.559+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:09:16.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.065 seconds
[2024-07-10T16:09:46.990+0000] {processor.py:157} INFO - Started process (PID=11176) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:09:46.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:09:46.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:46.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:09:47.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:09:47.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:47.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:09:47.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:47.028+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:09:47.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T16:10:17.510+0000] {processor.py:157} INFO - Started process (PID=11196) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:10:17.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:10:17.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:17.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:10:17.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:10:17.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:17.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:10:17.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:17.544+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:10:17.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:10:47.980+0000] {processor.py:157} INFO - Started process (PID=11216) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:10:47.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:10:47.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:47.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:10:47.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:10:48.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:48.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:10:48.010+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:48.010+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:10:48.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.038 seconds
[2024-07-10T16:11:18.467+0000] {processor.py:157} INFO - Started process (PID=11236) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:11:18.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:11:18.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:18.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:11:18.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:11:18.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:18.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:11:18.499+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:18.499+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:11:18.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T16:11:48.893+0000] {processor.py:157} INFO - Started process (PID=11256) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:11:48.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:11:48.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:48.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:11:48.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:11:48.917+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:48.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:11:48.927+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:48.927+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:11:48.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:12:19.317+0000] {processor.py:157} INFO - Started process (PID=11276) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:12:19.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:12:19.319+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:19.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:12:19.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:12:19.344+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:19.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:12:19.355+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:19.355+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:12:19.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T16:12:49.806+0000] {processor.py:157} INFO - Started process (PID=11296) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:12:49.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:12:49.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:49.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:12:49.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:12:49.829+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:49.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:12:49.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:49.839+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:12:49.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:13:20.257+0000] {processor.py:157} INFO - Started process (PID=11316) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:13:20.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:13:20.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:20.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:13:20.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:13:20.282+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:20.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:13:20.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:20.291+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:13:20.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:13:50.807+0000] {processor.py:157} INFO - Started process (PID=11336) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:13:50.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:13:50.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:50.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:13:50.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:13:50.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:50.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:13:50.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:50.842+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:13:50.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:14:21.332+0000] {processor.py:157} INFO - Started process (PID=11356) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:14:21.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:14:21.335+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:21.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:14:21.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:14:21.366+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:21.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:14:21.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:21.377+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:14:21.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T16:14:51.847+0000] {processor.py:157} INFO - Started process (PID=11376) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:14:51.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:14:51.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:51.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:14:51.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:14:51.871+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:51.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:14:51.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:51.881+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:14:51.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:15:22.376+0000] {processor.py:157} INFO - Started process (PID=11396) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:15:22.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:15:22.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:22.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:15:22.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:15:22.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:22.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:15:22.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:22.410+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:15:22.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:15:52.905+0000] {processor.py:157} INFO - Started process (PID=11416) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:15:52.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:15:52.907+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:52.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:15:52.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:15:52.928+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:52.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:15:52.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:52.938+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:15:52.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:16:23.375+0000] {processor.py:157} INFO - Started process (PID=11436) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:16:23.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:16:23.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:23.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:16:23.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:16:23.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:23.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:16:23.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:23.408+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:16:23.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T16:16:53.849+0000] {processor.py:157} INFO - Started process (PID=11456) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:16:53.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:16:53.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:53.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:16:53.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:16:53.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:53.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:16:53.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:53.921+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:16:53.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.081 seconds
[2024-07-10T16:17:24.363+0000] {processor.py:157} INFO - Started process (PID=11476) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:17:24.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:17:24.365+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:24.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:17:24.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:17:24.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:24.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:17:24.396+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:24.396+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:17:24.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:17:54.861+0000] {processor.py:157} INFO - Started process (PID=11496) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:17:54.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:17:54.863+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:54.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:17:54.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:17:54.884+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:54.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:17:54.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:54.895+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:17:54.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:18:25.348+0000] {processor.py:157} INFO - Started process (PID=11516) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:18:25.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:18:25.350+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:25.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:18:25.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:18:25.373+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:25.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:18:25.382+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:25.382+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:18:25.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:18:55.878+0000] {processor.py:157} INFO - Started process (PID=11536) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:18:55.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:18:55.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:55.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:18:55.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:18:55.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:55.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:18:55.912+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:55.912+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:18:55.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:19:26.406+0000] {processor.py:157} INFO - Started process (PID=11556) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:19:26.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:19:26.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:26.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:19:26.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:19:26.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:26.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:19:26.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:26.439+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:19:26.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:19:56.916+0000] {processor.py:157} INFO - Started process (PID=11576) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:19:56.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:19:56.918+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:56.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:19:56.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:19:56.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:56.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:19:56.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:56.951+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:19:56.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:20:27.417+0000] {processor.py:157} INFO - Started process (PID=11596) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:20:27.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:20:27.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:27.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:20:27.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:20:27.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:27.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:20:27.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:27.449+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:20:27.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T16:20:57.989+0000] {processor.py:157} INFO - Started process (PID=11616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:20:57.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:20:57.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:57.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:20:58.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:20:58.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:58.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:20:58.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:58.026+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:20:58.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T16:21:28.494+0000] {processor.py:157} INFO - Started process (PID=11636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:21:28.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:21:28.496+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:28.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:21:28.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:21:28.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:28.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:21:28.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:28.530+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:21:28.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:21:59.015+0000] {processor.py:157} INFO - Started process (PID=11656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:21:59.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:21:59.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:59.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:21:59.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:21:59.040+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:59.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:21:59.052+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:59.052+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:21:59.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T16:22:29.484+0000] {processor.py:157} INFO - Started process (PID=11676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:22:29.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:22:29.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:22:29.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:22:29.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:22:29.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:22:29.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:22:29.518+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:22:29.517+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:22:29.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:22:59.992+0000] {processor.py:157} INFO - Started process (PID=11696) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:22:59.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:22:59.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:22:59.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:23:00.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:23:00.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:00.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:23:00.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:00.035+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:23:00.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T16:23:30.539+0000] {processor.py:157} INFO - Started process (PID=11716) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:23:30.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:23:30.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:30.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:23:30.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:23:30.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:30.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:23:30.575+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:30.575+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:23:30.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:24:01.001+0000] {processor.py:157} INFO - Started process (PID=11736) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:24:01.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:24:01.003+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:01.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:24:01.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:24:01.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:01.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:24:01.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:01.035+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:24:01.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:24:31.533+0000] {processor.py:157} INFO - Started process (PID=11756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:24:31.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:24:31.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:31.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:24:31.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:24:31.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:31.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:24:31.567+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:31.567+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:24:31.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:25:02.092+0000] {processor.py:157} INFO - Started process (PID=11776) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:25:02.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:25:02.097+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:02.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:25:02.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:25:02.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:02.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:25:02.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:02.138+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:25:02.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T16:25:32.625+0000] {processor.py:157} INFO - Started process (PID=11796) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:25:32.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:25:32.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:32.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:25:32.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:25:32.651+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:32.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:25:32.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:32.661+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:25:32.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:26:03.118+0000] {processor.py:157} INFO - Started process (PID=11816) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:26:03.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:26:03.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:03.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:26:03.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:26:03.141+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:03.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:26:03.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:03.151+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:26:03.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:26:33.610+0000] {processor.py:157} INFO - Started process (PID=11836) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:26:33.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:26:33.612+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:33.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:26:33.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:26:33.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:33.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:26:33.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:33.643+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:26:33.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T16:27:04.124+0000] {processor.py:157} INFO - Started process (PID=11856) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:27:04.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:27:04.126+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:04.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:27:04.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:27:04.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:04.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:27:04.158+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:04.158+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:27:04.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:27:34.595+0000] {processor.py:157} INFO - Started process (PID=11876) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:27:34.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:27:34.597+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:34.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:27:34.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:27:34.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:34.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:27:34.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:34.629+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:27:34.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:28:05.121+0000] {processor.py:157} INFO - Started process (PID=11896) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:28:05.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:28:05.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:05.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:28:05.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:28:05.145+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:05.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:28:05.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:05.154+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:28:05.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:28:35.629+0000] {processor.py:157} INFO - Started process (PID=11916) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:28:35.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:28:35.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:35.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:28:35.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:28:35.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:35.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:28:35.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:35.662+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:28:35.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T16:29:06.110+0000] {processor.py:157} INFO - Started process (PID=11936) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:29:06.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:29:06.112+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:06.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:29:06.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:29:06.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:06.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:29:06.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:06.144+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:29:06.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:29:36.582+0000] {processor.py:157} INFO - Started process (PID=11956) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:29:36.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:29:36.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:36.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:29:36.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:29:36.606+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:36.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:29:36.616+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:36.616+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:29:36.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:30:07.097+0000] {processor.py:157} INFO - Started process (PID=11976) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:30:07.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:30:07.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:07.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:30:07.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:30:07.122+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:07.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:30:07.132+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:07.132+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:30:07.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:30:37.601+0000] {processor.py:157} INFO - Started process (PID=11996) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:30:37.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:30:37.604+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:37.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:30:37.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:30:37.625+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:37.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:30:37.635+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:37.635+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:30:37.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:31:08.115+0000] {processor.py:157} INFO - Started process (PID=12016) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:31:08.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:31:08.117+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:08.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:31:08.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:31:08.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:08.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:31:08.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:08.148+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:31:08.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:31:38.607+0000] {processor.py:157} INFO - Started process (PID=12036) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:31:38.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:31:38.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:38.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:31:38.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:31:38.637+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:38.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:31:38.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:38.648+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:31:38.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T16:32:09.074+0000] {processor.py:157} INFO - Started process (PID=12056) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:32:09.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:32:09.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:09.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:32:09.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:32:09.097+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:09.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:32:09.107+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:09.107+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:32:09.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:32:39.555+0000] {processor.py:157} INFO - Started process (PID=12076) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:32:39.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:32:39.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:39.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:32:39.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:32:39.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:39.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:32:39.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:39.588+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:32:39.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:33:10.080+0000] {processor.py:157} INFO - Started process (PID=12096) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:33:10.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:33:10.082+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:10.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:33:10.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:33:10.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:10.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:33:10.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:10.113+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:33:10.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:33:40.619+0000] {processor.py:157} INFO - Started process (PID=12116) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:33:40.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:33:40.621+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:40.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:33:40.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:33:40.651+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:40.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:33:40.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:40.661+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:33:40.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T16:34:11.140+0000] {processor.py:157} INFO - Started process (PID=12136) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:34:11.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:34:11.142+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:11.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:34:11.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:34:11.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:11.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:34:11.175+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:11.175+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:34:11.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:34:41.643+0000] {processor.py:157} INFO - Started process (PID=12156) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:34:41.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:34:41.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:41.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:34:41.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:34:41.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:41.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:34:41.681+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:41.681+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:34:41.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T16:35:12.100+0000] {processor.py:157} INFO - Started process (PID=12176) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:35:12.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:35:12.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:12.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:35:12.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:35:12.124+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:12.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:35:12.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:12.134+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:35:12.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:35:42.560+0000] {processor.py:157} INFO - Started process (PID=12196) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:35:42.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:35:42.564+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:42.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:35:42.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:35:42.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:42.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:35:42.595+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:42.595+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:35:42.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:36:13.095+0000] {processor.py:157} INFO - Started process (PID=12216) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:36:13.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:36:13.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:13.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:36:13.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:36:13.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:13.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:36:13.126+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:13.126+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:36:13.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:36:43.626+0000] {processor.py:157} INFO - Started process (PID=12236) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:36:43.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:36:43.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:43.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:36:43.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:36:43.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:43.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:36:43.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:43.660+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:36:43.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:37:14.145+0000] {processor.py:157} INFO - Started process (PID=12256) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:37:14.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:37:14.147+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:14.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:37:14.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:37:14.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:14.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:37:14.179+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:14.179+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:37:14.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:37:44.659+0000] {processor.py:157} INFO - Started process (PID=12276) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:37:44.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:37:44.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:44.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:37:44.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:37:44.684+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:44.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:37:44.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:44.693+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:37:44.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:38:15.174+0000] {processor.py:157} INFO - Started process (PID=12296) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:38:15.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:38:15.176+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:15.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:38:15.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:38:15.199+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:15.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:38:15.209+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:15.209+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:38:15.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:38:45.688+0000] {processor.py:157} INFO - Started process (PID=12316) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:38:45.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:38:45.690+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:45.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:38:45.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:38:45.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:45.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:38:45.725+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:45.724+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:38:45.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:39:16.187+0000] {processor.py:157} INFO - Started process (PID=12336) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:39:16.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:39:16.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:16.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:39:16.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:39:16.211+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:16.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:39:16.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:16.221+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:39:16.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:39:46.709+0000] {processor.py:157} INFO - Started process (PID=12356) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:39:46.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:39:46.712+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:46.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:39:46.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:39:46.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:46.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:39:46.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:46.746+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:39:46.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T16:40:17.218+0000] {processor.py:157} INFO - Started process (PID=12376) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:40:17.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:40:17.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:17.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:40:17.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:40:17.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:17.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:40:17.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:17.252+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:40:17.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:40:47.726+0000] {processor.py:157} INFO - Started process (PID=12396) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:40:47.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:40:47.729+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:47.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:40:47.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:40:47.750+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:47.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:40:47.760+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:47.760+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:40:47.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:41:18.260+0000] {processor.py:157} INFO - Started process (PID=12416) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:41:18.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:41:18.262+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:18.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:41:18.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:41:18.284+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:18.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:41:18.294+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:18.294+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:41:18.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:41:48.745+0000] {processor.py:157} INFO - Started process (PID=12436) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:41:48.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:41:48.748+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:48.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:41:48.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:41:48.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:48.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:41:48.788+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:48.788+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:41:48.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T16:42:19.249+0000] {processor.py:157} INFO - Started process (PID=12456) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:42:19.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:42:19.251+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:19.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:42:19.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:42:19.273+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:19.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:42:19.283+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:19.283+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:42:19.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:42:49.791+0000] {processor.py:157} INFO - Started process (PID=12476) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:42:49.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:42:49.793+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:49.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:42:49.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:42:49.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:49.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:42:49.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:49.826+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:42:49.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:43:20.367+0000] {processor.py:157} INFO - Started process (PID=12496) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:43:20.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:43:20.369+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:20.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:43:20.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:43:20.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:20.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:43:20.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:20.405+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:43:20.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T16:43:50.906+0000] {processor.py:157} INFO - Started process (PID=12516) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:43:50.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:43:50.908+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:50.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:43:50.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:43:50.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:50.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:43:50.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:50.942+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:43:50.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:44:21.401+0000] {processor.py:157} INFO - Started process (PID=12536) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:44:21.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:44:21.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:21.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:44:21.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:44:21.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:21.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:44:21.435+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:21.435+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:44:21.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:44:51.920+0000] {processor.py:157} INFO - Started process (PID=12556) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:44:51.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:44:51.922+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:51.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:44:51.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:44:51.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:51.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:44:51.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:51.953+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:44:51.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:45:22.376+0000] {processor.py:157} INFO - Started process (PID=12576) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:45:22.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:45:22.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:22.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:45:22.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:45:22.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:22.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:45:22.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:22.411+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:45:22.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:45:52.925+0000] {processor.py:157} INFO - Started process (PID=12596) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:45:52.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:45:52.927+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:52.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:45:52.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:45:52.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:52.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:45:52.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:52.958+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:45:52.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:46:23.386+0000] {processor.py:157} INFO - Started process (PID=12616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:46:23.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:46:23.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:23.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:46:23.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:46:23.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:23.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:46:23.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:23.421+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:46:23.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:46:53.921+0000] {processor.py:157} INFO - Started process (PID=12636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:46:53.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:46:53.923+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:53.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:46:53.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:46:53.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:53.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:46:53.954+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:53.954+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:46:53.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:47:24.393+0000] {processor.py:157} INFO - Started process (PID=12656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:47:24.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:47:24.395+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:24.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:47:24.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:47:24.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:24.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:47:24.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:24.425+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:47:24.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T16:47:54.857+0000] {processor.py:157} INFO - Started process (PID=12676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:47:54.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:47:54.859+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:54.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:47:54.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:47:54.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:54.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:47:54.890+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:54.890+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:47:54.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:48:25.375+0000] {processor.py:157} INFO - Started process (PID=12696) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:48:25.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:48:25.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:25.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:48:25.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:48:25.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:25.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:48:25.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:25.410+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:48:25.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:48:55.869+0000] {processor.py:157} INFO - Started process (PID=12716) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:48:55.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:48:55.871+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:55.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:48:55.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:48:55.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:55.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:48:55.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:55.901+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:48:55.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:49:26.402+0000] {processor.py:157} INFO - Started process (PID=12736) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:49:26.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:49:26.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:26.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:49:26.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:49:26.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:26.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:49:26.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:26.432+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:49:26.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.038 seconds
[2024-07-10T16:49:56.909+0000] {processor.py:157} INFO - Started process (PID=12756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:49:56.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:49:56.912+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:56.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:49:56.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:49:56.933+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:56.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:49:56.943+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:56.943+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:49:56.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:50:27.404+0000] {processor.py:157} INFO - Started process (PID=12776) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:50:27.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:50:27.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:27.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:50:27.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:50:27.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:27.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:50:27.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:27.438+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:50:27.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:50:57.905+0000] {processor.py:157} INFO - Started process (PID=12796) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:50:57.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:50:57.907+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:57.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:50:57.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:50:57.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:57.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:50:57.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:57.938+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:50:57.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:51:28.414+0000] {processor.py:157} INFO - Started process (PID=12816) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:51:28.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:51:28.416+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:28.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:51:28.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:51:28.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:28.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:51:28.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:28.448+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:51:28.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:51:58.893+0000] {processor.py:157} INFO - Started process (PID=12836) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:51:58.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:51:58.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:58.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:51:58.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:51:58.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:58.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:51:58.925+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:58.924+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:51:58.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T16:52:29.428+0000] {processor.py:157} INFO - Started process (PID=12856) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:52:29.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:52:29.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:29.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:52:29.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:52:29.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:29.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:52:29.465+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:29.465+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:52:29.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T16:52:59.962+0000] {processor.py:157} INFO - Started process (PID=12876) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:52:59.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:52:59.964+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:59.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:52:59.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:52:59.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:59.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:52:59.998+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:59.998+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:53:00.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T16:53:30.446+0000] {processor.py:157} INFO - Started process (PID=12896) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:53:30.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:53:30.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:53:30.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:53:30.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:53:30.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:53:30.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:53:30.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:53:30.489+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:53:30.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T16:54:00.980+0000] {processor.py:157} INFO - Started process (PID=12916) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:54:00.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:54:00.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:00.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:54:00.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:54:01.006+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:01.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:54:01.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:01.018+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:54:01.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T16:54:31.493+0000] {processor.py:157} INFO - Started process (PID=12936) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:54:31.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:54:31.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:31.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:54:31.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:54:31.517+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:31.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:54:31.526+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:31.526+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:54:31.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:55:01.998+0000] {processor.py:157} INFO - Started process (PID=12956) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:55:01.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:55:02.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:02.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:55:02.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:55:02.020+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:02.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:55:02.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:02.029+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:55:02.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T16:55:32.469+0000] {processor.py:157} INFO - Started process (PID=12976) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:55:32.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:55:32.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:32.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:55:32.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:55:32.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:32.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:55:32.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:32.502+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:55:32.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:56:02.995+0000] {processor.py:157} INFO - Started process (PID=12996) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:56:02.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:56:02.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:02.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:56:03.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:56:03.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:03.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:56:03.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:03.028+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:56:03.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T16:56:33.396+0000] {processor.py:157} INFO - Started process (PID=13016) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:56:33.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:56:33.398+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:33.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:56:33.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:56:33.420+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:33.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:56:33.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:33.430+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:56:33.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:57:03.826+0000] {processor.py:157} INFO - Started process (PID=13036) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:57:03.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:57:03.829+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:03.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:57:03.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:57:03.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:03.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:57:03.860+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:03.860+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:57:03.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:57:34.208+0000] {processor.py:157} INFO - Started process (PID=13056) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:57:34.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:57:34.211+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:34.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:57:34.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:57:34.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:34.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:57:34.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:34.242+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:57:34.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T16:58:04.728+0000] {processor.py:157} INFO - Started process (PID=13076) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:58:04.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:58:04.730+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:04.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:58:04.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:58:04.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:04.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:58:04.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:04.762+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:58:04.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T16:58:35.207+0000] {processor.py:157} INFO - Started process (PID=13096) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:58:35.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:58:35.208+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:35.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:58:35.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:58:35.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:35.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:58:35.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:35.237+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:58:35.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.039 seconds
[2024-07-10T16:59:05.707+0000] {processor.py:157} INFO - Started process (PID=13116) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:59:05.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:59:05.710+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:05.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:59:05.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:59:05.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:05.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:59:05.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:05.741+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:59:05.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T16:59:36.216+0000] {processor.py:157} INFO - Started process (PID=13136) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:59:36.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T16:59:36.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:36.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:59:36.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T16:59:36.240+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:36.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:59:36.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:36.249+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:59:36.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:00:06.768+0000] {processor.py:157} INFO - Started process (PID=13156) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:00:06.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:00:06.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:06.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:00:06.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:00:06.792+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:06.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:00:06.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:06.802+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:00:06.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:00:37.285+0000] {processor.py:157} INFO - Started process (PID=13176) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:00:37.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:00:37.288+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:37.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:00:37.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:00:37.309+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:37.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:00:37.318+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:37.318+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:00:37.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:01:07.854+0000] {processor.py:157} INFO - Started process (PID=13196) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:01:07.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:01:07.856+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:07.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:01:07.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:01:07.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:07.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:01:07.889+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:07.889+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:01:07.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:01:38.348+0000] {processor.py:157} INFO - Started process (PID=13216) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:01:38.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:01:38.350+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:38.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:01:38.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:01:38.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:38.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:01:38.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:38.381+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:01:38.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:02:08.870+0000] {processor.py:157} INFO - Started process (PID=13236) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:02:08.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:02:08.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:08.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:02:08.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:02:08.894+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:08.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:02:08.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:08.904+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:02:08.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:02:39.363+0000] {processor.py:157} INFO - Started process (PID=13256) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:02:39.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:02:39.366+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:39.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:02:39.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:02:39.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:39.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:02:39.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:39.397+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:02:39.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:03:09.834+0000] {processor.py:157} INFO - Started process (PID=13276) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:03:09.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:03:09.836+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:09.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:03:09.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:03:09.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:09.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:03:09.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:09.867+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:03:09.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:03:40.283+0000] {processor.py:157} INFO - Started process (PID=13296) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:03:40.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:03:40.286+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:40.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:03:40.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:03:40.308+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:40.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:03:40.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:40.317+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:03:40.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:04:10.751+0000] {processor.py:157} INFO - Started process (PID=13316) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:04:10.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:04:10.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:10.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:04:10.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:04:10.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:10.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:04:10.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:10.790+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:04:10.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T17:04:41.267+0000] {processor.py:157} INFO - Started process (PID=13336) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:04:41.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:04:41.269+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:41.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:04:41.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:04:41.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:41.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:04:41.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:41.301+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:04:41.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:05:11.784+0000] {processor.py:157} INFO - Started process (PID=13356) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:05:11.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:05:11.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:11.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:05:11.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:05:11.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:11.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:05:11.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:11.818+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:05:11.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:05:42.208+0000] {processor.py:157} INFO - Started process (PID=13376) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:05:42.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:05:42.210+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:42.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:05:42.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:05:42.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:42.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:05:42.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:42.241+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:05:42.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:06:12.637+0000] {processor.py:157} INFO - Started process (PID=13396) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:06:12.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:06:12.639+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:12.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:06:12.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:06:12.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:12.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:06:12.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:12.670+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:06:12.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:06:43.071+0000] {processor.py:157} INFO - Started process (PID=13416) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:06:43.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:06:43.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:43.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:06:43.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:06:43.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:43.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:06:43.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:43.105+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:06:43.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:07:13.476+0000] {processor.py:157} INFO - Started process (PID=13436) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:07:13.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:07:13.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:13.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:07:13.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:07:13.503+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:13.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:07:13.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:13.513+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:07:13.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T17:07:43.921+0000] {processor.py:157} INFO - Started process (PID=13456) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:07:43.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:07:43.923+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:43.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:07:43.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:07:43.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:43.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:07:43.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:43.955+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:07:43.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:08:14.394+0000] {processor.py:157} INFO - Started process (PID=13476) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:08:14.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:08:14.396+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:14.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:08:14.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:08:14.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:14.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:08:14.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:14.429+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:08:14.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:08:44.840+0000] {processor.py:157} INFO - Started process (PID=13496) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:08:44.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:08:44.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:44.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:08:44.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:08:44.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:44.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:08:44.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:44.874+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:08:44.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:09:15.262+0000] {processor.py:157} INFO - Started process (PID=13516) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:09:15.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:09:15.264+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:15.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:09:15.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:09:15.288+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:15.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:09:15.298+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:15.298+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:09:15.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T17:09:45.733+0000] {processor.py:157} INFO - Started process (PID=13535) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:09:45.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:09:45.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:45.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:09:45.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:09:45.772+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:45.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:09:45.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:45.785+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:09:45.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.064 seconds
[2024-07-10T17:10:16.275+0000] {processor.py:157} INFO - Started process (PID=13556) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:10:16.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:10:16.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:16.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:10:16.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:10:16.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:16.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:10:16.309+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:16.309+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:10:16.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:10:46.822+0000] {processor.py:157} INFO - Started process (PID=13576) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:10:46.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:10:46.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:46.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:10:46.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:10:46.846+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:46.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:10:46.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:46.855+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:10:46.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:11:17.400+0000] {processor.py:157} INFO - Started process (PID=13596) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:11:17.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:11:17.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:17.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:11:17.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:11:17.424+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:17.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:11:17.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:17.433+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:11:17.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:11:47.852+0000] {processor.py:157} INFO - Started process (PID=13616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:11:47.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:11:47.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:47.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:11:47.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:11:47.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:47.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:11:47.883+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:47.883+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:11:47.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.039 seconds
[2024-07-10T17:12:18.340+0000] {processor.py:157} INFO - Started process (PID=13636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:12:18.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:12:18.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:18.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:12:18.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:12:18.363+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:18.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:12:18.372+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:18.372+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:12:18.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:12:48.884+0000] {processor.py:157} INFO - Started process (PID=13656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:12:48.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:12:48.886+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:48.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:12:48.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:12:48.908+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:48.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:12:48.918+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:48.918+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:12:48.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:13:19.437+0000] {processor.py:157} INFO - Started process (PID=13676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:13:19.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:13:19.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:19.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:13:19.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:13:19.461+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:19.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:13:19.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:19.471+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:13:19.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:13:49.951+0000] {processor.py:157} INFO - Started process (PID=13696) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:13:49.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:13:49.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:49.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:13:49.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:13:49.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:49.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:13:49.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:49.984+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:13:49.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:14:20.458+0000] {processor.py:157} INFO - Started process (PID=13716) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:14:20.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:14:20.460+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:20.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:14:20.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:14:20.482+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:20.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:14:20.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:20.492+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:14:20.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:14:50.964+0000] {processor.py:157} INFO - Started process (PID=13736) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:14:50.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:14:50.967+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:50.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:14:50.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:14:50.989+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:50.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:14:50.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:50.999+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:14:51.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:15:21.495+0000] {processor.py:157} INFO - Started process (PID=13756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:15:21.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:15:21.497+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:21.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:15:21.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:15:21.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:21.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:15:21.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:21.528+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:15:21.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:15:52.019+0000] {processor.py:157} INFO - Started process (PID=13776) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:15:52.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:15:52.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:52.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:15:52.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:15:52.046+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:52.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:15:52.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:52.057+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:15:52.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T17:16:22.620+0000] {processor.py:157} INFO - Started process (PID=13796) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:16:22.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:16:22.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:22.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:16:22.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:16:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:16:22.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:22.652+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:16:22.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T17:16:53.121+0000] {processor.py:157} INFO - Started process (PID=13816) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:16:53.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:16:53.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:53.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:16:53.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:16:53.145+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:53.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:16:53.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:53.154+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:16:53.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:17:23.589+0000] {processor.py:157} INFO - Started process (PID=13836) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:17:23.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:17:23.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:23.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:17:23.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:17:23.612+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:23.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:17:23.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:23.621+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:17:23.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:17:54.097+0000] {processor.py:157} INFO - Started process (PID=13856) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:17:54.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:17:54.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:54.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:17:54.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:17:54.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:54.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:17:54.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:54.125+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:17:54.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.036 seconds
[2024-07-10T17:18:24.643+0000] {processor.py:157} INFO - Started process (PID=13876) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:18:24.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:18:24.646+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:24.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:18:24.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:18:24.667+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:24.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:18:24.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:24.677+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:18:24.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:18:55.190+0000] {processor.py:157} INFO - Started process (PID=13896) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:18:55.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:18:55.192+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:55.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:18:55.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:18:55.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:55.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:18:55.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:55.224+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:18:55.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:19:25.703+0000] {processor.py:157} INFO - Started process (PID=13916) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:19:25.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:19:25.706+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:25.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:19:25.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:19:25.727+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:25.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:19:25.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:25.736+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:19:25.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:19:56.227+0000] {processor.py:157} INFO - Started process (PID=13936) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:19:56.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:19:56.229+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:56.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:19:56.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:19:56.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:56.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:19:56.260+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:56.260+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:19:56.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:20:26.745+0000] {processor.py:157} INFO - Started process (PID=13956) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:20:26.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:20:26.748+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:26.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:20:26.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:20:26.769+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:26.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:20:26.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:26.778+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:20:26.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:20:57.280+0000] {processor.py:157} INFO - Started process (PID=13976) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:20:57.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:20:57.282+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:57.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:20:57.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:20:57.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:57.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:20:57.312+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:57.312+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:20:57.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:21:27.788+0000] {processor.py:157} INFO - Started process (PID=13996) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:21:27.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:21:27.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:27.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:21:27.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:21:27.815+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:27.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:21:27.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:27.825+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:21:27.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T17:21:58.256+0000] {processor.py:157} INFO - Started process (PID=14016) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:21:58.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:21:58.258+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:58.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:21:58.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:21:58.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:58.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:21:58.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:58.290+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:21:58.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:22:28.761+0000] {processor.py:157} INFO - Started process (PID=14036) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:22:28.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:22:28.763+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:28.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:22:28.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:22:28.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:28.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:22:28.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:28.795+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:22:28.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:22:59.182+0000] {processor.py:157} INFO - Started process (PID=14056) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:22:59.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:22:59.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:59.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:22:59.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:22:59.201+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:59.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:22:59.209+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:59.209+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:22:59.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.035 seconds
[2024-07-10T17:23:29.630+0000] {processor.py:157} INFO - Started process (PID=14076) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:23:29.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:23:29.632+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:23:29.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:23:29.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:23:29.654+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:23:29.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:23:29.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:23:29.663+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:23:29.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:24:00.106+0000] {processor.py:157} INFO - Started process (PID=14096) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:24:00.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:24:00.108+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:00.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:24:00.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:24:00.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:00.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:24:00.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:00.139+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:24:00.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:24:30.538+0000] {processor.py:157} INFO - Started process (PID=14116) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:24:30.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:24:30.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:30.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:24:30.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:24:30.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:30.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:24:30.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:30.581+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:24:30.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T17:25:01.024+0000] {processor.py:157} INFO - Started process (PID=14136) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:25:01.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:25:01.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:01.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:25:01.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:25:01.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:01.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:25:01.059+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:01.058+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:25:01.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:25:31.504+0000] {processor.py:157} INFO - Started process (PID=14156) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:25:31.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:25:31.507+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:31.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:25:31.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:25:31.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:31.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:25:31.538+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:31.538+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:25:31.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:26:02.003+0000] {processor.py:157} INFO - Started process (PID=14176) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:26:02.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:26:02.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:02.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:26:02.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:26:02.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:02.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:26:02.040+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:02.040+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:26:02.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T17:26:32.476+0000] {processor.py:157} INFO - Started process (PID=14196) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:26:32.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:26:32.478+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:32.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:26:32.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:26:32.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:32.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:26:32.510+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:32.510+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:26:32.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:27:02.972+0000] {processor.py:157} INFO - Started process (PID=14216) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:27:02.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:27:02.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:02.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:27:02.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:27:02.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:02.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:27:03.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:03.005+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:27:03.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:27:33.495+0000] {processor.py:157} INFO - Started process (PID=14236) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:27:33.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:27:33.497+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:33.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:27:33.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:27:33.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:33.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:27:33.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:33.529+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:27:33.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:28:03.993+0000] {processor.py:157} INFO - Started process (PID=14256) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:28:03.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:28:03.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:03.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:28:04.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:28:04.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:04.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:28:04.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:04.027+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:28:04.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:28:34.474+0000] {processor.py:157} INFO - Started process (PID=14276) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:28:34.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:28:34.477+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:34.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:28:34.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:28:34.499+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:34.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:28:34.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:34.508+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:28:34.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:29:05.001+0000] {processor.py:157} INFO - Started process (PID=14296) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:29:05.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:29:05.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:05.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:29:05.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:29:05.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:05.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:29:05.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:05.035+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:29:05.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:29:35.524+0000] {processor.py:157} INFO - Started process (PID=14316) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:29:35.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:29:35.526+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:35.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:29:35.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:29:35.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:35.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:29:35.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:35.557+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:29:35.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:30:06.042+0000] {processor.py:157} INFO - Started process (PID=14336) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:30:06.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:30:06.045+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:06.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:30:06.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:30:06.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:06.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:30:06.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:06.076+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:30:06.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:30:36.541+0000] {processor.py:157} INFO - Started process (PID=14356) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:30:36.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:30:36.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:36.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:30:36.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:30:36.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:36.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:30:36.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:36.576+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:30:36.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:31:07.058+0000] {processor.py:157} INFO - Started process (PID=14376) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:31:07.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:31:07.061+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:07.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:31:07.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:31:07.084+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:07.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:31:07.093+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:07.093+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:31:07.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:31:37.573+0000] {processor.py:157} INFO - Started process (PID=14396) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:31:37.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:31:37.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:37.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:31:37.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:31:37.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:37.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:31:37.608+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:37.608+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:31:37.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:32:08.076+0000] {processor.py:157} INFO - Started process (PID=14416) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:32:08.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:32:08.079+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:08.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:32:08.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:32:08.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:08.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:32:08.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:08.113+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:32:08.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T17:32:38.587+0000] {processor.py:157} INFO - Started process (PID=14436) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:32:38.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:32:38.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:38.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:32:38.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:32:38.613+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:38.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:32:38.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:38.622+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:32:38.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:33:09.097+0000] {processor.py:157} INFO - Started process (PID=14456) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:33:09.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:33:09.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:09.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:33:09.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:33:09.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:09.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:33:09.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:09.130+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:33:09.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:33:39.616+0000] {processor.py:157} INFO - Started process (PID=14476) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:33:39.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:33:39.618+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:39.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:33:39.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:33:39.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:39.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:33:39.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:39.650+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:33:39.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:34:10.092+0000] {processor.py:157} INFO - Started process (PID=14496) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:34:10.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:34:10.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:10.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:34:10.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:34:10.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:10.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:34:10.128+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:10.128+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:34:10.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:34:40.602+0000] {processor.py:157} INFO - Started process (PID=14516) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:34:40.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:34:40.604+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:40.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:34:40.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:34:40.626+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:40.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:34:40.635+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:40.635+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:34:40.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:35:11.038+0000] {processor.py:157} INFO - Started process (PID=14536) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:35:11.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:35:11.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:11.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:35:11.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:35:11.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:11.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:35:11.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:11.072+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:35:11.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:35:41.488+0000] {processor.py:157} INFO - Started process (PID=14556) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:35:41.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:35:41.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:41.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:35:41.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:35:41.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:41.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:35:41.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:41.521+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:35:41.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:36:12.009+0000] {processor.py:157} INFO - Started process (PID=14576) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:36:12.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:36:12.011+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:12.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:36:12.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:36:12.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:12.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:36:12.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:12.043+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:36:12.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:36:42.462+0000] {processor.py:157} INFO - Started process (PID=14596) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:36:42.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:36:42.465+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:42.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:36:42.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:36:42.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:42.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:36:42.496+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:42.496+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:36:42.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:37:12.988+0000] {processor.py:157} INFO - Started process (PID=14616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:37:12.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:37:12.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:12.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:37:13.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:37:13.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:13.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:37:13.023+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:13.023+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:37:13.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:37:43.476+0000] {processor.py:157} INFO - Started process (PID=14636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:37:43.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:37:43.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:43.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:37:43.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:37:43.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:43.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:37:43.511+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:43.511+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:37:43.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:38:14.032+0000] {processor.py:157} INFO - Started process (PID=14656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:38:14.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:38:14.034+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:14.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:38:14.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:38:14.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:14.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:38:14.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:14.066+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:38:14.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:38:44.574+0000] {processor.py:157} INFO - Started process (PID=14676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:38:44.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:38:44.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:44.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:38:44.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:38:44.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:44.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:38:44.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:44.609+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:38:44.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:39:15.072+0000] {processor.py:157} INFO - Started process (PID=14696) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:39:15.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:39:15.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:15.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:39:15.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:39:15.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:15.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:39:15.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:15.106+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:39:15.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:39:45.558+0000] {processor.py:157} INFO - Started process (PID=14716) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:39:45.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:39:45.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:45.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:39:45.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:39:45.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:45.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:39:45.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:45.592+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:39:45.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:40:16.100+0000] {processor.py:157} INFO - Started process (PID=14736) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:40:16.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:40:16.102+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:16.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:40:16.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:40:16.124+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:16.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:40:16.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:16.134+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:40:16.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:40:46.645+0000] {processor.py:157} INFO - Started process (PID=14756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:40:46.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:40:46.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:46.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:40:46.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:40:46.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:46.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:40:46.678+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:46.678+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:40:46.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:41:17.181+0000] {processor.py:157} INFO - Started process (PID=14776) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:41:17.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:41:17.183+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:17.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:41:17.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:41:17.204+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:17.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:41:17.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:17.214+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:41:17.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:41:47.533+0000] {processor.py:157} INFO - Started process (PID=14796) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:41:47.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:41:47.535+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:47.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:41:47.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:41:47.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:47.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:41:47.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:47.566+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:41:47.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:42:17.952+0000] {processor.py:157} INFO - Started process (PID=14816) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:42:17.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:42:17.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:17.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:42:17.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:42:17.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:17.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:42:17.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:17.985+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:42:17.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:42:48.414+0000] {processor.py:157} INFO - Started process (PID=14836) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:42:48.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:42:48.417+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:48.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:42:48.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:42:48.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:48.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:42:48.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:48.448+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:42:48.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:43:18.944+0000] {processor.py:157} INFO - Started process (PID=14856) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:43:18.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:43:18.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:18.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:43:18.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:43:18.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:18.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:43:18.978+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:18.978+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:43:18.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:43:49.438+0000] {processor.py:157} INFO - Started process (PID=14876) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:43:49.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:43:49.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:49.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:43:49.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:43:49.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:49.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:43:49.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:49.468+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:43:49.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.037 seconds
[2024-07-10T17:44:19.896+0000] {processor.py:157} INFO - Started process (PID=14896) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:44:19.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:44:19.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:19.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:44:19.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:44:19.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:19.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:44:19.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:19.929+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:44:19.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:44:50.419+0000] {processor.py:157} INFO - Started process (PID=14916) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:44:50.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:44:50.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:50.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:44:50.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:44:50.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:50.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:44:50.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:50.462+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:44:50.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T17:45:20.919+0000] {processor.py:157} INFO - Started process (PID=14936) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:45:20.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:45:20.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:20.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:45:20.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:45:20.943+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:20.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:45:20.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:20.953+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:45:20.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:45:51.458+0000] {processor.py:157} INFO - Started process (PID=14956) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:45:51.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:45:51.461+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:51.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:45:51.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:45:51.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:51.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:45:51.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:51.493+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:45:51.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:46:21.943+0000] {processor.py:157} INFO - Started process (PID=14976) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:46:21.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:46:21.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:21.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:46:21.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:46:21.967+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:21.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:46:21.976+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:21.976+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:46:21.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:46:52.474+0000] {processor.py:157} INFO - Started process (PID=14996) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:46:52.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:46:52.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:52.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:46:52.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:46:52.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:52.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:46:52.507+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:52.507+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:46:52.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:47:22.925+0000] {processor.py:157} INFO - Started process (PID=15016) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:47:22.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:47:22.927+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:22.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:47:22.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:47:22.949+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:22.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:47:22.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:22.958+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:47:22.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:47:53.472+0000] {processor.py:157} INFO - Started process (PID=15036) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:47:53.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:47:53.474+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:53.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:47:53.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:47:53.497+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:53.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:47:53.507+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:53.506+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:47:53.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:48:23.971+0000] {processor.py:157} INFO - Started process (PID=15056) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:48:23.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:48:23.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:23.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:48:23.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:48:23.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:23.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:48:24.007+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:24.007+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:48:24.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T17:48:54.490+0000] {processor.py:157} INFO - Started process (PID=15076) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:48:54.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:48:54.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:54.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:48:54.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:48:54.514+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:54.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:48:54.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:54.524+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:48:54.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:49:24.968+0000] {processor.py:157} INFO - Started process (PID=15096) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:49:24.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:49:24.970+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:24.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:49:24.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:49:24.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:24.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:49:25.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:25.001+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:49:25.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:49:55.502+0000] {processor.py:157} INFO - Started process (PID=15116) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:49:55.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:49:55.505+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:55.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:49:55.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:49:55.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:55.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:49:55.539+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:55.539+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:49:55.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T17:50:25.993+0000] {processor.py:157} INFO - Started process (PID=15136) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:50:25.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:50:25.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:25.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:50:26.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:50:26.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:26.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:50:26.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:26.027+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:50:26.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:50:56.470+0000] {processor.py:157} INFO - Started process (PID=15156) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:50:56.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:50:56.473+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:56.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:50:56.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:50:56.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:56.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:50:56.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:56.502+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:50:56.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:51:26.962+0000] {processor.py:157} INFO - Started process (PID=15176) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:51:26.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:51:26.964+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:26.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:51:26.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:51:26.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:26.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:51:26.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:26.995+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:51:27.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:51:57.490+0000] {processor.py:157} INFO - Started process (PID=15196) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:51:57.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:51:57.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:57.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:51:57.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:51:57.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:57.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:51:57.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:57.523+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:51:57.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:52:27.924+0000] {processor.py:157} INFO - Started process (PID=15216) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:52:27.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:52:27.926+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:27.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:52:27.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:52:27.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:27.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:52:27.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:27.955+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:52:27.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.038 seconds
[2024-07-10T17:52:58.414+0000] {processor.py:157} INFO - Started process (PID=15236) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:52:58.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:52:58.417+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:58.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:52:58.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:52:58.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:58.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:52:58.452+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:58.452+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:52:58.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T17:53:28.949+0000] {processor.py:157} INFO - Started process (PID=15256) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:53:28.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:53:28.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:28.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:53:28.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:53:28.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:28.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:53:28.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:28.983+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:53:28.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:53:59.461+0000] {processor.py:157} INFO - Started process (PID=15276) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:53:59.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:53:59.463+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:59.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:53:59.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:53:59.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:59.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:53:59.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:59.495+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:53:59.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:54:29.980+0000] {processor.py:157} INFO - Started process (PID=15296) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:54:29.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:54:29.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:54:29.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:54:29.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:54:30.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:54:30.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:54:30.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:54:30.015+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:54:30.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T17:55:00.412+0000] {processor.py:157} INFO - Started process (PID=15316) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:55:00.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:55:00.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:00.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:55:00.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:55:00.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:00.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:55:00.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:00.445+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:55:00.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:55:30.887+0000] {processor.py:157} INFO - Started process (PID=15336) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:55:30.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:55:30.891+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:30.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:55:30.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:55:30.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:30.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:55:30.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:30.931+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:55:30.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T17:56:01.424+0000] {processor.py:157} INFO - Started process (PID=15356) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:56:01.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:56:01.426+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:01.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:56:01.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:56:01.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:01.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:56:01.458+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:01.458+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:56:01.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T17:56:31.938+0000] {processor.py:157} INFO - Started process (PID=15376) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:56:31.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:56:31.940+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:31.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:56:31.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:56:31.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:31.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:56:31.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:31.972+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:56:31.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:57:02.356+0000] {processor.py:157} INFO - Started process (PID=15396) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:57:02.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:57:02.358+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:02.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:57:02.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:57:02.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:02.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:57:02.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:02.391+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:57:02.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:57:32.917+0000] {processor.py:157} INFO - Started process (PID=15416) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:57:32.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:57:32.919+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:32.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:57:32.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:57:32.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:32.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:57:32.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:32.950+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:57:32.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:58:03.414+0000] {processor.py:157} INFO - Started process (PID=15436) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:58:03.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:58:03.416+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:03.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:58:03.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:58:03.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:03.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:58:03.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:03.449+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:58:03.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T17:58:33.923+0000] {processor.py:157} INFO - Started process (PID=15456) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:58:33.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:58:33.925+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:33.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:58:33.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:58:33.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:33.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:58:33.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:33.956+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:58:33.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T17:59:04.436+0000] {processor.py:157} INFO - Started process (PID=15476) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:59:04.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:59:04.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:04.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:59:04.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:59:04.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:04.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:59:04.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:04.469+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:59:04.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T17:59:34.967+0000] {processor.py:157} INFO - Started process (PID=15496) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:59:34.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T17:59:34.970+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:34.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:59:34.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T17:59:34.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:34.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:59:35.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:35.001+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:59:35.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T18:00:05.494+0000] {processor.py:157} INFO - Started process (PID=15516) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:00:05.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:00:05.496+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:05.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:00:05.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:00:05.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:05.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:00:05.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:05.530+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:00:05.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T18:00:36.005+0000] {processor.py:157} INFO - Started process (PID=15536) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:00:36.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:00:36.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:36.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:00:36.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:00:36.030+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:36.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:00:36.039+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:36.039+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:00:36.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T18:01:06.507+0000] {processor.py:157} INFO - Started process (PID=15556) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:01:06.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:01:06.509+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:06.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:01:06.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:01:06.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:06.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:01:06.543+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:06.542+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:01:06.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T18:01:37.043+0000] {processor.py:157} INFO - Started process (PID=15576) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:01:37.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:01:37.046+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:37.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:01:37.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:01:37.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:37.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:01:37.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:37.076+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:01:37.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T18:02:07.517+0000] {processor.py:157} INFO - Started process (PID=15596) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:02:07.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:02:07.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:07.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:02:07.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:02:07.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:07.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:02:07.552+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:07.552+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:02:07.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T18:02:38.066+0000] {processor.py:157} INFO - Started process (PID=15616) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:02:38.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:02:38.068+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:38.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:02:38.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:02:38.090+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:38.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:02:38.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:38.100+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:02:38.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T18:03:08.552+0000] {processor.py:157} INFO - Started process (PID=15636) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:03:08.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:03:08.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:08.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:03:08.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:03:08.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:08.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:03:08.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:08.586+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:03:08.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T18:03:39.052+0000] {processor.py:157} INFO - Started process (PID=15656) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:03:39.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:03:39.054+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:39.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:03:39.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:03:39.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:39.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:03:39.085+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:39.085+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:03:39.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T18:04:09.557+0000] {processor.py:157} INFO - Started process (PID=15676) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:04:09.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:04:09.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:09.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:04:09.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:04:09.580+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:09.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:04:09.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:09.590+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:04:09.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T18:04:40.074+0000] {processor.py:157} INFO - Started process (PID=15696) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:04:40.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:04:40.077+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:40.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:04:40.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:04:40.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:40.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:04:40.114+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:40.114+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:04:40.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T18:05:10.519+0000] {processor.py:157} INFO - Started process (PID=15716) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:05:10.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:05:10.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:10.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:05:10.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:05:10.546+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:10.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:05:10.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:10.556+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:05:10.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T18:05:40.932+0000] {processor.py:157} INFO - Started process (PID=15736) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:05:40.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:05:40.935+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:40.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:05:40.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:05:40.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:40.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:05:40.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:40.965+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:05:40.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T18:06:11.448+0000] {processor.py:157} INFO - Started process (PID=15756) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:06:11.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:06:11.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:11.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:06:11.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:06:11.472+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:11.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:06:11.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:11.481+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:06:11.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T18:06:41.888+0000] {processor.py:157} INFO - Started process (PID=15776) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:06:41.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:06:41.890+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:41.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:06:41.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:06:41.912+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:41.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:06:41.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:41.921+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:06:41.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T18:07:12.356+0000] {processor.py:157} INFO - Started process (PID=15796) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:07:12.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:07:12.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:12.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:07:12.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:07:12.382+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:12.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:07:12.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:12.391+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:07:12.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T18:07:42.768+0000] {processor.py:157} INFO - Started process (PID=15816) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:07:42.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:07:42.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:42.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:07:42.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:07:42.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:42.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:07:42.807+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:42.807+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:07:42.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T18:23:53.897+0000] {processor.py:157} INFO - Started process (PID=15838) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:23:53.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:23:53.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:23:53.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:23:53.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:23:53.977+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:23:53.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:23:54.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:23:54.013+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:23:54.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.149 seconds
[2024-07-10T18:24:24.541+0000] {processor.py:157} INFO - Started process (PID=15857) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:24:24.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:24:24.545+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:24.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:24:24.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:24:24.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:24.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:24:24.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:24.588+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:24:24.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T18:24:54.993+0000] {processor.py:157} INFO - Started process (PID=15878) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:24:54.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:24:54.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:54.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:24:55.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:24:55.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:55.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:24:55.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:55.028+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:24:55.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T18:25:25.409+0000] {processor.py:157} INFO - Started process (PID=15898) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:25:25.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:25:25.412+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:25.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:25:25.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:25:25.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:25.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:25:25.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:25.450+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:25:25.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T18:25:55.875+0000] {processor.py:157} INFO - Started process (PID=15918) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:25:55.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:25:55.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:55.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:25:55.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:25:55.900+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:55.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:25:55.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:55.909+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:25:55.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T18:26:26.348+0000] {processor.py:157} INFO - Started process (PID=15938) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:26:26.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:26:26.350+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:26.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:26:26.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:26:26.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:26.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:26:26.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:26.381+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:26:26.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T18:26:56.848+0000] {processor.py:157} INFO - Started process (PID=15958) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:26:56.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:26:56.851+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:56.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:26:56.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:26:56.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:56.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:26:56.882+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:56.882+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:26:56.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T18:27:27.305+0000] {processor.py:157} INFO - Started process (PID=15978) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:27:27.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:27:27.307+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:27:27.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:27:27.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:27:27.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:27:27.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:27:27.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:27:27.340+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:27:27.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T18:43:31.850+0000] {processor.py:157} INFO - Started process (PID=15998) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:43:31.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:43:31.853+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:43:31.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:43:31.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:43:31.887+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:43:31.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:43:31.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:43:31.898+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:43:31.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T18:59:22.305+0000] {processor.py:157} INFO - Started process (PID=16018) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:59:22.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:59:22.307+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:22.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:59:22.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:59:22.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:22.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:59:22.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:22.359+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:59:22.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.068 seconds
[2024-07-10T18:59:52.861+0000] {processor.py:157} INFO - Started process (PID=16038) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:59:52.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T18:59:52.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:52.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:59:52.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T18:59:52.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:52.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:59:52.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:52.898+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:59:52.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T19:00:23.395+0000] {processor.py:157} INFO - Started process (PID=16058) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:00:23.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:00:23.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:23.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:00:23.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:00:23.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:23.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:00:23.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:23.431+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:00:23.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T19:00:53.923+0000] {processor.py:157} INFO - Started process (PID=16078) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:00:53.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:00:53.926+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:53.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:00:53.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:00:53.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:53.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:00:53.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:53.958+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:00:53.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:01:24.440+0000] {processor.py:157} INFO - Started process (PID=16098) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:01:24.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:01:24.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:24.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:01:24.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:01:24.466+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:24.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:01:24.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:24.476+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:01:24.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:01:54.986+0000] {processor.py:157} INFO - Started process (PID=16118) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:01:54.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:01:54.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:54.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:01:54.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:01:55.010+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:55.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:01:55.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:55.019+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:01:55.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:02:25.507+0000] {processor.py:157} INFO - Started process (PID=16138) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:02:25.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:02:25.509+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:25.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:02:25.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:02:25.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:25.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:02:25.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:25.540+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:02:25.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:02:56.003+0000] {processor.py:157} INFO - Started process (PID=16158) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:02:56.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:02:56.007+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:56.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:02:56.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:02:56.037+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:56.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:02:56.049+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:56.049+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:02:56.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T19:03:26.562+0000] {processor.py:157} INFO - Started process (PID=16178) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:03:26.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:03:26.564+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:26.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:03:26.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:03:26.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:26.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:03:26.596+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:26.596+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:03:26.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:03:57.143+0000] {processor.py:157} INFO - Started process (PID=16198) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:03:57.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:03:57.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:57.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:03:57.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:03:57.167+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:57.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:03:57.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:57.177+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:03:57.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:04:27.614+0000] {processor.py:157} INFO - Started process (PID=16218) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:04:27.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:04:27.616+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:27.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:04:27.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:04:27.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:27.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:04:27.647+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:27.647+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:04:27.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:04:58.033+0000] {processor.py:157} INFO - Started process (PID=16238) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:04:58.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:04:58.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:58.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:04:58.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:04:58.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:58.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:04:58.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:58.067+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:04:58.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:05:28.506+0000] {processor.py:157} INFO - Started process (PID=16258) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:05:28.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:05:28.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:28.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:05:28.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:05:28.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:28.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:05:28.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:28.540+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:05:28.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:05:58.887+0000] {processor.py:157} INFO - Started process (PID=16278) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:05:58.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:05:58.889+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:58.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:05:58.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:05:58.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:58.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:05:58.922+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:58.922+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:05:58.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:06:29.301+0000] {processor.py:157} INFO - Started process (PID=16298) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:06:29.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:06:29.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:29.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:06:29.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:06:29.325+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:29.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:06:29.335+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:29.335+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:06:29.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:06:59.747+0000] {processor.py:157} INFO - Started process (PID=16318) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:06:59.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:06:59.750+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:59.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:06:59.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:06:59.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:59.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:06:59.784+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:59.784+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:06:59.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T19:07:30.214+0000] {processor.py:157} INFO - Started process (PID=16338) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:07:30.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:07:30.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:07:30.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:07:30.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:07:30.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:07:30.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:07:30.247+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:07:30.247+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:07:30.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:08:00.713+0000] {processor.py:157} INFO - Started process (PID=16358) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:08:00.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:08:00.716+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:00.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:08:00.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:08:00.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:00.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:08:00.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:00.746+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:08:00.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:08:31.172+0000] {processor.py:157} INFO - Started process (PID=16378) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:08:31.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:08:31.175+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:31.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:08:31.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:08:31.196+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:31.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:08:31.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:31.206+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:08:31.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:09:01.712+0000] {processor.py:157} INFO - Started process (PID=16398) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:09:01.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:09:01.715+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:01.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:09:01.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:09:01.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:01.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:09:01.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:01.746+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:09:01.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:09:32.171+0000] {processor.py:157} INFO - Started process (PID=16418) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:09:32.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:09:32.173+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:32.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:09:32.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:09:32.195+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:32.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:09:32.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:32.205+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:09:32.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:10:02.660+0000] {processor.py:157} INFO - Started process (PID=16438) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:10:02.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:10:02.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:02.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:10:02.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:10:02.684+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:02.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:10:02.694+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:02.693+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:10:02.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:10:33.198+0000] {processor.py:157} INFO - Started process (PID=16458) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:10:33.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:10:33.200+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:33.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:10:33.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:10:33.222+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:33.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:10:33.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:33.232+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:10:33.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:11:03.702+0000] {processor.py:157} INFO - Started process (PID=16478) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:11:03.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:11:03.704+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:03.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:11:03.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:11:03.726+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:03.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:11:03.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:03.736+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:11:03.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:11:34.161+0000] {processor.py:157} INFO - Started process (PID=16498) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:11:34.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:11:34.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:34.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:11:34.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:11:34.200+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:34.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:11:34.211+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:34.211+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:11:34.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.061 seconds
[2024-07-10T19:12:04.719+0000] {processor.py:157} INFO - Started process (PID=16518) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:12:04.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:12:04.721+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:04.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:12:04.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:12:04.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:04.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:12:04.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:04.753+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:12:04.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:12:35.165+0000] {processor.py:157} INFO - Started process (PID=16538) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:12:35.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:12:35.167+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:35.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:12:35.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:12:35.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:35.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:12:35.199+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:35.199+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:12:35.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:13:05.649+0000] {processor.py:157} INFO - Started process (PID=16558) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:13:05.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:13:05.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:05.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:13:05.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:13:05.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:05.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:13:05.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:05.685+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:13:05.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:13:36.064+0000] {processor.py:157} INFO - Started process (PID=16578) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:13:36.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:13:36.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:36.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:13:36.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:13:36.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:36.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:13:36.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:36.099+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:13:36.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:14:06.490+0000] {processor.py:157} INFO - Started process (PID=16598) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:14:06.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:14:06.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:06.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:14:06.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:14:06.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:06.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:14:06.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:06.523+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:14:06.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:14:36.994+0000] {processor.py:157} INFO - Started process (PID=16618) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:14:36.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:14:36.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:36.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:14:37.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:14:37.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:37.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:14:37.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:37.028+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:14:37.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:15:07.428+0000] {processor.py:157} INFO - Started process (PID=16638) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:15:07.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:15:07.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:07.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:15:07.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:15:07.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:07.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:15:07.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:07.461+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:15:07.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:15:37.939+0000] {processor.py:157} INFO - Started process (PID=16658) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:15:37.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:15:37.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:37.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:15:37.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:15:37.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:37.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:15:37.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:37.973+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:15:37.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:16:08.419+0000] {processor.py:157} INFO - Started process (PID=16678) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:16:08.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:16:08.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:08.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:16:08.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:16:08.444+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:08.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:16:08.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:08.454+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:16:08.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:16:38.943+0000] {processor.py:157} INFO - Started process (PID=16698) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:16:38.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:16:38.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:38.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:16:38.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:16:38.978+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:38.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:16:38.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:38.989+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:16:38.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T19:17:09.422+0000] {processor.py:157} INFO - Started process (PID=16718) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:17:09.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:17:09.424+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:09.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:17:09.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:17:09.444+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:09.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:17:09.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:09.453+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:17:09.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T19:17:39.909+0000] {processor.py:157} INFO - Started process (PID=16738) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:17:39.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:17:39.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:39.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:17:39.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:17:39.932+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:39.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:17:39.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:39.942+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:17:39.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:18:10.418+0000] {processor.py:157} INFO - Started process (PID=16758) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:18:10.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:18:10.420+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:10.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:18:10.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:18:10.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:10.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:18:10.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:10.451+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:18:10.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:18:40.937+0000] {processor.py:157} INFO - Started process (PID=16778) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:18:40.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:18:40.939+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:40.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:18:40.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:18:40.961+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:40.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:18:40.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:40.971+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:18:40.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:19:11.440+0000] {processor.py:157} INFO - Started process (PID=16798) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:19:11.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:19:11.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:11.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:19:11.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:19:11.463+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:11.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:19:11.473+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:11.473+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:19:11.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:19:41.975+0000] {processor.py:157} INFO - Started process (PID=16818) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:19:41.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:19:41.978+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:41.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:19:41.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:19:42.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:42.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:19:42.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:42.009+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:19:42.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:20:12.452+0000] {processor.py:157} INFO - Started process (PID=16838) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:20:12.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:20:12.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:12.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:20:12.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:20:12.472+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:12.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:20:12.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:12.481+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:20:12.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.037 seconds
[2024-07-10T19:20:42.965+0000] {processor.py:157} INFO - Started process (PID=16858) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:20:42.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:20:42.969+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:42.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:20:42.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:20:42.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:42.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:20:43.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:43.000+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:20:43.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:21:13.450+0000] {processor.py:157} INFO - Started process (PID=16878) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:21:13.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:21:13.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:13.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:21:13.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:21:13.474+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:13.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:21:13.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:13.484+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:21:13.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:21:43.992+0000] {processor.py:157} INFO - Started process (PID=16898) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:21:43.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:21:43.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:43.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:21:44.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:21:44.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:44.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:21:44.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:44.027+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:21:44.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:22:14.501+0000] {processor.py:157} INFO - Started process (PID=16918) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:22:14.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:22:14.503+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:14.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:22:14.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:22:14.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:14.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:22:14.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:14.534+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:22:14.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:22:44.999+0000] {processor.py:157} INFO - Started process (PID=16938) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:22:45.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:22:45.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:45.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:22:45.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:22:45.023+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:45.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:22:45.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:45.032+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:22:45.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:23:15.531+0000] {processor.py:157} INFO - Started process (PID=16958) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:23:15.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:23:15.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:15.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:23:15.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:23:15.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:15.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:23:15.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:15.566+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:23:15.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:23:46.084+0000] {processor.py:157} INFO - Started process (PID=16978) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:23:46.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:23:46.085+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:46.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:23:46.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:23:46.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:46.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:23:46.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:46.116+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:23:46.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:24:16.598+0000] {processor.py:157} INFO - Started process (PID=16998) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:24:16.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:24:16.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:16.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:24:16.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:24:16.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:16.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:24:16.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:16.633+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:24:16.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:24:47.134+0000] {processor.py:157} INFO - Started process (PID=17018) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:24:47.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:24:47.137+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:47.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:24:47.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:24:47.158+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:47.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:24:47.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:47.168+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:24:47.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:25:17.646+0000] {processor.py:157} INFO - Started process (PID=17038) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:25:17.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:25:17.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:17.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:25:17.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:25:17.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:17.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:25:17.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:17.680+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:25:17.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:25:48.160+0000] {processor.py:157} INFO - Started process (PID=17058) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:25:48.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:25:48.164+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:48.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:25:48.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:25:48.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:48.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:25:48.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:48.198+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:25:48.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T19:26:18.705+0000] {processor.py:157} INFO - Started process (PID=17078) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:26:18.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:26:18.707+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:18.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:26:18.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:26:18.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:18.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:26:18.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:18.741+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:26:18.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:26:49.268+0000] {processor.py:157} INFO - Started process (PID=17098) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:26:49.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:26:49.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:49.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:26:49.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:26:49.294+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:49.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:26:49.304+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:49.304+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:26:49.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:27:19.804+0000] {processor.py:157} INFO - Started process (PID=17118) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:27:19.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:27:19.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:19.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:27:19.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:27:19.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:19.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:27:19.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:19.837+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:27:19.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:27:50.318+0000] {processor.py:157} INFO - Started process (PID=17138) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:27:50.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:27:50.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:50.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:27:50.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:27:50.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:50.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:27:50.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:50.351+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:27:50.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:28:20.754+0000] {processor.py:157} INFO - Started process (PID=17158) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:28:20.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:28:20.756+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:20.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:28:20.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:28:20.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:20.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:28:20.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:20.787+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:28:20.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:28:51.221+0000] {processor.py:157} INFO - Started process (PID=17178) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:28:51.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:28:51.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:51.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:28:51.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:28:51.244+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:51.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:28:51.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:51.254+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:28:51.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:29:21.775+0000] {processor.py:157} INFO - Started process (PID=17198) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:29:21.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:29:21.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:21.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:29:21.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:29:21.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:21.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:29:21.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:21.809+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:29:21.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:29:52.277+0000] {processor.py:157} INFO - Started process (PID=17218) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:29:52.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:29:52.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:52.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:29:52.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:29:52.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:52.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:29:52.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:52.313+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:29:52.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:30:22.761+0000] {processor.py:157} INFO - Started process (PID=17238) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:30:22.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:30:22.763+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:22.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:30:22.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:30:22.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:22.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:30:22.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:22.795+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:30:22.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:30:53.266+0000] {processor.py:157} INFO - Started process (PID=17258) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:30:53.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:30:53.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:53.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:30:53.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:30:53.292+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:53.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:30:53.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:53.301+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:30:53.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:31:23.776+0000] {processor.py:157} INFO - Started process (PID=17278) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:31:23.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:31:23.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:23.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:31:23.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:31:23.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:23.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:31:23.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:23.818+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:31:23.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T19:31:54.270+0000] {processor.py:157} INFO - Started process (PID=17298) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:31:54.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:31:54.273+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:54.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:31:54.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:31:54.290+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:54.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:31:54.298+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:54.298+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:31:54.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.035 seconds
[2024-07-10T19:32:24.788+0000] {processor.py:157} INFO - Started process (PID=17318) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:32:24.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:32:24.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:24.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:32:24.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:32:24.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:24.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:32:24.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:24.821+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:32:24.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:32:55.213+0000] {processor.py:157} INFO - Started process (PID=17338) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:32:55.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:32:55.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:55.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:32:55.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:32:55.236+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:55.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:32:55.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:55.246+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:32:55.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:33:25.690+0000] {processor.py:157} INFO - Started process (PID=17358) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:33:25.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:33:25.692+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:25.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:33:25.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:33:25.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:25.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:33:25.724+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:25.724+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:33:25.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:33:56.182+0000] {processor.py:157} INFO - Started process (PID=17378) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:33:56.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:33:56.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:56.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:33:56.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:33:56.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:56.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:33:56.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:56.216+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:33:56.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:34:26.708+0000] {processor.py:157} INFO - Started process (PID=17398) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:34:26.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:34:26.710+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:26.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:34:26.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:34:26.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:26.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:34:26.742+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:26.742+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:34:26.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:34:57.184+0000] {processor.py:157} INFO - Started process (PID=17418) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:34:57.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:34:57.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:57.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:34:57.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:34:57.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:57.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:34:57.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:57.217+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:34:57.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:35:27.661+0000] {processor.py:157} INFO - Started process (PID=17438) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:35:27.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:35:27.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:27.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:35:27.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:35:27.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:27.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:35:27.695+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:27.695+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:35:27.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:35:58.159+0000] {processor.py:157} INFO - Started process (PID=17458) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:35:58.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:35:58.161+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:58.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:35:58.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:35:58.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:58.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:35:58.194+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:58.194+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:35:58.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:36:28.698+0000] {processor.py:157} INFO - Started process (PID=17478) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:36:28.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:36:28.700+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:28.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:36:28.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:36:28.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:28.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:36:28.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:28.732+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:36:28.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:36:59.191+0000] {processor.py:157} INFO - Started process (PID=17498) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:36:59.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:36:59.194+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:59.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:36:59.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:36:59.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:59.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:36:59.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:59.223+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:36:59.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:37:29.621+0000] {processor.py:157} INFO - Started process (PID=17518) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:37:29.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:37:29.624+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:37:29.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:37:29.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:37:29.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:37:29.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:37:29.656+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:37:29.655+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:37:29.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:38:00.075+0000] {processor.py:157} INFO - Started process (PID=17538) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:38:00.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:38:00.077+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:00.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:38:00.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:38:00.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:00.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:38:00.109+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:00.109+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:38:00.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:38:30.555+0000] {processor.py:157} INFO - Started process (PID=17558) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:38:30.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:38:30.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:30.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:38:30.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:38:30.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:30.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:38:30.587+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:30.587+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:38:30.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:39:00.957+0000] {processor.py:157} INFO - Started process (PID=17578) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:39:00.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:39:00.960+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:00.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:39:00.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:39:00.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:00.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:39:00.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:00.996+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:39:01.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T19:39:31.496+0000] {processor.py:157} INFO - Started process (PID=17598) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:39:31.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:39:31.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:31.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:39:31.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:39:31.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:31.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:39:31.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:31.529+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:39:31.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:40:01.969+0000] {processor.py:157} INFO - Started process (PID=17618) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:40:01.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:40:01.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:01.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:40:01.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:40:01.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:01.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:40:02.002+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:02.002+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:40:02.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:40:32.434+0000] {processor.py:157} INFO - Started process (PID=17638) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:40:32.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:40:32.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:32.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:40:32.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:40:32.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:32.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:40:32.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:32.467+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:40:32.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:41:02.910+0000] {processor.py:157} INFO - Started process (PID=17658) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:41:02.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:41:02.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:02.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:41:02.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:41:02.935+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:02.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:41:02.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:02.945+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:41:02.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:41:33.371+0000] {processor.py:157} INFO - Started process (PID=17678) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:41:33.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:41:33.373+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:33.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:41:33.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:41:33.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:33.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:41:33.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:33.403+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:41:33.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:42:03.760+0000] {processor.py:157} INFO - Started process (PID=17698) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:42:03.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:42:03.763+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:03.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:42:03.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:42:03.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:03.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:42:03.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:03.796+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:42:03.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T19:42:34.243+0000] {processor.py:157} INFO - Started process (PID=17718) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:42:34.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:42:34.245+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:34.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:42:34.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:42:34.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:34.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:42:34.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:34.275+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:42:34.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:43:04.661+0000] {processor.py:157} INFO - Started process (PID=17738) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:43:04.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:43:04.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:04.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:43:04.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:43:04.683+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:04.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:43:04.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:04.693+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:43:04.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.039 seconds
[2024-07-10T19:43:35.096+0000] {processor.py:157} INFO - Started process (PID=17758) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:43:35.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:43:35.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:35.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:43:35.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:43:35.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:35.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:43:35.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:35.129+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:43:35.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:44:05.591+0000] {processor.py:157} INFO - Started process (PID=17778) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:44:05.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:44:05.594+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:05.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:44:05.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:44:05.616+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:05.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:44:05.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:05.629+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:44:05.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T19:44:36.080+0000] {processor.py:157} INFO - Started process (PID=17798) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:44:36.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:44:36.081+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:36.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:44:36.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:44:36.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:36.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:44:36.112+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:36.112+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:44:36.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:45:06.527+0000] {processor.py:157} INFO - Started process (PID=17818) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:45:06.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:45:06.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:06.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:45:06.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:45:06.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:06.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:45:06.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:06.560+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:45:06.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:45:36.962+0000] {processor.py:157} INFO - Started process (PID=17838) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:45:36.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:45:36.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:36.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:45:36.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:45:36.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:36.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:45:36.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:36.997+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:45:37.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:46:07.478+0000] {processor.py:157} INFO - Started process (PID=17858) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:46:07.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:46:07.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:07.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:46:07.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:46:07.504+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:07.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:46:07.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:07.513+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:46:07.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:46:37.938+0000] {processor.py:157} INFO - Started process (PID=17878) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:46:37.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:46:37.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:37.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:46:37.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:46:37.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:37.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:46:37.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:37.972+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:46:37.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:47:08.417+0000] {processor.py:157} INFO - Started process (PID=17898) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:47:08.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:47:08.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:08.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:47:08.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:47:08.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:08.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:47:08.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:08.451+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:47:08.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:47:38.840+0000] {processor.py:157} INFO - Started process (PID=17918) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:47:38.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:47:38.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:38.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:47:38.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:47:38.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:38.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:47:38.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:38.873+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:47:38.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:48:09.321+0000] {processor.py:157} INFO - Started process (PID=17938) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:48:09.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:48:09.323+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:09.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:48:09.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:48:09.345+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:09.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:48:09.355+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:09.355+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:48:09.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:48:39.798+0000] {processor.py:157} INFO - Started process (PID=17958) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:48:39.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:48:39.800+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:39.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:48:39.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:48:39.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:39.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:48:39.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:39.832+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:48:39.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:49:10.289+0000] {processor.py:157} INFO - Started process (PID=17978) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:49:10.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:49:10.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:10.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:49:10.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:49:10.312+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:10.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:49:10.322+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:10.322+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:49:10.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:49:40.816+0000] {processor.py:157} INFO - Started process (PID=17998) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:49:40.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:49:40.819+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:40.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:49:40.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:49:40.841+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:40.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:49:40.851+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:40.851+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:49:40.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:50:11.246+0000] {processor.py:157} INFO - Started process (PID=18018) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:50:11.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:50:11.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:11.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:50:11.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:50:11.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:11.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:50:11.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:11.281+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:50:11.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:50:41.732+0000] {processor.py:157} INFO - Started process (PID=18038) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:50:41.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:50:41.734+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:41.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:50:41.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:50:41.756+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:41.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:50:41.765+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:41.765+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:50:41.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:51:12.204+0000] {processor.py:157} INFO - Started process (PID=18058) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:51:12.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:51:12.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:12.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:51:12.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:51:12.229+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:12.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:51:12.238+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:12.238+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:51:12.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:51:42.754+0000] {processor.py:157} INFO - Started process (PID=18078) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:51:42.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:51:42.757+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:42.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:51:42.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:51:42.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:42.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:51:42.794+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:42.794+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:51:42.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T19:52:13.223+0000] {processor.py:157} INFO - Started process (PID=18098) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:52:13.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:52:13.227+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:13.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:52:13.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:52:13.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:13.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:52:13.262+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:13.262+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:52:13.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T19:52:43.770+0000] {processor.py:157} INFO - Started process (PID=18118) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:52:43.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:52:43.773+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:43.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:52:43.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:52:43.794+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:43.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:52:43.805+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:43.805+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:52:43.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:53:14.237+0000] {processor.py:157} INFO - Started process (PID=18138) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:53:14.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:53:14.239+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:14.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:53:14.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:53:14.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:14.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:53:14.269+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:14.269+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:53:14.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T19:53:44.751+0000] {processor.py:157} INFO - Started process (PID=18158) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:53:44.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:53:44.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:44.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:53:44.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:53:44.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:44.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:53:44.784+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:44.784+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:53:44.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:54:15.208+0000] {processor.py:157} INFO - Started process (PID=18178) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:54:15.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:54:15.210+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:15.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:54:15.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:54:15.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:15.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:54:15.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:15.241+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:54:15.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:54:45.702+0000] {processor.py:157} INFO - Started process (PID=18198) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:54:45.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:54:45.704+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:45.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:54:45.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:54:45.726+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:45.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:54:45.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:45.736+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:54:45.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:55:16.190+0000] {processor.py:157} INFO - Started process (PID=18218) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:55:16.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:55:16.193+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:16.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:55:16.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:55:16.215+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:16.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:55:16.225+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:16.225+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:55:16.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:55:46.640+0000] {processor.py:157} INFO - Started process (PID=18238) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:55:46.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:55:46.642+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:46.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:55:46.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:55:46.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:46.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:55:46.673+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:46.673+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:55:46.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:56:17.146+0000] {processor.py:157} INFO - Started process (PID=18258) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:56:17.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:56:17.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:17.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:56:17.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:56:17.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:17.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:56:17.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:17.181+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:56:17.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T19:56:47.636+0000] {processor.py:157} INFO - Started process (PID=18278) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:56:47.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:56:47.639+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:47.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:56:47.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:56:47.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:47.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:56:47.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:47.670+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:56:47.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:57:18.150+0000] {processor.py:157} INFO - Started process (PID=18298) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:57:18.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:57:18.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:18.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:57:18.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:57:18.173+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:18.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:57:18.182+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:18.182+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:57:18.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T19:57:48.628+0000] {processor.py:157} INFO - Started process (PID=18318) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:57:48.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:57:48.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:48.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:57:48.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:57:48.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:48.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:57:48.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:48.661+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:57:48.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:58:19.112+0000] {processor.py:157} INFO - Started process (PID=18338) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:58:19.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:58:19.115+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:19.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:58:19.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:58:19.136+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:19.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:58:19.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:19.146+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:58:19.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T19:58:49.568+0000] {processor.py:157} INFO - Started process (PID=18358) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:58:49.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:58:49.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:49.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:58:49.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:58:49.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:49.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:58:49.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:49.601+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:58:49.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T19:59:20.062+0000] {processor.py:157} INFO - Started process (PID=18378) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:59:20.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:59:20.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:20.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:59:20.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:59:20.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:20.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:59:20.097+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:20.097+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:59:20.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T19:59:50.535+0000] {processor.py:157} INFO - Started process (PID=18398) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:59:50.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T19:59:50.537+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:50.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:59:50.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T19:59:50.559+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:50.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:59:50.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:50.569+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:59:50.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:00:21.069+0000] {processor.py:157} INFO - Started process (PID=18418) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:00:21.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:00:21.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:00:21.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:00:21.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:00:21.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:00:21.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:00:21.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:00:21.116+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:00:21.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T20:16:48.229+0000] {processor.py:157} INFO - Started process (PID=18440) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:16:48.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:16:48.234+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:16:48.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:16:48.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:16:48.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:16:48.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:16:48.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:16:48.331+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:16:48.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.129 seconds
[2024-07-10T20:17:18.908+0000] {processor.py:157} INFO - Started process (PID=18459) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:17:18.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:17:18.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:18.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:17:18.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:17:18.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:18.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:17:18.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:18.954+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:17:18.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T20:17:49.389+0000] {processor.py:157} INFO - Started process (PID=18480) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:17:49.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:17:49.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:49.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:17:49.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:17:49.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:49.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:17:49.446+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:49.446+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:17:49.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.068 seconds
[2024-07-10T20:18:19.922+0000] {processor.py:157} INFO - Started process (PID=18500) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:18:19.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:18:19.924+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:19.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:18:19.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:18:19.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:19.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:18:19.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:19.962+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:18:19.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.055 seconds
[2024-07-10T20:18:50.426+0000] {processor.py:157} INFO - Started process (PID=18520) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:18:50.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:18:50.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:50.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:18:50.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:18:50.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:50.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:18:50.463+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:50.463+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:18:50.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T20:19:20.869+0000] {processor.py:157} INFO - Started process (PID=18540) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:19:20.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:19:20.871+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:20.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:19:20.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:19:20.894+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:20.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:19:20.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:20.903+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:19:20.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T20:19:51.362+0000] {processor.py:157} INFO - Started process (PID=18560) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:19:51.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:19:51.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:51.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:19:51.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:19:51.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:51.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:19:51.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:51.397+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:19:51.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T20:20:21.833+0000] {processor.py:157} INFO - Started process (PID=18580) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:20:21.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:20:21.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:21.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:20:21.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:20:21.859+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:21.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:20:21.870+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:21.870+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:20:21.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T20:20:52.360+0000] {processor.py:157} INFO - Started process (PID=18600) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:20:52.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:20:52.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:52.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:20:52.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:20:52.395+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:52.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:20:52.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:52.407+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:20:52.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T20:21:22.737+0000] {processor.py:157} INFO - Started process (PID=18620) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:21:22.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:21:22.739+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:22.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:21:22.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:21:22.761+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:22.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:21:22.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:22.771+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:21:22.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T20:21:53.215+0000] {processor.py:157} INFO - Started process (PID=18640) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:21:53.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:21:53.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:53.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:21:53.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:21:53.240+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:53.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:21:53.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:53.250+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:21:53.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:22:23.636+0000] {processor.py:157} INFO - Started process (PID=18660) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:22:23.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:22:23.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:23.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:22:23.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:22:23.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:23.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:22:23.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:23.670+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:22:23.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T20:22:54.060+0000] {processor.py:157} INFO - Started process (PID=18680) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:22:54.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:22:54.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:54.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:22:54.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:22:54.084+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:54.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:22:54.094+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:54.094+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:22:54.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T20:23:24.493+0000] {processor.py:157} INFO - Started process (PID=18700) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:23:24.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:23:24.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:24.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:23:24.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:23:24.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:24.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:23:24.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:24.530+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:23:24.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.047 seconds
[2024-07-10T20:23:54.901+0000] {processor.py:157} INFO - Started process (PID=18720) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:23:54.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:23:54.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:54.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:23:54.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:23:54.924+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:54.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:23:54.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:54.934+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:23:54.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T20:24:25.297+0000] {processor.py:157} INFO - Started process (PID=18740) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:24:25.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:24:25.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:25.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:24:25.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:24:25.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:25.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:24:25.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:25.329+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:24:25.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T20:24:55.812+0000] {processor.py:157} INFO - Started process (PID=18760) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:24:55.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:24:55.814+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:55.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:24:55.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:24:55.836+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:55.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:24:55.845+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:55.845+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:24:55.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:25:26.303+0000] {processor.py:157} INFO - Started process (PID=18780) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:25:26.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:25:26.306+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:26.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:25:26.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:25:26.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:26.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:25:26.337+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:26.337+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:25:26.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T20:25:56.792+0000] {processor.py:157} INFO - Started process (PID=18800) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:25:56.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:25:56.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:56.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:25:56.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:25:56.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:56.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:25:56.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:56.834+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:25:56.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T20:26:27.201+0000] {processor.py:157} INFO - Started process (PID=18820) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:26:27.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:26:27.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:27.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:26:27.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:26:27.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:27.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:26:27.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:27.248+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:26:27.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T20:26:57.645+0000] {processor.py:157} INFO - Started process (PID=18840) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:26:57.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:26:57.647+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:57.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:26:57.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:26:57.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:57.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:26:57.679+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:57.679+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:26:57.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T20:27:28.042+0000] {processor.py:157} INFO - Started process (PID=18860) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:27:28.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:27:28.044+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:28.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:27:28.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:27:28.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:28.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:27:28.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:28.076+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:27:28.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T20:27:58.537+0000] {processor.py:157} INFO - Started process (PID=18880) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:27:58.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:27:58.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:58.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:27:58.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:27:58.563+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:58.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:27:58.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:58.573+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:27:58.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T20:28:28.983+0000] {processor.py:157} INFO - Started process (PID=18900) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:28:28.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:28:28.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:28.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:28:28.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:28:29.007+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:29.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:28:29.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:29.017+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:28:29.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:28:59.488+0000] {processor.py:157} INFO - Started process (PID=18920) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:28:59.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:28:59.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:59.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:28:59.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:28:59.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:59.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:28:59.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:59.521+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:28:59.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T20:29:29.993+0000] {processor.py:157} INFO - Started process (PID=18940) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:29:29.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:29:29.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:29:29.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:29:30.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:29:30.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:29:30.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:29:30.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:29:30.028+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:29:30.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T20:30:00.490+0000] {processor.py:157} INFO - Started process (PID=18960) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:30:00.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:30:00.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:00.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:30:00.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:30:00.515+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:00.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:30:00.525+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:00.524+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:30:00.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:30:30.992+0000] {processor.py:157} INFO - Started process (PID=18980) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:30:30.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:30:30.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:30.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:30:31.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:30:31.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:31.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:30:31.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:31.026+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:30:31.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:31:01.519+0000] {processor.py:157} INFO - Started process (PID=19000) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:31:01.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:31:01.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:01.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:31:01.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:31:01.549+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:01.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:31:01.559+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:01.559+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:31:01.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.049 seconds
[2024-07-10T20:31:32.022+0000] {processor.py:157} INFO - Started process (PID=19020) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:31:32.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:31:32.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:32.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:31:32.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:31:32.046+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:32.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:31:32.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:32.056+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:31:32.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:32:02.527+0000] {processor.py:157} INFO - Started process (PID=19040) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:32:02.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:32:02.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:02.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:32:02.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:32:02.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:02.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:32:02.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:02.573+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:32:02.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.056 seconds
[2024-07-10T20:32:33.056+0000] {processor.py:157} INFO - Started process (PID=19060) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:32:33.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:32:33.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:33.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:32:33.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:32:33.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:33.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:32:33.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:33.091+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:32:33.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T20:33:03.568+0000] {processor.py:157} INFO - Started process (PID=19080) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:33:03.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:33:03.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:33:03.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:33:03.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:33:03.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:33:03.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:33:03.602+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:33:03.602+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:33:03.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:50:10.546+0000] {processor.py:157} INFO - Started process (PID=19100) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:50:10.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:50:10.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:10.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:50:10.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:50:10.568+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:10.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:50:10.577+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:10.577+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:50:10.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.039 seconds
[2024-07-10T20:50:40.993+0000] {processor.py:157} INFO - Started process (PID=19121) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:50:40.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:50:40.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:40.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:50:41.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:50:41.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:41.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:50:41.047+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:41.047+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:50:41.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.065 seconds
[2024-07-10T20:51:11.499+0000] {processor.py:157} INFO - Started process (PID=19142) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:51:11.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:51:11.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:11.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:51:11.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:51:11.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:11.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:51:11.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:11.532+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:51:11.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T20:51:41.961+0000] {processor.py:157} INFO - Started process (PID=19162) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:51:41.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:51:41.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:41.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:51:41.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:51:41.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:41.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:51:41.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:41.994+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:51:42.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T20:52:12.464+0000] {processor.py:157} INFO - Started process (PID=19182) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:52:12.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:52:12.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:12.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:52:12.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:52:12.488+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:12.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:52:12.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:12.498+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:52:12.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T20:52:42.996+0000] {processor.py:157} INFO - Started process (PID=19202) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:52:42.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:52:43.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:43.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:52:43.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:52:43.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:43.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:52:43.030+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:43.030+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:52:43.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T20:53:13.462+0000] {processor.py:157} INFO - Started process (PID=19222) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:53:13.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:53:13.464+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:13.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:53:13.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:53:13.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:13.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:53:13.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:13.495+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:53:13.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T20:53:43.940+0000] {processor.py:157} INFO - Started process (PID=19242) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:53:43.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:53:43.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:43.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:53:43.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:53:43.964+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:43.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:53:43.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:43.973+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:53:43.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T20:54:14.435+0000] {processor.py:157} INFO - Started process (PID=19262) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:54:14.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:54:14.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:14.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:54:14.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:54:14.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:14.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:54:14.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:14.469+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:54:14.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T20:54:44.960+0000] {processor.py:157} INFO - Started process (PID=19282) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:54:44.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T20:54:44.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:44.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:54:44.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T20:54:44.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:44.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:54:44.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:44.996+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:54:45.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T21:12:10.570+0000] {processor.py:157} INFO - Started process (PID=19304) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:12:10.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T21:12:10.575+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:12:10.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:12:10.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:12:10.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:12:10.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:12:10.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:12:10.650+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:12:10.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.098 seconds
[2024-07-10T21:28:33.416+0000] {processor.py:157} INFO - Started process (PID=19324) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:28:33.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T21:28:33.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:28:33.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:28:33.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:28:33.446+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:28:33.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:28:33.456+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:28:33.456+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:28:33.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T21:29:03.921+0000] {processor.py:157} INFO - Started process (PID=19344) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:29:03.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T21:29:03.925+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:03.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:29:03.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:29:03.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:03.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:29:03.967+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:03.967+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:29:03.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T21:29:34.398+0000] {processor.py:157} INFO - Started process (PID=19364) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:29:34.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T21:29:34.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:34.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:29:34.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:29:34.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:34.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:29:34.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:34.440+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:29:34.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T21:45:07.639+0000] {processor.py:157} INFO - Started process (PID=19386) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:45:07.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T21:45:07.644+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:45:07.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:45:07.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T21:45:07.694+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:45:07.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:45:07.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:45:07.718+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:45:07.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.107 seconds
[2024-07-10T22:01:51.193+0000] {processor.py:157} INFO - Started process (PID=19406) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:01:51.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:01:51.201+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:01:51.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:01:51.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:01:51.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:01:51.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:01:51.294+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:01:51.294+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:01:51.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.127 seconds
[2024-07-10T22:02:21.792+0000] {processor.py:157} INFO - Started process (PID=19426) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:02:21.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:02:21.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:21.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:02:21.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:02:21.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:21.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:02:21.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:21.832+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:02:21.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T22:02:52.205+0000] {processor.py:157} INFO - Started process (PID=19446) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:02:52.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:02:52.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:52.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:02:52.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:02:52.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:52.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:02:52.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:52.241+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:02:52.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T22:03:22.591+0000] {processor.py:157} INFO - Started process (PID=19466) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:03:22.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:03:22.593+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:22.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:03:22.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:03:22.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:22.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:03:22.627+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:22.627+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:03:22.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T22:03:53.018+0000] {processor.py:157} INFO - Started process (PID=19486) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:03:53.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:03:53.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:53.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:03:53.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:03:53.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:53.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:03:53.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:53.062+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:03:53.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T22:20:43.454+0000] {processor.py:157} INFO - Started process (PID=19506) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:20:43.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:20:43.458+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:20:43.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:20:43.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:20:43.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:20:43.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:20:43.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:20:43.544+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:20:43.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.110 seconds
[2024-07-10T22:21:14.027+0000] {processor.py:157} INFO - Started process (PID=19526) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:21:14.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:21:14.031+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:14.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:21:14.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:21:14.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:14.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:21:14.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:14.080+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:21:14.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.064 seconds
[2024-07-10T22:21:44.435+0000] {processor.py:157} INFO - Started process (PID=19546) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:21:44.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:21:44.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:44.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:21:44.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:21:44.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:44.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:21:44.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:44.479+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:21:44.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T22:22:14.901+0000] {processor.py:157} INFO - Started process (PID=19566) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:22:14.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:22:14.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:14.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:22:14.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:22:14.927+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:14.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:22:14.936+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:14.936+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:22:14.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T22:22:45.420+0000] {processor.py:157} INFO - Started process (PID=19586) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:22:45.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:22:45.424+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:45.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:22:45.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:22:45.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:45.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:22:45.465+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:45.465+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:22:45.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.059 seconds
[2024-07-10T22:23:15.874+0000] {processor.py:157} INFO - Started process (PID=19606) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:23:15.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:23:15.875+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:15.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:23:15.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:23:15.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:15.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:23:15.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:15.903+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:23:15.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.037 seconds
[2024-07-10T22:23:46.251+0000] {processor.py:157} INFO - Started process (PID=19626) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:23:46.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:23:46.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:46.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:23:46.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:23:46.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:46.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:23:46.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:46.285+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:23:46.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T22:24:16.736+0000] {processor.py:157} INFO - Started process (PID=19646) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:24:16.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:24:16.739+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:24:16.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:24:16.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:24:16.760+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:24:16.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:24:16.770+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:24:16.769+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:24:16.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T22:28:59.989+0000] {processor.py:157} INFO - Started process (PID=19668) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:28:59.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:28:59.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:28:59.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:29:00.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:29:00.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:00.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:29:00.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:00.026+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:29:00.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T22:29:30.491+0000] {processor.py:157} INFO - Started process (PID=19688) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:29:30.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:29:30.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:30.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:29:30.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:29:30.525+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:30.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:29:30.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:30.536+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:29:30.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T22:46:44.881+0000] {processor.py:157} INFO - Started process (PID=19708) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:46:44.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:46:44.887+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:46:44.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:46:44.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:46:44.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:46:44.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:46:44.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:46:44.971+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:46:44.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.121 seconds
[2024-07-10T22:47:15.462+0000] {processor.py:157} INFO - Started process (PID=19728) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:47:15.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:47:15.464+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:15.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:47:15.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:47:15.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:15.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:47:15.503+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:15.503+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:47:15.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.051 seconds
[2024-07-10T22:47:45.932+0000] {processor.py:157} INFO - Started process (PID=19748) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:47:45.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:47:45.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:45.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:47:45.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:47:45.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:45.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:47:45.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:45.966+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:47:45.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T22:48:16.401+0000] {processor.py:157} INFO - Started process (PID=19768) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:48:16.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:48:16.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:16.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:48:16.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:48:16.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:16.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:48:16.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:16.438+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:48:16.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T22:48:46.838+0000] {processor.py:157} INFO - Started process (PID=19788) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:48:46.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T22:48:46.841+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:46.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:48:46.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T22:48:46.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:46.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:48:46.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:46.879+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:48:46.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.050 seconds
[2024-07-10T23:03:22.528+0000] {processor.py:157} INFO - Started process (PID=19808) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:03:22.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:03:22.532+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:03:22.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:03:22.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:03:22.574+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:03:22.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:03:22.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:03:22.591+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:03:22.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.081 seconds
[2024-07-10T23:16:57.000+0000] {processor.py:157} INFO - Started process (PID=19828) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:16:57.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:16:57.006+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:16:57.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:16:57.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:16:57.039+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:16:57.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:16:57.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:16:57.051+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:16:57.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.063 seconds
[2024-07-10T23:17:27.502+0000] {processor.py:157} INFO - Started process (PID=19848) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:17:27.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:17:27.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:27.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:17:27.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:17:27.538+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:27.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:17:27.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:27.548+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:17:27.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T23:17:58.057+0000] {processor.py:157} INFO - Started process (PID=19868) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:17:58.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:17:58.060+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:58.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:17:58.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:17:58.090+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:58.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:17:58.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:58.101+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:17:58.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.054 seconds
[2024-07-10T23:18:28.618+0000] {processor.py:157} INFO - Started process (PID=19888) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:18:28.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:18:28.620+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:28.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:18:28.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:18:28.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:28.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:18:28.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:28.660+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:18:28.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.053 seconds
[2024-07-10T23:18:59.148+0000] {processor.py:157} INFO - Started process (PID=19908) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:18:59.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:18:59.149+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:59.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:18:59.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:18:59.176+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:59.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:18:59.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:59.186+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:18:59.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.048 seconds
[2024-07-10T23:19:29.693+0000] {processor.py:157} INFO - Started process (PID=19928) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:19:29.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:19:29.695+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:19:29.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:19:29.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:19:29.718+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:19:29.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:19:29.727+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:19:29.727+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:19:29.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:20:00.206+0000] {processor.py:157} INFO - Started process (PID=19948) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:20:00.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:20:00.209+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:00.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:20:00.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:20:00.238+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:00.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:20:00.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:00.249+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:20:00.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.052 seconds
[2024-07-10T23:20:30.704+0000] {processor.py:157} INFO - Started process (PID=19968) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:20:30.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:20:30.706+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:30.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:20:30.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:20:30.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:30.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:20:30.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:30.738+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:20:30.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:21:01.156+0000] {processor.py:157} INFO - Started process (PID=19988) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:21:01.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:21:01.158+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:01.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:21:01.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:21:01.182+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:01.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:21:01.192+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:01.192+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:21:01.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T23:21:31.598+0000] {processor.py:157} INFO - Started process (PID=20008) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:21:31.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:21:31.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:31.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:21:31.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:21:31.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:31.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:21:31.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:31.632+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:21:31.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:22:02.132+0000] {processor.py:157} INFO - Started process (PID=20028) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:22:02.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:22:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:02.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:22:02.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:22:02.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:02.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:22:02.163+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:02.163+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:22:02.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.039 seconds
[2024-07-10T23:22:32.641+0000] {processor.py:157} INFO - Started process (PID=20048) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:22:32.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:22:32.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:32.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:22:32.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:22:32.665+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:32.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:22:32.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:32.675+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:22:32.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:23:03.188+0000] {processor.py:157} INFO - Started process (PID=20068) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:23:03.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:23:03.190+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:03.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:23:03.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:23:03.213+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:03.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:23:03.225+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:03.225+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:23:03.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.046 seconds
[2024-07-10T23:23:33.682+0000] {processor.py:157} INFO - Started process (PID=20088) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:23:33.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:23:33.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:33.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:23:33.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:23:33.716+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:33.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:23:33.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:33.728+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:23:33.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.057 seconds
[2024-07-10T23:24:04.217+0000] {processor.py:157} INFO - Started process (PID=20108) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:24:04.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:24:04.219+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:04.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:24:04.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:24:04.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:04.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:24:04.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:04.251+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:24:04.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:24:34.695+0000] {processor.py:157} INFO - Started process (PID=20128) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:24:34.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:24:34.697+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:34.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:24:34.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:24:34.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:34.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:24:34.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:34.728+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:24:34.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:25:05.145+0000] {processor.py:157} INFO - Started process (PID=20148) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:25:05.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:25:05.147+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:05.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:25:05.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:25:05.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:05.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:25:05.178+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:05.178+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:25:05.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:25:35.615+0000] {processor.py:157} INFO - Started process (PID=20168) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:25:35.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:25:35.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:35.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:25:35.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:25:35.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:35.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:25:35.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:35.647+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:25:35.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:26:06.108+0000] {processor.py:157} INFO - Started process (PID=20188) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:26:06.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:26:06.111+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:06.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:26:06.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:26:06.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:06.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:26:06.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:06.144+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:26:06.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T23:26:36.603+0000] {processor.py:157} INFO - Started process (PID=20208) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:26:36.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:26:36.605+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:36.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:26:36.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:26:36.627+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:36.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:26:36.637+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:36.637+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:26:36.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T23:27:07.134+0000] {processor.py:157} INFO - Started process (PID=20228) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:27:07.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:27:07.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:07.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:27:07.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:27:07.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:07.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:27:07.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:07.168+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:27:07.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:27:37.631+0000] {processor.py:157} INFO - Started process (PID=20248) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:27:37.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:27:37.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:37.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:27:37.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:27:37.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:37.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:27:37.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:37.664+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:27:37.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:28:08.135+0000] {processor.py:157} INFO - Started process (PID=20268) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:28:08.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:28:08.137+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:08.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:28:08.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:28:08.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:08.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:28:08.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:08.169+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:28:08.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:28:38.654+0000] {processor.py:157} INFO - Started process (PID=20288) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:28:38.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:28:38.656+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:38.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:28:38.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:28:38.676+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:38.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:28:38.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:38.685+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:28:38.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.038 seconds
[2024-07-10T23:29:09.196+0000] {processor.py:157} INFO - Started process (PID=20308) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:29:09.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:29:09.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:09.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:29:09.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:29:09.219+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:09.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:29:09.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:09.228+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:29:09.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T23:29:39.723+0000] {processor.py:157} INFO - Started process (PID=20328) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:29:39.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:29:39.725+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:39.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:29:39.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:29:39.747+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:39.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:29:39.757+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:39.757+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:29:39.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:30:10.275+0000] {processor.py:157} INFO - Started process (PID=20348) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:30:10.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:30:10.283+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:10.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:30:10.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:30:10.345+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:10.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:30:10.361+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:10.361+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:30:10.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.101 seconds
[2024-07-10T23:30:40.788+0000] {processor.py:157} INFO - Started process (PID=20368) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:30:40.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:30:40.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:40.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:30:40.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:30:40.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:40.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:30:40.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:40.822+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:30:40.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T23:31:11.302+0000] {processor.py:157} INFO - Started process (PID=20388) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:31:11.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:31:11.305+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:11.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:31:11.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:31:11.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:11.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:31:11.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:11.336+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:31:11.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:31:41.800+0000] {processor.py:157} INFO - Started process (PID=20408) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:31:41.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:31:41.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:41.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:31:41.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:31:41.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:41.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:31:41.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:41.832+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:31:41.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.040 seconds
[2024-07-10T23:32:12.353+0000] {processor.py:157} INFO - Started process (PID=20428) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:32:12.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:32:12.356+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:12.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:32:12.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:32:12.378+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:12.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:32:12.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:12.388+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:32:12.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T23:32:42.833+0000] {processor.py:157} INFO - Started process (PID=20448) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:32:42.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:32:42.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:42.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:32:42.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:32:42.857+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:42.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:32:42.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:42.867+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:32:42.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:33:13.384+0000] {processor.py:157} INFO - Started process (PID=20468) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:33:13.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:33:13.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:13.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:33:13.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:33:13.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:13.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:33:13.418+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:13.418+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:33:13.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T23:33:43.923+0000] {processor.py:157} INFO - Started process (PID=20488) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:33:43.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:33:43.925+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:43.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:33:43.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:33:43.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:43.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:33:43.957+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:43.957+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:33:43.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:34:14.388+0000] {processor.py:157} INFO - Started process (PID=20508) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:34:14.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:34:14.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:14.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:34:14.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:34:14.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:14.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:34:14.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:14.422+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:34:14.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:34:44.832+0000] {processor.py:157} INFO - Started process (PID=20528) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:34:44.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:34:44.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:44.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:34:44.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:34:44.856+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:44.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:34:44.865+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:44.865+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:34:44.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:35:15.316+0000] {processor.py:157} INFO - Started process (PID=20548) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:35:15.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:35:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:15.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:35:15.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:35:15.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:15.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:35:15.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:15.351+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:35:15.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:35:45.778+0000] {processor.py:157} INFO - Started process (PID=20568) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:35:45.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:35:45.780+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:45.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:35:45.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:35:45.801+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:45.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:35:45.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:45.811+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:35:45.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:36:16.298+0000] {processor.py:157} INFO - Started process (PID=20588) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:36:16.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:36:16.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:16.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:36:16.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:36:16.322+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:16.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:36:16.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:16.332+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:36:16.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:36:46.801+0000] {processor.py:157} INFO - Started process (PID=20608) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:36:46.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:36:46.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:46.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:36:46.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:36:46.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:46.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:36:46.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:46.834+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:36:46.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:37:17.336+0000] {processor.py:157} INFO - Started process (PID=20628) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:37:17.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:37:17.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:17.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:37:17.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:37:17.360+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:17.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:37:17.370+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:17.370+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:37:17.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:37:47.871+0000] {processor.py:157} INFO - Started process (PID=20648) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:37:47.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:37:47.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:47.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:37:47.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:37:47.894+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:47.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:37:47.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:47.904+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:37:47.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:38:18.330+0000] {processor.py:157} INFO - Started process (PID=20668) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:38:18.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:38:18.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:18.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:38:18.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:38:18.353+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:18.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:38:18.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:18.364+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:38:18.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:38:48.802+0000] {processor.py:157} INFO - Started process (PID=20688) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:38:48.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:38:48.804+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:48.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:38:48.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:38:48.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:48.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:38:48.836+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:48.836+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:38:48.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:39:19.269+0000] {processor.py:157} INFO - Started process (PID=20708) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:39:19.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:39:19.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:19.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:39:19.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:39:19.293+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:19.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:39:19.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:19.303+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:39:19.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:39:49.776+0000] {processor.py:157} INFO - Started process (PID=20728) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:39:49.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:39:49.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:49.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:39:49.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:39:49.799+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:49.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:39:49.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:49.808+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:39:49.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:40:20.254+0000] {processor.py:157} INFO - Started process (PID=20748) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:40:20.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:40:20.257+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:20.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:40:20.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:40:20.278+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:20.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:40:20.288+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:20.288+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:40:20.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:40:50.794+0000] {processor.py:157} INFO - Started process (PID=20768) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:40:50.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:40:50.797+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:50.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:40:50.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:40:50.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:50.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:40:50.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:50.828+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:40:50.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:41:21.262+0000] {processor.py:157} INFO - Started process (PID=20788) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:41:21.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:41:21.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:21.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:41:21.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:41:21.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:21.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:41:21.310+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:21.310+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:41:21.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.058 seconds
[2024-07-10T23:41:51.827+0000] {processor.py:157} INFO - Started process (PID=20808) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:41:51.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:41:51.830+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:51.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:41:51.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:41:51.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:51.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:41:51.859+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:51.859+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:41:51.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:42:22.329+0000] {processor.py:157} INFO - Started process (PID=20828) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:42:22.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:42:22.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:22.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:42:22.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:42:22.354+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:22.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:42:22.365+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:22.365+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:42:22.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T23:42:52.865+0000] {processor.py:157} INFO - Started process (PID=20848) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:42:52.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:42:52.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:52.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:42:52.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:42:52.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:52.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:42:52.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:52.898+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:42:52.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:43:23.347+0000] {processor.py:157} INFO - Started process (PID=20868) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:43:23.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:43:23.349+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:23.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:43:23.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:43:23.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:23.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:43:23.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:23.381+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:43:23.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:43:53.872+0000] {processor.py:157} INFO - Started process (PID=20888) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:43:53.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:43:53.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:53.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:43:53.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:43:53.896+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:53.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:43:53.906+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:53.906+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:43:53.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:44:24.378+0000] {processor.py:157} INFO - Started process (PID=20908) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:44:24.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:44:24.380+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:24.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:44:24.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:44:24.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:24.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:44:24.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:24.408+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:44:24.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.038 seconds
[2024-07-10T23:44:54.878+0000] {processor.py:157} INFO - Started process (PID=20928) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:44:54.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:44:54.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:54.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:44:54.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:44:54.896+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:54.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:44:54.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:54.905+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:44:54.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.035 seconds
[2024-07-10T23:45:25.340+0000] {processor.py:157} INFO - Started process (PID=20948) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:45:25.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:45:25.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:25.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:45:25.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:45:25.361+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:25.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:45:25.370+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:25.370+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:45:25.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.039 seconds
[2024-07-10T23:45:55.847+0000] {processor.py:157} INFO - Started process (PID=20968) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:45:55.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:45:55.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:55.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:45:55.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:45:55.871+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:55.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:45:55.880+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:55.880+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:45:55.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:46:26.443+0000] {processor.py:157} INFO - Started process (PID=20988) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:46:26.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:46:26.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:26.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:46:26.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:46:26.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:26.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:46:26.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:26.476+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:46:26.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:46:56.948+0000] {processor.py:157} INFO - Started process (PID=21008) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:46:56.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:46:56.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:56.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:46:56.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:46:56.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:56.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:46:56.982+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:56.982+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:46:56.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:47:27.438+0000] {processor.py:157} INFO - Started process (PID=21028) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:47:27.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:47:27.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:27.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:47:27.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:47:27.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:27.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:47:27.472+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:27.472+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:47:27.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:47:57.787+0000] {processor.py:157} INFO - Started process (PID=21048) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:47:57.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:47:57.789+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:57.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:47:57.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:47:57.810+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:57.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:47:57.819+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:57.819+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:47:57.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:48:28.319+0000] {processor.py:157} INFO - Started process (PID=21068) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:48:28.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:48:28.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:28.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:48:28.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:48:28.344+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:28.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:48:28.353+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:28.353+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:48:28.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:48:58.796+0000] {processor.py:157} INFO - Started process (PID=21088) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:48:58.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:48:58.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:58.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:48:58.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:48:58.820+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:58.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:48:58.830+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:58.830+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:48:58.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:49:29.222+0000] {processor.py:157} INFO - Started process (PID=21108) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:49:29.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:49:29.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:29.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:49:29.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:49:29.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:29.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:49:29.256+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:29.255+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:49:29.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:49:59.655+0000] {processor.py:157} INFO - Started process (PID=21128) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:49:59.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:49:59.658+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:59.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:49:59.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:49:59.681+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:59.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:49:59.691+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:59.691+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:49:59.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T23:50:30.079+0000] {processor.py:157} INFO - Started process (PID=21148) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:50:30.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:50:30.081+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:50:30.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:50:30.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:50:30.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:50:30.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:50:30.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:50:30.113+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:50:30.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:51:00.515+0000] {processor.py:157} INFO - Started process (PID=21168) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:51:00.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:51:00.517+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:00.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:51:00.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:51:00.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:00.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:51:00.550+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:00.550+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:51:00.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T23:51:30.929+0000] {processor.py:157} INFO - Started process (PID=21188) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:51:30.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:51:30.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:30.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:51:30.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:51:30.952+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:30.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:51:30.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:30.962+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:51:30.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:52:01.454+0000] {processor.py:157} INFO - Started process (PID=21208) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:52:01.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:52:01.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:01.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:52:01.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:52:01.477+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:01.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:52:01.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:01.487+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:52:01.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:52:31.950+0000] {processor.py:157} INFO - Started process (PID=21228) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:52:31.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:52:31.952+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:31.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:52:31.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:52:31.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:31.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:52:31.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:31.984+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:52:31.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:53:02.410+0000] {processor.py:157} INFO - Started process (PID=21248) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:53:02.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:53:02.412+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:02.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:53:02.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:53:02.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:02.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:53:02.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:02.443+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:53:02.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:53:32.867+0000] {processor.py:157} INFO - Started process (PID=21268) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:53:32.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:53:32.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:32.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:53:32.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:53:32.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:32.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:53:32.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:32.902+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:53:32.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T23:54:03.267+0000] {processor.py:157} INFO - Started process (PID=21288) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:54:03.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:54:03.269+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:03.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:54:03.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:54:03.293+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:03.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:54:03.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:03.303+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:54:03.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.045 seconds
[2024-07-10T23:54:33.719+0000] {processor.py:157} INFO - Started process (PID=21308) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:54:33.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:54:33.721+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:33.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:54:33.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:54:33.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:33.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:54:33.752+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:33.752+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:54:33.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:55:04.170+0000] {processor.py:157} INFO - Started process (PID=21328) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:55:04.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:55:04.172+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:04.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:55:04.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:55:04.193+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:04.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:55:04.203+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:04.203+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:55:04.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:55:34.707+0000] {processor.py:157} INFO - Started process (PID=21348) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:55:34.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:55:34.709+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:34.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:55:34.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:55:34.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:34.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:55:34.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:34.741+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:55:34.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:56:05.154+0000] {processor.py:157} INFO - Started process (PID=21368) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:56:05.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:56:05.157+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:05.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:56:05.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:56:05.178+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:05.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:56:05.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:05.189+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:56:05.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.044 seconds
[2024-07-10T23:56:35.665+0000] {processor.py:157} INFO - Started process (PID=21388) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:56:35.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:56:35.668+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:35.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:56:35.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:56:35.689+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:35.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:56:35.699+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:35.699+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:56:35.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:57:06.092+0000] {processor.py:157} INFO - Started process (PID=21408) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:57:06.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:57:06.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:06.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:57:06.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:57:06.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:06.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:57:06.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:06.125+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:57:06.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:57:36.591+0000] {processor.py:157} INFO - Started process (PID=21428) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:57:36.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:57:36.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:36.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:57:36.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:57:36.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:36.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:57:36.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:36.623+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:57:36.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.041 seconds
[2024-07-10T23:58:07.086+0000] {processor.py:157} INFO - Started process (PID=21448) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:58:07.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:58:07.088+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:07.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:58:07.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:58:07.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:07.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:58:07.114+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:07.114+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:58:07.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.036 seconds
[2024-07-10T23:58:37.617+0000] {processor.py:157} INFO - Started process (PID=21468) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:58:37.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:58:37.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:37.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:58:37.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:58:37.641+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:37.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:58:37.651+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:37.651+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:58:37.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.043 seconds
[2024-07-10T23:59:08.137+0000] {processor.py:157} INFO - Started process (PID=21488) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:59:08.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:59:08.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:08.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:59:08.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:59:08.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:08.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:59:08.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:08.170+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:59:08.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
[2024-07-10T23:59:38.670+0000] {processor.py:157} INFO - Started process (PID=21508) to work on /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:59:38.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data-pipeline.py for tasks to queue
[2024-07-10T23:59:38.672+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:38.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:59:38.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['github-archive-pipeline']) retrieved from /opt/airflow/dags/data-pipeline.py
[2024-07-10T23:59:38.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:38.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:59:38.703+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:38.703+0000] {dag.py:3696} INFO - Setting next_dagrun for github-archive-pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:59:38.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data-pipeline.py took 0.042 seconds
