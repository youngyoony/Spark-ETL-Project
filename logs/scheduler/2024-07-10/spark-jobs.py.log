[2024-07-10T09:58:50.387+0000] {processor.py:157} INFO - Started process (PID=14260) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:58:50.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T09:58:50.389+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:58:50.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:58:50.398+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:58:50.397+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T09:58:50.398+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:58:50.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T09:58:56.545+0000] {processor.py:157} INFO - Started process (PID=14280) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:58:56.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T09:58:56.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:58:56.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:58:56.553+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:58:56.552+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T09:58:56.553+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:58:56.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.023 seconds
[2024-07-10T09:59:26.936+0000] {processor.py:157} INFO - Started process (PID=14300) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:59:26.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T09:59:26.939+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:59:26.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:59:26.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:59:26.944+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T09:59:26.946+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:59:26.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T09:59:53.247+0000] {processor.py:157} INFO - Started process (PID=14305) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:59:53.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T09:59:53.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:59:53.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:59:53.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T09:59:53.278+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T09:59:53.281+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T09:59:53.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-10T10:00:23.719+0000] {processor.py:157} INFO - Started process (PID=14325) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:23.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:00:23.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:23.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:23.729+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:23.728+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:00:23.730+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:23.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.031 seconds
[2024-07-10T10:00:44.038+0000] {processor.py:157} INFO - Started process (PID=14345) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:44.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:00:44.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:44.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:44.049+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:44.048+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:00:44.049+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:44.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:00:48.089+0000] {processor.py:157} INFO - Started process (PID=14350) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:48.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:00:48.093+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:48.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:48.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:00:48.100+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:00:48.101+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:00:48.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.029 seconds
[2024-07-10T10:01:18.479+0000] {processor.py:157} INFO - Started process (PID=14370) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:01:18.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:01:18.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:01:18.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:01:18.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:01:18.485+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:01:18.487+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:01:18.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.024 seconds
[2024-07-10T10:01:48.836+0000] {processor.py:157} INFO - Started process (PID=14390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:01:48.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:01:48.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:01:48.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:01:48.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:01:48.842+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:01:48.844+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:01:48.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.023 seconds
[2024-07-10T10:02:19.214+0000] {processor.py:157} INFO - Started process (PID=14410) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:02:19.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:02:19.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:02:19.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:02:19.222+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:02:19.220+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:02:19.222+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:02:19.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:02:49.616+0000] {processor.py:157} INFO - Started process (PID=14430) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:02:49.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:02:49.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:02:49.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:02:49.625+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:02:49.623+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:02:49.625+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:02:49.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:03:20.009+0000] {processor.py:157} INFO - Started process (PID=14450) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:03:20.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:03:20.011+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:03:20.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:03:20.016+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:03:20.015+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:03:20.017+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:03:20.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.024 seconds
[2024-07-10T10:03:50.424+0000] {processor.py:157} INFO - Started process (PID=14470) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:03:50.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:03:50.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:03:50.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:03:50.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:03:50.430+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:03:50.432+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:03:50.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.021 seconds
[2024-07-10T10:04:20.773+0000] {processor.py:157} INFO - Started process (PID=14495) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:04:20.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:04:20.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:04:20.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:04:20.780+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:04:20.779+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:04:20.781+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:04:20.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.023 seconds
[2024-07-10T10:04:51.133+0000] {processor.py:157} INFO - Started process (PID=14515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:04:51.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:04:51.137+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:04:51.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:04:51.143+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:04:51.142+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:04:51.143+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:04:51.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.032 seconds
[2024-07-10T10:05:21.526+0000] {processor.py:157} INFO - Started process (PID=14535) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:05:21.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:05:21.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:05:21.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:05:21.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:05:21.532+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:05:21.534+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:05:21.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.024 seconds
[2024-07-10T10:05:51.909+0000] {processor.py:157} INFO - Started process (PID=14555) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:05:51.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:05:51.912+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:05:51.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:05:51.917+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:05:51.916+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:05:51.918+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:05:51.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:06:22.309+0000] {processor.py:157} INFO - Started process (PID=14575) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:06:22.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:06:22.312+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:06:22.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:06:22.319+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:06:22.318+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:06:22.320+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:06:22.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.028 seconds
[2024-07-10T10:06:52.726+0000] {processor.py:157} INFO - Started process (PID=14595) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:06:52.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:06:52.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:06:52.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:06:52.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:06:52.737+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:06:52.738+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:06:52.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.034 seconds
[2024-07-10T10:07:23.132+0000] {processor.py:157} INFO - Started process (PID=14615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:07:23.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:07:23.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:07:23.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:07:23.141+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:07:23.140+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:07:23.142+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:07:23.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:07:53.520+0000] {processor.py:157} INFO - Started process (PID=14635) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:07:53.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:07:53.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:07:53.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:07:53.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:07:53.527+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:07:53.529+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:07:53.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:08:23.900+0000] {processor.py:157} INFO - Started process (PID=14655) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:08:23.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:08:23.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:08:23.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:08:23.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:08:23.904+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:08:23.905+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:08:23.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.014 seconds
[2024-07-10T10:08:54.278+0000] {processor.py:157} INFO - Started process (PID=14675) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:08:54.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:08:54.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:08:54.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:08:54.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:08:54.284+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:08:54.286+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:08:54.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:09:24.614+0000] {processor.py:157} INFO - Started process (PID=14695) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:09:24.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:09:24.616+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:09:24.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:09:24.621+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:09:24.620+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:09:24.621+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:09:24.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.023 seconds
[2024-07-10T10:09:54.989+0000] {processor.py:157} INFO - Started process (PID=14715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:09:54.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:09:54.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:09:54.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:09:54.998+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:09:54.997+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:09:54.998+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:09:55.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.029 seconds
[2024-07-10T10:10:25.382+0000] {processor.py:157} INFO - Started process (PID=14735) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:10:25.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:10:25.385+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:10:25.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:10:25.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:10:25.390+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:10:25.391+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:10:25.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:10:55.803+0000] {processor.py:157} INFO - Started process (PID=14755) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:10:55.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:10:55.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:10:55.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:10:55.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:10:55.810+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:10:55.811+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:10:55.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:11:26.173+0000] {processor.py:157} INFO - Started process (PID=14775) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:11:26.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:11:26.176+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:11:26.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:11:26.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:11:26.180+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:11:26.182+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:11:26.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:11:56.539+0000] {processor.py:157} INFO - Started process (PID=14795) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:11:56.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:11:56.542+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:11:56.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:11:56.546+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:11:56.545+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:11:56.547+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:11:56.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:12:26.909+0000] {processor.py:157} INFO - Started process (PID=14815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:12:26.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:12:26.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:12:26.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:12:26.915+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:12:26.914+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:12:26.916+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:12:26.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.022 seconds
[2024-07-10T10:12:57.326+0000] {processor.py:157} INFO - Started process (PID=14835) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:12:57.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:12:57.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:12:57.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:12:57.334+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:12:57.332+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:12:57.334+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:12:57.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:13:27.742+0000] {processor.py:157} INFO - Started process (PID=14855) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:13:27.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:13:27.745+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:13:27.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:13:27.749+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:13:27.748+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:13:27.750+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:13:27.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.024 seconds
[2024-07-10T10:13:58.176+0000] {processor.py:157} INFO - Started process (PID=14875) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:13:58.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:13:58.179+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:13:58.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:13:58.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:13:58.185+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:13:58.186+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:13:58.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.028 seconds
[2024-07-10T10:14:28.583+0000] {processor.py:157} INFO - Started process (PID=14895) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:14:28.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:14:28.587+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:14:28.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:14:28.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:14:28.591+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:14:28.592+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:14:28.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.028 seconds
[2024-07-10T10:14:58.981+0000] {processor.py:157} INFO - Started process (PID=14915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:14:58.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:14:58.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:14:58.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:14:58.989+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:14:58.988+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:14:58.990+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:14:59.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:15:29.328+0000] {processor.py:157} INFO - Started process (PID=14935) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:15:29.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:15:29.330+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:15:29.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:15:29.335+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:15:29.334+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:15:29.335+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:15:29.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.024 seconds
[2024-07-10T10:15:59.721+0000] {processor.py:157} INFO - Started process (PID=14955) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:15:59.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:15:59.724+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:15:59.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:15:59.730+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:15:59.728+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:15:59.730+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:15:59.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.029 seconds
[2024-07-10T10:16:30.077+0000] {processor.py:157} INFO - Started process (PID=14975) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:16:30.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:16:30.079+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:16:30.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:16:30.083+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:16:30.082+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:16:30.083+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:16:30.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.017 seconds
[2024-07-10T10:17:00.469+0000] {processor.py:157} INFO - Started process (PID=14995) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:17:00.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:17:00.472+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:17:00.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:17:00.477+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:17:00.476+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:17:00.478+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:17:00.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:17:30.868+0000] {processor.py:157} INFO - Started process (PID=15015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:17:30.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:17:30.871+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:17:30.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:17:30.876+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:17:30.875+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:17:30.877+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:17:30.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:18:01.238+0000] {processor.py:157} INFO - Started process (PID=15035) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:18:01.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:18:01.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:18:01.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:18:01.247+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:18:01.246+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:18:01.248+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:18:01.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:18:31.641+0000] {processor.py:157} INFO - Started process (PID=15055) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:18:31.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:18:31.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:18:31.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:18:31.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:18:31.648+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:18:31.650+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:18:31.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:19:02.028+0000] {processor.py:157} INFO - Started process (PID=15075) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:19:02.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:19:02.031+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:19:02.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:19:02.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:19:02.035+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:19:02.037+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:19:02.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:19:32.448+0000] {processor.py:157} INFO - Started process (PID=15095) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:19:32.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:19:32.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:19:32.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:19:32.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:19:32.456+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:19:32.458+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:19:32.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:20:02.841+0000] {processor.py:157} INFO - Started process (PID=15115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:20:02.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:20:02.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:20:02.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:20:02.848+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:20:02.847+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:20:02.849+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:20:02.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:20:33.248+0000] {processor.py:157} INFO - Started process (PID=15135) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:20:33.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:20:33.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:20:33.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:20:33.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:20:33.254+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:20:33.256+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:20:33.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:21:03.650+0000] {processor.py:157} INFO - Started process (PID=15155) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:21:03.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:21:03.654+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:21:03.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:21:03.659+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:21:03.658+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:21:03.659+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:21:03.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:21:34.065+0000] {processor.py:157} INFO - Started process (PID=15175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:21:34.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:21:34.068+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:21:34.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:21:34.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:21:34.073+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:21:34.075+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:21:34.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:22:04.434+0000] {processor.py:157} INFO - Started process (PID=15195) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:22:04.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:22:04.437+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:22:04.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:22:04.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:22:04.441+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:22:04.442+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:22:04.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.023 seconds
[2024-07-10T10:22:34.804+0000] {processor.py:157} INFO - Started process (PID=15215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:22:34.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:22:34.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:22:34.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:22:34.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:22:34.812+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:22:34.814+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:22:34.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:23:05.181+0000] {processor.py:157} INFO - Started process (PID=15235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:23:05.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:23:05.185+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:23:05.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:23:05.190+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:23:05.189+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:23:05.190+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:23:05.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:23:35.543+0000] {processor.py:157} INFO - Started process (PID=15255) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:23:35.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:23:35.545+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:23:35.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:23:35.550+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:23:35.549+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:23:35.551+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:23:35.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:24:05.916+0000] {processor.py:157} INFO - Started process (PID=15275) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:24:05.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:24:05.918+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:24:05.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:24:05.923+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:24:05.922+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:24:05.924+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:24:05.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.024 seconds
[2024-07-10T10:24:36.262+0000] {processor.py:157} INFO - Started process (PID=15295) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:24:36.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:24:36.265+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:24:36.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:24:36.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:24:36.269+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:24:36.271+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:24:36.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.023 seconds
[2024-07-10T10:25:06.653+0000] {processor.py:157} INFO - Started process (PID=15315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:25:06.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:25:06.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:25:06.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:25:06.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:25:06.668+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:25:06.670+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:25:06.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T10:25:37.009+0000] {processor.py:157} INFO - Started process (PID=15335) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:25:37.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:25:37.013+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:25:37.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:25:37.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:25:37.018+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:25:37.019+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:25:37.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.029 seconds
[2024-07-10T10:26:07.341+0000] {processor.py:157} INFO - Started process (PID=15355) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:26:07.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:26:07.345+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:26:07.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:26:07.350+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:26:07.349+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:26:07.351+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:26:07.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.028 seconds
[2024-07-10T10:26:37.674+0000] {processor.py:157} INFO - Started process (PID=15375) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:26:37.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:26:37.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:26:37.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:26:37.679+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:26:37.678+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:26:37.679+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:26:37.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.021 seconds
[2024-07-10T10:27:07.991+0000] {processor.py:157} INFO - Started process (PID=15395) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:27:07.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:27:07.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:27:07.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:27:08.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:27:08.000+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:27:08.002+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:27:08.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:27:38.332+0000] {processor.py:157} INFO - Started process (PID=15415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:27:38.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:27:38.334+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:27:38.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:27:38.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:27:38.338+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:27:38.340+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:27:38.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:28:08.698+0000] {processor.py:157} INFO - Started process (PID=15435) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:28:08.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:28:08.701+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:28:08.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:28:08.707+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:28:08.706+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:28:08.707+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:28:08.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:28:39.043+0000] {processor.py:157} INFO - Started process (PID=15455) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:28:39.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:28:39.046+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:28:39.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:28:39.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:28:39.050+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:28:39.052+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:28:39.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:29:09.442+0000] {processor.py:157} INFO - Started process (PID=15475) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:29:09.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:29:09.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:29:09.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:29:09.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:29:09.448+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:29:09.450+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:29:09.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.022 seconds
[2024-07-10T10:29:39.819+0000] {processor.py:157} INFO - Started process (PID=15495) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:29:39.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:29:39.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:29:39.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:29:39.827+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:29:39.826+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:29:39.828+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:29:39.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.027 seconds
[2024-07-10T10:30:10.232+0000] {processor.py:157} INFO - Started process (PID=15515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:30:10.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:30:10.238+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:30:10.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:30:10.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:30:10.244+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:30:10.246+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:30:10.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T10:30:40.638+0000] {processor.py:157} INFO - Started process (PID=15535) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:30:40.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:30:40.646+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:30:40.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:30:40.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:30:40.651+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:30:40.654+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:30:40.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T10:31:11.045+0000] {processor.py:157} INFO - Started process (PID=15555) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:31:11.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:31:11.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:31:11.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:31:11.053+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:31:11.052+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:31:11.054+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:31:11.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.024 seconds
[2024-07-10T10:31:41.422+0000] {processor.py:157} INFO - Started process (PID=15575) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:31:41.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:31:41.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:31:41.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:31:41.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:31:41.443+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:31:41.446+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:31:41.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T10:32:11.826+0000] {processor.py:157} INFO - Started process (PID=15595) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:32:11.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:32:11.829+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:32:11.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:32:11.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:32:11.835+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:32:11.837+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:32:11.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.037 seconds
[2024-07-10T10:32:42.260+0000] {processor.py:157} INFO - Started process (PID=15615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:32:42.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:32:42.265+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:32:42.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:32:42.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:32:42.269+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:32:42.271+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:32:42.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.036 seconds
[2024-07-10T10:33:12.646+0000] {processor.py:157} INFO - Started process (PID=15635) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:33:12.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:33:12.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:33:12.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:33:12.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:33:12.653+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:33:12.655+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:33:12.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.026 seconds
[2024-07-10T10:33:43.071+0000] {processor.py:157} INFO - Started process (PID=15655) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:33:43.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:33:43.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:33:43.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:33:43.079+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:33:43.078+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:33:43.080+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:33:43.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.030 seconds
[2024-07-10T10:34:11.113+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:34:11.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:34:11.118+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:34:11.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:34:11.122+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:34:11.121+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:34:11.123+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:34:11.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.025 seconds
[2024-07-10T10:34:41.508+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:34:41.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:34:41.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:34:41.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:34:41.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:34:41.539+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:34:41.542+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:34:41.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-10T10:35:11.992+0000] {processor.py:157} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:35:11.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:35:11.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:35:11.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:35:12.006+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:35:12.004+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:35:12.006+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:35:12.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T10:35:42.400+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:35:42.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:35:42.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:35:42.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:35:42.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:35:42.405+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:35:42.407+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:35:42.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.039 seconds
[2024-07-10T10:36:09.765+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:09.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:36:09.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:09.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:09.781+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:09.780+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:36:09.782+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:09.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-10T10:36:40.125+0000] {processor.py:157} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:40.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:36:40.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:40.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:40.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:40.136+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:36:40.139+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:40.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T10:36:43.148+0000] {processor.py:157} INFO - Started process (PID=291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:43.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:36:43.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:43.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:43.157+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:36:43.156+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:36:43.157+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:36:43.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.035 seconds
[2024-07-10T10:37:13.584+0000] {processor.py:157} INFO - Started process (PID=311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:13.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:37:13.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:13.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:13.600+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:13.598+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:37:13.601+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:13.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T10:37:43.988+0000] {processor.py:157} INFO - Started process (PID=331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:43.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:37:43.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:43.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:43.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:43.995+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 11, in <module>
    import fetch_data
ModuleNotFoundError: No module named 'fetch_data'
[2024-07-10T10:37:43.997+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:44.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.030 seconds
[2024-07-10T10:37:51.137+0000] {processor.py:157} INFO - Started process (PID=351) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:51.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:37:51.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:51.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:51.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:37:51.228+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:37:51.229+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:37:51.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-10T10:38:21.605+0000] {processor.py:157} INFO - Started process (PID=371) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:38:21.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:38:21.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:21.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:38:21.683+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:21.682+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:38:21.683+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:38:21.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-10T10:38:51.937+0000] {processor.py:157} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:38:51.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:38:51.940+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:51.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:38:51.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:38:51.995+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:38:51.996+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:38:52.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-10T10:39:22.275+0000] {processor.py:157} INFO - Started process (PID=411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:39:22.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:39:22.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:22.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:39:22.328+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:22.328+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:39:22.329+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:39:22.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-10T10:39:52.676+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:39:52.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:39:52.679+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:52.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:39:52.742+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:39:52.741+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:39:52.743+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:39:52.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-10T10:40:23.029+0000] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:40:23.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:40:23.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:23.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:40:23.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:23.079+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:40:23.080+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:40:23.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T10:40:53.445+0000] {processor.py:157} INFO - Started process (PID=471) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:40:53.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:40:53.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:53.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:40:53.515+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:40:53.514+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:40:53.515+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:40:53.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-10T10:41:23.841+0000] {processor.py:157} INFO - Started process (PID=491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:41:23.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:41:23.844+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:23.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:41:23.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:23.897+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:41:23.898+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:41:23.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-10T10:41:54.204+0000] {processor.py:157} INFO - Started process (PID=511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:41:54.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:41:54.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:54.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:41:54.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:41:54.248+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:41:54.249+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:41:54.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T10:42:24.513+0000] {processor.py:157} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:42:24.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:42:24.516+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:24.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:42:24.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:24.580+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:42:24.581+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:42:24.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-10T10:42:54.902+0000] {processor.py:157} INFO - Started process (PID=551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:42:54.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:42:54.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:54.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:42:54.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:42:54.951+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:42:54.951+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:42:54.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T10:43:25.295+0000] {processor.py:157} INFO - Started process (PID=571) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:43:25.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:43:25.298+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:25.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:43:25.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:25.352+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:43:25.353+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:43:25.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-10T10:43:55.685+0000] {processor.py:157} INFO - Started process (PID=591) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:43:55.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:43:55.690+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:55.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:43:55.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:43:55.736+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:43:55.737+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:43:55.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-10T10:44:26.073+0000] {processor.py:157} INFO - Started process (PID=611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:44:26.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:44:26.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:26.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:44:26.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:26.123+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:44:26.124+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:44:26.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T10:44:56.488+0000] {processor.py:157} INFO - Started process (PID=631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:44:56.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:44:56.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:56.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:44:56.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:44:56.547+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:44:56.548+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:44:56.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-10T10:45:26.894+0000] {processor.py:157} INFO - Started process (PID=651) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:45:26.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:45:26.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:26.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:45:26.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:26.937+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:45:26.938+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:45:26.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T10:45:57.274+0000] {processor.py:157} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:45:57.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:45:57.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:57.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:45:57.324+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:45:57.323+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:45:57.324+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:45:57.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T10:46:27.674+0000] {processor.py:157} INFO - Started process (PID=691) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:46:27.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:46:27.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:27.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:46:27.724+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:27.724+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:46:27.724+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:46:27.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T10:46:58.097+0000] {processor.py:157} INFO - Started process (PID=711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:46:58.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:46:58.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:58.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:46:58.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:46:58.146+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:46:58.146+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:46:58.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T10:47:28.498+0000] {processor.py:157} INFO - Started process (PID=731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:47:28.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:47:28.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:28.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:47:28.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:28.547+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:47:28.548+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:47:28.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T10:47:58.878+0000] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:47:58.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:47:58.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:58.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:47:58.928+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:47:58.927+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:47:58.928+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:47:58.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T10:48:29.257+0000] {processor.py:157} INFO - Started process (PID=771) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:48:29.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:48:29.260+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:29.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:48:29.306+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:29.305+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:48:29.306+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:48:29.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T10:48:59.614+0000] {processor.py:157} INFO - Started process (PID=791) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:48:59.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:48:59.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:59.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:48:59.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:48:59.663+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:48:59.664+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:48:59.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T10:49:29.982+0000] {processor.py:157} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:49:29.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:49:29.986+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:49:29.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:49:30.031+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:49:30.031+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:49:30.032+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:49:30.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T10:50:00.322+0000] {processor.py:157} INFO - Started process (PID=831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:50:00.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:50:00.325+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:00.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:50:00.367+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:00.367+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:50:00.368+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:50:00.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T10:50:30.754+0000] {processor.py:157} INFO - Started process (PID=851) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:50:30.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:50:30.756+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:30.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:50:30.819+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:50:30.818+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:50:30.819+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:50:30.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-10T10:51:01.111+0000] {processor.py:157} INFO - Started process (PID=871) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:51:01.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:51:01.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:01.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:51:01.152+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:01.151+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:51:01.152+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:51:01.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T10:51:31.513+0000] {processor.py:157} INFO - Started process (PID=891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:51:31.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:51:31.516+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:31.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:51:31.563+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:51:31.562+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:51:31.563+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:51:31.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T10:52:01.914+0000] {processor.py:157} INFO - Started process (PID=911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:52:01.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:52:01.918+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:52:01.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:52:02.011+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:52:02.010+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:52:02.011+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:52:02.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-10T10:52:32.354+0000] {processor.py:157} INFO - Started process (PID=931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:52:32.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:52:32.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:52:32.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:52:32.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:52:32.409+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:52:32.410+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:52:32.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-10T10:53:02.723+0000] {processor.py:157} INFO - Started process (PID=951) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:53:02.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:53:02.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:02.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:53:02.770+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:02.770+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:53:02.771+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:53:02.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T10:53:33.127+0000] {processor.py:157} INFO - Started process (PID=971) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:53:33.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:53:33.131+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:33.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:53:33.196+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:53:33.195+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:53:33.196+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:53:33.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-10T10:54:03.571+0000] {processor.py:157} INFO - Started process (PID=991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:54:03.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:54:03.575+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:03.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:54:03.635+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:03.635+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:54:03.636+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:54:03.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-10T10:54:34.070+0000] {processor.py:157} INFO - Started process (PID=1011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:54:34.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:54:34.073+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:34.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:54:34.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:54:34.147+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:54:34.148+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:54:34.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-10T10:55:04.492+0000] {processor.py:157} INFO - Started process (PID=1031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:55:04.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:55:04.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:04.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:55:04.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:04.583+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:55:04.584+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:55:04.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-10T10:55:34.921+0000] {processor.py:157} INFO - Started process (PID=1051) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:55:34.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:55:34.923+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:34.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:55:34.979+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:55:34.978+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:55:34.979+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:55:34.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-10T10:56:05.298+0000] {processor.py:157} INFO - Started process (PID=1071) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:56:05.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:56:05.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:05.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:56:05.369+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:05.369+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:56:05.370+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:56:05.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-10T10:56:35.687+0000] {processor.py:157} INFO - Started process (PID=1091) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:56:35.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:56:35.691+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:35.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:56:35.759+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:56:35.758+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:56:35.759+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:56:35.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-10T10:57:06.095+0000] {processor.py:157} INFO - Started process (PID=1111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:06.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:57:06.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:06.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:06.143+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:06.143+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 40, in <module>
    python_callable=fetch_data.fetch_data_from_api,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'fetch_data' has no attribute 'fetch_data_from_api'
[2024-07-10T10:57:06.144+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:06.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T10:57:19.256+0000] {processor.py:157} INFO - Started process (PID=1116) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:19.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:57:19.261+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:19.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:19.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:19.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:19.362+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-10T10:57:19.365+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:19.365+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-10T10:57:19.367+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:19.367+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-07-10T10:57:19.367+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:19.367+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:data_pipeline' as access control is unset.
[2024-07-10T10:57:19.367+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:19.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:57:19.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:19.371+0000] {dag.py:2937} INFO - Creating ORM DAG for data_pipeline
[2024-07-10T10:57:19.375+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:19.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:57:19.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-10T10:57:49.615+0000] {processor.py:157} INFO - Started process (PID=1136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:49.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:57:49.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:49.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:49.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:57:49.681+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:49.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:57:49.690+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:57:49.690+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:57:49.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-10T10:58:20.049+0000] {processor.py:157} INFO - Started process (PID=1156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:20.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:58:20.053+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:20.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:20.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:20.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:20.155+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:data_pipeline' as access control is unset.
[2024-07-10T10:58:20.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:20.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:58:20.163+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:20.162+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:58:20.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-10T10:58:24.103+0000] {processor.py:157} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:24.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:58:24.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:24.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:24.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:24.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:24.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:58:24.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:24.169+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:58:24.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-10T10:58:35.259+0000] {processor.py:157} INFO - Started process (PID=1179) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:35.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:58:35.261+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:35.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:35.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:35.306+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:35.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:58:35.314+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:35.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:58:35.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T10:58:38.335+0000] {processor.py:157} INFO - Started process (PID=1186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:38.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:58:38.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:38.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:38.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:38.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:38.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T10:58:38.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:38.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T10:58:38.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-10T10:58:52.497+0000] {processor.py:157} INFO - Started process (PID=1191) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:52.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:58:52.499+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:52.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:52.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:58:52.507+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 29, in <module>
    bash_command=f'/opt/airflow/jobs/spark-submit.sh {main} ',
                                                      ^^^^
NameError: name 'main' is not defined
[2024-07-10T10:58:52.509+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:58:52.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.029 seconds
[2024-07-10T10:59:10.815+0000] {processor.py:157} INFO - Started process (PID=1211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:59:10.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:59:10.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:10.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:59:10.829+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:10.828+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 29, in <module>
    bash_command=f'/opt/airflow/jobs/spark-submit.sh {main.py} ',
                                                      ^^^^
NameError: name 'main' is not defined
[2024-07-10T10:59:10.829+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:59:10.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.030 seconds
[2024-07-10T10:59:41.227+0000] {processor.py:157} INFO - Started process (PID=1231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:59:41.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T10:59:41.230+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:41.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:59:41.239+0000] {logging_mixin.py:151} INFO - [2024-07-10T10:59:41.238+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 29, in <module>
    bash_command=f'/opt/airflow/jobs/spark-submit.sh {main.py} ',
                                                      ^^^^
NameError: name 'main' is not defined
[2024-07-10T10:59:41.240+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T10:59:41.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.030 seconds
[2024-07-10T11:00:11.641+0000] {processor.py:157} INFO - Started process (PID=1251) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:00:11.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:00:11.647+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:11.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:00:11.672+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:11.670+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 29, in <module>
    bash_command=f'/opt/airflow/jobs/spark-submit.sh {main.py} ',
                                                      ^^^^
NameError: name 'main' is not defined
[2024-07-10T11:00:11.673+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:00:11.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T11:00:42.080+0000] {processor.py:157} INFO - Started process (PID=1271) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:00:42.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:00:42.082+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:42.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:00:42.092+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:00:42.090+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark-jobs.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-jobs.py", line 29, in <module>
    bash_command=f'/opt/airflow/jobs/spark-submit.sh {main.py} ',
                                                      ^^^^
NameError: name 'main' is not defined
[2024-07-10T11:00:42.092+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:00:42.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.029 seconds
[2024-07-10T11:01:11.459+0000] {processor.py:157} INFO - Started process (PID=1291) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:01:11.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:01:11.461+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:11.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:01:11.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:01:11.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:11.523+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:data_pipeline' as access control is unset.
[2024-07-10T11:01:11.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:11.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:01:11.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:11.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:01:11.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-10T11:01:41.928+0000] {processor.py:157} INFO - Started process (PID=1311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:01:41.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:01:41.930+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:41.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:01:41.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:01:41.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:41.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:01:42.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:01:42.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:01:42.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-10T11:02:12.288+0000] {processor.py:157} INFO - Started process (PID=1331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:02:12.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:02:12.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:12.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:02:12.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:02:12.322+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:12.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:02:12.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:12.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:02:12.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T11:02:42.764+0000] {processor.py:157} INFO - Started process (PID=1351) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:02:42.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:02:42.766+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:42.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:02:42.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:02:42.794+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:42.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:02:42.804+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:02:42.804+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:02:42.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:03:13.187+0000] {processor.py:157} INFO - Started process (PID=1371) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:03:13.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:03:13.190+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:13.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:03:13.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:03:13.226+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:13.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:03:13.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:13.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:03:13.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T11:03:43.584+0000] {processor.py:157} INFO - Started process (PID=1391) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:03:43.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:03:43.589+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:43.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:03:43.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:03:43.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:43.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:03:43.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:03:43.643+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:03:43.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-10T11:04:14.032+0000] {processor.py:157} INFO - Started process (PID=1411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:04:14.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:04:14.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:14.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:04:14.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:04:14.053+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:14.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:04:14.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:14.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:04:14.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-10T11:04:44.470+0000] {processor.py:157} INFO - Started process (PID=1431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:04:44.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:04:44.472+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:44.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:04:44.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:04:44.500+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:44.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:04:44.509+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:04:44.509+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:04:44.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:05:14.879+0000] {processor.py:157} INFO - Started process (PID=1451) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:05:14.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:05:14.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:14.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:05:14.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:05:14.910+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:14.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:05:14.919+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:14.919+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:05:14.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:05:45.238+0000] {processor.py:157} INFO - Started process (PID=1471) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:05:45.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:05:45.239+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:45.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:05:45.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:05:45.267+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:45.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:05:45.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:05:45.277+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:05:45.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:06:15.648+0000] {processor.py:157} INFO - Started process (PID=1491) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:06:15.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:06:15.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:15.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:06:15.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:06:15.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:15.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:06:15.688+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:15.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:06:15.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T11:06:46.021+0000] {processor.py:157} INFO - Started process (PID=1511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:06:46.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:06:46.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:46.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:06:46.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:06:46.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:46.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:06:46.060+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:06:46.060+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:06:46.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:07:16.450+0000] {processor.py:157} INFO - Started process (PID=1531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:16.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:07:16.452+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:16.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:16.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:16.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:16.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:07:16.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:16.501+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:07:16.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-10T11:07:46.797+0000] {processor.py:157} INFO - Started process (PID=1551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:46.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:07:46.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:46.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:46.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:46.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:46.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:07:46.838+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:46.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:07:46.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T11:07:53.863+0000] {processor.py:157} INFO - Started process (PID=1556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:53.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:07:53.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:53.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:53.880+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:53.878+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:07:53.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:07:53.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:53.944+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:data_pipeline' as access control is unset.
[2024-07-10T11:07:53.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:53.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:07:53.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:07:53.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:07:53.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-10T11:08:24.330+0000] {processor.py:157} INFO - Started process (PID=1576) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:08:24.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:08:24.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:24.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:08:24.344+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:24.343+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:08:24.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:08:24.372+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:24.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:08:24.382+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:24.382+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:08:24.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T11:08:54.719+0000] {processor.py:157} INFO - Started process (PID=1596) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:08:54.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:08:54.720+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:54.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:08:54.734+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:54.733+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:08:54.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:08:54.757+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:54.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:08:54.765+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:08:54.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:08:54.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T11:09:01.789+0000] {processor.py:157} INFO - Started process (PID=1601) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:09:01.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:09:01.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:01.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:09:01.800+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:01.799+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:09:01.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:09:01.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:01.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:09:01.829+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:01.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:09:01.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:09:32.216+0000] {processor.py:157} INFO - Started process (PID=1621) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:09:32.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:09:32.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:32.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:09:32.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:32.231+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:09:32.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:09:32.251+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:32.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:09:32.262+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:09:32.262+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:09:32.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T11:10:02.649+0000] {processor.py:157} INFO - Started process (PID=1641) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:10:02.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:10:02.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:02.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:10:02.674+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:02.673+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:10:02.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:10:02.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:02.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:10:02.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:02.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:10:02.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-10T11:10:33.075+0000] {processor.py:157} INFO - Started process (PID=1661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:10:33.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:10:33.077+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:33.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:10:33.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:33.100+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:10:33.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:10:33.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:33.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:10:33.152+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:10:33.152+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:10:33.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-10T11:11:03.488+0000] {processor.py:157} INFO - Started process (PID=1681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:03.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:11:03.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:03.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:03.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:03.501+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:11:03.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:03.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:03.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:11:03.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:03.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:11:03.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T11:11:13.556+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:13.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:11:13.558+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:13.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:13.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:13.565+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:11:13.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:13.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:13.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:11:13.593+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:13.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:11:13.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T11:11:44.010+0000] {processor.py:157} INFO - Started process (PID=201) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:44.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:11:44.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:44.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:44.042+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:44.041+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:11:44.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:11:44.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:44.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:11:44.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:11:44.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:11:44.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-10T11:12:14.474+0000] {processor.py:157} INFO - Started process (PID=221) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:14.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:12:14.477+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:14.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:14.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:14.485+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:12:14.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:14.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:14.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:12:14.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:14.512+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:12:14.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:12:44.957+0000] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:44.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:12:44.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:44.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:45.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:45.000+0000] {templater.py:78} ERROR - Failed to resolve template field 'bash_command'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/template/templater.py", line 76, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/jinja2/loaders.py", line 218, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /opt/airflow/jobs/download-data.sh
[2024-07-10T11:12:45.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:45.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:45.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:12:45.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:45.036+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:12:45.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-10T11:12:46.130+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:46.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:12:46.133+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:46.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:46.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:12:46.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:46.198+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:data_pipeline' as access control is unset.
[2024-07-10T11:12:46.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:46.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:12:46.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:12:46.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:12:46.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-10T11:13:16.574+0000] {processor.py:157} INFO - Started process (PID=281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:13:16.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:13:16.577+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:16.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:13:16.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:13:16.606+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:16.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:13:16.615+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:16.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:13:16.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:13:46.971+0000] {processor.py:157} INFO - Started process (PID=301) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:13:46.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:13:46.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:46.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:13:46.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:13:47.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:47.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:13:47.010+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:13:47.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:13:47.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T11:14:17.438+0000] {processor.py:157} INFO - Started process (PID=321) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:14:17.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:14:17.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:17.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:14:17.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:14:17.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:17.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:14:17.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:17.480+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:14:17.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T11:14:47.890+0000] {processor.py:157} INFO - Started process (PID=341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:14:47.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:14:47.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:47.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:14:47.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:14:47.919+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:47.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:14:47.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:14:47.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:14:47.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T11:15:18.306+0000] {processor.py:157} INFO - Started process (PID=361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:15:18.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:15:18.309+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:18.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:15:18.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:15:18.334+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:18.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:15:18.343+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:18.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:15:18.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T11:15:48.927+0000] {processor.py:157} INFO - Started process (PID=381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:15:48.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:15:48.930+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:48.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:15:48.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:15:48.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:48.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:15:48.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:15:48.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:15:48.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T11:16:19.402+0000] {processor.py:157} INFO - Started process (PID=401) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:16:19.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:16:19.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:19.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:16:19.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:16:19.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:19.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:16:19.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:19.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:16:19.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:16:49.917+0000] {processor.py:157} INFO - Started process (PID=421) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:16:49.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:16:49.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:49.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:16:49.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:16:49.949+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:49.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:16:49.961+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:16:49.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:16:49.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T11:17:17.208+0000] {processor.py:157} INFO - Started process (PID=426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:17.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:17:17.213+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:17.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:17.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:17.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:17.313+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:data_pipeline' as access control is unset.
[2024-07-10T11:17:17.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:17.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:17:17.323+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:17.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:17:17.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-10T11:17:27.399+0000] {processor.py:157} INFO - Started process (PID=446) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:27.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:17:27.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:27.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:27.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:27.426+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:27.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:17:27.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:27.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:17:27.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T11:17:57.893+0000] {processor.py:157} INFO - Started process (PID=466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:57.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:17:57.896+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:57.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:57.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:17:57.924+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:57.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:17:57.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:17:57.934+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:17:57.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:18:28.265+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:18:28.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:18:28.267+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:28.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:18:28.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:18:28.296+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:28.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:18:28.306+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:28.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:18:28.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:18:58.675+0000] {processor.py:157} INFO - Started process (PID=506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:18:58.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:18:58.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:58.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:18:58.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:18:58.720+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:58.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:18:58.730+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:18:58.730+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:18:58.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-10T11:19:29.078+0000] {processor.py:157} INFO - Started process (PID=526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:19:29.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:19:29.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:29.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:19:29.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:19:29.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:29.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:19:29.115+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:29.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:19:29.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T11:19:59.496+0000] {processor.py:157} INFO - Started process (PID=546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:19:59.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:19:59.500+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:59.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:19:59.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:19:59.525+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:59.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:19:59.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:19:59.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:19:59.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T11:20:29.934+0000] {processor.py:157} INFO - Started process (PID=566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:20:29.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:20:29.936+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:29.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:20:29.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:20:29.964+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:29.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:20:29.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:20:29.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:20:29.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:21:00.358+0000] {processor.py:157} INFO - Started process (PID=586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:21:00.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:21:00.361+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:00.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:21:00.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:21:00.390+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:00.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:21:00.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:00.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:21:00.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:21:30.831+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:21:30.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:21:30.848+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:30.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:21:30.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:21:30.891+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:30.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:21:30.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:21:30.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:21:30.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-10T11:22:01.230+0000] {processor.py:157} INFO - Started process (PID=626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:22:01.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:22:01.236+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:01.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:22:01.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:22:01.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:01.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:22:01.282+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:01.282+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:22:01.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T11:22:31.682+0000] {processor.py:157} INFO - Started process (PID=646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:22:31.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:22:31.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:31.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:22:31.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:22:31.713+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:31.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:22:31.723+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:22:31.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:22:31.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:23:02.043+0000] {processor.py:157} INFO - Started process (PID=666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:23:02.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:23:02.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:02.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:23:02.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:23:02.084+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:02.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:23:02.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:02.095+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:23:02.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-10T11:23:32.460+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:23:32.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:23:32.466+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:32.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:23:32.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:23:32.507+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:32.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:23:32.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:23:32.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:23:32.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-10T11:24:03.064+0000] {processor.py:157} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:24:03.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:24:03.068+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:03.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:24:03.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:24:03.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:03.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:24:03.109+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:03.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:24:03.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T11:24:33.549+0000] {processor.py:157} INFO - Started process (PID=726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:24:33.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:24:33.553+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:33.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:24:33.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:24:33.584+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:33.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:24:33.593+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:24:33.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:24:33.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T11:25:04.008+0000] {processor.py:157} INFO - Started process (PID=746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:25:04.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:25:04.012+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:04.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:25:04.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:25:04.040+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:04.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:25:04.049+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:04.049+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:25:04.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:25:34.442+0000] {processor.py:157} INFO - Started process (PID=766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:25:34.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:25:34.447+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:34.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:25:34.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:25:34.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:34.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:25:34.491+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:25:34.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:25:34.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T11:26:04.859+0000] {processor.py:157} INFO - Started process (PID=786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:26:04.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:26:04.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:04.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:26:04.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:26:04.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:04.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:26:04.906+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:04.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:26:04.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T11:26:35.289+0000] {processor.py:157} INFO - Started process (PID=806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:26:35.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:26:35.293+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:35.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:26:35.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:26:35.316+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:35.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:26:35.324+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:26:35.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:26:35.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T11:27:05.710+0000] {processor.py:157} INFO - Started process (PID=826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:27:05.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:27:05.713+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:05.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:27:05.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:27:05.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:05.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:27:05.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:05.750+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:27:05.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:27:36.219+0000] {processor.py:157} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:27:36.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:27:36.222+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:36.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:27:36.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:27:36.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:36.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:27:36.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:27:36.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:27:36.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T11:28:06.737+0000] {processor.py:157} INFO - Started process (PID=866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:28:06.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:28:06.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:06.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:28:06.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:28:06.770+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:06.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:28:06.780+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:06.780+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:28:06.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T11:28:37.151+0000] {processor.py:157} INFO - Started process (PID=886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:28:37.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:28:37.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:37.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:28:37.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:28:37.185+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:37.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:28:37.197+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:28:37.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:28:37.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T11:29:07.577+0000] {processor.py:157} INFO - Started process (PID=906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:29:07.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:29:07.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:07.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:29:07.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:29:07.613+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:07.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:29:07.624+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:07.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:29:07.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T11:29:38.001+0000] {processor.py:157} INFO - Started process (PID=926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:29:38.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:29:38.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:38.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:29:38.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:29:38.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:38.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:29:38.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:29:38.041+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:29:38.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:30:08.439+0000] {processor.py:157} INFO - Started process (PID=946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:30:08.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:30:08.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:08.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:30:08.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:30:08.466+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:08.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:30:08.475+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:08.475+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:30:08.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T11:30:38.924+0000] {processor.py:157} INFO - Started process (PID=966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:30:38.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:30:38.926+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:38.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:30:38.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:30:38.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:38.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:30:38.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:30:38.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:30:38.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T11:31:09.312+0000] {processor.py:157} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:31:09.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:31:09.316+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:09.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:31:09.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:31:09.355+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:09.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:31:09.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:09.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:31:09.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-10T11:31:39.728+0000] {processor.py:157} INFO - Started process (PID=1006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:31:39.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:31:39.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:39.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:31:39.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:31:39.761+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:39.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:31:39.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:31:39.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:31:39.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T11:32:10.148+0000] {processor.py:157} INFO - Started process (PID=1026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:32:10.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:32:10.152+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:10.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:32:10.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:32:10.193+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:10.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:32:10.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:10.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:32:10.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-10T11:32:40.536+0000] {processor.py:157} INFO - Started process (PID=1046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:32:40.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:32:40.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:40.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:32:40.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:32:40.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:40.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:32:40.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:32:40.590+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:32:40.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-10T11:33:10.918+0000] {processor.py:157} INFO - Started process (PID=1066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:33:10.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:33:10.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:10.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:33:10.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:33:10.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:10.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:33:10.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:10.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:33:10.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T11:33:41.338+0000] {processor.py:157} INFO - Started process (PID=1086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:33:41.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:33:41.341+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:41.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:33:41.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:33:41.375+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:41.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:33:41.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:33:41.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:33:41.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T11:34:11.684+0000] {processor.py:157} INFO - Started process (PID=1106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:34:11.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:34:11.687+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:11.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:34:11.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:34:11.720+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:11.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:34:11.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:11.733+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:34:11.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T11:34:42.096+0000] {processor.py:157} INFO - Started process (PID=1126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:34:42.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:34:42.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:42.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:34:42.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:34:42.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:42.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:34:42.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:34:42.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:34:42.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:35:12.501+0000] {processor.py:157} INFO - Started process (PID=1146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:35:12.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:35:12.504+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:12.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:35:12.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:35:12.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:12.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:35:12.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:12.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:35:12.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:35:42.898+0000] {processor.py:157} INFO - Started process (PID=1166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:35:42.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:35:42.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:42.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:35:42.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:35:42.930+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:42.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:35:42.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:35:42.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:35:42.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T11:36:13.343+0000] {processor.py:157} INFO - Started process (PID=1186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:36:13.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:36:13.346+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:13.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:36:13.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:36:13.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:13.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:36:13.390+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:13.390+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:36:13.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T11:36:43.729+0000] {processor.py:157} INFO - Started process (PID=1206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:36:43.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:36:43.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:43.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:36:43.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:36:43.764+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:43.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:36:43.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:36:43.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:36:43.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T11:37:14.175+0000] {processor.py:157} INFO - Started process (PID=1226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:37:14.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:37:14.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:14.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:37:14.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:37:14.222+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:14.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:37:14.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:14.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:37:14.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-10T11:37:44.506+0000] {processor.py:157} INFO - Started process (PID=1246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:37:44.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:37:44.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:44.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:37:44.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:37:44.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:44.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:37:44.546+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:37:44.546+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:37:44.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:38:14.965+0000] {processor.py:157} INFO - Started process (PID=1266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:38:14.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:38:14.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:14.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:38:14.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:38:14.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:14.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:38:15.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:15.004+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:38:15.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:38:45.397+0000] {processor.py:157} INFO - Started process (PID=1286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:38:45.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:38:45.401+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:45.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:38:45.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:38:45.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:45.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:38:45.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:38:45.440+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:38:45.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T11:39:15.799+0000] {processor.py:157} INFO - Started process (PID=1306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:39:15.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:39:15.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:15.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:39:15.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:39:15.840+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:15.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:39:15.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:15.852+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:39:15.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-10T11:39:46.225+0000] {processor.py:157} INFO - Started process (PID=1326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:39:46.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:39:46.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:46.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:39:46.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:39:46.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:46.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:39:46.264+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:39:46.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:39:46.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:40:16.673+0000] {processor.py:157} INFO - Started process (PID=1346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:40:16.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:40:16.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:16.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:40:16.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:40:16.711+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:16.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:40:16.723+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:16.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:40:16.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T11:40:47.033+0000] {processor.py:157} INFO - Started process (PID=1366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:40:47.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:40:47.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:47.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:40:47.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:40:47.059+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:47.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:40:47.068+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:40:47.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:40:47.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T11:41:17.453+0000] {processor.py:157} INFO - Started process (PID=1386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:41:17.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:41:17.456+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:17.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:41:17.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:41:17.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:17.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:41:17.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:17.494+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:41:17.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T11:41:47.871+0000] {processor.py:157} INFO - Started process (PID=1406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:41:47.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:41:47.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:47.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:41:47.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:41:47.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:47.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:41:47.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:41:47.916+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:41:47.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T11:42:18.335+0000] {processor.py:157} INFO - Started process (PID=1426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:42:18.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:42:18.338+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:18.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:42:18.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:42:18.367+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:18.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:42:18.376+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:18.376+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:42:18.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:42:48.751+0000] {processor.py:157} INFO - Started process (PID=1446) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:42:48.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:42:48.755+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:48.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:42:48.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:42:48.789+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:48.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:42:48.801+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:42:48.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:42:48.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T11:43:19.108+0000] {processor.py:157} INFO - Started process (PID=1466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:43:19.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:43:19.112+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:19.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:43:19.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:43:19.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:19.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:43:19.147+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:19.147+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:43:19.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:43:49.538+0000] {processor.py:157} INFO - Started process (PID=1486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:43:49.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:43:49.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:49.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:43:49.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:43:49.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:49.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:43:49.580+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:43:49.580+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:43:49.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:44:19.990+0000] {processor.py:157} INFO - Started process (PID=1506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:44:19.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:44:19.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:19.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:44:20.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:44:20.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:20.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:44:20.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:20.029+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:44:20.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:44:50.410+0000] {processor.py:157} INFO - Started process (PID=1526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:44:50.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:44:50.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:50.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:44:50.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:44:50.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:50.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:44:50.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:44:50.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:44:50.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:45:20.803+0000] {processor.py:157} INFO - Started process (PID=1546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:45:20.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:45:20.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:20.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:45:20.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:45:20.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:20.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:45:20.845+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:20.845+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:45:20.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T11:45:51.184+0000] {processor.py:157} INFO - Started process (PID=1566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:45:51.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:45:51.187+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:51.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:45:51.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:45:51.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:51.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:45:51.225+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:45:51.225+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:45:51.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T11:46:21.599+0000] {processor.py:157} INFO - Started process (PID=1586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:46:21.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:46:21.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:21.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:46:21.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:46:21.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:21.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:46:21.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:21.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:46:21.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-10T11:46:51.975+0000] {processor.py:157} INFO - Started process (PID=1606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:46:51.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:46:51.977+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:51.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:46:51.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:46:52.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:52.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:46:52.016+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:46:52.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:46:52.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:47:22.416+0000] {processor.py:157} INFO - Started process (PID=1626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:47:22.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:47:22.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:22.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:47:22.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:47:22.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:22.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:47:22.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:22.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:47:22.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-10T11:47:52.885+0000] {processor.py:157} INFO - Started process (PID=1646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:47:52.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:47:52.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:52.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:47:52.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:47:52.918+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:52.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:47:52.928+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:47:52.928+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:47:52.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T11:48:23.267+0000] {processor.py:157} INFO - Started process (PID=1666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:48:23.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:48:23.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:23.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:48:23.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:48:23.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:23.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:48:23.310+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:23.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:48:23.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T11:48:53.655+0000] {processor.py:157} INFO - Started process (PID=1686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:48:53.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:48:53.658+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:53.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:48:53.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:48:53.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:53.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:48:53.699+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:48:53.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:48:53.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T11:49:24.018+0000] {processor.py:157} INFO - Started process (PID=1706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:49:24.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:49:24.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:24.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:49:24.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:49:24.049+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:24.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:49:24.059+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:24.059+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:49:24.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:49:54.418+0000] {processor.py:157} INFO - Started process (PID=1726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:49:54.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:49:54.420+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:54.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:49:54.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:49:54.447+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:54.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:49:54.456+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:49:54.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:49:54.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T11:50:24.804+0000] {processor.py:157} INFO - Started process (PID=1746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:50:24.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:50:24.807+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:24.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:50:24.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:50:24.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:24.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:50:24.844+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:24.843+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:50:24.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:50:55.191+0000] {processor.py:157} INFO - Started process (PID=1766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:50:55.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:50:55.194+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:55.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:50:55.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:50:55.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:55.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:50:55.230+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:50:55.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:50:55.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:51:25.573+0000] {processor.py:157} INFO - Started process (PID=1786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:51:25.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:51:25.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:25.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:51:25.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:51:25.604+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:25.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:51:25.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:25.614+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:51:25.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:51:55.990+0000] {processor.py:157} INFO - Started process (PID=1806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:51:55.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:51:55.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:55.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:51:56.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:51:56.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:56.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:51:56.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:51:56.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:51:56.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T11:52:26.353+0000] {processor.py:157} INFO - Started process (PID=1826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:52:26.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:52:26.356+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:26.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:52:26.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:52:26.383+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:26.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:52:26.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:26.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:52:26.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:52:56.717+0000] {processor.py:157} INFO - Started process (PID=1846) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:52:56.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:52:56.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:56.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:52:56.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:52:56.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:56.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:52:56.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:52:56.751+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:52:56.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T11:53:27.083+0000] {processor.py:157} INFO - Started process (PID=1866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:53:27.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:53:27.086+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:27.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:53:27.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:53:27.114+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:27.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:53:27.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:27.123+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:53:27.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:53:57.455+0000] {processor.py:157} INFO - Started process (PID=1886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:53:57.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:53:57.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:57.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:53:57.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:53:57.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:57.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:53:57.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:53:57.490+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:53:57.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T11:54:27.918+0000] {processor.py:157} INFO - Started process (PID=1906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:54:27.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:54:27.922+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:27.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:54:27.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:54:27.949+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:27.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:54:27.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:27.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:54:27.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:54:58.337+0000] {processor.py:157} INFO - Started process (PID=1926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:54:58.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:54:58.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:58.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:54:58.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:54:58.369+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:58.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:54:58.378+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:54:58.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:54:58.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:55:28.725+0000] {processor.py:157} INFO - Started process (PID=1946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:55:28.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:55:28.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:28.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:55:28.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:55:28.755+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:28.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:55:28.764+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:28.764+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:55:28.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T11:55:59.124+0000] {processor.py:157} INFO - Started process (PID=1966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:55:59.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:55:59.127+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:59.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:55:59.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:55:59.155+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:59.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:55:59.164+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:55:59.164+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:55:59.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:56:29.526+0000] {processor.py:157} INFO - Started process (PID=1986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:56:29.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:56:29.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:29.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:56:29.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:56:29.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:29.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:56:29.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:29.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:56:29.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:56:59.939+0000] {processor.py:157} INFO - Started process (PID=2006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:56:59.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:56:59.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:59.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:56:59.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:56:59.969+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:59.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:56:59.978+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:56:59.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:56:59.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:57:30.323+0000] {processor.py:157} INFO - Started process (PID=2026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:57:30.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:57:30.326+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:30.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:57:30.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:57:30.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:30.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:57:30.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:57:30.362+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:57:30.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T11:58:00.696+0000] {processor.py:157} INFO - Started process (PID=2046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:58:00.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:58:00.699+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:00.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:58:00.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:58:00.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:00.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:58:00.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:00.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:58:00.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T11:58:31.120+0000] {processor.py:157} INFO - Started process (PID=2066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:58:31.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:58:31.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:31.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:58:31.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:58:31.150+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:31.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:58:31.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:58:31.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:58:31.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T11:59:01.530+0000] {processor.py:157} INFO - Started process (PID=2086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:59:01.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:59:01.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:01.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:59:01.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:59:01.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:01.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:59:01.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:01.570+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:59:01.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T11:59:31.945+0000] {processor.py:157} INFO - Started process (PID=2106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:59:31.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T11:59:31.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:31.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:59:31.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T11:59:31.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:31.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T11:59:31.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T11:59:31.984+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T11:59:31.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:00:02.384+0000] {processor.py:157} INFO - Started process (PID=2126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:00:02.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:00:02.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:02.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:00:02.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:00:02.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:02.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:00:02.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:02.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:00:02.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:00:32.751+0000] {processor.py:157} INFO - Started process (PID=2146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:00:32.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:00:32.754+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:32.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:00:32.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:00:32.780+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:32.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:00:32.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:00:32.790+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:00:32.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:01:03.135+0000] {processor.py:157} INFO - Started process (PID=2166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:01:03.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:01:03.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:03.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:01:03.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:01:03.165+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:03.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:01:03.174+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:03.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:01:03.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:01:33.590+0000] {processor.py:157} INFO - Started process (PID=2186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:01:33.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:01:33.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:33.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:01:33.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:01:33.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:33.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:01:33.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:01:33.623+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:01:33.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T12:02:04.130+0000] {processor.py:157} INFO - Started process (PID=2206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:02:04.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:02:04.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:04.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:02:04.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:02:04.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:04.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:02:04.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:04.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:02:04.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:02:34.579+0000] {processor.py:157} INFO - Started process (PID=2226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:02:34.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:02:34.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:34.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:02:34.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:02:34.607+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:34.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:02:34.616+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:02:34.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:02:34.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T12:03:05.081+0000] {processor.py:157} INFO - Started process (PID=2246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:03:05.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:03:05.083+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:05.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:03:05.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:03:05.108+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:05.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:03:05.117+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:05.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:03:05.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T12:03:35.482+0000] {processor.py:157} INFO - Started process (PID=2266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:03:35.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:03:35.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:35.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:03:35.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:03:35.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:35.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:03:35.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:03:35.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:03:35.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:04:05.935+0000] {processor.py:157} INFO - Started process (PID=2286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:04:05.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:04:05.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:05.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:04:05.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:04:05.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:05.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:04:05.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:05.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:04:05.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:04:36.399+0000] {processor.py:157} INFO - Started process (PID=2306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:04:36.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:04:36.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:36.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:04:36.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:04:36.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:36.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:04:36.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:04:36.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:04:36.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T12:05:06.827+0000] {processor.py:157} INFO - Started process (PID=2326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:05:06.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:05:06.830+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:06.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:05:06.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:05:06.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:06.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:05:06.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:06.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:05:06.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:05:37.240+0000] {processor.py:157} INFO - Started process (PID=2346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:05:37.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:05:37.243+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:37.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:05:37.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:05:37.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:37.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:05:37.279+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:05:37.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:05:37.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:06:07.650+0000] {processor.py:157} INFO - Started process (PID=2366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:06:07.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:06:07.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:07.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:06:07.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:06:07.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:07.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:06:07.702+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:07.702+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:06:07.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T12:06:38.066+0000] {processor.py:157} INFO - Started process (PID=2386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:06:38.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:06:38.069+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:38.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:06:38.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:06:38.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:38.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:06:38.110+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:06:38.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:06:38.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T12:07:08.517+0000] {processor.py:157} INFO - Started process (PID=2406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:07:08.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:07:08.522+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:08.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:07:08.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:07:08.567+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:08.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:07:08.577+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:08.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:07:08.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-10T12:07:38.931+0000] {processor.py:157} INFO - Started process (PID=2426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:07:38.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:07:38.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:38.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:07:38.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:07:38.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:38.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:07:38.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:07:38.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:07:38.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T12:08:09.342+0000] {processor.py:157} INFO - Started process (PID=2446) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:08:09.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:08:09.345+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:09.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:08:09.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:08:09.378+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:09.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:08:09.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:09.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:08:09.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T12:08:39.761+0000] {processor.py:157} INFO - Started process (PID=2466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:08:39.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:08:39.764+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:39.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:08:39.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:08:39.794+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:39.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:08:39.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:08:39.803+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:08:39.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:09:10.132+0000] {processor.py:157} INFO - Started process (PID=2486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:09:10.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:09:10.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:10.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:09:10.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:09:10.167+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:10.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:09:10.176+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:10.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:09:10.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T12:09:40.573+0000] {processor.py:157} INFO - Started process (PID=2506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:09:40.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:09:40.577+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:40.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:09:40.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:09:40.608+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:40.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:09:40.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:09:40.617+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:09:40.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T12:10:10.994+0000] {processor.py:157} INFO - Started process (PID=2526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:10:10.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:10:10.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:10.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:10:11.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:10:11.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:11.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:10:11.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:11.041+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:10:11.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T12:10:41.425+0000] {processor.py:157} INFO - Started process (PID=2546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:10:41.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:10:41.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:41.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:10:41.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:10:41.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:41.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:10:41.465+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:10:41.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:10:41.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:11:11.830+0000] {processor.py:157} INFO - Started process (PID=2566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:11:11.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:11:11.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:11.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:11:11.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:11:11.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:11.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:11:11.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:11.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:11:11.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T12:11:42.262+0000] {processor.py:157} INFO - Started process (PID=2586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:11:42.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:11:42.265+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:42.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:11:42.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:11:42.292+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:42.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:11:42.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:11:42.301+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:11:42.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:12:12.622+0000] {processor.py:157} INFO - Started process (PID=2606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:12:12.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:12:12.626+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:12.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:12:12.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:12:12.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:12.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:12:12.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:12.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:12:12.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:12:43.121+0000] {processor.py:157} INFO - Started process (PID=2626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:12:43.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:12:43.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:43.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:12:43.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:12:43.150+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:43.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:12:43.163+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:12:43.162+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:12:43.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T12:13:13.687+0000] {processor.py:157} INFO - Started process (PID=2646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:13:13.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:13:13.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:13.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:13:13.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:13:13.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:13.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:13:13.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:13.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:13:13.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-10T12:13:44.061+0000] {processor.py:157} INFO - Started process (PID=2666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:13:44.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:13:44.064+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:44.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:13:44.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:13:44.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:44.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:13:44.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:13:44.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:13:44.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T12:14:14.488+0000] {processor.py:157} INFO - Started process (PID=2686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:14:14.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:14:14.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:14.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:14:14.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:14:14.515+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:14.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:14:14.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:14.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:14:14.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:14:44.867+0000] {processor.py:157} INFO - Started process (PID=2706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:14:44.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:14:44.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:44.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:14:44.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:14:44.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:44.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:14:44.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:14:44.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:14:44.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.038 seconds
[2024-07-10T12:15:15.165+0000] {processor.py:157} INFO - Started process (PID=2726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:15:15.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:15:15.167+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:15.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:15:15.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:15:15.190+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:15.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:15:15.200+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:15.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:15:15.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T12:15:45.503+0000] {processor.py:157} INFO - Started process (PID=2746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:15:45.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:15:45.504+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:45.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:15:45.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:15:45.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:45.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:15:45.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:15:45.533+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:15:45.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-10T12:16:15.940+0000] {processor.py:157} INFO - Started process (PID=2766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:16:15.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:16:15.943+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:15.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:16:15.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:16:15.970+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:15.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:16:15.980+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:15.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:16:15.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:16:46.275+0000] {processor.py:157} INFO - Started process (PID=2786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:16:46.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:16:46.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:46.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:16:46.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:16:46.304+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:46.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:16:46.315+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:16:46.315+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:16:46.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:17:16.720+0000] {processor.py:157} INFO - Started process (PID=2806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:17:16.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:17:16.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:16.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:17:16.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:17:16.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:16.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:17:16.756+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:16.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:17:16.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:17:47.125+0000] {processor.py:157} INFO - Started process (PID=2826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:17:47.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:17:47.127+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:47.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:17:47.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:17:47.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:47.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:17:47.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:17:47.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:17:47.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T12:18:17.574+0000] {processor.py:157} INFO - Started process (PID=2846) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:18:17.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:18:17.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:17.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:18:17.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:18:17.608+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:17.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:18:17.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:17.619+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:18:17.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T12:18:47.983+0000] {processor.py:157} INFO - Started process (PID=2866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:18:47.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:18:47.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:47.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:18:48.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:18:48.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:48.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:18:48.039+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:18:48.039+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:18:48.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-10T12:19:18.346+0000] {processor.py:157} INFO - Started process (PID=2886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:19:18.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:19:18.349+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:18.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:19:18.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:19:18.376+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:18.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:19:18.386+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:18.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:19:18.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:19:48.793+0000] {processor.py:157} INFO - Started process (PID=2906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:19:48.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:19:48.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:48.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:19:48.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:19:48.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:48.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:19:48.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:19:48.833+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:19:48.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:20:19.211+0000] {processor.py:157} INFO - Started process (PID=2926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:20:19.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:20:19.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:19.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:20:19.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:20:19.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:19.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:20:19.247+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:19.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:20:19.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T12:20:49.591+0000] {processor.py:157} INFO - Started process (PID=2946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:20:49.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:20:49.594+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:49.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:20:49.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:20:49.621+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:49.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:20:49.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:20:49.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:20:49.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:21:19.987+0000] {processor.py:157} INFO - Started process (PID=2966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:21:19.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:21:19.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:19.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:21:20.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:21:20.016+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:20.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:21:20.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:20.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:21:20.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:21:50.514+0000] {processor.py:157} INFO - Started process (PID=2986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:21:50.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:21:50.516+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:50.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:21:50.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:21:50.546+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:50.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:21:50.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:21:50.557+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:21:50.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T12:22:21.013+0000] {processor.py:157} INFO - Started process (PID=3006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:22:21.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:22:21.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:21.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:22:21.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:22:21.049+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:21.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:22:21.061+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:21.061+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:22:21.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T12:22:51.438+0000] {processor.py:157} INFO - Started process (PID=3026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:22:51.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:22:51.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:51.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:22:51.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:22:51.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:51.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:22:51.503+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:22:51.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:22:51.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-10T12:23:21.838+0000] {processor.py:157} INFO - Started process (PID=3046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:23:21.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:23:21.841+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:21.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:23:21.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:23:21.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:21.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:23:21.882+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:21.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:23:21.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T12:23:52.214+0000] {processor.py:157} INFO - Started process (PID=3066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:23:52.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:23:52.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:52.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:23:52.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:23:52.248+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:52.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:23:52.258+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:23:52.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:23:52.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T12:24:22.647+0000] {processor.py:157} INFO - Started process (PID=3086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:24:22.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:24:22.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:22.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:24:22.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:24:22.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:22.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:24:22.684+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:22.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:24:22.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T12:24:53.087+0000] {processor.py:157} INFO - Started process (PID=3106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:24:53.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:24:53.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:53.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:24:53.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:24:53.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:53.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:24:53.128+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:24:53.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:24:53.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T12:25:23.515+0000] {processor.py:157} INFO - Started process (PID=3126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:25:23.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:25:23.518+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:23.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:25:23.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:25:23.545+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:23.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:25:23.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:23.554+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:25:23.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T12:25:53.969+0000] {processor.py:157} INFO - Started process (PID=3146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:25:53.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:25:53.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:53.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:25:53.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:25:53.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:53.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:25:54.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:25:54.009+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:25:54.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:26:24.408+0000] {processor.py:157} INFO - Started process (PID=3166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:26:24.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:26:24.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:24.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:26:24.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:26:24.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:24.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:26:24.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:24.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:26:24.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:26:54.831+0000] {processor.py:157} INFO - Started process (PID=3186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:26:54.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:26:54.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:54.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:26:54.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:26:54.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:54.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:26:54.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:26:54.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:26:54.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:27:25.245+0000] {processor.py:157} INFO - Started process (PID=3206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:27:25.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:27:25.248+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:25.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:27:25.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:27:25.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:25.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:27:25.284+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:25.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:27:25.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:27:55.628+0000] {processor.py:157} INFO - Started process (PID=3226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:27:55.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:27:55.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:55.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:27:55.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:27:55.657+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:55.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:27:55.667+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:27:55.667+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:27:55.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:28:26.101+0000] {processor.py:157} INFO - Started process (PID=3246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:28:26.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:28:26.107+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:26.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:28:26.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:28:26.131+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:26.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:28:26.140+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:26.140+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:28:26.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:28:56.491+0000] {processor.py:157} INFO - Started process (PID=3266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:28:56.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:28:56.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:56.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:28:56.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:28:56.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:56.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:28:56.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:28:56.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:28:56.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:29:26.899+0000] {processor.py:157} INFO - Started process (PID=3286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:29:26.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:29:26.901+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:26.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:29:26.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:29:26.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:26.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:29:26.939+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:26.939+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:29:26.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:29:57.325+0000] {processor.py:157} INFO - Started process (PID=3306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:29:57.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:29:57.328+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:57.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:29:57.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:29:57.357+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:57.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:29:57.367+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:29:57.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:29:57.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T12:30:27.739+0000] {processor.py:157} INFO - Started process (PID=3326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:30:27.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:30:27.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:27.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:30:27.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:30:27.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:27.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:30:27.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:27.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:30:27.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-10T12:30:58.117+0000] {processor.py:157} INFO - Started process (PID=3346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:30:58.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:30:58.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:58.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:30:58.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:30:58.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:58.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:30:58.156+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:30:58.156+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:30:58.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:31:28.547+0000] {processor.py:157} INFO - Started process (PID=3366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:31:28.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:31:28.549+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:28.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:31:28.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:31:28.568+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:28.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:31:28.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:28.576+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:31:28.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.036 seconds
[2024-07-10T12:31:58.935+0000] {processor.py:157} INFO - Started process (PID=3386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:31:58.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:31:58.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:58.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:31:58.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:31:58.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:58.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:31:58.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:31:58.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:31:58.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:32:29.356+0000] {processor.py:157} INFO - Started process (PID=3406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:32:29.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:32:29.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:29.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:32:29.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:32:29.385+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:29.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:32:29.395+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:29.395+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:32:29.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:32:59.791+0000] {processor.py:157} INFO - Started process (PID=3426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:32:59.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:32:59.794+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:59.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:32:59.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:32:59.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:59.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:32:59.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:32:59.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:32:59.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T12:33:30.208+0000] {processor.py:157} INFO - Started process (PID=3446) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:33:30.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:33:30.211+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:30.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:33:30.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:33:30.234+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:30.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:33:30.243+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:33:30.243+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:33:30.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T12:34:00.573+0000] {processor.py:157} INFO - Started process (PID=3466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:34:00.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:34:00.577+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:00.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:34:00.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:34:00.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:00.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:34:00.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:00.610+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:34:00.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T12:34:30.943+0000] {processor.py:157} INFO - Started process (PID=3486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:34:30.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:34:30.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:30.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:34:30.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:34:30.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:30.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:34:30.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:34:30.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:34:30.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:35:01.328+0000] {processor.py:157} INFO - Started process (PID=3506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:35:01.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:35:01.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:01.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:35:01.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:35:01.357+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:01.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:35:01.367+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:01.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:35:01.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:35:31.716+0000] {processor.py:157} INFO - Started process (PID=3526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:35:31.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:35:31.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:31.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:35:31.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:35:31.745+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:31.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:35:31.755+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:35:31.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:35:31.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:36:02.106+0000] {processor.py:157} INFO - Started process (PID=3546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:36:02.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:36:02.108+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:02.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:36:02.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:36:02.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:02.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:36:02.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:02.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:36:02.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:36:32.513+0000] {processor.py:157} INFO - Started process (PID=3566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:36:32.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:36:32.517+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:32.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:36:32.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:36:32.543+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:32.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:36:32.553+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:36:32.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:36:32.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:37:02.887+0000] {processor.py:157} INFO - Started process (PID=3586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:37:02.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:37:02.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:02.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:37:02.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:37:02.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:02.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:37:02.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:02.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:37:02.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T12:37:33.288+0000] {processor.py:157} INFO - Started process (PID=3606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:37:33.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:37:33.292+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:33.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:37:33.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:37:33.318+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:33.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:37:33.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:37:33.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:37:33.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:38:03.677+0000] {processor.py:157} INFO - Started process (PID=3626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:38:03.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:38:03.681+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:03.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:38:03.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:38:03.710+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:03.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:38:03.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:03.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:38:03.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T12:38:34.033+0000] {processor.py:157} INFO - Started process (PID=3646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:38:34.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:38:34.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:34.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:38:34.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:38:34.063+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:34.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:38:34.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:38:34.072+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:38:34.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:39:04.443+0000] {processor.py:157} INFO - Started process (PID=3666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:39:04.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:39:04.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:04.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:39:04.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:39:04.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:04.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:39:04.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:04.480+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:39:04.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T12:39:34.814+0000] {processor.py:157} INFO - Started process (PID=3686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:39:34.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:39:34.815+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:34.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:39:34.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:39:34.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:34.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:39:34.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:39:34.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:39:34.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.037 seconds
[2024-07-10T12:40:05.218+0000] {processor.py:157} INFO - Started process (PID=3706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:40:05.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:40:05.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:05.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:40:05.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:40:05.245+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:05.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:40:05.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:05.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:40:05.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T12:40:35.624+0000] {processor.py:157} INFO - Started process (PID=3726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:40:35.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:40:35.626+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:35.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:40:35.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:40:35.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:35.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:40:35.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:40:35.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:40:35.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:41:06.001+0000] {processor.py:157} INFO - Started process (PID=3746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:41:06.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:41:06.003+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:06.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:41:06.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:41:06.030+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:06.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:41:06.040+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:06.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:41:06.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:41:36.388+0000] {processor.py:157} INFO - Started process (PID=3766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:41:36.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:41:36.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:36.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:41:36.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:41:36.418+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:36.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:41:36.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:41:36.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:41:36.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:42:06.770+0000] {processor.py:157} INFO - Started process (PID=3786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:42:06.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:42:06.772+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:06.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:42:06.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:42:06.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:06.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:42:06.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:06.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:42:06.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T12:42:37.225+0000] {processor.py:157} INFO - Started process (PID=3806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:42:37.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:42:37.229+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:37.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:42:37.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:42:37.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:37.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:42:37.264+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:42:37.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:42:37.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:43:07.703+0000] {processor.py:157} INFO - Started process (PID=3826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:43:07.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:43:07.706+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:07.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:43:07.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:43:07.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:07.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:43:07.742+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:07.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:43:07.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:43:38.152+0000] {processor.py:157} INFO - Started process (PID=3846) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:43:38.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:43:38.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:38.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:43:38.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:43:38.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:38.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:43:38.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:43:38.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:43:38.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T12:44:08.633+0000] {processor.py:157} INFO - Started process (PID=3866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:44:08.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:44:08.635+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:08.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:44:08.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:44:08.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:08.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:44:08.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:08.671+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:44:08.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T12:44:38.989+0000] {processor.py:157} INFO - Started process (PID=3886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:44:38.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:44:38.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:38.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:44:39.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:44:39.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:39.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:44:39.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:44:39.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:44:39.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:45:09.380+0000] {processor.py:157} INFO - Started process (PID=3906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:45:09.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:45:09.383+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:09.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:45:09.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:45:09.409+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:09.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:45:09.418+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:09.418+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:45:09.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:45:39.843+0000] {processor.py:157} INFO - Started process (PID=3926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:45:39.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:45:39.846+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:39.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:45:39.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:45:39.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:39.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:45:39.882+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:45:39.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:45:39.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:46:10.225+0000] {processor.py:157} INFO - Started process (PID=3946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:46:10.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:46:10.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:10.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:46:10.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:46:10.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:10.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:46:10.264+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:10.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:46:10.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:46:40.701+0000] {processor.py:157} INFO - Started process (PID=3966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:46:40.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:46:40.704+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:40.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:46:40.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:46:40.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:40.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:46:40.740+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:46:40.740+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:46:40.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:47:11.153+0000] {processor.py:157} INFO - Started process (PID=3986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:47:11.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:47:11.156+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:11.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:47:11.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:47:11.176+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:11.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:47:11.185+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:11.185+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:47:11.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.039 seconds
[2024-07-10T12:47:41.589+0000] {processor.py:157} INFO - Started process (PID=4006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:47:41.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:47:41.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:41.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:47:41.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:47:41.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:41.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:47:41.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:47:41.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:47:41.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:48:12.109+0000] {processor.py:157} INFO - Started process (PID=4026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:48:12.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:48:12.112+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:12.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:48:12.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:48:12.140+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:12.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:48:12.149+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:12.149+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:48:12.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:48:42.583+0000] {processor.py:157} INFO - Started process (PID=4046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:48:42.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:48:42.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:42.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:48:42.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:48:42.613+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:42.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:48:42.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:48:42.622+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:48:42.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:49:13.110+0000] {processor.py:157} INFO - Started process (PID=4066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:49:13.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:49:13.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:13.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:49:13.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:49:13.140+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:13.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:49:13.150+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:13.150+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:49:13.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:49:43.559+0000] {processor.py:157} INFO - Started process (PID=4086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:49:43.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:49:43.562+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:43.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:49:43.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:49:43.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:43.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:49:43.597+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:49:43.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:49:43.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T12:50:14.012+0000] {processor.py:157} INFO - Started process (PID=4106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:50:14.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:50:14.016+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:14.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:50:14.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:50:14.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:14.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:50:14.052+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:14.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:50:14.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:50:44.417+0000] {processor.py:157} INFO - Started process (PID=4126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:50:44.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:50:44.420+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:44.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:50:44.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:50:44.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:44.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:50:44.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:50:44.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:50:44.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:51:14.822+0000] {processor.py:157} INFO - Started process (PID=4146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:51:14.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:51:14.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:14.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:51:14.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:51:14.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:14.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:51:14.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:14.861+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:51:14.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:51:45.271+0000] {processor.py:157} INFO - Started process (PID=4166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:51:45.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:51:45.274+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:45.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:51:45.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:51:45.302+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:45.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:51:45.311+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:51:45.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:51:45.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:52:15.631+0000] {processor.py:157} INFO - Started process (PID=4186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:52:15.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:52:15.634+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:15.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:52:15.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:52:15.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:15.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:52:15.672+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:15.672+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:52:15.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T12:52:46.022+0000] {processor.py:157} INFO - Started process (PID=4206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:52:46.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:52:46.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:46.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:52:46.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:52:46.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:46.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:52:46.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:52:46.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:52:46.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T12:53:16.372+0000] {processor.py:157} INFO - Started process (PID=4226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:53:16.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:53:16.375+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:16.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:53:16.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:53:16.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:16.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:53:16.409+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:16.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:53:16.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T12:53:46.729+0000] {processor.py:157} INFO - Started process (PID=4246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:53:46.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:53:46.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:46.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:53:46.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:53:46.759+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:46.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:53:46.768+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:53:46.768+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:53:46.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:54:17.161+0000] {processor.py:157} INFO - Started process (PID=4266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:54:17.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:54:17.164+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:17.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:54:17.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:54:17.193+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:17.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:54:17.202+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:17.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:54:17.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:54:47.541+0000] {processor.py:157} INFO - Started process (PID=4286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:54:47.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:54:47.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:47.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:54:47.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:54:47.568+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:47.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:54:47.577+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:54:47.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:54:47.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T12:55:18.032+0000] {processor.py:157} INFO - Started process (PID=4306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:55:18.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:55:18.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:18.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:55:18.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:55:18.063+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:18.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:55:18.073+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:18.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:55:18.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:55:48.428+0000] {processor.py:157} INFO - Started process (PID=4326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:55:48.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:55:48.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:48.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:55:48.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:55:48.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:48.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:55:48.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:55:48.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:55:48.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T12:56:18.783+0000] {processor.py:157} INFO - Started process (PID=4346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:56:18.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:56:18.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:18.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:56:18.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:56:18.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:18.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:56:18.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:18.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:56:18.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T12:56:49.185+0000] {processor.py:157} INFO - Started process (PID=4366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:56:49.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:56:49.188+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:49.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:56:49.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:56:49.212+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:49.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:56:49.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:56:49.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:56:49.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T12:57:19.591+0000] {processor.py:157} INFO - Started process (PID=4386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:57:19.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:57:19.594+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:19.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:57:19.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:57:19.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:19.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:57:19.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:19.633+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:57:19.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T12:57:49.984+0000] {processor.py:157} INFO - Started process (PID=4406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:57:49.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:57:49.986+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:49.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:57:49.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:57:50.014+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:50.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:57:50.023+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:57:50.023+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:57:50.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T12:58:20.412+0000] {processor.py:157} INFO - Started process (PID=4426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:58:20.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:58:20.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:20.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:58:20.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:58:20.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:20.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:58:20.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:20.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:58:20.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:58:50.809+0000] {processor.py:157} INFO - Started process (PID=4446) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:58:50.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:58:50.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:50.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:58:50.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:58:50.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:50.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:58:50.847+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:58:50.846+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:58:50.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T12:59:21.207+0000] {processor.py:157} INFO - Started process (PID=4466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:59:21.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:59:21.210+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:21.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:59:21.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:59:21.236+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:21.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:59:21.245+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:21.245+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:59:21.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T12:59:51.590+0000] {processor.py:157} INFO - Started process (PID=4486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:59:51.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T12:59:51.593+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:51.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:59:51.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T12:59:51.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:51.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T12:59:51.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T12:59:51.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T12:59:51.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:00:21.964+0000] {processor.py:157} INFO - Started process (PID=4506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:00:21.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:00:21.969+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:21.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:00:21.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:00:21.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:21.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:00:22.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:22.004+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:00:22.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:00:52.376+0000] {processor.py:157} INFO - Started process (PID=4526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:00:52.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:00:52.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:52.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:00:52.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:00:52.406+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:52.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:00:52.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:00:52.415+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:00:52.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:01:22.747+0000] {processor.py:157} INFO - Started process (PID=4546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:01:22.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:01:22.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:22.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:01:22.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:01:22.777+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:22.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:01:22.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:22.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:01:22.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:01:53.185+0000] {processor.py:157} INFO - Started process (PID=4566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:01:53.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:01:53.188+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:53.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:01:53.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:01:53.215+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:53.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:01:53.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:01:53.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:01:53.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:02:23.606+0000] {processor.py:157} INFO - Started process (PID=4586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:02:23.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:02:23.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:23.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:02:23.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:02:23.636+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:23.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:02:23.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:23.645+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:02:23.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:02:54.006+0000] {processor.py:157} INFO - Started process (PID=4606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:02:54.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:02:54.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:54.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:02:54.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:02:54.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:54.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:02:54.045+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:02:54.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:02:54.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:03:24.431+0000] {processor.py:157} INFO - Started process (PID=4626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:03:24.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:03:24.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:24.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:03:24.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:03:24.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:24.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:03:24.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:24.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:03:24.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:03:54.824+0000] {processor.py:157} INFO - Started process (PID=4646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:03:54.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:03:54.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:54.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:03:54.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:03:54.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:54.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:03:54.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:03:54.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:03:54.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:04:25.245+0000] {processor.py:157} INFO - Started process (PID=4666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:04:25.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:04:25.248+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:25.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:04:25.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:04:25.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:25.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:04:25.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:25.285+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:04:25.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:04:55.620+0000] {processor.py:157} INFO - Started process (PID=4686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:04:55.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:04:55.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:55.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:04:55.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:04:55.651+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:55.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:04:55.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:04:55.661+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:04:55.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T13:05:26.027+0000] {processor.py:157} INFO - Started process (PID=4706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:05:26.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:05:26.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:26.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:05:26.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:05:26.054+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:26.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:05:26.063+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:26.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:05:26.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T13:05:56.502+0000] {processor.py:157} INFO - Started process (PID=4726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:05:56.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:05:56.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:56.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:05:56.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:05:56.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:56.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:05:56.538+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:05:56.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:05:56.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T13:06:26.960+0000] {processor.py:157} INFO - Started process (PID=4746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:06:26.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:06:26.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:26.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:06:26.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:06:26.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:26.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:06:27.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:27.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:06:27.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T13:06:57.386+0000] {processor.py:157} INFO - Started process (PID=4766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:06:57.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:06:57.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:57.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:06:57.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:06:57.416+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:57.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:06:57.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:06:57.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:06:57.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:07:27.768+0000] {processor.py:157} INFO - Started process (PID=4786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:07:27.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:07:27.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:27.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:07:27.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:07:27.797+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:27.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:07:27.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:27.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:07:27.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:07:58.128+0000] {processor.py:157} INFO - Started process (PID=4806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:07:58.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:07:58.131+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:58.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:07:58.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:07:58.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:58.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:07:58.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:07:58.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:07:58.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:08:28.503+0000] {processor.py:157} INFO - Started process (PID=4826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:08:28.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:08:28.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:28.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:08:28.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:08:28.532+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:28.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:08:28.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:28.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:08:28.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:08:58.901+0000] {processor.py:157} INFO - Started process (PID=4846) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:08:58.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:08:58.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:58.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:08:58.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:08:58.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:58.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:08:58.940+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:08:58.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:08:58.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:09:29.274+0000] {processor.py:157} INFO - Started process (PID=4866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:09:29.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:09:29.276+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:29.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:09:29.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:09:29.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:29.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:09:29.308+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:29.308+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:09:29.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T13:09:59.682+0000] {processor.py:157} INFO - Started process (PID=4886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:09:59.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:09:59.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:59.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:09:59.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:09:59.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:59.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:09:59.724+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:09:59.724+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:09:59.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T13:10:30.096+0000] {processor.py:157} INFO - Started process (PID=4906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:10:30.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:10:30.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:30.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:10:30.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:10:30.137+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:30.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:10:30.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:10:30.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:10:30.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-10T13:11:00.544+0000] {processor.py:157} INFO - Started process (PID=4926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:11:00.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:11:00.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:00.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:11:00.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:11:00.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:00.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:11:00.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:00.583+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:11:00.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:11:30.943+0000] {processor.py:157} INFO - Started process (PID=4946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:11:30.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:11:30.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:30.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:11:30.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:11:30.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:30.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:11:30.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:11:30.981+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:11:30.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:12:01.391+0000] {processor.py:157} INFO - Started process (PID=4966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:12:01.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:12:01.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:01.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:12:01.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:12:01.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:01.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:12:01.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:01.430+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:12:01.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:12:31.789+0000] {processor.py:157} INFO - Started process (PID=4986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:12:31.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:12:31.792+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:31.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:12:31.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:12:31.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:31.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:12:31.827+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:12:31.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:12:31.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T13:13:02.131+0000] {processor.py:157} INFO - Started process (PID=5006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:13:02.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:13:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:02.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:13:02.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:13:02.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:02.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:13:02.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:02.169+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:13:02.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:13:32.539+0000] {processor.py:157} INFO - Started process (PID=5026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:13:32.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:13:32.542+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:32.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:13:32.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:13:32.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:32.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:13:32.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:13:32.578+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:13:32.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:14:02.963+0000] {processor.py:157} INFO - Started process (PID=5046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:14:02.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:14:02.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:02.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:14:02.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:14:02.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:02.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:14:03.002+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:03.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:14:03.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:14:33.356+0000] {processor.py:157} INFO - Started process (PID=5066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:14:33.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:14:33.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:33.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:14:33.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:14:33.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:33.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:14:33.389+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:14:33.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:14:33.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T13:15:03.773+0000] {processor.py:157} INFO - Started process (PID=5086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:15:03.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:15:03.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:03.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:15:03.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:15:03.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:03.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:15:03.812+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:03.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:15:03.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:15:34.188+0000] {processor.py:157} INFO - Started process (PID=5106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:15:34.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:15:34.191+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:34.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:15:34.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:15:34.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:34.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:15:34.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:15:34.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:15:34.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:16:04.567+0000] {processor.py:157} INFO - Started process (PID=5126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:16:04.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:16:04.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:04.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:16:04.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:16:04.599+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:04.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:16:04.608+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:04.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:16:04.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T13:16:34.928+0000] {processor.py:157} INFO - Started process (PID=5146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:16:34.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:16:34.930+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:34.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:16:34.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:16:34.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:34.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:16:34.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:16:34.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:16:34.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:17:05.305+0000] {processor.py:157} INFO - Started process (PID=5166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:17:05.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:17:05.308+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:05.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:17:05.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:17:05.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:05.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:17:05.345+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:05.345+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:17:05.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:17:35.773+0000] {processor.py:157} INFO - Started process (PID=5186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:17:35.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:17:35.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:35.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:17:35.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:17:35.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:35.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:17:35.812+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:17:35.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:17:35.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:18:06.199+0000] {processor.py:157} INFO - Started process (PID=5206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:18:06.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:18:06.201+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:06.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:18:06.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:18:06.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:06.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:18:06.229+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:06.229+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:18:06.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.038 seconds
[2024-07-10T13:18:36.641+0000] {processor.py:157} INFO - Started process (PID=5226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:18:36.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:18:36.644+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:36.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:18:36.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:18:36.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:36.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:18:36.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:18:36.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:18:36.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:19:07.112+0000] {processor.py:157} INFO - Started process (PID=5246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:19:07.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:19:07.114+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:07.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:19:07.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:19:07.131+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:07.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:19:07.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:07.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:19:07.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.034 seconds
[2024-07-10T13:19:37.545+0000] {processor.py:157} INFO - Started process (PID=5266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:19:37.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:19:37.549+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:37.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:19:37.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:19:37.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:37.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:19:37.596+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:19:37.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:19:37.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T13:20:08.015+0000] {processor.py:157} INFO - Started process (PID=5286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:20:08.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:20:08.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:08.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:20:08.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:20:08.045+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:08.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:20:08.054+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:08.054+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:20:08.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:20:38.449+0000] {processor.py:157} INFO - Started process (PID=5306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:20:38.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:20:38.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:38.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:20:38.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:20:38.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:38.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:20:38.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:20:38.490+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:20:38.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T13:21:08.878+0000] {processor.py:157} INFO - Started process (PID=5326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:21:08.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:21:08.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:08.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:21:08.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:21:08.907+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:08.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:21:08.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:08.916+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:21:08.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:21:39.305+0000] {processor.py:157} INFO - Started process (PID=5346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:21:39.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:21:39.307+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:39.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:21:39.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:21:39.328+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:39.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:21:39.338+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:21:39.338+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:21:39.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T13:22:09.706+0000] {processor.py:157} INFO - Started process (PID=5366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:22:09.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:22:09.709+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:09.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:22:09.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:22:09.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:09.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:22:09.745+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:09.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:22:09.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:22:40.101+0000] {processor.py:157} INFO - Started process (PID=5386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:22:40.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:22:40.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:40.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:22:40.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:22:40.131+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:40.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:22:40.140+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:22:40.140+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:22:40.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:23:10.530+0000] {processor.py:157} INFO - Started process (PID=5406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:23:10.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:23:10.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:10.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:23:10.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:23:10.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:10.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:23:10.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:10.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:23:10.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:23:40.960+0000] {processor.py:157} INFO - Started process (PID=5426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:23:40.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:23:40.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:40.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:23:40.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:23:40.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:40.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:23:40.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:23:40.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:23:41.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:24:11.398+0000] {processor.py:157} INFO - Started process (PID=5446) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:24:11.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:24:11.401+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:11.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:24:11.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:24:11.426+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:11.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:24:11.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:11.435+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:24:11.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:24:41.813+0000] {processor.py:157} INFO - Started process (PID=5466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:24:41.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:24:41.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:41.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:24:41.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:24:41.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:41.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:24:41.853+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:24:41.853+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:24:41.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:25:12.223+0000] {processor.py:157} INFO - Started process (PID=5486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:25:12.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:25:12.226+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:12.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:25:12.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:25:12.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:12.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:25:12.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:12.259+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:25:12.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T13:25:42.600+0000] {processor.py:157} INFO - Started process (PID=5506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:25:42.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:25:42.603+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:42.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:25:42.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:25:42.630+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:42.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:25:42.639+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:25:42.639+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:25:42.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:26:13.018+0000] {processor.py:157} INFO - Started process (PID=5526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:26:13.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:26:13.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:13.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:26:13.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:26:13.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:13.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:26:13.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:13.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:26:13.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:26:43.457+0000] {processor.py:157} INFO - Started process (PID=5546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:26:43.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:26:43.460+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:43.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:26:43.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:26:43.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:43.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:26:43.496+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:26:43.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:26:43.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:27:13.855+0000] {processor.py:157} INFO - Started process (PID=5566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:27:13.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:27:13.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:13.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:27:13.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:27:13.885+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:13.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:27:13.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:13.895+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:27:13.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:27:44.284+0000] {processor.py:157} INFO - Started process (PID=5586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:27:44.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:27:44.287+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:44.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:27:44.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:27:44.315+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:44.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:27:44.323+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:27:44.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:27:44.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:28:14.621+0000] {processor.py:157} INFO - Started process (PID=5606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:28:14.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:28:14.624+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:14.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:28:14.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:28:14.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:14.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:28:14.659+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:14.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:28:14.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:28:44.972+0000] {processor.py:157} INFO - Started process (PID=5626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:28:44.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:28:44.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:44.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:28:44.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:28:44.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:44.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:28:45.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:28:45.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:28:45.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T13:29:15.374+0000] {processor.py:157} INFO - Started process (PID=5646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:29:15.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:29:15.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:15.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:29:15.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:29:15.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:15.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:29:15.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:15.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:29:15.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:29:45.752+0000] {processor.py:157} INFO - Started process (PID=5666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:29:45.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:29:45.755+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:45.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:29:45.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:29:45.777+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:45.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:29:45.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:29:45.786+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:29:45.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T13:30:16.180+0000] {processor.py:157} INFO - Started process (PID=5686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:30:16.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:30:16.183+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:16.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:30:16.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:30:16.211+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:16.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:30:16.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:16.220+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:30:16.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:30:46.599+0000] {processor.py:157} INFO - Started process (PID=5706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:30:46.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:30:46.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:46.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:30:46.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:30:46.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:46.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:30:46.637+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:30:46.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:30:46.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:31:16.981+0000] {processor.py:157} INFO - Started process (PID=5726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:31:16.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:31:16.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:16.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:31:16.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:31:17.010+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:17.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:31:17.020+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:17.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:31:17.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:31:47.411+0000] {processor.py:157} INFO - Started process (PID=5746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:31:47.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:31:47.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:47.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:31:47.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:31:47.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:47.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:31:47.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:31:47.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:31:47.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:32:17.773+0000] {processor.py:157} INFO - Started process (PID=5766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:32:17.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:32:17.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:17.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:32:17.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:32:17.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:17.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:32:17.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:17.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:32:17.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:32:48.183+0000] {processor.py:157} INFO - Started process (PID=5786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:32:48.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:32:48.187+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:48.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:32:48.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:32:48.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:48.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:32:48.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:32:48.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:32:48.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:33:18.598+0000] {processor.py:157} INFO - Started process (PID=5806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:33:18.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:33:18.602+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:18.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:33:18.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:33:18.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:18.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:33:18.637+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:18.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:33:18.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:33:48.995+0000] {processor.py:157} INFO - Started process (PID=5826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:33:48.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:33:48.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:48.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:33:49.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:33:49.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:49.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:33:49.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:33:49.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:33:49.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:34:19.518+0000] {processor.py:157} INFO - Started process (PID=5846) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:34:19.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:34:19.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:19.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:34:19.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:34:19.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:19.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:34:19.558+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:19.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:34:19.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:34:49.910+0000] {processor.py:157} INFO - Started process (PID=5866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:34:49.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:34:49.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:49.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:34:49.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:34:49.939+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:49.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:34:49.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:34:49.948+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:34:49.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:35:20.329+0000] {processor.py:157} INFO - Started process (PID=5886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:35:20.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:35:20.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:20.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:35:20.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:35:20.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:20.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:35:20.368+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:20.368+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:35:20.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:35:50.745+0000] {processor.py:157} INFO - Started process (PID=5906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:35:50.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:35:50.748+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:50.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:35:50.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:35:50.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:50.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:35:50.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:35:50.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:35:50.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:36:21.147+0000] {processor.py:157} INFO - Started process (PID=5926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:36:21.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:36:21.149+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:21.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:36:21.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:36:21.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:21.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:36:21.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:21.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:36:21.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:36:51.579+0000] {processor.py:157} INFO - Started process (PID=5946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:36:51.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:36:51.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:51.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:36:51.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:36:51.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:51.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:36:51.618+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:36:51.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:36:51.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:37:21.991+0000] {processor.py:157} INFO - Started process (PID=5966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:37:21.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:37:21.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:21.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:37:22.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:37:22.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:22.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:37:22.030+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:22.030+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:37:22.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:37:52.400+0000] {processor.py:157} INFO - Started process (PID=5986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:37:52.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:37:52.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:52.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:37:52.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:37:52.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:52.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:37:52.426+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:37:52.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:37:52.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.035 seconds
[2024-07-10T13:38:22.817+0000] {processor.py:157} INFO - Started process (PID=6006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:38:22.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:38:22.820+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:22.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:38:22.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:38:22.847+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:22.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:38:22.857+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:22.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:38:22.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:38:53.181+0000] {processor.py:157} INFO - Started process (PID=6026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:38:53.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:38:53.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:53.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:38:53.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:38:53.211+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:53.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:38:53.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:38:53.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:38:53.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:39:23.688+0000] {processor.py:157} INFO - Started process (PID=6046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:39:23.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:39:23.692+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:23.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:39:23.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:39:23.724+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:23.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:39:23.735+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:23.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:39:23.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T13:39:54.098+0000] {processor.py:157} INFO - Started process (PID=6066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:39:54.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:39:54.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:54.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:39:54.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:39:54.126+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:54.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:39:54.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:39:54.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:39:54.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:40:24.530+0000] {processor.py:157} INFO - Started process (PID=6086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:40:24.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:40:24.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:24.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:40:24.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:40:24.559+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:24.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:40:24.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:24.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:40:24.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:40:54.916+0000] {processor.py:157} INFO - Started process (PID=6106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:40:54.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:40:54.919+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:54.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:40:54.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:40:54.943+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:54.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:40:54.954+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:40:54.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:40:54.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T13:41:25.327+0000] {processor.py:157} INFO - Started process (PID=6126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:41:25.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:41:25.330+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:25.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:41:25.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:41:25.357+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:25.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:41:25.367+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:25.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:41:25.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:41:55.731+0000] {processor.py:157} INFO - Started process (PID=6146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:41:55.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:41:55.734+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:55.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:41:55.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:41:55.764+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:55.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:41:55.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:41:55.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:41:55.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T13:42:26.131+0000] {processor.py:157} INFO - Started process (PID=6166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:42:26.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:42:26.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:26.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:42:26.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:42:26.162+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:26.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:42:26.171+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:26.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:42:26.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:42:56.557+0000] {processor.py:157} INFO - Started process (PID=6186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:42:56.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:42:56.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:56.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:42:56.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:42:56.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:56.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:42:56.597+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:42:56.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:42:56.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:43:26.967+0000] {processor.py:157} INFO - Started process (PID=6206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:43:26.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:43:26.970+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:26.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:43:26.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:43:26.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:26.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:43:27.006+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:27.006+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:43:27.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:43:57.353+0000] {processor.py:157} INFO - Started process (PID=6226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:43:57.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:43:57.356+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:57.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:43:57.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:43:57.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:57.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:43:57.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:43:57.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:43:57.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T13:44:27.730+0000] {processor.py:157} INFO - Started process (PID=6246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:44:27.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:44:27.734+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:27.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:44:27.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:44:27.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:27.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:44:27.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:27.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:44:27.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T13:44:58.140+0000] {processor.py:157} INFO - Started process (PID=6266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:44:58.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:44:58.142+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:58.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:44:58.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:44:58.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:58.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:44:58.175+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:44:58.175+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:44:58.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T13:45:28.560+0000] {processor.py:157} INFO - Started process (PID=6286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:45:28.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:45:28.563+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:28.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:45:28.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:45:28.589+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:28.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:45:28.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:28.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:45:28.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:45:59.033+0000] {processor.py:157} INFO - Started process (PID=6306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:45:59.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:45:59.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:59.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:45:59.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:45:59.065+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:59.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:45:59.077+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:45:59.077+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:45:59.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T13:46:29.458+0000] {processor.py:157} INFO - Started process (PID=6326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:46:29.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:46:29.461+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:29.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:46:29.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:46:29.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:29.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:46:29.499+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:29.499+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:46:29.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:46:59.853+0000] {processor.py:157} INFO - Started process (PID=6346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:46:59.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:46:59.856+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:59.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:46:59.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:46:59.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:59.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:46:59.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:46:59.888+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:46:59.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T13:47:30.210+0000] {processor.py:157} INFO - Started process (PID=6366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:47:30.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:47:30.213+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:30.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:47:30.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:47:30.240+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:30.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:47:30.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:47:30.249+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:47:30.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:48:00.548+0000] {processor.py:157} INFO - Started process (PID=6386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:48:00.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:48:00.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:00.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:48:00.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:48:00.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:00.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:48:00.587+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:00.587+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:48:00.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:48:31.049+0000] {processor.py:157} INFO - Started process (PID=6406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:48:31.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:48:31.053+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:31.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:48:31.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:48:31.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:31.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:48:31.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:48:31.089+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:48:31.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T13:49:01.562+0000] {processor.py:157} INFO - Started process (PID=6426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:49:01.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:49:01.564+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:01.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:49:01.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:49:01.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:01.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:49:01.600+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:01.600+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:49:01.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:49:32.013+0000] {processor.py:157} INFO - Started process (PID=6446) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:49:32.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:49:32.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:32.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:49:32.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:49:32.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:32.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:49:32.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:49:32.051+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:49:32.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:50:02.394+0000] {processor.py:157} INFO - Started process (PID=6466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:50:02.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:50:02.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:02.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:50:02.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:50:02.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:02.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:50:02.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:02.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:50:02.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T13:50:32.812+0000] {processor.py:157} INFO - Started process (PID=6486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:50:32.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:50:32.815+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:32.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:50:32.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:50:32.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:32.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:50:32.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:50:32.852+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:50:32.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:51:03.256+0000] {processor.py:157} INFO - Started process (PID=6506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:51:03.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:51:03.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:03.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:51:03.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:51:03.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:03.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:51:03.295+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:03.295+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:51:03.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:51:33.667+0000] {processor.py:157} INFO - Started process (PID=6526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:51:33.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:51:33.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:33.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:51:33.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:51:33.697+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:33.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:51:33.706+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:51:33.706+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:51:33.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:52:04.061+0000] {processor.py:157} INFO - Started process (PID=6546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:52:04.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:52:04.064+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:04.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:52:04.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:52:04.090+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:04.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:52:04.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:04.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:52:04.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:52:34.483+0000] {processor.py:157} INFO - Started process (PID=6566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:52:34.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:52:34.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:34.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:52:34.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:52:34.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:34.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:52:34.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:52:34.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:52:34.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T13:53:04.893+0000] {processor.py:157} INFO - Started process (PID=6586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:53:04.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:53:04.897+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:04.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:53:04.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:53:04.924+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:04.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:53:04.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:04.934+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:53:04.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:53:35.296+0000] {processor.py:157} INFO - Started process (PID=6606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:53:35.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:53:35.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:35.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:53:35.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:53:35.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:35.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:53:35.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:53:35.342+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:53:35.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T13:54:05.708+0000] {processor.py:157} INFO - Started process (PID=6626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:54:05.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:54:05.711+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:05.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:54:05.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:54:05.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:05.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:54:05.747+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:05.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:54:05.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:54:36.136+0000] {processor.py:157} INFO - Started process (PID=6646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:54:36.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:54:36.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:36.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:54:36.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:54:36.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:36.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:54:36.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:54:36.177+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:54:36.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T13:55:06.553+0000] {processor.py:157} INFO - Started process (PID=6666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:55:06.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:55:06.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:06.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:55:06.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:55:06.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:06.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:55:06.593+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:06.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:55:06.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T13:55:36.945+0000] {processor.py:157} INFO - Started process (PID=6686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:55:36.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:55:36.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:36.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:55:36.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:55:36.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:36.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:55:36.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:55:36.981+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:55:36.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:56:07.327+0000] {processor.py:157} INFO - Started process (PID=6706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:56:07.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:56:07.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:07.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:56:07.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:56:07.359+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:07.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:56:07.370+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:07.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:56:07.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T13:56:37.711+0000] {processor.py:157} INFO - Started process (PID=6726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:56:37.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:56:37.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:37.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:56:37.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:56:37.742+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:37.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:56:37.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:56:37.751+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:56:37.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:57:08.121+0000] {processor.py:157} INFO - Started process (PID=6746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:57:08.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:57:08.124+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:08.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:57:08.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:57:08.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:08.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:57:08.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:08.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:57:08.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:57:38.534+0000] {processor.py:157} INFO - Started process (PID=6766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:57:38.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:57:38.537+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:38.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:57:38.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:57:38.562+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:38.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:57:38.572+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:57:38.572+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:57:38.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T13:58:08.920+0000] {processor.py:157} INFO - Started process (PID=6786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:58:08.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:58:08.923+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:08.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:58:08.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:58:08.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:08.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:58:08.954+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:08.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:58:08.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T13:58:39.310+0000] {processor.py:157} INFO - Started process (PID=6806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:58:39.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:58:39.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:39.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:58:39.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:58:39.345+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:39.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:58:39.358+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:58:39.357+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:58:39.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T13:59:09.725+0000] {processor.py:157} INFO - Started process (PID=6826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:59:09.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:59:09.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:09.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:59:09.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:59:09.755+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:09.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:59:09.764+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:09.764+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:59:09.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T13:59:40.100+0000] {processor.py:157} INFO - Started process (PID=6846) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:59:40.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T13:59:40.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:40.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:59:40.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T13:59:40.132+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:40.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T13:59:40.141+0000] {logging_mixin.py:151} INFO - [2024-07-10T13:59:40.141+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T13:59:40.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T14:00:10.518+0000] {processor.py:157} INFO - Started process (PID=6866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:00:10.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:00:10.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:10.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:00:10.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:00:10.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:10.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:00:10.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:10.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:00:10.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T14:00:40.925+0000] {processor.py:157} INFO - Started process (PID=6886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:00:40.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:00:40.928+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:40.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:00:40.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:00:40.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:40.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:00:40.964+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:00:40.964+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:00:40.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T14:01:11.349+0000] {processor.py:157} INFO - Started process (PID=6906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:01:11.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:01:11.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:11.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:01:11.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:01:11.379+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:11.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:01:11.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:11.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:01:11.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T14:01:41.748+0000] {processor.py:157} INFO - Started process (PID=6926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:01:41.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:01:41.752+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:41.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:01:41.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:01:41.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:41.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:01:41.788+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:01:41.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:01:41.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:02:12.140+0000] {processor.py:157} INFO - Started process (PID=6946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:02:12.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:02:12.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:12.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:02:12.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:02:12.173+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:12.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:02:12.182+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:12.182+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:02:12.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:02:42.557+0000] {processor.py:157} INFO - Started process (PID=6966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:02:42.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:02:42.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:42.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:02:42.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:02:42.589+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:42.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:02:42.599+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:02:42.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:02:42.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T14:03:12.920+0000] {processor.py:157} INFO - Started process (PID=6986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:03:12.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:03:12.923+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:12.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:03:12.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:03:12.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:12.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:03:12.960+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:12.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:03:12.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:03:43.365+0000] {processor.py:157} INFO - Started process (PID=7006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:03:43.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:03:43.369+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:43.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:03:43.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:03:43.398+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:43.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:03:43.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:03:43.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:03:43.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:04:13.816+0000] {processor.py:157} INFO - Started process (PID=7026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:04:13.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:04:13.817+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:13.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:04:13.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:04:13.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:13.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:04:13.846+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:13.846+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:04:13.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.038 seconds
[2024-07-10T14:04:44.232+0000] {processor.py:157} INFO - Started process (PID=7046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:04:44.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:04:44.234+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:44.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:04:44.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:04:44.262+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:44.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:04:44.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:04:44.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:04:44.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:05:14.682+0000] {processor.py:157} INFO - Started process (PID=7066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:05:14.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:05:14.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:14.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:05:14.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:05:14.713+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:14.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:05:14.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:14.722+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:05:14.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:05:45.060+0000] {processor.py:157} INFO - Started process (PID=7086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:05:45.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:05:45.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:45.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:05:45.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:05:45.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:45.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:05:45.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:05:45.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:05:45.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T14:06:15.413+0000] {processor.py:157} INFO - Started process (PID=7106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:06:15.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:06:15.416+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:15.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:06:15.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:06:15.444+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:15.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:06:15.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:15.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:06:15.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:06:45.847+0000] {processor.py:157} INFO - Started process (PID=7126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:06:45.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:06:45.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:45.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:06:45.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:06:45.877+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:45.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:06:45.886+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:06:45.886+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:06:45.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:07:16.284+0000] {processor.py:157} INFO - Started process (PID=7146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:07:16.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:07:16.287+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:16.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:07:16.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:07:16.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:16.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:07:16.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:16.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:07:16.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T14:07:46.748+0000] {processor.py:157} INFO - Started process (PID=7166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:07:46.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:07:46.752+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:46.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:07:46.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:07:46.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:46.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:07:46.788+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:07:46.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:07:46.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:08:17.168+0000] {processor.py:157} INFO - Started process (PID=7186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:08:17.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:08:17.171+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:17.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:08:17.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:08:17.196+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:17.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:08:17.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:17.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:08:17.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T14:08:47.554+0000] {processor.py:157} INFO - Started process (PID=7206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:08:47.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:08:47.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:47.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:08:47.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:08:47.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:47.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:08:47.594+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:08:47.594+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:08:47.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:09:17.963+0000] {processor.py:157} INFO - Started process (PID=7226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:09:17.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:09:17.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:17.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:09:17.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:09:17.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:17.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:09:18.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:17.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:09:18.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T14:09:48.403+0000] {processor.py:157} INFO - Started process (PID=7246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:09:48.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:09:48.406+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:48.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:09:48.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:09:48.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:48.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:09:48.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:09:48.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:09:48.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:10:18.822+0000] {processor.py:157} INFO - Started process (PID=7266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:10:18.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:10:18.824+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:18.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:10:18.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:10:18.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:18.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:10:18.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:18.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:10:18.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T14:10:49.398+0000] {processor.py:157} INFO - Started process (PID=7286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:10:49.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:10:49.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:49.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:10:49.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:10:49.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:49.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:10:49.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:10:49.455+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:10:49.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-10T14:11:19.852+0000] {processor.py:157} INFO - Started process (PID=7306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:11:19.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:11:19.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:19.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:11:19.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:11:19.890+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:19.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:11:19.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:19.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:11:19.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T14:11:50.295+0000] {processor.py:157} INFO - Started process (PID=7326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:11:50.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:11:50.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:50.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:11:50.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:11:50.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:50.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:11:50.338+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:11:50.338+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:11:50.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T14:12:20.721+0000] {processor.py:157} INFO - Started process (PID=7346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:12:20.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:12:20.724+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:20.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:12:20.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:12:20.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:20.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:12:20.765+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:20.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:12:20.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T14:12:51.174+0000] {processor.py:157} INFO - Started process (PID=7366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:12:51.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:12:51.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:51.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:12:51.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:12:51.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:51.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:12:51.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:12:51.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:12:51.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T14:13:21.594+0000] {processor.py:157} INFO - Started process (PID=7386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:13:21.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:13:21.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:21.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:13:21.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:13:21.626+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:21.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:13:21.636+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:21.636+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:13:21.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:13:52.014+0000] {processor.py:157} INFO - Started process (PID=7406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:13:52.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:13:52.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:52.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:13:52.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:13:52.041+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:52.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:13:52.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:13:52.051+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:13:52.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T14:14:22.374+0000] {processor.py:157} INFO - Started process (PID=7426) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:14:22.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:14:22.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:22.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:14:22.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:14:22.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:22.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:14:22.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:22.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:14:22.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:14:52.822+0000] {processor.py:157} INFO - Started process (PID=7446) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:14:52.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:14:52.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:52.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:14:52.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:14:52.853+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:52.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:14:52.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:14:52.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:14:52.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:15:23.224+0000] {processor.py:157} INFO - Started process (PID=7466) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:15:23.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:15:23.227+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:23.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:15:23.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:15:23.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:23.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:15:23.261+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:23.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:15:23.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T14:15:53.645+0000] {processor.py:157} INFO - Started process (PID=7486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:15:53.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:15:53.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:53.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:15:53.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:15:53.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:53.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:15:53.686+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:15:53.686+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:15:53.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:16:24.090+0000] {processor.py:157} INFO - Started process (PID=7506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:16:24.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:16:24.093+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:24.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:16:24.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:16:24.121+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:24.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:16:24.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:24.130+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:16:24.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:16:54.541+0000] {processor.py:157} INFO - Started process (PID=7526) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:16:54.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:16:54.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:54.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:16:54.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:16:54.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:54.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:16:54.579+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:16:54.579+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:16:54.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T14:17:24.964+0000] {processor.py:157} INFO - Started process (PID=7546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:17:24.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:17:24.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:24.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:17:24.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:17:24.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:24.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:17:25.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:25.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:17:25.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T14:17:55.373+0000] {processor.py:157} INFO - Started process (PID=7566) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:17:55.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:17:55.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:55.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:17:55.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:17:55.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:55.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:17:55.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:17:55.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:17:55.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:18:25.774+0000] {processor.py:157} INFO - Started process (PID=7586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:18:25.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:18:25.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:25.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:18:25.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:18:25.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:25.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:18:25.812+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:25.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:18:25.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:18:56.194+0000] {processor.py:157} INFO - Started process (PID=7606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:18:56.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:18:56.197+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:56.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:18:56.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:18:56.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:56.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:18:56.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:18:56.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:18:56.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T14:19:26.569+0000] {processor.py:157} INFO - Started process (PID=7626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:19:26.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:19:26.572+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:26.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:19:26.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:19:26.602+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:26.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:19:26.612+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:26.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:19:26.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T14:19:56.984+0000] {processor.py:157} INFO - Started process (PID=7646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:19:56.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:19:56.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:56.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:19:56.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:19:57.013+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:57.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:19:57.022+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:19:57.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:19:57.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T14:20:27.401+0000] {processor.py:157} INFO - Started process (PID=7666) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:20:27.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:20:27.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:27.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:20:27.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:20:27.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:27.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:20:27.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:27.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:20:27.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:20:57.814+0000] {processor.py:157} INFO - Started process (PID=7686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:20:57.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:20:57.817+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:57.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:20:57.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:20:57.844+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:57.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:20:57.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:20:57.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:20:57.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:21:28.227+0000] {processor.py:157} INFO - Started process (PID=7706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:21:28.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:21:28.229+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:28.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:21:28.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:21:28.257+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:28.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:21:28.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:28.266+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:21:28.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:21:58.653+0000] {processor.py:157} INFO - Started process (PID=7726) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:21:58.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:21:58.657+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:58.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:21:58.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:21:58.682+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:58.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:21:58.692+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:21:58.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:21:58.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:22:29.093+0000] {processor.py:157} INFO - Started process (PID=7746) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:22:29.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:22:29.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:29.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:22:29.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:22:29.126+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:29.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:22:29.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:29.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:22:29.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T14:22:59.502+0000] {processor.py:157} INFO - Started process (PID=7766) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:22:59.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:22:59.505+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:59.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:22:59.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:22:59.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:59.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:22:59.537+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:22:59.537+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:22:59.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T14:23:29.883+0000] {processor.py:157} INFO - Started process (PID=7786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:23:29.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:23:29.886+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:29.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:23:29.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:23:29.915+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:29.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:23:29.924+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:23:29.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:23:29.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:24:00.317+0000] {processor.py:157} INFO - Started process (PID=7806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:24:00.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:24:00.319+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:00.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:24:00.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:24:00.347+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:00.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:24:00.356+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:00.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:24:00.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:24:30.714+0000] {processor.py:157} INFO - Started process (PID=7826) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:24:30.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:24:30.717+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:30.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:24:30.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:24:30.745+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:30.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:24:30.754+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:24:30.754+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:24:30.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:25:01.151+0000] {processor.py:157} INFO - Started process (PID=7846) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:25:01.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:25:01.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:01.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:25:01.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:25:01.180+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:01.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:25:01.190+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:01.190+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:25:01.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T14:25:31.578+0000] {processor.py:157} INFO - Started process (PID=7866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:25:31.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:25:31.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:31.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:25:31.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:25:31.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:31.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:25:31.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:25:31.619+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:25:31.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:26:01.980+0000] {processor.py:157} INFO - Started process (PID=7886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:26:01.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:26:01.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:01.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:26:01.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:26:02.011+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:02.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:26:02.020+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:02.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:26:02.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:26:32.362+0000] {processor.py:157} INFO - Started process (PID=7906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:26:32.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:26:32.366+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:32.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:26:32.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:26:32.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:32.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:26:32.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:26:32.402+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:26:32.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:27:02.741+0000] {processor.py:157} INFO - Started process (PID=7926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:27:02.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:27:02.744+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:02.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:27:02.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:27:02.772+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:02.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:27:02.781+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:02.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:27:02.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:27:33.147+0000] {processor.py:157} INFO - Started process (PID=7946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:27:33.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:27:33.150+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:33.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:27:33.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:27:33.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:33.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:27:33.187+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:27:33.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:27:33.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:28:03.537+0000] {processor.py:157} INFO - Started process (PID=7966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:28:03.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:28:03.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:03.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:28:03.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:28:03.571+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:03.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:28:03.582+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:03.582+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:28:03.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T14:28:33.997+0000] {processor.py:157} INFO - Started process (PID=7986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:28:33.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:28:34.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:34.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:28:34.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:28:34.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:34.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:28:34.038+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:28:34.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:28:34.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:29:04.438+0000] {processor.py:157} INFO - Started process (PID=8006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:29:04.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:29:04.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:04.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:29:04.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:29:04.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:04.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:29:04.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:04.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:29:04.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T14:29:34.791+0000] {processor.py:157} INFO - Started process (PID=8026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:29:34.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:29:34.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:34.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:29:34.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:29:34.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:34.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:29:34.833+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:29:34.833+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:29:34.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T14:30:05.213+0000] {processor.py:157} INFO - Started process (PID=8046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:30:05.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:30:05.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:05.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:30:05.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:30:05.247+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:05.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:30:05.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:05.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:30:05.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T14:30:35.629+0000] {processor.py:157} INFO - Started process (PID=8066) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:30:35.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:30:35.632+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:35.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:30:35.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:30:35.658+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:35.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:30:35.668+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:30:35.668+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:30:35.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:31:06.018+0000] {processor.py:157} INFO - Started process (PID=8086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:31:06.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:31:06.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:06.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:31:06.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:31:06.047+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:06.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:31:06.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:06.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:31:06.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T14:31:36.426+0000] {processor.py:157} INFO - Started process (PID=8106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:31:36.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:31:36.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:36.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:31:36.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:31:36.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:36.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:31:36.466+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:31:36.466+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:31:36.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T14:32:06.843+0000] {processor.py:157} INFO - Started process (PID=8126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:32:06.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:32:06.847+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:06.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:32:06.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:32:06.875+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:06.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:32:06.885+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:06.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:32:06.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T14:32:37.238+0000] {processor.py:157} INFO - Started process (PID=8146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:32:37.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:32:37.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:37.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:32:37.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:32:37.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:37.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:32:37.279+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:32:37.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:32:37.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:33:07.592+0000] {processor.py:157} INFO - Started process (PID=8166) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:33:07.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:33:07.594+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:07.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:33:07.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:33:07.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:07.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:33:07.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:07.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:33:07.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T14:33:37.951+0000] {processor.py:157} INFO - Started process (PID=8186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:33:37.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:33:37.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:37.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:33:37.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:33:37.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:37.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:33:37.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:33:37.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:33:37.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T14:34:08.360+0000] {processor.py:157} INFO - Started process (PID=8206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:34:08.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:34:08.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:08.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:34:08.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:34:08.382+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:08.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:34:08.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:08.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:34:08.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T14:34:38.771+0000] {processor.py:157} INFO - Started process (PID=8226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:34:38.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:34:38.773+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:38.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:34:38.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:34:38.799+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:38.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:34:38.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:34:38.809+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:34:38.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T14:35:09.165+0000] {processor.py:157} INFO - Started process (PID=8246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:35:09.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:35:09.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:09.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:35:09.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:35:09.195+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:09.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:35:09.204+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:09.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:35:09.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T14:35:39.604+0000] {processor.py:157} INFO - Started process (PID=8266) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:35:39.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:35:39.608+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:39.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:35:39.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:35:39.636+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:39.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:35:39.646+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:35:39.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:35:39.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T14:36:10.002+0000] {processor.py:157} INFO - Started process (PID=8286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:36:10.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:36:10.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:10.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:36:10.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:36:10.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:10.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:36:10.044+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:10.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:36:10.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T14:36:40.487+0000] {processor.py:157} INFO - Started process (PID=8306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:36:40.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:36:40.491+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:40.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:36:40.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:36:40.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:40.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:36:40.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:36:40.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:36:40.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T14:37:10.918+0000] {processor.py:157} INFO - Started process (PID=8326) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:37:10.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:37:10.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:10.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:37:10.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:37:10.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:10.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:37:10.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:10.963+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:37:10.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T14:37:41.330+0000] {processor.py:157} INFO - Started process (PID=8346) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:37:41.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:37:41.334+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:41.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:37:41.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:37:41.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:41.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:37:41.372+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:37:41.372+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:37:41.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T14:38:11.760+0000] {processor.py:157} INFO - Started process (PID=8366) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:38:11.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:38:11.764+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:11.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:38:11.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:38:11.788+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:11.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:38:11.797+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:11.797+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:38:11.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T14:38:42.259+0000] {processor.py:157} INFO - Started process (PID=8386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:38:42.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:38:42.263+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:42.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:38:42.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:38:42.290+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:42.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:38:42.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:38:42.299+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:38:42.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T14:39:28.823+0000] {processor.py:157} INFO - Started process (PID=8393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:39:28.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:39:28.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:39:28.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:39:28.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:39:28.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:39:28.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:39:28.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:39:28.861+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:39:28.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T14:43:31.746+0000] {processor.py:157} INFO - Started process (PID=8413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:43:31.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:43:31.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:43:31.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:43:31.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:43:31.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:43:31.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:43:31.843+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:43:31.843+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:43:31.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-10T14:44:02.330+0000] {processor.py:157} INFO - Started process (PID=8433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:44:02.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T14:44:02.333+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:44:02.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:44:02.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T14:44:02.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:44:02.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T14:44:02.373+0000] {logging_mixin.py:151} INFO - [2024-07-10T14:44:02.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T14:44:02.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T15:00:39.328+0000] {processor.py:157} INFO - Started process (PID=8453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:00:39.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:00:39.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:00:39.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:00:39.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:00:39.389+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:00:39.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:00:39.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:00:39.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:00:39.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-10T15:01:09.863+0000] {processor.py:157} INFO - Started process (PID=8473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:01:09.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:01:09.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:09.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:01:09.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:01:09.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:09.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:01:09.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:09.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:01:09.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T15:01:40.386+0000] {processor.py:157} INFO - Started process (PID=8493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:01:40.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:01:40.390+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:40.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:01:40.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:01:40.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:40.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:01:40.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:01:40.433+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:01:40.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T15:02:10.903+0000] {processor.py:157} INFO - Started process (PID=8513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:02:10.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:02:10.906+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:10.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:02:10.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:02:10.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:10.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:02:10.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:10.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:02:10.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:02:41.402+0000] {processor.py:157} INFO - Started process (PID=8533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:02:41.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:02:41.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:41.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:02:41.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:02:41.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:41.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:02:41.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:02:41.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:02:41.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.038 seconds
[2024-07-10T15:03:11.883+0000] {processor.py:157} INFO - Started process (PID=8553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:03:11.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:03:11.885+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:11.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:03:11.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:03:11.910+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:11.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:03:11.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:11.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:03:11.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:03:42.346+0000] {processor.py:157} INFO - Started process (PID=8573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:03:42.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:03:42.350+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:42.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:03:42.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:03:42.375+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:42.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:03:42.385+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:03:42.385+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:03:42.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:04:12.872+0000] {processor.py:157} INFO - Started process (PID=8593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:04:12.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:04:12.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:12.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:04:12.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:04:12.899+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:12.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:04:12.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:12.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:04:12.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:04:43.400+0000] {processor.py:157} INFO - Started process (PID=8613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:04:43.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:04:43.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:43.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:04:43.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:04:43.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:43.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:04:43.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:04:43.438+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:04:43.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:05:13.824+0000] {processor.py:157} INFO - Started process (PID=8633) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:05:13.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:05:13.827+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:13.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:05:13.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:05:13.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:13.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:05:13.862+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:13.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:05:13.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:05:44.393+0000] {processor.py:157} INFO - Started process (PID=8653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:05:44.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:05:44.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:44.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:05:44.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:05:44.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:44.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:05:44.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:05:44.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:05:44.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:06:14.830+0000] {processor.py:157} INFO - Started process (PID=8673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:06:14.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:06:14.835+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:14.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:06:14.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:06:14.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:14.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:06:14.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:14.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:06:14.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T15:06:45.338+0000] {processor.py:157} INFO - Started process (PID=8693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:06:45.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:06:45.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:45.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:06:45.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:06:45.366+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:45.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:06:45.376+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:06:45.376+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:06:45.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:07:15.783+0000] {processor.py:157} INFO - Started process (PID=8713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:07:15.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:07:15.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:15.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:07:15.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:07:15.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:15.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:07:15.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:15.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:07:15.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:07:46.141+0000] {processor.py:157} INFO - Started process (PID=8733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:07:46.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:07:46.143+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:46.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:07:46.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:07:46.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:46.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:07:46.180+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:07:46.180+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:07:46.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T15:08:16.592+0000] {processor.py:157} INFO - Started process (PID=8753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:08:16.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:08:16.595+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:16.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:08:16.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:08:16.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:16.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:08:16.632+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:16.632+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:08:16.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T15:08:47.041+0000] {processor.py:157} INFO - Started process (PID=8773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:08:47.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:08:47.045+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:47.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:08:47.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:08:47.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:47.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:08:47.082+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:08:47.082+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:08:47.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T15:09:17.491+0000] {processor.py:157} INFO - Started process (PID=8793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:09:17.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:09:17.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:17.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:09:17.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:09:17.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:17.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:09:17.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:17.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:09:17.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T15:09:47.954+0000] {processor.py:157} INFO - Started process (PID=8813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:09:47.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:09:47.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:47.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:09:47.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:09:47.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:47.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:09:48.012+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:09:48.011+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:09:48.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-10T15:10:18.452+0000] {processor.py:157} INFO - Started process (PID=8833) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:10:18.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:10:18.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:18.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:10:18.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:10:18.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:18.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:10:18.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:18.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:10:18.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:10:48.964+0000] {processor.py:157} INFO - Started process (PID=8853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:10:48.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:10:48.967+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:48.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:10:48.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:10:48.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:48.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:10:49.002+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:10:49.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:10:49.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T15:11:19.481+0000] {processor.py:157} INFO - Started process (PID=8873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:11:19.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:11:19.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:19.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:11:19.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:11:19.509+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:19.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:11:19.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:19.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:11:19.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:11:49.989+0000] {processor.py:157} INFO - Started process (PID=8893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:11:49.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:11:49.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:49.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:11:50.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:11:50.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:50.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:11:50.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:11:50.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:11:50.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:12:20.514+0000] {processor.py:157} INFO - Started process (PID=8913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:12:20.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:12:20.517+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:20.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:12:20.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:12:20.542+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:20.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:12:20.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:20.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:12:20.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:12:50.984+0000] {processor.py:157} INFO - Started process (PID=8933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:12:50.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:12:50.986+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:50.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:12:50.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:12:51.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:51.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:12:51.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:12:51.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:12:51.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T15:13:21.535+0000] {processor.py:157} INFO - Started process (PID=8953) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:13:21.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:13:21.537+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:21.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:13:21.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:13:21.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:21.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:13:21.571+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:21.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:13:21.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:13:52.100+0000] {processor.py:157} INFO - Started process (PID=8973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:13:52.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:13:52.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:52.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:13:52.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:13:52.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:52.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:13:52.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:13:52.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:13:52.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:14:22.615+0000] {processor.py:157} INFO - Started process (PID=8993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:14:22.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:14:22.618+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:22.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:14:22.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:14:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:14:22.653+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:22.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:14:22.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:14:53.165+0000] {processor.py:157} INFO - Started process (PID=9013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:14:53.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:14:53.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:53.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:14:53.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:14:53.197+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:53.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:14:53.208+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:14:53.208+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:14:53.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T15:15:23.706+0000] {processor.py:157} INFO - Started process (PID=9033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:15:23.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:15:23.710+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:23.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:15:23.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:15:23.734+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:23.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:15:23.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:23.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:15:23.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:15:54.275+0000] {processor.py:157} INFO - Started process (PID=9053) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:15:54.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:15:54.279+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:54.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:15:54.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:15:54.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:54.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:15:54.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:15:54.313+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:15:54.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:16:24.778+0000] {processor.py:157} INFO - Started process (PID=9073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:16:24.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:16:24.782+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:24.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:16:24.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:16:24.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:24.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:16:24.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:24.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:16:24.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T15:16:55.349+0000] {processor.py:157} INFO - Started process (PID=9093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:16:55.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:16:55.354+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:55.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:16:55.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:16:55.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:55.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:16:55.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:16:55.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:16:55.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T15:17:25.910+0000] {processor.py:157} INFO - Started process (PID=9113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:17:25.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:17:25.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:25.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:17:25.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:17:25.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:25.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:17:25.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:25.948+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:17:25.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:17:56.419+0000] {processor.py:157} INFO - Started process (PID=9133) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:17:56.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:17:56.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:56.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:17:56.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:17:56.447+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:56.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:17:56.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:17:56.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:17:56.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:18:26.907+0000] {processor.py:157} INFO - Started process (PID=9153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:18:26.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:18:26.910+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:26.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:18:26.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:18:26.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:26.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:18:26.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:26.943+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:18:26.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:18:57.390+0000] {processor.py:157} INFO - Started process (PID=9173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:18:57.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:18:57.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:57.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:18:57.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:18:57.417+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:57.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:18:57.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:18:57.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:18:57.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:19:27.946+0000] {processor.py:157} INFO - Started process (PID=9193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:19:27.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:19:27.949+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:27.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:19:27.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:19:27.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:27.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:19:27.981+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:27.981+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:19:27.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T15:19:58.464+0000] {processor.py:157} INFO - Started process (PID=9213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:19:58.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:19:58.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:58.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:19:58.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:19:58.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:58.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:19:58.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:19:58.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:19:58.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:20:28.956+0000] {processor.py:157} INFO - Started process (PID=9233) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:20:28.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:20:28.959+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:28.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:20:28.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:20:28.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:28.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:20:28.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:28.992+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:20:28.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:20:59.502+0000] {processor.py:157} INFO - Started process (PID=9253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:20:59.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:20:59.505+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:59.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:20:59.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:20:59.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:59.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:20:59.539+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:20:59.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:20:59.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:21:30.021+0000] {processor.py:157} INFO - Started process (PID=9273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:21:30.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:21:30.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:21:30.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:21:30.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:21:30.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:21:30.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:21:30.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:21:30.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:21:30.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:22:00.544+0000] {processor.py:157} INFO - Started process (PID=9293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:22:00.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:22:00.546+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:00.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:22:00.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:22:00.571+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:00.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:22:00.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:00.581+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:22:00.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:22:31.057+0000] {processor.py:157} INFO - Started process (PID=9313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:22:31.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:22:31.060+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:31.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:22:31.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:22:31.088+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:31.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:22:31.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:22:31.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:22:31.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T15:23:01.517+0000] {processor.py:157} INFO - Started process (PID=9333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:23:01.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:23:01.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:01.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:23:01.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:23:01.545+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:01.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:23:01.555+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:01.555+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:23:01.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T15:23:32.029+0000] {processor.py:157} INFO - Started process (PID=9353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:23:32.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:23:32.032+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:32.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:23:32.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:23:32.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:32.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:23:32.069+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:23:32.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:23:32.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T15:24:02.548+0000] {processor.py:157} INFO - Started process (PID=9373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:24:02.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:24:02.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:02.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:24:02.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:24:02.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:02.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:24:02.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:02.585+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:24:02.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:24:33.042+0000] {processor.py:157} INFO - Started process (PID=9393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:24:33.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:24:33.044+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:33.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:24:33.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:24:33.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:33.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:24:33.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:24:33.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:24:33.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T15:25:03.560+0000] {processor.py:157} INFO - Started process (PID=9413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:25:03.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:25:03.564+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:03.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:25:03.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:25:03.589+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:03.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:25:03.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:03.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:25:03.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T15:25:34.052+0000] {processor.py:157} INFO - Started process (PID=9433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:25:34.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:25:34.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:34.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:25:34.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:25:34.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:34.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:25:34.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:25:34.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:25:34.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T15:26:04.573+0000] {processor.py:157} INFO - Started process (PID=9453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:26:04.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:26:04.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:04.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:26:04.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:26:04.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:04.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:26:04.611+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:04.611+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:26:04.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:26:35.085+0000] {processor.py:157} INFO - Started process (PID=9473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:26:35.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:26:35.088+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:35.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:26:35.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:26:35.112+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:35.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:26:35.122+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:26:35.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:26:35.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:27:05.549+0000] {processor.py:157} INFO - Started process (PID=9493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:27:05.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:27:05.552+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:05.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:27:05.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:27:05.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:05.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:27:05.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:05.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:27:05.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:27:35.945+0000] {processor.py:157} INFO - Started process (PID=9513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:27:35.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:27:35.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:35.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:27:35.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:27:35.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:35.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:27:35.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:27:35.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:27:35.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:28:06.429+0000] {processor.py:157} INFO - Started process (PID=9533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:28:06.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:28:06.431+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:06.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:28:06.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:28:06.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:06.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:28:06.464+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:06.464+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:28:06.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:28:36.825+0000] {processor.py:157} INFO - Started process (PID=9553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:28:36.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:28:36.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:36.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:28:36.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:28:36.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:36.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:28:36.860+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:28:36.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:28:36.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T15:29:07.243+0000] {processor.py:157} INFO - Started process (PID=9573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:29:07.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:29:07.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:07.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:29:07.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:29:07.269+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:07.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:29:07.279+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:07.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:29:07.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:29:37.704+0000] {processor.py:157} INFO - Started process (PID=9593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:29:37.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:29:37.708+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:37.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:29:37.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:29:37.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:37.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:29:37.742+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:29:37.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:29:37.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:30:08.126+0000] {processor.py:157} INFO - Started process (PID=9613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:30:08.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:30:08.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:08.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:30:08.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:30:08.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:08.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:30:08.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:08.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:30:08.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T15:30:38.628+0000] {processor.py:157} INFO - Started process (PID=9633) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:30:38.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:30:38.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:38.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:30:38.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:30:38.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:38.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:30:38.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:30:38.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:30:38.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:31:09.173+0000] {processor.py:157} INFO - Started process (PID=9653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:31:09.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:31:09.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:09.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:31:09.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:31:09.201+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:09.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:31:09.212+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:09.212+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:31:09.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:31:39.749+0000] {processor.py:157} INFO - Started process (PID=9673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:31:39.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:31:39.752+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:39.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:31:39.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:31:39.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:39.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:31:39.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:31:39.786+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:31:39.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:32:10.214+0000] {processor.py:157} INFO - Started process (PID=9693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:32:10.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:32:10.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:10.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:32:10.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:32:10.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:10.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:32:10.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:10.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:32:10.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:32:40.728+0000] {processor.py:157} INFO - Started process (PID=9713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:32:40.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:32:40.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:40.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:32:40.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:32:40.757+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:40.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:32:40.767+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:32:40.767+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:32:40.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:33:11.246+0000] {processor.py:157} INFO - Started process (PID=9733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:33:11.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:33:11.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:11.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:33:11.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:33:11.274+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:11.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:33:11.284+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:11.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:33:11.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:33:41.770+0000] {processor.py:157} INFO - Started process (PID=9753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:33:41.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:33:41.773+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:41.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:33:41.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:33:41.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:41.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:33:41.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:33:41.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:33:41.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:34:12.233+0000] {processor.py:157} INFO - Started process (PID=9773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:34:12.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:34:12.236+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:12.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:34:12.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:34:12.261+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:12.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:34:12.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:12.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:34:12.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:34:42.771+0000] {processor.py:157} INFO - Started process (PID=9793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:34:42.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:34:42.774+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:42.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:34:42.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:34:42.803+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:42.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:34:42.814+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:34:42.814+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:34:42.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T15:35:13.292+0000] {processor.py:157} INFO - Started process (PID=9813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:35:13.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:35:13.295+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:13.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:35:13.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:35:13.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:13.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:35:13.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:13.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:35:13.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:35:43.818+0000] {processor.py:157} INFO - Started process (PID=9833) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:35:43.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:35:43.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:43.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:35:43.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:35:43.845+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:43.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:35:43.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:35:43.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:35:43.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:36:14.355+0000] {processor.py:157} INFO - Started process (PID=9853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:36:14.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:36:14.358+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:14.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:36:14.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:36:14.380+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:14.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:36:14.389+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:14.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:36:14.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T15:36:44.855+0000] {processor.py:157} INFO - Started process (PID=9873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:36:44.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:36:44.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:44.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:36:44.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:36:44.883+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:44.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:36:44.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:36:44.895+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:36:44.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T15:37:15.368+0000] {processor.py:157} INFO - Started process (PID=9893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:37:15.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:37:15.370+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:15.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:37:15.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:37:15.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:15.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:37:15.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:15.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:37:15.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:37:45.869+0000] {processor.py:157} INFO - Started process (PID=9913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:37:45.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:37:45.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:45.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:37:45.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:37:45.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:45.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:37:45.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:37:45.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:37:45.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T15:38:16.366+0000] {processor.py:157} INFO - Started process (PID=9933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:38:16.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:38:16.369+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:16.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:38:16.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:38:16.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:16.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:38:16.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:16.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:38:16.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:38:46.913+0000] {processor.py:157} INFO - Started process (PID=9953) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:38:46.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:38:46.917+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:46.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:38:46.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:38:46.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:46.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:38:46.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:38:46.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:38:46.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T15:39:17.440+0000] {processor.py:157} INFO - Started process (PID=9973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:39:17.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:39:17.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:17.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:39:17.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:39:17.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:17.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:39:17.478+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:17.478+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:39:17.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:39:47.981+0000] {processor.py:157} INFO - Started process (PID=9993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:39:47.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:39:47.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:47.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:39:47.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:39:48.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:48.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:39:48.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:39:48.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:39:48.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:40:18.449+0000] {processor.py:157} INFO - Started process (PID=10013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:40:18.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:40:18.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:18.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:40:18.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:40:18.478+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:18.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:40:18.488+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:18.488+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:40:18.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:40:48.852+0000] {processor.py:157} INFO - Started process (PID=10033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:40:48.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:40:48.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:48.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:40:48.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:40:48.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:48.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:40:48.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:40:48.888+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:40:48.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:41:19.279+0000] {processor.py:157} INFO - Started process (PID=10053) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:41:19.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:41:19.282+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:19.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:41:19.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:41:19.306+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:19.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:41:19.316+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:19.316+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:41:19.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:41:49.759+0000] {processor.py:157} INFO - Started process (PID=10073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:41:49.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:41:49.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:49.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:41:49.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:41:49.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:49.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:41:49.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:41:49.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:41:49.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:42:20.284+0000] {processor.py:157} INFO - Started process (PID=10093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:42:20.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:42:20.286+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:20.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:42:20.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:42:20.310+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:20.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:42:20.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:20.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:42:20.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:42:50.742+0000] {processor.py:157} INFO - Started process (PID=10113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:42:50.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:42:50.745+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:50.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:42:50.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:42:50.769+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:50.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:42:50.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:42:50.779+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:42:50.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:43:21.248+0000] {processor.py:157} INFO - Started process (PID=10133) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:43:21.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:43:21.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:21.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:43:21.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:43:21.272+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:21.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:43:21.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:21.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:43:21.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T15:43:51.764+0000] {processor.py:157} INFO - Started process (PID=10153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:43:51.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:43:51.767+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:51.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:43:51.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:43:51.792+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:51.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:43:51.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:43:51.802+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:43:51.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:44:22.313+0000] {processor.py:157} INFO - Started process (PID=10173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:44:22.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:44:22.316+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:22.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:44:22.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:44:22.341+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:22.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:44:22.350+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:22.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:44:22.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:44:52.828+0000] {processor.py:157} INFO - Started process (PID=10193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:44:52.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:44:52.831+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:52.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:44:52.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:44:52.854+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:52.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:44:52.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:44:52.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:44:52.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:45:23.283+0000] {processor.py:157} INFO - Started process (PID=10213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:45:23.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:45:23.287+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:23.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:45:23.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:45:23.311+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:23.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:45:23.321+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:23.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:45:23.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:45:53.834+0000] {processor.py:157} INFO - Started process (PID=10233) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:45:53.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:45:53.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:53.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:45:53.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:45:53.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:53.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:45:53.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:45:53.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:45:53.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:46:24.315+0000] {processor.py:157} INFO - Started process (PID=10253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:46:24.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:46:24.318+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:24.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:46:24.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:46:24.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:24.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:46:24.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:24.352+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:46:24.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:46:54.810+0000] {processor.py:157} INFO - Started process (PID=10273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:46:54.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:46:54.813+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:54.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:46:54.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:46:54.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:54.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:46:54.847+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:46:54.847+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:46:54.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:47:25.399+0000] {processor.py:157} INFO - Started process (PID=10293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:47:25.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:47:25.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:25.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:47:25.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:47:25.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:25.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:47:25.437+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:25.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:47:25.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:47:55.929+0000] {processor.py:157} INFO - Started process (PID=10313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:47:55.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:47:55.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:55.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:47:55.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:47:55.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:55.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:47:55.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:47:55.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:47:55.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:48:26.408+0000] {processor.py:157} INFO - Started process (PID=10333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:48:26.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:48:26.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:26.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:48:26.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:48:26.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:26.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:48:26.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:26.445+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:48:26.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:48:56.813+0000] {processor.py:157} INFO - Started process (PID=10353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:48:56.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:48:56.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:56.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:48:56.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:48:56.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:56.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:48:56.849+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:48:56.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:48:56.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T15:49:27.294+0000] {processor.py:157} INFO - Started process (PID=10373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:49:27.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:49:27.297+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:27.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:49:27.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:49:27.322+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:27.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:49:27.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:27.331+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:49:27.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:49:57.741+0000] {processor.py:157} INFO - Started process (PID=10393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:49:57.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:49:57.744+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:57.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:49:57.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:49:57.768+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:57.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:49:57.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:49:57.778+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:49:57.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:50:28.087+0000] {processor.py:157} INFO - Started process (PID=10413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:50:28.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:50:28.090+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:28.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:50:28.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:50:28.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:28.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:50:28.126+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:28.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:50:28.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:50:58.525+0000] {processor.py:157} INFO - Started process (PID=10433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:50:58.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:50:58.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:58.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:50:58.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:50:58.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:58.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:50:58.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:50:58.561+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:50:58.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:51:28.910+0000] {processor.py:157} INFO - Started process (PID=10453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:51:28.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:51:28.912+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:28.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:51:28.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:51:28.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:28.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:51:28.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:28.944+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:51:28.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T15:51:59.365+0000] {processor.py:157} INFO - Started process (PID=10473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:51:59.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:51:59.368+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:59.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:51:59.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:51:59.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:59.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:51:59.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:51:59.403+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:51:59.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:52:29.868+0000] {processor.py:157} INFO - Started process (PID=10493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:52:29.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:52:29.870+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:52:29.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:52:29.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:52:29.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:52:29.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:52:29.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:52:29.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:52:29.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:53:00.312+0000] {processor.py:157} INFO - Started process (PID=10513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:53:00.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:53:00.315+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:00.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:53:00.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:53:00.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:00.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:53:00.349+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:00.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:53:00.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:53:30.736+0000] {processor.py:157} INFO - Started process (PID=10533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:53:30.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:53:30.739+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:30.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:53:30.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:53:30.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:30.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:53:30.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:53:30.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:53:30.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T15:54:01.207+0000] {processor.py:157} INFO - Started process (PID=10553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:54:01.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:54:01.210+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:01.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:54:01.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:54:01.235+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:01.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:54:01.245+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:01.245+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:54:01.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:54:31.753+0000] {processor.py:157} INFO - Started process (PID=10573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:54:31.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:54:31.756+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:31.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:54:31.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:54:31.781+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:31.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:54:31.791+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:54:31.791+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:54:31.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T15:55:02.286+0000] {processor.py:157} INFO - Started process (PID=10593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:55:02.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:55:02.289+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:02.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:55:02.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:55:02.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:02.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:55:02.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:02.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:55:02.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T15:55:32.813+0000] {processor.py:157} INFO - Started process (PID=10613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:55:32.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:55:32.817+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:32.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:55:32.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:55:32.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:32.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:55:32.852+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:55:32.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:55:32.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T15:56:03.345+0000] {processor.py:157} INFO - Started process (PID=10633) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:56:03.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:56:03.347+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:03.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:56:03.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:56:03.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:03.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:56:03.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:03.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:56:03.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T15:56:33.855+0000] {processor.py:157} INFO - Started process (PID=10653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:56:33.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:56:33.860+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:33.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:56:33.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:56:33.891+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:33.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:56:33.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:56:33.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:56:33.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T15:57:04.363+0000] {processor.py:157} INFO - Started process (PID=10673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:57:04.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:57:04.366+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:04.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:57:04.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:57:04.390+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:04.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:57:04.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:04.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:57:04.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:57:34.935+0000] {processor.py:157} INFO - Started process (PID=10693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:57:34.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:57:34.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:34.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:57:34.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:57:34.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:34.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:57:34.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:57:34.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:57:34.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:58:05.464+0000] {processor.py:157} INFO - Started process (PID=10713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:58:05.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:58:05.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:05.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:58:05.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:58:05.491+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:05.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:58:05.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:05.501+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:58:05.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T15:58:36.020+0000] {processor.py:157} INFO - Started process (PID=10733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:58:36.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:58:36.023+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:36.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:58:36.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:58:36.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:36.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:58:36.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:58:36.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:58:36.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T15:59:06.551+0000] {processor.py:157} INFO - Started process (PID=10753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:59:06.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:59:06.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:06.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:59:06.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:59:06.579+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:06.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:59:06.589+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:06.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:59:06.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T15:59:37.030+0000] {processor.py:157} INFO - Started process (PID=10773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:59:37.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T15:59:37.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:37.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:59:37.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T15:59:37.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:37.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T15:59:37.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T15:59:37.066+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T15:59:37.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:00:07.563+0000] {processor.py:157} INFO - Started process (PID=10793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:00:07.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:00:07.567+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:07.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:00:07.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:00:07.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:07.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:00:07.599+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:07.599+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:00:07.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:00:38.086+0000] {processor.py:157} INFO - Started process (PID=10813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:00:38.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:00:38.088+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:38.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:00:38.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:00:38.111+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:38.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:00:38.121+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:00:38.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:00:38.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T16:01:08.594+0000] {processor.py:157} INFO - Started process (PID=10833) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:01:08.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:01:08.597+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:08.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:01:08.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:01:08.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:08.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:01:08.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:08.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:01:08.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:01:39.099+0000] {processor.py:157} INFO - Started process (PID=10853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:01:39.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:01:39.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:39.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:01:39.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:01:39.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:39.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:01:39.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:01:39.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:01:39.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T16:02:09.549+0000] {processor.py:157} INFO - Started process (PID=10873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:02:09.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:02:09.552+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:09.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:02:09.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:02:09.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:09.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:02:09.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:09.585+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:02:09.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:02:40.089+0000] {processor.py:157} INFO - Started process (PID=10893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:02:40.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:02:40.092+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:40.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:02:40.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:02:40.118+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:40.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:02:40.128+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:02:40.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:02:40.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T16:03:10.577+0000] {processor.py:157} INFO - Started process (PID=10913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:03:10.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:03:10.580+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:10.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:03:10.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:03:10.604+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:10.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:03:10.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:10.614+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:03:10.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:03:41.118+0000] {processor.py:157} INFO - Started process (PID=10933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:03:41.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:03:41.121+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:41.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:03:41.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:03:41.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:41.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:03:41.156+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:03:41.156+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:03:41.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:04:11.603+0000] {processor.py:157} INFO - Started process (PID=10953) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:04:11.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:04:11.606+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:11.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:04:11.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:04:11.630+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:11.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:04:11.639+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:11.639+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:04:11.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:04:42.136+0000] {processor.py:157} INFO - Started process (PID=10973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:04:42.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:04:42.140+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:42.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:04:42.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:04:42.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:42.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:04:42.176+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:04:42.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:04:42.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T16:05:12.623+0000] {processor.py:157} INFO - Started process (PID=10993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:05:12.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:05:12.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:12.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:05:12.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:05:12.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:12.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:05:12.665+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:12.665+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:05:12.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T16:05:43.049+0000] {processor.py:157} INFO - Started process (PID=11013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:05:43.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:05:43.053+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:43.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:05:43.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:05:43.078+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:43.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:05:43.088+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:05:43.087+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:05:43.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:06:13.560+0000] {processor.py:157} INFO - Started process (PID=11033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:06:13.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:06:13.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:13.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:06:13.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:06:13.599+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:13.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:06:13.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:13.610+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:06:13.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T16:06:44.069+0000] {processor.py:157} INFO - Started process (PID=11053) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:06:44.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:06:44.073+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:44.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:06:44.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:06:44.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:44.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:06:44.110+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:06:44.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:06:44.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T16:07:14.555+0000] {processor.py:157} INFO - Started process (PID=11073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:07:14.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:07:14.558+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:14.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:07:14.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:07:14.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:14.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:07:14.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:14.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:07:14.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:07:45.078+0000] {processor.py:157} INFO - Started process (PID=11093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:07:45.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:07:45.081+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:45.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:07:45.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:07:45.107+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:45.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:07:45.117+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:07:45.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:07:45.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:08:15.582+0000] {processor.py:157} INFO - Started process (PID=11113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:08:15.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:08:15.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:15.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:08:15.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:08:15.610+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:15.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:08:15.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:15.619+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:08:15.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:08:45.988+0000] {processor.py:157} INFO - Started process (PID=11133) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:08:45.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:08:45.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:45.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:08:46.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:08:46.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:46.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:08:46.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:08:46.025+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:08:46.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:09:16.515+0000] {processor.py:157} INFO - Started process (PID=11153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:09:16.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:09:16.518+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:16.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:09:16.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:09:16.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:16.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:09:16.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:16.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:09:16.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-10T16:09:46.985+0000] {processor.py:157} INFO - Started process (PID=11173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:09:46.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:09:46.989+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:46.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:09:47.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:09:47.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:47.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:09:47.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:09:47.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:09:47.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T16:10:17.507+0000] {processor.py:157} INFO - Started process (PID=11193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:10:17.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:10:17.510+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:17.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:10:17.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:10:17.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:17.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:10:17.544+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:17.544+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:10:17.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:10:47.977+0000] {processor.py:157} INFO - Started process (PID=11213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:10:47.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:10:47.979+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:47.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:10:47.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:10:48.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:48.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:10:48.010+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:10:48.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:10:48.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T16:11:18.463+0000] {processor.py:157} INFO - Started process (PID=11233) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:11:18.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:11:18.465+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:18.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:11:18.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:11:18.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:18.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:11:18.499+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:18.499+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:11:18.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:11:48.889+0000] {processor.py:157} INFO - Started process (PID=11253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:11:48.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:11:48.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:48.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:11:48.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:11:48.917+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:48.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:11:48.927+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:11:48.927+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:11:48.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:12:19.314+0000] {processor.py:157} INFO - Started process (PID=11273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:12:19.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:12:19.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:19.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:12:19.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:12:19.344+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:19.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:12:19.355+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:19.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:12:19.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T16:12:49.802+0000] {processor.py:157} INFO - Started process (PID=11293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:12:49.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:12:49.805+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:49.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:12:49.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:12:49.829+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:49.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:12:49.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:12:49.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:12:49.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:13:20.253+0000] {processor.py:157} INFO - Started process (PID=11313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:13:20.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:13:20.256+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:20.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:13:20.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:13:20.282+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:20.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:13:20.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:20.291+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:13:20.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:13:50.802+0000] {processor.py:157} INFO - Started process (PID=11333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:13:50.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:13:50.807+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:50.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:13:50.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:13:50.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:50.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:13:50.842+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:13:50.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:13:50.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:14:21.329+0000] {processor.py:157} INFO - Started process (PID=11353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:14:21.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:14:21.334+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:21.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:14:21.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:14:21.366+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:21.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:14:21.377+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:21.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:14:21.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T16:14:51.843+0000] {processor.py:157} INFO - Started process (PID=11373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:14:51.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:14:51.846+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:51.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:14:51.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:14:51.871+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:51.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:14:51.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:14:51.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:14:51.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:15:22.373+0000] {processor.py:157} INFO - Started process (PID=11393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:15:22.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:15:22.376+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:22.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:15:22.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:15:22.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:22.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:15:22.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:22.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:15:22.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:15:52.901+0000] {processor.py:157} INFO - Started process (PID=11413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:15:52.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:15:52.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:52.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:15:52.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:15:52.928+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:52.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:15:52.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:15:52.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:15:52.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:16:23.371+0000] {processor.py:157} INFO - Started process (PID=11433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:16:23.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:16:23.374+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:23.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:16:23.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:16:23.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:23.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:16:23.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:23.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:16:23.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:16:53.849+0000] {processor.py:157} INFO - Started process (PID=11453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:16:53.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:16:53.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:53.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:16:53.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:16:53.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:53.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:16:53.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:16:53.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:16:53.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-10T16:17:24.359+0000] {processor.py:157} INFO - Started process (PID=11473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:17:24.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:17:24.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:24.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:17:24.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:17:24.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:24.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:17:24.396+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:24.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:17:24.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:17:54.857+0000] {processor.py:157} INFO - Started process (PID=11493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:17:54.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:17:54.860+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:54.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:17:54.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:17:54.884+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:54.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:17:54.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:17:54.895+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:17:54.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:18:25.343+0000] {processor.py:157} INFO - Started process (PID=11513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:18:25.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:18:25.346+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:25.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:18:25.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:18:25.373+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:25.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:18:25.382+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:25.382+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:18:25.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:18:55.874+0000] {processor.py:157} INFO - Started process (PID=11533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:18:55.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:18:55.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:55.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:18:55.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:18:55.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:55.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:18:55.912+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:18:55.912+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:18:55.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:19:26.401+0000] {processor.py:157} INFO - Started process (PID=11553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:19:26.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:19:26.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:26.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:19:26.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:19:26.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:26.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:19:26.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:26.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:19:26.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:19:56.913+0000] {processor.py:157} INFO - Started process (PID=11573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:19:56.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:19:56.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:56.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:19:56.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:19:56.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:56.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:19:56.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:19:56.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:19:56.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:20:27.415+0000] {processor.py:157} INFO - Started process (PID=11593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:20:27.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:20:27.417+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:27.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:20:27.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:20:27.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:27.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:20:27.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:27.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:20:27.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T16:20:57.985+0000] {processor.py:157} INFO - Started process (PID=11613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:20:57.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:20:57.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:57.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:20:57.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:20:58.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:58.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:20:58.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:20:58.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:20:58.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T16:21:28.491+0000] {processor.py:157} INFO - Started process (PID=11633) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:21:28.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:21:28.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:28.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:21:28.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:21:28.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:28.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:21:28.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:28.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:21:28.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T16:21:59.013+0000] {processor.py:157} INFO - Started process (PID=11653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:21:59.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:21:59.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:59.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:21:59.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:21:59.040+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:59.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:21:59.052+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:21:59.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:21:59.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:22:29.480+0000] {processor.py:157} INFO - Started process (PID=11673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:22:29.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:22:29.483+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:22:29.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:22:29.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:22:29.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:22:29.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:22:29.518+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:22:29.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:22:29.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:22:59.988+0000] {processor.py:157} INFO - Started process (PID=11693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:22:59.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:22:59.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:22:59.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:23:00.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:23:00.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:00.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:23:00.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:00.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:23:00.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T16:23:30.537+0000] {processor.py:157} INFO - Started process (PID=11713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:23:30.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:23:30.539+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:30.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:23:30.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:23:30.565+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:30.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:23:30.575+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:23:30.575+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:23:30.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:24:00.997+0000] {processor.py:157} INFO - Started process (PID=11733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:24:00.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:24:01.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:01.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:24:01.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:24:01.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:01.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:24:01.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:01.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:24:01.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:24:31.529+0000] {processor.py:157} INFO - Started process (PID=11753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:24:31.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:24:31.532+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:31.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:24:31.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:24:31.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:31.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:24:31.567+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:24:31.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:24:31.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:25:02.092+0000] {processor.py:157} INFO - Started process (PID=11773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:25:02.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:25:02.097+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:02.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:25:02.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:25:02.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:02.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:25:02.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:02.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:25:02.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T16:25:32.625+0000] {processor.py:157} INFO - Started process (PID=11793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:25:32.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:25:32.628+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:32.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:25:32.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:25:32.651+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:32.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:25:32.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:25:32.661+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:25:32.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:26:03.114+0000] {processor.py:157} INFO - Started process (PID=11813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:26:03.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:26:03.117+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:03.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:26:03.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:26:03.141+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:03.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:26:03.151+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:03.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:26:03.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:26:33.606+0000] {processor.py:157} INFO - Started process (PID=11833) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:26:33.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:26:33.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:33.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:26:33.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:26:33.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:33.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:26:33.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:26:33.643+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:26:33.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:27:04.120+0000] {processor.py:157} INFO - Started process (PID=11853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:27:04.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:27:04.123+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:04.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:27:04.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:27:04.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:04.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:27:04.158+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:04.158+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:27:04.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:27:34.591+0000] {processor.py:157} INFO - Started process (PID=11873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:27:34.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:27:34.594+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:34.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:27:34.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:27:34.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:34.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:27:34.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:27:34.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:27:34.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:28:05.117+0000] {processor.py:157} INFO - Started process (PID=11893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:28:05.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:28:05.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:05.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:28:05.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:28:05.145+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:05.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:28:05.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:05.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:28:05.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:28:35.626+0000] {processor.py:157} INFO - Started process (PID=11913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:28:35.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:28:35.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:35.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:28:35.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:28:35.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:35.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:28:35.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:28:35.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:28:35.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T16:29:06.107+0000] {processor.py:157} INFO - Started process (PID=11933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:29:06.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:29:06.110+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:06.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:29:06.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:29:06.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:06.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:29:06.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:06.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:29:06.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:29:36.579+0000] {processor.py:157} INFO - Started process (PID=11953) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:29:36.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:29:36.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:36.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:29:36.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:29:36.606+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:36.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:29:36.616+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:29:36.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:29:36.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:30:07.093+0000] {processor.py:157} INFO - Started process (PID=11973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:30:07.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:30:07.097+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:07.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:30:07.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:30:07.122+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:07.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:30:07.132+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:07.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:30:07.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:30:37.598+0000] {processor.py:157} INFO - Started process (PID=11993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:30:37.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:30:37.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:37.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:30:37.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:30:37.625+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:37.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:30:37.635+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:30:37.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:30:37.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:31:08.110+0000] {processor.py:157} INFO - Started process (PID=12013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:31:08.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:31:08.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:08.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:31:08.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:31:08.138+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:08.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:31:08.148+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:08.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:31:08.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:31:38.607+0000] {processor.py:157} INFO - Started process (PID=12033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:31:38.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:31:38.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:38.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:31:38.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:31:38.637+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:38.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:31:38.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:31:38.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:31:38.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T16:32:09.070+0000] {processor.py:157} INFO - Started process (PID=12053) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:32:09.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:32:09.073+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:09.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:32:09.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:32:09.097+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:09.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:32:09.108+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:09.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:32:09.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:32:39.551+0000] {processor.py:157} INFO - Started process (PID=12073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:32:39.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:32:39.554+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:39.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:32:39.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:32:39.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:39.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:32:39.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:32:39.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:32:39.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:33:10.077+0000] {processor.py:157} INFO - Started process (PID=12093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:33:10.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:33:10.079+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:10.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:33:10.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:33:10.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:10.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:33:10.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:10.113+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:33:10.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T16:33:40.615+0000] {processor.py:157} INFO - Started process (PID=12113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:33:40.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:33:40.620+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:40.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:33:40.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:33:40.651+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:40.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:33:40.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:33:40.661+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:33:40.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T16:34:11.136+0000] {processor.py:157} INFO - Started process (PID=12133) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:34:11.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:34:11.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:11.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:34:11.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:34:11.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:11.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:34:11.175+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:11.175+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:34:11.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:34:41.642+0000] {processor.py:157} INFO - Started process (PID=12153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:34:41.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:34:41.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:41.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:34:41.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:34:41.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:41.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:34:41.681+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:34:41.681+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:34:41.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:35:12.097+0000] {processor.py:157} INFO - Started process (PID=12173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:35:12.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:35:12.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:12.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:35:12.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:35:12.124+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:12.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:35:12.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:12.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:35:12.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:35:42.556+0000] {processor.py:157} INFO - Started process (PID=12193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:35:42.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:35:42.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:42.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:35:42.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:35:42.585+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:42.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:35:42.595+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:35:42.595+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:35:42.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:36:13.092+0000] {processor.py:157} INFO - Started process (PID=12213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:36:13.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:36:13.094+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:13.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:36:13.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:36:13.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:13.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:36:13.126+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:13.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:36:13.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:36:43.623+0000] {processor.py:157} INFO - Started process (PID=12233) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:36:43.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:36:43.626+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:43.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:36:43.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:36:43.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:43.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:36:43.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:36:43.660+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:36:43.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:37:14.142+0000] {processor.py:157} INFO - Started process (PID=12253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:37:14.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:37:14.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:14.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:37:14.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:37:14.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:14.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:37:14.179+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:14.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:37:14.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:37:44.655+0000] {processor.py:157} INFO - Started process (PID=12273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:37:44.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:37:44.658+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:44.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:37:44.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:37:44.684+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:44.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:37:44.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:37:44.693+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:37:44.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:38:15.170+0000] {processor.py:157} INFO - Started process (PID=12293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:38:15.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:38:15.173+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:15.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:38:15.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:38:15.199+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:15.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:38:15.209+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:15.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:38:15.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:38:45.684+0000] {processor.py:157} INFO - Started process (PID=12313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:38:45.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:38:45.687+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:45.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:38:45.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:38:45.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:45.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:38:45.725+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:38:45.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:38:45.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T16:39:16.184+0000] {processor.py:157} INFO - Started process (PID=12333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:39:16.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:39:16.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:16.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:39:16.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:39:16.211+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:16.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:39:16.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:16.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:39:16.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:39:46.705+0000] {processor.py:157} INFO - Started process (PID=12353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:39:46.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:39:46.709+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:46.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:39:46.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:39:46.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:46.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:39:46.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:39:46.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:39:46.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T16:40:17.214+0000] {processor.py:157} INFO - Started process (PID=12373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:40:17.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:40:17.218+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:17.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:40:17.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:40:17.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:17.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:40:17.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:17.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:40:17.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:40:47.722+0000] {processor.py:157} INFO - Started process (PID=12393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:40:47.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:40:47.725+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:47.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:40:47.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:40:47.750+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:47.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:40:47.760+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:40:47.760+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:40:47.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:41:18.256+0000] {processor.py:157} INFO - Started process (PID=12413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:41:18.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:41:18.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:18.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:41:18.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:41:18.284+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:18.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:41:18.294+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:18.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:41:18.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:41:48.741+0000] {processor.py:157} INFO - Started process (PID=12433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:41:48.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:41:48.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:48.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:41:48.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:41:48.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:48.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:41:48.788+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:41:48.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:41:48.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T16:42:19.245+0000] {processor.py:157} INFO - Started process (PID=12453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:42:19.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:42:19.248+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:19.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:42:19.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:42:19.273+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:19.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:42:19.283+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:19.283+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:42:19.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:42:49.787+0000] {processor.py:157} INFO - Started process (PID=12473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:42:49.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:42:49.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:49.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:42:49.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:42:49.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:49.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:42:49.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:42:49.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:42:49.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T16:43:20.365+0000] {processor.py:157} INFO - Started process (PID=12493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:43:20.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:43:20.368+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:20.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:43:20.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:43:20.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:20.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:43:20.405+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:20.405+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:43:20.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T16:43:50.903+0000] {processor.py:157} INFO - Started process (PID=12513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:43:50.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:43:50.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:50.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:43:50.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:43:50.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:50.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:43:50.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:43:50.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:43:50.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:44:21.396+0000] {processor.py:157} INFO - Started process (PID=12533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:44:21.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:44:21.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:21.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:44:21.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:44:21.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:21.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:44:21.435+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:21.435+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:44:21.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:44:51.917+0000] {processor.py:157} INFO - Started process (PID=12553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:44:51.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:44:51.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:51.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:44:51.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:44:51.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:51.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:44:51.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:44:51.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:44:51.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:45:22.375+0000] {processor.py:157} INFO - Started process (PID=12573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:45:22.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:45:22.378+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:22.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:45:22.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:45:22.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:22.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:45:22.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:22.411+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:45:22.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:45:52.921+0000] {processor.py:157} INFO - Started process (PID=12593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:45:52.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:45:52.924+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:52.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:45:52.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:45:52.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:52.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:45:52.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:45:52.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:45:52.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:46:23.383+0000] {processor.py:157} INFO - Started process (PID=12613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:46:23.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:46:23.386+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:23.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:46:23.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:46:23.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:23.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:46:23.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:23.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:46:23.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:46:53.917+0000] {processor.py:157} INFO - Started process (PID=12633) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:46:53.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:46:53.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:53.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:46:53.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:46:53.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:53.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:46:53.954+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:46:53.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:46:53.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:47:24.391+0000] {processor.py:157} INFO - Started process (PID=12653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:47:24.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:47:24.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:24.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:47:24.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:47:24.415+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:24.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:47:24.425+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:24.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:47:24.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T16:47:54.853+0000] {processor.py:157} INFO - Started process (PID=12673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:47:54.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:47:54.856+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:54.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:47:54.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:47:54.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:54.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:47:54.890+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:47:54.890+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:47:54.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:48:25.371+0000] {processor.py:157} INFO - Started process (PID=12693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:48:25.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:48:25.373+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:25.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:48:25.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:48:25.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:25.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:48:25.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:25.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:48:25.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:48:55.864+0000] {processor.py:157} INFO - Started process (PID=12713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:48:55.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:48:55.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:55.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:48:55.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:48:55.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:55.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:48:55.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:48:55.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:48:55.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:49:26.399+0000] {processor.py:157} INFO - Started process (PID=12733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:49:26.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:49:26.401+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:26.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:49:26.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:49:26.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:26.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:49:26.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:26.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:49:26.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T16:49:56.906+0000] {processor.py:157} INFO - Started process (PID=12753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:49:56.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:49:56.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:56.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:49:56.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:49:56.933+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:56.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:49:56.943+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:49:56.943+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:49:56.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:50:27.400+0000] {processor.py:157} INFO - Started process (PID=12773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:50:27.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:50:27.404+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:27.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:50:27.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:50:27.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:27.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:50:27.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:27.438+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:50:27.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:50:57.901+0000] {processor.py:157} INFO - Started process (PID=12793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:50:57.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:50:57.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:57.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:50:57.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:50:57.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:57.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:50:57.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:50:57.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:50:57.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:51:28.410+0000] {processor.py:157} INFO - Started process (PID=12813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:51:28.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:51:28.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:28.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:51:28.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:51:28.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:28.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:51:28.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:28.448+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:51:28.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:51:58.892+0000] {processor.py:157} INFO - Started process (PID=12833) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:51:58.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:51:58.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:58.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:51:58.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:51:58.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:58.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:51:58.925+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:51:58.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:51:58.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T16:52:29.423+0000] {processor.py:157} INFO - Started process (PID=12853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:52:29.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:52:29.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:29.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:52:29.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:52:29.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:29.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:52:29.465+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:29.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:52:29.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T16:52:59.960+0000] {processor.py:157} INFO - Started process (PID=12873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:52:59.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:52:59.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:59.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:52:59.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:52:59.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:59.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:52:59.998+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:52:59.998+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:53:00.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T16:53:30.443+0000] {processor.py:157} INFO - Started process (PID=12893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:53:30.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:53:30.447+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:53:30.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:53:30.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:53:30.480+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:53:30.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:53:30.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:53:30.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:53:30.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T16:54:00.977+0000] {processor.py:157} INFO - Started process (PID=12913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:54:00.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:54:00.980+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:00.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:54:00.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:54:01.006+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:01.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:54:01.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:01.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:54:01.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T16:54:31.490+0000] {processor.py:157} INFO - Started process (PID=12933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:54:31.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:54:31.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:31.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:54:31.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:54:31.517+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:31.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:54:31.526+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:54:31.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:54:31.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:55:01.995+0000] {processor.py:157} INFO - Started process (PID=12953) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:55:01.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:55:01.998+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:01.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:55:02.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:55:02.020+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:02.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:55:02.029+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:02.029+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:55:02.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T16:55:32.466+0000] {processor.py:157} INFO - Started process (PID=12973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:55:32.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:55:32.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:32.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:55:32.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:55:32.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:32.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:55:32.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:55:32.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:55:32.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:56:02.992+0000] {processor.py:157} INFO - Started process (PID=12993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:56:02.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:56:02.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:02.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:56:03.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:56:03.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:03.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:56:03.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:03.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:56:03.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T16:56:33.392+0000] {processor.py:157} INFO - Started process (PID=13013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:56:33.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:56:33.395+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:33.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:56:33.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:56:33.420+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:33.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:56:33.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:56:33.430+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:56:33.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:57:03.822+0000] {processor.py:157} INFO - Started process (PID=13033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:57:03.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:57:03.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:03.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:57:03.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:57:03.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:03.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:57:03.860+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:03.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:57:03.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T16:57:34.206+0000] {processor.py:157} INFO - Started process (PID=13053) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:57:34.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:57:34.208+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:34.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:57:34.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:57:34.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:34.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:57:34.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:57:34.242+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:57:34.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T16:58:04.725+0000] {processor.py:157} INFO - Started process (PID=13073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:58:04.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:58:04.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:04.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:58:04.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:58:04.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:04.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:58:04.762+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:04.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:58:04.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T16:58:35.205+0000] {processor.py:157} INFO - Started process (PID=13093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:58:35.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:58:35.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:35.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:58:35.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:58:35.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:35.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:58:35.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:58:35.237+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:58:35.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T16:59:05.704+0000] {processor.py:157} INFO - Started process (PID=13113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:59:05.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:59:05.707+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:05.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:59:05.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:59:05.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:05.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:59:05.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:05.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:59:05.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T16:59:36.212+0000] {processor.py:157} INFO - Started process (PID=13133) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:59:36.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T16:59:36.215+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:36.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:59:36.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T16:59:36.240+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:36.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T16:59:36.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T16:59:36.249+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T16:59:36.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:00:06.764+0000] {processor.py:157} INFO - Started process (PID=13153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:00:06.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:00:06.768+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:06.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:00:06.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:00:06.792+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:06.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:00:06.802+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:06.802+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:00:06.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:00:37.282+0000] {processor.py:157} INFO - Started process (PID=13173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:00:37.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:00:37.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:37.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:00:37.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:00:37.309+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:37.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:00:37.318+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:00:37.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:00:37.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:01:07.850+0000] {processor.py:157} INFO - Started process (PID=13193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:01:07.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:01:07.853+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:07.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:01:07.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:01:07.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:07.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:01:07.889+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:07.889+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:01:07.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T17:01:38.345+0000] {processor.py:157} INFO - Started process (PID=13213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:01:38.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:01:38.348+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:38.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:01:38.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:01:38.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:38.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:01:38.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:01:38.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:01:38.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:02:08.865+0000] {processor.py:157} INFO - Started process (PID=13233) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:02:08.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:02:08.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:08.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:02:08.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:02:08.894+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:08.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:02:08.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:08.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:02:08.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:02:39.359+0000] {processor.py:157} INFO - Started process (PID=13253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:02:39.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:02:39.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:39.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:02:39.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:02:39.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:39.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:02:39.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:02:39.397+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:02:39.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:03:09.832+0000] {processor.py:157} INFO - Started process (PID=13273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:03:09.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:03:09.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:09.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:03:09.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:03:09.858+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:09.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:03:09.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:09.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:03:09.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:03:40.279+0000] {processor.py:157} INFO - Started process (PID=13293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:03:40.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:03:40.282+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:40.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:03:40.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:03:40.308+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:40.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:03:40.317+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:03:40.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:03:40.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:04:10.748+0000] {processor.py:157} INFO - Started process (PID=13313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:04:10.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:04:10.751+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:10.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:04:10.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:04:10.779+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:10.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:04:10.790+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:10.790+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:04:10.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T17:04:41.264+0000] {processor.py:157} INFO - Started process (PID=13333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:04:41.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:04:41.267+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:41.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:04:41.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:04:41.291+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:41.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:04:41.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:04:41.301+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:04:41.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:05:11.780+0000] {processor.py:157} INFO - Started process (PID=13353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:05:11.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:05:11.783+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:11.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:05:11.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:05:11.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:11.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:05:11.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:11.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:05:11.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:05:42.204+0000] {processor.py:157} INFO - Started process (PID=13373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:05:42.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:05:42.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:42.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:05:42.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:05:42.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:42.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:05:42.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:05:42.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:05:42.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:06:12.634+0000] {processor.py:157} INFO - Started process (PID=13393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:06:12.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:06:12.636+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:12.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:06:12.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:06:12.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:12.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:06:12.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:12.670+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:06:12.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T17:06:43.068+0000] {processor.py:157} INFO - Started process (PID=13413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:06:43.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:06:43.071+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:43.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:06:43.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:06:43.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:43.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:06:43.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:06:43.105+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:06:43.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:07:13.476+0000] {processor.py:157} INFO - Started process (PID=13433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:07:13.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:07:13.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:13.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:07:13.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:07:13.503+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:13.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:07:13.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:13.513+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:07:13.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:07:43.918+0000] {processor.py:157} INFO - Started process (PID=13453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:07:43.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:07:43.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:43.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:07:43.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:07:43.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:43.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:07:43.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:07:43.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:07:43.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:08:14.391+0000] {processor.py:157} INFO - Started process (PID=13473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:08:14.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:08:14.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:14.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:08:14.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:08:14.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:14.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:08:14.429+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:14.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:08:14.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:08:44.836+0000] {processor.py:157} INFO - Started process (PID=13493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:08:44.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:08:44.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:44.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:08:44.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:08:44.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:44.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:08:44.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:08:44.874+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:08:44.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:09:15.258+0000] {processor.py:157} INFO - Started process (PID=13513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:09:15.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:09:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:15.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:09:15.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:09:15.288+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:15.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:09:15.298+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:15.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:09:15.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T17:09:45.733+0000] {processor.py:157} INFO - Started process (PID=13533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:09:45.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:09:45.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:45.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:09:45.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:09:45.772+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:45.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:09:45.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:09:45.785+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:09:45.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-10T17:10:16.271+0000] {processor.py:157} INFO - Started process (PID=13553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:10:16.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:10:16.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:16.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:10:16.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:10:16.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:16.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:10:16.309+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:16.309+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:10:16.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:10:46.819+0000] {processor.py:157} INFO - Started process (PID=13573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:10:46.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:10:46.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:46.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:10:46.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:10:46.846+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:46.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:10:46.855+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:10:46.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:10:46.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:11:17.396+0000] {processor.py:157} INFO - Started process (PID=13593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:11:17.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:11:17.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:17.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:11:17.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:11:17.424+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:17.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:11:17.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:17.433+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:11:17.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:11:47.850+0000] {processor.py:157} INFO - Started process (PID=13613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:11:47.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:11:47.851+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:47.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:11:47.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:11:47.874+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:47.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:11:47.883+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:11:47.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:11:47.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T17:12:18.336+0000] {processor.py:157} INFO - Started process (PID=13633) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:12:18.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:12:18.339+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:18.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:12:18.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:12:18.363+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:18.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:12:18.373+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:18.372+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:12:18.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:12:48.881+0000] {processor.py:157} INFO - Started process (PID=13653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:12:48.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:12:48.884+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:48.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:12:48.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:12:48.908+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:48.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:12:48.918+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:12:48.918+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:12:48.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:13:19.433+0000] {processor.py:157} INFO - Started process (PID=13673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:13:19.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:13:19.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:19.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:13:19.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:13:19.461+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:19.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:13:19.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:19.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:13:19.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:13:49.947+0000] {processor.py:157} INFO - Started process (PID=13693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:13:49.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:13:49.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:49.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:13:49.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:13:49.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:49.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:13:49.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:13:49.984+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:13:49.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:14:20.454+0000] {processor.py:157} INFO - Started process (PID=13713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:14:20.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:14:20.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:20.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:14:20.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:14:20.482+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:20.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:14:20.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:20.492+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:14:20.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:14:50.962+0000] {processor.py:157} INFO - Started process (PID=13733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:14:50.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:14:50.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:50.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:14:50.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:14:50.989+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:50.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:14:50.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:14:50.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:14:51.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:15:21.493+0000] {processor.py:157} INFO - Started process (PID=13753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:15:21.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:15:21.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:21.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:15:21.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:15:21.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:21.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:15:21.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:21.528+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:15:21.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T17:15:52.015+0000] {processor.py:157} INFO - Started process (PID=13773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:15:52.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:15:52.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:52.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:15:52.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:15:52.046+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:52.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:15:52.057+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:15:52.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:15:52.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T17:16:22.617+0000] {processor.py:157} INFO - Started process (PID=13793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:16:22.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:16:22.619+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:22.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:16:22.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:16:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:16:22.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:22.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:16:22.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:16:53.117+0000] {processor.py:157} INFO - Started process (PID=13813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:16:53.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:16:53.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:53.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:16:53.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:16:53.145+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:53.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:16:53.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:16:53.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:16:53.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:17:23.586+0000] {processor.py:157} INFO - Started process (PID=13833) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:17:23.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:17:23.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:23.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:17:23.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:17:23.612+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:23.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:17:23.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:23.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:17:23.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:17:54.092+0000] {processor.py:157} INFO - Started process (PID=13853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:17:54.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:17:54.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:54.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:17:54.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:17:54.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:54.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:17:54.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:17:54.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:17:54.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T17:18:24.640+0000] {processor.py:157} INFO - Started process (PID=13873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:18:24.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:18:24.643+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:24.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:18:24.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:18:24.667+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:24.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:18:24.677+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:24.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:18:24.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:18:55.187+0000] {processor.py:157} INFO - Started process (PID=13893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:18:55.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:18:55.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:55.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:18:55.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:18:55.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:55.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:18:55.224+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:18:55.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:18:55.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:19:25.700+0000] {processor.py:157} INFO - Started process (PID=13913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:19:25.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:19:25.703+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:25.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:19:25.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:19:25.727+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:25.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:19:25.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:25.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:19:25.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:19:56.223+0000] {processor.py:157} INFO - Started process (PID=13933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:19:56.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:19:56.226+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:56.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:19:56.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:19:56.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:56.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:19:56.260+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:19:56.260+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:19:56.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:20:26.741+0000] {processor.py:157} INFO - Started process (PID=13953) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:20:26.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:20:26.744+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:26.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:20:26.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:20:26.769+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:26.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:20:26.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:26.778+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:20:26.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:20:57.277+0000] {processor.py:157} INFO - Started process (PID=13973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:20:57.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:20:57.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:57.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:20:57.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:20:57.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:57.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:20:57.312+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:20:57.312+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:20:57.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:21:27.784+0000] {processor.py:157} INFO - Started process (PID=13993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:21:27.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:21:27.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:27.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:21:27.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:21:27.815+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:27.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:21:27.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:27.825+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:21:27.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T17:21:58.252+0000] {processor.py:157} INFO - Started process (PID=14013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:21:58.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:21:58.255+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:58.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:21:58.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:21:58.280+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:58.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:21:58.290+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:21:58.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:21:58.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:22:28.757+0000] {processor.py:157} INFO - Started process (PID=14033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:22:28.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:22:28.760+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:28.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:22:28.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:22:28.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:28.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:22:28.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:28.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:22:28.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:22:59.179+0000] {processor.py:157} INFO - Started process (PID=14053) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:22:59.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:22:59.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:59.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:22:59.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:22:59.201+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:59.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:22:59.209+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:22:59.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:22:59.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.038 seconds
[2024-07-10T17:23:29.627+0000] {processor.py:157} INFO - Started process (PID=14073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:23:29.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:23:29.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:23:29.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:23:29.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:23:29.654+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:23:29.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:23:29.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:23:29.663+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:23:29.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:24:00.102+0000] {processor.py:157} INFO - Started process (PID=14093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:24:00.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:24:00.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:00.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:24:00.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:24:00.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:00.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:24:00.139+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:00.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:24:00.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:24:30.536+0000] {processor.py:157} INFO - Started process (PID=14113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:24:30.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:24:30.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:30.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:24:30.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:24:30.570+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:30.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:24:30.581+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:24:30.581+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:24:30.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-10T17:25:01.021+0000] {processor.py:157} INFO - Started process (PID=14133) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:25:01.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:25:01.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:01.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:25:01.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:25:01.048+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:01.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:25:01.059+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:01.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:25:01.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:25:31.501+0000] {processor.py:157} INFO - Started process (PID=14153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:25:31.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:25:31.504+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:31.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:25:31.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:25:31.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:31.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:25:31.538+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:25:31.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:25:31.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:26:01.998+0000] {processor.py:157} INFO - Started process (PID=14173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:26:01.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:26:02.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:02.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:26:02.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:26:02.024+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:02.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:26:02.034+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:02.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:26:02.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:26:32.473+0000] {processor.py:157} INFO - Started process (PID=14193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:26:32.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:26:32.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:32.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:26:32.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:26:32.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:32.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:26:32.510+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:26:32.510+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:26:32.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:27:02.969+0000] {processor.py:157} INFO - Started process (PID=14213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:27:02.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:27:02.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:02.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:27:02.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:27:02.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:02.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:27:03.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:03.005+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:27:03.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:27:33.491+0000] {processor.py:157} INFO - Started process (PID=14233) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:27:33.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:27:33.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:33.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:27:33.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:27:33.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:33.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:27:33.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:27:33.529+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:27:33.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:28:03.988+0000] {processor.py:157} INFO - Started process (PID=14253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:28:03.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:28:03.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:03.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:28:04.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:28:04.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:04.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:28:04.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:04.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:28:04.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:28:34.471+0000] {processor.py:157} INFO - Started process (PID=14273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:28:34.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:28:34.474+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:34.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:28:34.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:28:34.499+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:34.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:28:34.508+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:28:34.508+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:28:34.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:29:04.997+0000] {processor.py:157} INFO - Started process (PID=14293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:29:04.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:29:05.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:05.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:29:05.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:29:05.025+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:05.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:29:05.035+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:05.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:29:05.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:29:35.521+0000] {processor.py:157} INFO - Started process (PID=14313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:29:35.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:29:35.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:35.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:29:35.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:29:35.547+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:35.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:29:35.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:29:35.557+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:29:35.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:30:06.039+0000] {processor.py:157} INFO - Started process (PID=14333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:30:06.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:30:06.042+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:06.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:30:06.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:30:06.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:06.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:30:06.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:06.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:30:06.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:30:36.537+0000] {processor.py:157} INFO - Started process (PID=14353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:30:36.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:30:36.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:36.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:30:36.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:30:36.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:36.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:30:36.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:30:36.576+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:30:36.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:31:07.055+0000] {processor.py:157} INFO - Started process (PID=14373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:31:07.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:31:07.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:07.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:31:07.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:31:07.084+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:07.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:31:07.093+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:07.093+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:31:07.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:31:37.570+0000] {processor.py:157} INFO - Started process (PID=14393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:31:37.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:31:37.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:37.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:31:37.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:31:37.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:37.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:31:37.608+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:31:37.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:31:37.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:32:08.072+0000] {processor.py:157} INFO - Started process (PID=14413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:32:08.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:32:08.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:08.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:32:08.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:32:08.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:08.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:32:08.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:08.113+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:32:08.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T17:32:38.584+0000] {processor.py:157} INFO - Started process (PID=14433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:32:38.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:32:38.587+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:38.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:32:38.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:32:38.613+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:38.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:32:38.622+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:32:38.622+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:32:38.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T17:33:09.093+0000] {processor.py:157} INFO - Started process (PID=14453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:33:09.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:33:09.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:09.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:33:09.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:33:09.120+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:09.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:33:09.130+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:09.130+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:33:09.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:33:39.612+0000] {processor.py:157} INFO - Started process (PID=14473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:33:39.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:33:39.615+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:39.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:33:39.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:33:39.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:39.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:33:39.650+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:33:39.649+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:33:39.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:34:10.089+0000] {processor.py:157} INFO - Started process (PID=14493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:34:10.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:34:10.092+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:10.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:34:10.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:34:10.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:10.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:34:10.128+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:10.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:34:10.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:34:40.598+0000] {processor.py:157} INFO - Started process (PID=14513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:34:40.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:34:40.602+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:40.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:34:40.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:34:40.626+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:40.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:34:40.636+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:34:40.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:34:40.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:35:11.035+0000] {processor.py:157} INFO - Started process (PID=14533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:35:11.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:35:11.038+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:11.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:35:11.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:35:11.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:11.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:35:11.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:11.072+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:35:11.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:35:41.486+0000] {processor.py:157} INFO - Started process (PID=14553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:35:41.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:35:41.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:41.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:35:41.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:35:41.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:41.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:35:41.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:35:41.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:35:41.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T17:36:12.005+0000] {processor.py:157} INFO - Started process (PID=14573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:36:12.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:36:12.008+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:12.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:36:12.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:36:12.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:12.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:36:12.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:12.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:36:12.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T17:36:42.459+0000] {processor.py:157} INFO - Started process (PID=14593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:36:42.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:36:42.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:42.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:36:42.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:36:42.486+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:42.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:36:42.496+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:36:42.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:36:42.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:37:12.984+0000] {processor.py:157} INFO - Started process (PID=14613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:37:12.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:37:12.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:12.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:37:12.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:37:13.013+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:13.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:37:13.023+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:13.023+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:37:13.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:37:43.473+0000] {processor.py:157} INFO - Started process (PID=14633) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:37:43.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:37:43.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:43.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:37:43.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:37:43.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:43.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:37:43.511+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:37:43.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:37:43.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:38:14.028+0000] {processor.py:157} INFO - Started process (PID=14653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:38:14.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:38:14.031+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:14.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:38:14.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:38:14.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:14.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:38:14.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:14.066+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:38:14.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:38:44.570+0000] {processor.py:157} INFO - Started process (PID=14673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:38:44.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:38:44.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:44.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:38:44.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:38:44.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:44.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:38:44.609+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:38:44.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:38:44.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:39:15.070+0000] {processor.py:157} INFO - Started process (PID=14693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:39:15.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:39:15.072+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:15.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:39:15.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:39:15.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:15.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:39:15.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:15.106+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:39:15.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T17:39:45.554+0000] {processor.py:157} INFO - Started process (PID=14713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:39:45.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:39:45.558+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:45.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:39:45.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:39:45.583+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:45.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:39:45.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:39:45.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:39:45.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:40:16.097+0000] {processor.py:157} INFO - Started process (PID=14733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:40:16.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:40:16.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:16.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:40:16.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:40:16.124+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:16.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:40:16.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:16.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:40:16.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:40:46.642+0000] {processor.py:157} INFO - Started process (PID=14753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:40:46.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:40:46.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:46.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:40:46.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:40:46.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:46.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:40:46.678+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:40:46.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:40:46.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T17:41:17.178+0000] {processor.py:157} INFO - Started process (PID=14773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:41:17.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:41:17.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:17.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:41:17.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:41:17.204+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:17.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:41:17.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:17.214+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:41:17.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T17:41:47.532+0000] {processor.py:157} INFO - Started process (PID=14793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:41:47.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:41:47.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:47.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:41:47.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:41:47.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:47.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:41:47.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:41:47.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:41:47.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T17:42:17.948+0000] {processor.py:157} INFO - Started process (PID=14813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:42:17.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:42:17.951+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:17.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:42:17.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:42:17.975+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:17.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:42:17.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:17.985+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:42:17.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:42:48.410+0000] {processor.py:157} INFO - Started process (PID=14833) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:42:48.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:42:48.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:48.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:42:48.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:42:48.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:48.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:42:48.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:42:48.448+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:42:48.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:43:18.940+0000] {processor.py:157} INFO - Started process (PID=14853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:43:18.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:43:18.943+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:18.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:43:18.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:43:18.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:18.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:43:18.978+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:18.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:43:18.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:43:49.436+0000] {processor.py:157} INFO - Started process (PID=14873) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:43:49.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:43:49.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:49.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:43:49.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:43:49.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:49.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:43:49.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:43:49.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:43:49.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-10T17:44:19.892+0000] {processor.py:157} INFO - Started process (PID=14893) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:44:19.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:44:19.895+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:19.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:44:19.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:44:19.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:19.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:44:19.929+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:19.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:44:19.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:44:50.417+0000] {processor.py:157} INFO - Started process (PID=14913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:44:50.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:44:50.421+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:50.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:44:50.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:44:50.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:50.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:44:50.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:44:50.462+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:44:50.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T17:45:20.915+0000] {processor.py:157} INFO - Started process (PID=14933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:45:20.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:45:20.919+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:20.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:45:20.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:45:20.943+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:20.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:45:20.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:20.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:45:20.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:45:51.454+0000] {processor.py:157} INFO - Started process (PID=14953) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:45:51.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:45:51.458+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:51.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:45:51.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:45:51.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:51.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:45:51.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:45:51.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:45:51.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T17:46:21.939+0000] {processor.py:157} INFO - Started process (PID=14973) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:46:21.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:46:21.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:21.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:46:21.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:46:21.967+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:21.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:46:21.976+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:21.976+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:46:21.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:46:52.470+0000] {processor.py:157} INFO - Started process (PID=14993) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:46:52.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:46:52.473+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:52.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:46:52.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:46:52.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:52.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:46:52.507+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:46:52.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:46:52.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:47:22.922+0000] {processor.py:157} INFO - Started process (PID=15013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:47:22.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:47:22.925+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:22.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:47:22.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:47:22.949+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:22.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:47:22.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:22.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:47:22.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T17:47:53.468+0000] {processor.py:157} INFO - Started process (PID=15033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:47:53.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:47:53.471+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:53.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:47:53.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:47:53.497+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:53.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:47:53.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:47:53.506+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:47:53.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:48:23.966+0000] {processor.py:157} INFO - Started process (PID=15053) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:48:23.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:48:23.969+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:23.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:48:23.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:48:23.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:23.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:48:24.007+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:24.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:48:24.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T17:48:54.487+0000] {processor.py:157} INFO - Started process (PID=15073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:48:54.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:48:54.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:54.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:48:54.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:48:54.514+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:54.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:48:54.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:48:54.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:48:54.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:49:24.964+0000] {processor.py:157} INFO - Started process (PID=15093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:49:24.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:49:24.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:24.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:49:24.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:49:24.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:24.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:49:25.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:25.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:49:25.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:49:55.498+0000] {processor.py:157} INFO - Started process (PID=15113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:49:55.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:49:55.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:55.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:49:55.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:49:55.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:55.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:49:55.539+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:49:55.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:49:55.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T17:50:25.989+0000] {processor.py:157} INFO - Started process (PID=15133) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:50:25.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:50:25.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:25.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:50:26.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:50:26.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:26.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:50:26.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:26.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:50:26.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:50:56.467+0000] {processor.py:157} INFO - Started process (PID=15153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:50:56.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:50:56.470+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:56.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:50:56.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:50:56.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:56.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:50:56.502+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:50:56.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:50:56.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:51:26.958+0000] {processor.py:157} INFO - Started process (PID=15173) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:51:26.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:51:26.961+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:26.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:51:26.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:51:26.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:26.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:51:26.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:26.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:51:27.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:51:57.487+0000] {processor.py:157} INFO - Started process (PID=15193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:51:57.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:51:57.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:57.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:51:57.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:51:57.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:57.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:51:57.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:51:57.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:51:57.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T17:52:27.922+0000] {processor.py:157} INFO - Started process (PID=15213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:52:27.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:52:27.924+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:27.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:52:27.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:52:27.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:27.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:52:27.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:27.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:52:27.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T17:52:58.411+0000] {processor.py:157} INFO - Started process (PID=15233) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:52:58.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:52:58.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:58.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:52:58.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:52:58.442+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:58.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:52:58.452+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:52:58.452+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:52:58.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T17:53:28.945+0000] {processor.py:157} INFO - Started process (PID=15253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:53:28.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:53:28.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:28.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:53:28.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:53:28.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:28.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:53:28.983+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:28.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:53:28.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:53:59.457+0000] {processor.py:157} INFO - Started process (PID=15273) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:53:59.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:53:59.460+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:59.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:53:59.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:53:59.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:59.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:53:59.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:53:59.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:53:59.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:54:29.976+0000] {processor.py:157} INFO - Started process (PID=15293) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:54:29.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:54:29.980+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:54:29.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:54:29.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:54:30.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:54:30.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:54:30.015+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:54:30.015+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:54:30.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:55:00.410+0000] {processor.py:157} INFO - Started process (PID=15313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:55:00.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:55:00.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:00.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:55:00.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:55:00.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:00.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:55:00.445+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:00.445+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:55:00.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:55:30.884+0000] {processor.py:157} INFO - Started process (PID=15333) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:55:30.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:55:30.889+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:30.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:55:30.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:55:30.920+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:30.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:55:30.931+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:55:30.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:55:30.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T17:56:01.420+0000] {processor.py:157} INFO - Started process (PID=15353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:56:01.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:56:01.423+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:01.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:56:01.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:56:01.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:01.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:56:01.458+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:01.458+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:56:01.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T17:56:31.934+0000] {processor.py:157} INFO - Started process (PID=15373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:56:31.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:56:31.937+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:31.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:56:31.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:56:31.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:31.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:56:31.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:56:31.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:56:31.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T17:57:02.353+0000] {processor.py:157} INFO - Started process (PID=15393) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:57:02.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:57:02.356+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:02.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:57:02.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:57:02.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:02.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:57:02.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:02.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:57:02.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T17:57:32.914+0000] {processor.py:157} INFO - Started process (PID=15413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:57:32.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:57:32.916+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:32.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:57:32.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:57:32.941+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:32.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:57:32.950+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:57:32.950+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:57:32.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T17:58:03.411+0000] {processor.py:157} INFO - Started process (PID=15433) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:58:03.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:58:03.414+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:03.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:58:03.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:58:03.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:03.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:58:03.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:03.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:58:03.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:58:33.919+0000] {processor.py:157} INFO - Started process (PID=15453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:58:33.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:58:33.922+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:33.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:58:33.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:58:33.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:33.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:58:33.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:58:33.956+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:58:33.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T17:59:04.433+0000] {processor.py:157} INFO - Started process (PID=15473) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:59:04.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:59:04.436+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:04.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:59:04.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:59:04.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:04.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:59:04.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:04.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:59:04.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T17:59:34.963+0000] {processor.py:157} INFO - Started process (PID=15493) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:59:34.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T17:59:34.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:34.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:59:34.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T17:59:34.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:34.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T17:59:35.001+0000] {logging_mixin.py:151} INFO - [2024-07-10T17:59:35.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T17:59:35.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T18:00:05.490+0000] {processor.py:157} INFO - Started process (PID=15513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:00:05.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:00:05.493+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:05.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:00:05.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:00:05.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:05.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:00:05.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:05.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:00:05.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T18:00:36.001+0000] {processor.py:157} INFO - Started process (PID=15533) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:00:36.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:00:36.004+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:36.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:00:36.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:00:36.030+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:36.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:00:36.039+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:00:36.039+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:00:36.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T18:01:06.504+0000] {processor.py:157} INFO - Started process (PID=15553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:01:06.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:01:06.507+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:06.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:01:06.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:01:06.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:06.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:01:06.543+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:06.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:01:06.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T18:01:37.040+0000] {processor.py:157} INFO - Started process (PID=15573) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:01:37.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:01:37.043+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:37.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:01:37.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:01:37.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:37.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:01:37.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:01:37.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:01:37.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T18:02:07.514+0000] {processor.py:157} INFO - Started process (PID=15593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:02:07.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:02:07.517+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:07.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:02:07.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:02:07.541+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:07.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:02:07.552+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:07.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:02:07.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T18:02:38.062+0000] {processor.py:157} INFO - Started process (PID=15613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:02:38.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:02:38.065+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:38.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:02:38.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:02:38.090+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:38.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:02:38.100+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:02:38.100+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:02:38.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T18:03:08.550+0000] {processor.py:157} INFO - Started process (PID=15633) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:03:08.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:03:08.552+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:08.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:03:08.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:03:08.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:08.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:03:08.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:08.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:03:08.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T18:03:39.048+0000] {processor.py:157} INFO - Started process (PID=15653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:03:39.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:03:39.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:39.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:03:39.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:03:39.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:39.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:03:39.085+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:03:39.085+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:03:39.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T18:04:09.554+0000] {processor.py:157} INFO - Started process (PID=15673) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:04:09.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:04:09.557+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:09.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:04:09.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:04:09.580+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:09.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:04:09.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:09.590+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:04:09.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T18:04:40.070+0000] {processor.py:157} INFO - Started process (PID=15693) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:04:40.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:04:40.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:40.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:04:40.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:04:40.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:40.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:04:40.114+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:04:40.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:04:40.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T18:05:10.516+0000] {processor.py:157} INFO - Started process (PID=15713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:05:10.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:05:10.519+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:10.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:05:10.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:05:10.546+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:10.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:05:10.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:10.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:05:10.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T18:05:40.929+0000] {processor.py:157} INFO - Started process (PID=15733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:05:40.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:05:40.932+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:40.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:05:40.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:05:40.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:40.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:05:40.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:05:40.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:05:40.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T18:06:11.445+0000] {processor.py:157} INFO - Started process (PID=15753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:06:11.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:06:11.448+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:11.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:06:11.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:06:11.472+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:11.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:06:11.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:11.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:06:11.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T18:06:41.886+0000] {processor.py:157} INFO - Started process (PID=15773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:06:41.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:06:41.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:41.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:06:41.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:06:41.912+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:41.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:06:41.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:06:41.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:06:41.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T18:07:12.354+0000] {processor.py:157} INFO - Started process (PID=15793) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:07:12.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:07:12.358+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:12.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:07:12.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:07:12.382+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:12.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:07:12.391+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:12.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:07:12.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T18:07:42.765+0000] {processor.py:157} INFO - Started process (PID=15813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:07:42.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:07:42.768+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:42.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:07:42.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:07:42.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:42.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:07:42.807+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:07:42.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:07:42.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T18:23:53.891+0000] {processor.py:157} INFO - Started process (PID=15835) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:23:53.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:23:53.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:23:53.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:23:53.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:23:53.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:23:53.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:23:54.020+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:23:54.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:23:54.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.162 seconds
[2024-07-10T18:24:24.541+0000] {processor.py:157} INFO - Started process (PID=15855) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:24:24.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:24:24.545+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:24.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:24:24.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:24:24.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:24.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:24:24.588+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:24.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:24:24.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-10T18:24:54.989+0000] {processor.py:157} INFO - Started process (PID=15875) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:24:54.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:24:54.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:54.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:24:55.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:24:55.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:55.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:24:55.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:24:55.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:24:55.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T18:25:25.406+0000] {processor.py:157} INFO - Started process (PID=15895) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:25:25.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:25:25.410+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:25.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:25:25.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:25:25.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:25.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:25:25.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:25.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:25:25.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T18:25:55.870+0000] {processor.py:157} INFO - Started process (PID=15915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:25:55.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:25:55.875+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:55.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:25:55.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:25:55.900+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:55.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:25:55.909+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:25:55.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:25:55.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T18:26:26.345+0000] {processor.py:157} INFO - Started process (PID=15935) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:26:26.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:26:26.348+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:26.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:26:26.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:26:26.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:26.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:26:26.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:26.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:26:26.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T18:26:56.844+0000] {processor.py:157} INFO - Started process (PID=15955) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:26:56.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:26:56.848+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:56.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:26:56.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:26:56.872+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:56.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:26:56.882+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:26:56.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:26:56.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T18:27:27.303+0000] {processor.py:157} INFO - Started process (PID=15975) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:27:27.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:27:27.306+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:27:27.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:27:27.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:27:27.331+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:27:27.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:27:27.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:27:27.340+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:27:27.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T18:43:31.849+0000] {processor.py:157} INFO - Started process (PID=15995) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:43:31.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:43:31.853+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:43:31.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:43:31.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:43:31.887+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:43:31.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:43:31.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:43:31.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:43:31.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-10T18:59:22.301+0000] {processor.py:157} INFO - Started process (PID=16015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:59:22.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:59:22.304+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:22.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:59:22.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:59:22.337+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:22.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:59:22.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:22.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:59:22.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-10T18:59:52.858+0000] {processor.py:157} INFO - Started process (PID=16035) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:59:52.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T18:59:52.861+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:52.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:59:52.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T18:59:52.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:52.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T18:59:52.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T18:59:52.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T18:59:52.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T19:00:23.390+0000] {processor.py:157} INFO - Started process (PID=16055) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:00:23.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:00:23.393+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:23.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:00:23.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:00:23.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:23.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:00:23.432+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:23.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:00:23.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T19:00:53.919+0000] {processor.py:157} INFO - Started process (PID=16075) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:00:53.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:00:53.922+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:53.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:00:53.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:00:53.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:53.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:00:53.958+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:00:53.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:00:53.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:01:24.436+0000] {processor.py:157} INFO - Started process (PID=16095) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:01:24.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:01:24.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:24.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:01:24.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:01:24.466+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:24.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:01:24.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:24.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:01:24.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:01:54.983+0000] {processor.py:157} INFO - Started process (PID=16115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:01:54.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:01:54.986+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:54.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:01:54.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:01:55.010+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:55.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:01:55.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:01:55.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:01:55.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:02:25.504+0000] {processor.py:157} INFO - Started process (PID=16135) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:02:25.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:02:25.507+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:25.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:02:25.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:02:25.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:25.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:02:25.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:25.540+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:02:25.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T19:02:56.000+0000] {processor.py:157} INFO - Started process (PID=16155) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:02:56.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:02:56.005+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:56.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:02:56.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:02:56.037+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:56.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:02:56.049+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:02:56.049+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:02:56.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T19:03:26.556+0000] {processor.py:157} INFO - Started process (PID=16175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:03:26.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:03:26.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:26.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:03:26.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:03:26.586+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:26.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:03:26.596+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:26.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:03:26.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:03:57.139+0000] {processor.py:157} INFO - Started process (PID=16195) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:03:57.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:03:57.143+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:57.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:03:57.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:03:57.167+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:57.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:03:57.177+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:03:57.177+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:03:57.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:04:27.610+0000] {processor.py:157} INFO - Started process (PID=16215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:04:27.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:04:27.613+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:27.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:04:27.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:04:27.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:27.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:04:27.647+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:27.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:04:27.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:04:58.030+0000] {processor.py:157} INFO - Started process (PID=16235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:04:58.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:04:58.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:58.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:04:58.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:04:58.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:58.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:04:58.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:04:58.067+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:04:58.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:05:28.502+0000] {processor.py:157} INFO - Started process (PID=16255) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:05:28.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:05:28.505+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:28.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:05:28.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:05:28.531+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:28.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:05:28.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:28.540+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:05:28.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:05:58.882+0000] {processor.py:157} INFO - Started process (PID=16275) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:05:58.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:05:58.886+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:58.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:05:58.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:05:58.911+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:58.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:05:58.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:05:58.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:05:58.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:06:29.300+0000] {processor.py:157} INFO - Started process (PID=16295) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:06:29.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:06:29.302+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:29.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:06:29.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:06:29.325+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:29.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:06:29.335+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:29.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:06:29.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T19:06:59.746+0000] {processor.py:157} INFO - Started process (PID=16315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:06:59.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:06:59.749+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:59.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:06:59.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:06:59.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:59.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:06:59.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:06:59.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:06:59.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:07:30.210+0000] {processor.py:157} INFO - Started process (PID=16335) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:07:30.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:07:30.213+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:07:30.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:07:30.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:07:30.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:07:30.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:07:30.247+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:07:30.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:07:30.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:08:00.709+0000] {processor.py:157} INFO - Started process (PID=16355) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:08:00.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:08:00.713+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:00.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:08:00.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:08:00.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:00.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:08:00.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:00.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:08:00.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:08:31.169+0000] {processor.py:157} INFO - Started process (PID=16375) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:08:31.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:08:31.172+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:31.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:08:31.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:08:31.196+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:31.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:08:31.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:08:31.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:08:31.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:09:01.708+0000] {processor.py:157} INFO - Started process (PID=16395) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:09:01.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:09:01.712+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:01.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:09:01.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:09:01.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:01.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:09:01.746+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:01.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:09:01.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:09:32.166+0000] {processor.py:157} INFO - Started process (PID=16415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:09:32.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:09:32.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:32.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:09:32.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:09:32.195+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:32.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:09:32.205+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:09:32.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:09:32.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:10:02.656+0000] {processor.py:157} INFO - Started process (PID=16435) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:10:02.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:10:02.659+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:02.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:10:02.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:10:02.684+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:02.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:10:02.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:02.693+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:10:02.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:10:33.194+0000] {processor.py:157} INFO - Started process (PID=16455) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:10:33.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:10:33.197+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:33.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:10:33.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:10:33.222+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:33.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:10:33.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:10:33.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:10:33.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:11:03.699+0000] {processor.py:157} INFO - Started process (PID=16475) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:11:03.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:11:03.702+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:03.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:11:03.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:11:03.726+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:03.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:11:03.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:03.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:11:03.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:11:34.161+0000] {processor.py:157} INFO - Started process (PID=16495) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:11:34.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:11:34.166+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:34.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:11:34.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:11:34.200+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:34.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:11:34.211+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:11:34.211+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:11:34.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T19:12:04.716+0000] {processor.py:157} INFO - Started process (PID=16515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:12:04.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:12:04.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:04.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:12:04.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:12:04.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:04.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:12:04.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:04.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:12:04.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:12:35.162+0000] {processor.py:157} INFO - Started process (PID=16535) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:12:35.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:12:35.165+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:35.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:12:35.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:12:35.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:35.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:12:35.199+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:12:35.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:12:35.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:13:05.644+0000] {processor.py:157} INFO - Started process (PID=16555) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:13:05.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:13:05.648+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:05.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:13:05.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:13:05.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:05.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:13:05.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:05.685+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:13:05.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:13:36.060+0000] {processor.py:157} INFO - Started process (PID=16575) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:13:36.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:13:36.063+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:36.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:13:36.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:13:36.089+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:36.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:13:36.099+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:13:36.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:13:36.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:14:06.487+0000] {processor.py:157} INFO - Started process (PID=16595) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:14:06.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:14:06.489+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:06.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:14:06.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:14:06.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:06.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:14:06.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:06.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:14:06.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:14:36.992+0000] {processor.py:157} INFO - Started process (PID=16615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:14:36.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:14:36.995+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:36.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:14:37.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:14:37.019+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:37.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:14:37.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:14:37.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:14:37.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:15:07.424+0000] {processor.py:157} INFO - Started process (PID=16635) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:15:07.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:15:07.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:07.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:15:07.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:15:07.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:07.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:15:07.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:07.461+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:15:07.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:15:37.935+0000] {processor.py:157} INFO - Started process (PID=16655) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:15:37.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:15:37.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:37.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:15:37.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:15:37.963+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:37.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:15:37.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:15:37.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:15:37.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:16:08.415+0000] {processor.py:157} INFO - Started process (PID=16675) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:16:08.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:16:08.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:08.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:16:08.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:16:08.444+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:08.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:16:08.455+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:08.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:16:08.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:16:38.939+0000] {processor.py:157} INFO - Started process (PID=16695) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:16:38.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:16:38.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:38.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:16:38.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:16:38.978+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:38.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:16:38.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:16:38.989+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:16:38.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T19:17:09.420+0000] {processor.py:157} INFO - Started process (PID=16715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:17:09.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:17:09.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:09.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:17:09.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:17:09.444+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:09.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:17:09.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:09.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:17:09.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T19:17:39.905+0000] {processor.py:157} INFO - Started process (PID=16735) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:17:39.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:17:39.908+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:39.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:17:39.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:17:39.932+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:39.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:17:39.942+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:17:39.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:17:39.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:18:10.416+0000] {processor.py:157} INFO - Started process (PID=16755) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:18:10.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:18:10.418+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:10.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:18:10.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:18:10.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:10.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:18:10.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:10.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:18:10.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:18:40.933+0000] {processor.py:157} INFO - Started process (PID=16775) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:18:40.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:18:40.936+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:40.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:18:40.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:18:40.961+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:40.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:18:40.971+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:18:40.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:18:40.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:19:11.437+0000] {processor.py:157} INFO - Started process (PID=16795) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:19:11.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:19:11.439+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:11.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:19:11.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:19:11.463+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:11.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:19:11.473+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:11.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:19:11.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:19:41.972+0000] {processor.py:157} INFO - Started process (PID=16815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:19:41.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:19:41.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:41.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:19:41.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:19:42.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:42.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:19:42.009+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:19:42.009+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:19:42.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:20:12.446+0000] {processor.py:157} INFO - Started process (PID=16835) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:20:12.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:20:12.450+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:12.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:20:12.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:20:12.472+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:12.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:20:12.481+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:12.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:20:12.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T19:20:42.962+0000] {processor.py:157} INFO - Started process (PID=16855) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:20:42.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:20:42.965+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:42.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:20:42.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:20:42.990+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:42.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:20:43.000+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:20:43.000+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:20:43.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:21:13.445+0000] {processor.py:157} INFO - Started process (PID=16875) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:21:13.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:21:13.449+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:13.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:21:13.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:21:13.474+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:13.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:21:13.484+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:13.484+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:21:13.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:21:43.987+0000] {processor.py:157} INFO - Started process (PID=16895) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:21:43.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:21:43.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:43.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:21:44.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:21:44.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:44.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:21:44.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:21:44.027+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:21:44.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:22:14.498+0000] {processor.py:157} INFO - Started process (PID=16915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:22:14.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:22:14.501+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:14.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:22:14.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:22:14.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:14.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:22:14.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:14.533+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:22:14.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T19:22:44.995+0000] {processor.py:157} INFO - Started process (PID=16935) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:22:44.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:22:44.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:44.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:22:45.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:22:45.023+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:45.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:22:45.033+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:22:45.032+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:22:45.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:23:15.528+0000] {processor.py:157} INFO - Started process (PID=16955) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:23:15.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:23:15.532+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:15.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:23:15.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:23:15.556+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:15.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:23:15.566+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:15.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:23:15.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:23:46.081+0000] {processor.py:157} INFO - Started process (PID=16975) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:23:46.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:23:46.083+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:46.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:23:46.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:23:46.106+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:46.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:23:46.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:23:46.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:23:46.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T19:24:16.594+0000] {processor.py:157} INFO - Started process (PID=16995) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:24:16.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:24:16.597+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:16.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:24:16.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:24:16.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:16.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:24:16.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:16.633+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:24:16.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:24:47.130+0000] {processor.py:157} INFO - Started process (PID=17015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:24:47.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:24:47.133+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:47.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:24:47.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:24:47.158+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:47.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:24:47.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:24:47.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:24:47.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:25:17.641+0000] {processor.py:157} INFO - Started process (PID=17035) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:25:17.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:25:17.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:17.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:25:17.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:25:17.671+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:17.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:25:17.680+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:17.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:25:17.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:25:48.157+0000] {processor.py:157} INFO - Started process (PID=17055) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:25:48.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:25:48.161+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:48.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:25:48.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:25:48.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:48.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:25:48.198+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:25:48.198+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:25:48.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T19:26:18.701+0000] {processor.py:157} INFO - Started process (PID=17075) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:26:18.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:26:18.704+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:18.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:26:18.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:26:18.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:18.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:26:18.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:18.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:26:18.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:26:49.264+0000] {processor.py:157} INFO - Started process (PID=17095) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:26:49.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:26:49.268+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:49.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:26:49.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:26:49.294+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:49.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:26:49.304+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:26:49.304+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:26:49.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:27:19.800+0000] {processor.py:157} INFO - Started process (PID=17115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:27:19.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:27:19.804+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:19.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:27:19.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:27:19.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:19.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:27:19.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:19.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:27:19.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:27:50.315+0000] {processor.py:157} INFO - Started process (PID=17135) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:27:50.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:27:50.319+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:50.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:27:50.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:27:50.342+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:50.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:27:50.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:27:50.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:27:50.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:28:20.750+0000] {processor.py:157} INFO - Started process (PID=17155) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:28:20.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:28:20.753+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:20.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:28:20.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:28:20.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:20.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:28:20.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:20.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:28:20.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:28:51.217+0000] {processor.py:157} INFO - Started process (PID=17175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:28:51.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:28:51.220+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:51.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:28:51.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:28:51.244+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:51.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:28:51.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:28:51.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:28:51.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:29:21.771+0000] {processor.py:157} INFO - Started process (PID=17195) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:29:21.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:29:21.774+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:21.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:29:21.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:29:21.798+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:21.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:29:21.809+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:21.809+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:29:21.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:29:52.274+0000] {processor.py:157} INFO - Started process (PID=17215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:29:52.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:29:52.277+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:52.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:29:52.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:29:52.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:52.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:29:52.313+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:29:52.313+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:29:52.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:30:22.757+0000] {processor.py:157} INFO - Started process (PID=17235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:30:22.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:30:22.760+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:22.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:30:22.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:30:22.786+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:22.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:30:22.795+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:22.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:30:22.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:30:53.262+0000] {processor.py:157} INFO - Started process (PID=17255) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:30:53.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:30:53.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:53.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:30:53.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:30:53.292+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:53.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:30:53.301+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:30:53.301+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:30:53.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:31:23.774+0000] {processor.py:157} INFO - Started process (PID=17275) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:31:23.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:31:23.778+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:23.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:31:23.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:31:23.806+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:23.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:31:23.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:23.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:31:23.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T19:31:54.268+0000] {processor.py:157} INFO - Started process (PID=17295) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:31:54.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:31:54.270+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:54.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:31:54.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:31:54.290+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:54.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:31:54.298+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:31:54.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:31:54.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.039 seconds
[2024-07-10T19:32:24.785+0000] {processor.py:157} INFO - Started process (PID=17315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:32:24.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:32:24.788+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:24.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:32:24.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:32:24.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:24.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:32:24.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:24.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:32:24.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:32:55.209+0000] {processor.py:157} INFO - Started process (PID=17335) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:32:55.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:32:55.213+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:55.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:32:55.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:32:55.236+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:55.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:32:55.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:32:55.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:32:55.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:33:25.686+0000] {processor.py:157} INFO - Started process (PID=17355) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:33:25.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:33:25.689+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:25.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:33:25.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:33:25.714+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:25.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:33:25.724+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:25.724+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:33:25.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:33:56.179+0000] {processor.py:157} INFO - Started process (PID=17375) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:33:56.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:33:56.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:56.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:33:56.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:33:56.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:56.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:33:56.216+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:33:56.215+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:33:56.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:34:26.705+0000] {processor.py:157} INFO - Started process (PID=17395) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:34:26.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:34:26.708+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:26.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:34:26.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:34:26.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:26.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:34:26.742+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:26.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:34:26.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:34:57.182+0000] {processor.py:157} INFO - Started process (PID=17415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:34:57.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:34:57.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:57.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:34:57.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:34:57.207+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:57.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:34:57.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:34:57.217+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:34:57.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:35:27.658+0000] {processor.py:157} INFO - Started process (PID=17435) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:35:27.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:35:27.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:27.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:35:27.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:35:27.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:27.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:35:27.695+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:27.695+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:35:27.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:35:58.156+0000] {processor.py:157} INFO - Started process (PID=17455) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:35:58.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:35:58.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:58.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:35:58.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:35:58.184+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:58.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:35:58.194+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:35:58.194+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:35:58.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:36:28.694+0000] {processor.py:157} INFO - Started process (PID=17475) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:36:28.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:36:28.697+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:28.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:36:28.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:36:28.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:28.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:36:28.732+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:28.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:36:28.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:36:59.189+0000] {processor.py:157} INFO - Started process (PID=17495) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:36:59.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:36:59.191+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:59.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:36:59.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:36:59.214+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:59.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:36:59.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:36:59.223+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:36:59.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T19:37:29.617+0000] {processor.py:157} INFO - Started process (PID=17515) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:37:29.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:37:29.620+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:37:29.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:37:29.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:37:29.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:37:29.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:37:29.656+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:37:29.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:37:29.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:38:00.071+0000] {processor.py:157} INFO - Started process (PID=17535) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:38:00.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:38:00.074+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:00.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:38:00.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:38:00.098+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:00.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:38:00.109+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:00.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:38:00.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:38:30.553+0000] {processor.py:157} INFO - Started process (PID=17555) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:38:30.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:38:30.555+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:30.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:38:30.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:38:30.578+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:30.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:38:30.587+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:38:30.587+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:38:30.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:39:00.956+0000] {processor.py:157} INFO - Started process (PID=17575) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:39:00.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:39:00.960+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:00.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:39:00.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:39:00.987+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:00.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:39:00.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:00.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:39:01.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:39:31.492+0000] {processor.py:157} INFO - Started process (PID=17595) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:39:31.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:39:31.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:31.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:39:31.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:39:31.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:31.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:39:31.529+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:39:31.529+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:39:31.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:40:01.964+0000] {processor.py:157} INFO - Started process (PID=17615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:40:01.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:40:01.968+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:01.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:40:01.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:40:01.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:01.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:40:02.002+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:02.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:40:02.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:40:32.430+0000] {processor.py:157} INFO - Started process (PID=17635) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:40:32.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:40:32.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:32.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:40:32.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:40:32.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:32.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:40:32.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:40:32.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:40:32.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:41:02.907+0000] {processor.py:157} INFO - Started process (PID=17655) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:41:02.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:41:02.910+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:02.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:41:02.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:41:02.935+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:02.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:41:02.945+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:02.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:41:02.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:41:33.368+0000] {processor.py:157} INFO - Started process (PID=17675) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:41:33.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:41:33.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:33.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:41:33.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:41:33.394+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:33.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:41:33.403+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:41:33.403+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:41:33.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:42:03.760+0000] {processor.py:157} INFO - Started process (PID=17695) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:42:03.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:42:03.763+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:03.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:42:03.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:42:03.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:03.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:42:03.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:03.796+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:42:03.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:42:34.239+0000] {processor.py:157} INFO - Started process (PID=17715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:42:34.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:42:34.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:34.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:42:34.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:42:34.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:34.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:42:34.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:42:34.275+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:42:34.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:43:04.659+0000] {processor.py:157} INFO - Started process (PID=17735) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:43:04.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:43:04.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:04.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:43:04.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:43:04.683+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:04.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:43:04.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:04.693+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:43:04.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T19:43:35.093+0000] {processor.py:157} INFO - Started process (PID=17755) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:43:35.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:43:35.095+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:35.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:43:35.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:43:35.119+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:35.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:43:35.129+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:43:35.129+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:43:35.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:44:05.587+0000] {processor.py:157} INFO - Started process (PID=17775) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:44:05.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:44:05.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:05.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:44:05.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:44:05.616+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:05.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:44:05.629+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:05.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:44:05.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T19:44:36.075+0000] {processor.py:157} INFO - Started process (PID=17795) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:44:36.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:44:36.078+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:36.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:44:36.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:44:36.103+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:36.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:44:36.112+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:44:36.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:44:36.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:45:06.525+0000] {processor.py:157} INFO - Started process (PID=17815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:45:06.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:45:06.527+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:06.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:45:06.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:45:06.551+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:06.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:45:06.560+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:06.560+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:45:06.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:45:36.957+0000] {processor.py:157} INFO - Started process (PID=17835) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:45:36.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:45:36.961+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:36.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:45:36.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:45:36.988+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:36.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:45:36.997+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:45:36.997+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:45:37.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:46:07.474+0000] {processor.py:157} INFO - Started process (PID=17855) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:46:07.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:46:07.478+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:07.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:46:07.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:46:07.504+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:07.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:46:07.513+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:07.513+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:46:07.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:46:37.934+0000] {processor.py:157} INFO - Started process (PID=17875) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:46:37.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:46:37.938+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:37.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:46:37.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:46:37.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:37.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:46:37.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:46:37.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:46:37.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:47:08.413+0000] {processor.py:157} INFO - Started process (PID=17895) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:47:08.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:47:08.416+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:08.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:47:08.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:47:08.441+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:08.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:47:08.451+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:08.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:47:08.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:47:38.836+0000] {processor.py:157} INFO - Started process (PID=17915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:47:38.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:47:38.839+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:38.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:47:38.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:47:38.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:38.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:47:38.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:47:38.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:47:38.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:48:09.317+0000] {processor.py:157} INFO - Started process (PID=17935) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:48:09.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:48:09.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:09.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:48:09.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:48:09.345+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:09.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:48:09.355+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:09.355+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:48:09.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:48:39.793+0000] {processor.py:157} INFO - Started process (PID=17955) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:48:39.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:48:39.797+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:39.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:48:39.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:48:39.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:39.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:48:39.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:48:39.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:48:39.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:49:10.285+0000] {processor.py:157} INFO - Started process (PID=17975) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:49:10.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:49:10.288+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:10.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:49:10.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:49:10.312+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:10.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:49:10.322+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:10.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:49:10.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:49:40.813+0000] {processor.py:157} INFO - Started process (PID=17995) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:49:40.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:49:40.816+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:40.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:49:40.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:49:40.841+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:40.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:49:40.851+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:49:40.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:49:40.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:50:11.241+0000] {processor.py:157} INFO - Started process (PID=18015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:50:11.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:50:11.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:11.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:50:11.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:50:11.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:11.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:50:11.281+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:11.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:50:11.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T19:50:41.730+0000] {processor.py:157} INFO - Started process (PID=18035) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:50:41.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:50:41.733+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:41.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:50:41.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:50:41.756+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:41.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:50:41.765+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:50:41.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:50:41.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:51:12.200+0000] {processor.py:157} INFO - Started process (PID=18055) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:51:12.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:51:12.204+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:12.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:51:12.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:51:12.229+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:12.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:51:12.238+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:12.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:51:12.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:51:42.748+0000] {processor.py:157} INFO - Started process (PID=18075) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:51:42.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:51:42.752+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:42.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:51:42.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:51:42.785+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:42.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:51:42.794+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:51:42.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:51:42.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T19:52:13.219+0000] {processor.py:157} INFO - Started process (PID=18095) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:52:13.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:52:13.223+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:13.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:52:13.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:52:13.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:13.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:52:13.262+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:13.262+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:52:13.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T19:52:43.766+0000] {processor.py:157} INFO - Started process (PID=18115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:52:43.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:52:43.769+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:43.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:52:43.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:52:43.794+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:43.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:52:43.805+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:52:43.805+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:52:43.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T19:53:14.235+0000] {processor.py:157} INFO - Started process (PID=18135) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:53:14.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:53:14.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:14.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:53:14.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:53:14.259+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:14.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:53:14.269+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:14.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:53:14.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T19:53:44.747+0000] {processor.py:157} INFO - Started process (PID=18155) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:53:44.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:53:44.750+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:44.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:53:44.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:53:44.775+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:44.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:53:44.784+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:53:44.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:53:44.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:54:15.205+0000] {processor.py:157} INFO - Started process (PID=18175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:54:15.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:54:15.208+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:15.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:54:15.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:54:15.231+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:15.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:54:15.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:15.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:54:15.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T19:54:45.698+0000] {processor.py:157} INFO - Started process (PID=18195) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:54:45.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:54:45.701+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:45.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:54:45.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:54:45.726+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:45.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:54:45.736+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:54:45.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:54:45.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:55:16.187+0000] {processor.py:157} INFO - Started process (PID=18215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:55:16.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:55:16.190+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:16.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:55:16.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:55:16.215+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:16.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:55:16.225+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:16.225+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:55:16.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:55:46.637+0000] {processor.py:157} INFO - Started process (PID=18235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:55:46.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:55:46.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:46.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:55:46.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:55:46.663+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:46.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:55:46.673+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:55:46.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:55:46.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:56:17.142+0000] {processor.py:157} INFO - Started process (PID=18255) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:56:17.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:56:17.145+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:17.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:56:17.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:56:17.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:17.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:56:17.181+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:17.181+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:56:17.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:56:47.633+0000] {processor.py:157} INFO - Started process (PID=18275) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:56:47.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:56:47.636+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:47.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:56:47.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:56:47.661+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:47.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:56:47.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:56:47.670+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:56:47.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T19:57:18.147+0000] {processor.py:157} INFO - Started process (PID=18295) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:57:18.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:57:18.150+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:18.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:57:18.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:57:18.173+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:18.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:57:18.182+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:18.182+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:57:18.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:57:48.624+0000] {processor.py:157} INFO - Started process (PID=18315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:57:48.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:57:48.627+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:48.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:57:48.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:57:48.652+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:48.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:57:48.662+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:57:48.661+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:57:48.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:58:19.109+0000] {processor.py:157} INFO - Started process (PID=18335) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:58:19.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:58:19.112+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:19.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:58:19.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:58:19.136+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:19.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:58:19.146+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:19.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:58:19.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T19:58:49.565+0000] {processor.py:157} INFO - Started process (PID=18355) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:58:49.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:58:49.567+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:49.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:58:49.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:58:49.591+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:49.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:58:49.601+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:58:49.601+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:58:49.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T19:59:20.058+0000] {processor.py:157} INFO - Started process (PID=18375) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:59:20.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:59:20.061+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:20.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:59:20.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:59:20.087+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:20.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:59:20.096+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:20.096+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:59:20.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T19:59:50.532+0000] {processor.py:157} INFO - Started process (PID=18395) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:59:50.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T19:59:50.534+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:50.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:59:50.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T19:59:50.559+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:50.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T19:59:50.569+0000] {logging_mixin.py:151} INFO - [2024-07-10T19:59:50.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T19:59:50.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T20:00:21.066+0000] {processor.py:157} INFO - Started process (PID=18415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:00:21.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:00:21.070+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:00:21.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:00:21.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:00:21.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:00:21.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:00:21.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:00:21.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:00:21.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T20:16:48.227+0000] {processor.py:157} INFO - Started process (PID=18437) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:16:48.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:16:48.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:16:48.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:16:48.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:16:48.307+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:16:48.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:16:48.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:16:48.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:16:48.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-10T20:17:18.908+0000] {processor.py:157} INFO - Started process (PID=18457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:17:18.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:17:18.913+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:18.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:17:18.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:17:18.944+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:18.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:17:18.955+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:18.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:17:18.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T20:17:49.386+0000] {processor.py:157} INFO - Started process (PID=18477) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:17:49.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:17:49.390+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:49.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:17:49.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:17:49.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:49.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:17:49.446+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:17:49.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:17:49.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-10T20:18:19.918+0000] {processor.py:157} INFO - Started process (PID=18497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:18:19.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:18:19.921+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:19.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:18:19.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:18:19.946+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:19.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:18:19.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:19.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:18:19.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T20:18:50.425+0000] {processor.py:157} INFO - Started process (PID=18517) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:18:50.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:18:50.427+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:50.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:18:50.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:18:50.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:50.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:18:50.463+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:18:50.463+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:18:50.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T20:19:20.865+0000] {processor.py:157} INFO - Started process (PID=18537) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:19:20.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:19:20.868+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:20.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:19:20.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:19:20.894+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:20.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:19:20.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:20.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:19:20.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T20:19:51.359+0000] {processor.py:157} INFO - Started process (PID=18557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:19:51.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:19:51.362+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:51.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:19:51.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:19:51.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:51.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:19:51.397+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:19:51.397+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:19:51.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T20:20:21.829+0000] {processor.py:157} INFO - Started process (PID=18577) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:20:21.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:20:21.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:21.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:20:21.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:20:21.859+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:21.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:20:21.870+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:21.870+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:20:21.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T20:20:52.356+0000] {processor.py:157} INFO - Started process (PID=18597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:20:52.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:20:52.361+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:52.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:20:52.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:20:52.395+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:52.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:20:52.407+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:20:52.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:20:52.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T20:21:22.735+0000] {processor.py:157} INFO - Started process (PID=18617) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:21:22.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:21:22.737+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:22.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:21:22.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:21:22.761+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:22.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:21:22.771+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:22.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:21:22.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T20:21:53.212+0000] {processor.py:157} INFO - Started process (PID=18637) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:21:53.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:21:53.215+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:53.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:21:53.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:21:53.240+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:53.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:21:53.250+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:21:53.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:21:53.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T20:22:23.632+0000] {processor.py:157} INFO - Started process (PID=18657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:22:23.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:22:23.635+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:23.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:22:23.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:22:23.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:23.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:22:23.670+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:23.670+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:22:23.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T20:22:54.055+0000] {processor.py:157} INFO - Started process (PID=18677) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:22:54.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:22:54.058+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:54.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:22:54.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:22:54.083+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:54.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:22:54.094+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:22:54.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:22:54.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T20:23:24.492+0000] {processor.py:157} INFO - Started process (PID=18697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:23:24.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:23:24.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:24.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:23:24.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:23:24.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:24.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:23:24.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:24.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:23:24.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T20:23:54.898+0000] {processor.py:157} INFO - Started process (PID=18717) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:23:54.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:23:54.900+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:54.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:23:54.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:23:54.924+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:54.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:23:54.934+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:23:54.934+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:23:54.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T20:24:25.294+0000] {processor.py:157} INFO - Started process (PID=18737) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:24:25.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:24:25.297+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:25.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:24:25.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:24:25.320+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:25.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:24:25.329+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:25.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:24:25.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T20:24:55.807+0000] {processor.py:157} INFO - Started process (PID=18757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:24:55.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:24:55.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:55.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:24:55.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:24:55.836+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:55.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:24:55.845+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:24:55.845+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:24:55.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T20:25:26.299+0000] {processor.py:157} INFO - Started process (PID=18777) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:25:26.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:25:26.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:26.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:25:26.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:25:26.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:26.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:25:26.337+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:26.337+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:25:26.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T20:25:56.792+0000] {processor.py:157} INFO - Started process (PID=18797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:25:56.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:25:56.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:56.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:25:56.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:25:56.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:56.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:25:56.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:25:56.834+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:25:56.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T20:26:27.198+0000] {processor.py:157} INFO - Started process (PID=18817) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:26:27.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:26:27.203+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:27.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:26:27.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:26:27.237+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:27.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:26:27.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:27.248+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:26:27.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T20:26:57.644+0000] {processor.py:157} INFO - Started process (PID=18837) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:26:57.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:26:57.646+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:57.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:26:57.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:26:57.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:57.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:26:57.679+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:26:57.679+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:26:57.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T20:27:28.040+0000] {processor.py:157} INFO - Started process (PID=18857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:27:28.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:27:28.042+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:28.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:27:28.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:27:28.066+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:28.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:27:28.076+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:28.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:27:28.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T20:27:58.534+0000] {processor.py:157} INFO - Started process (PID=18877) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:27:58.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:27:58.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:58.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:27:58.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:27:58.563+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:58.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:27:58.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:27:58.573+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:27:58.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T20:28:28.980+0000] {processor.py:157} INFO - Started process (PID=18897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:28:28.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:28:28.982+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:28.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:28:28.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:28:29.007+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:29.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:28:29.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:29.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:28:29.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T20:28:59.484+0000] {processor.py:157} INFO - Started process (PID=18917) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:28:59.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:28:59.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:59.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:28:59.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:28:59.512+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:59.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:28:59.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:28:59.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:28:59.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T20:29:29.990+0000] {processor.py:157} INFO - Started process (PID=18937) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:29:29.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:29:29.993+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:29:29.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:29:30.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:29:30.018+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:29:30.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:29:30.028+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:29:30.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:29:30.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T20:30:00.487+0000] {processor.py:157} INFO - Started process (PID=18957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:30:00.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:30:00.490+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:00.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:30:00.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:30:00.515+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:00.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:30:00.524+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:00.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:30:00.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T20:30:30.988+0000] {processor.py:157} INFO - Started process (PID=18977) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:30:30.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:30:30.992+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:30.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:30:31.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:30:31.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:31.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:30:31.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:30:31.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:30:31.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T20:31:01.517+0000] {processor.py:157} INFO - Started process (PID=18997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:31:01.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:31:01.521+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:01.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:31:01.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:31:01.549+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:01.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:31:01.559+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:01.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:31:01.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T20:31:32.017+0000] {processor.py:157} INFO - Started process (PID=19017) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:31:32.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:31:32.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:32.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:31:32.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:31:32.046+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:32.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:31:32.056+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:31:32.056+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:31:32.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T20:32:02.524+0000] {processor.py:157} INFO - Started process (PID=19037) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:32:02.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:32:02.528+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:02.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:32:02.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:32:02.561+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:02.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:32:02.573+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:02.573+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:32:02.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-10T20:32:33.051+0000] {processor.py:157} INFO - Started process (PID=19057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:32:33.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:32:33.054+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:33.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:32:33.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:32:33.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:33.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:32:33.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:32:33.091+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:32:33.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T20:33:03.565+0000] {processor.py:157} INFO - Started process (PID=19077) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:33:03.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:33:03.568+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:33:03.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:33:03.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:33:03.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:33:03.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:33:03.602+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:33:03.602+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:33:03.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T20:50:10.544+0000] {processor.py:157} INFO - Started process (PID=19097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:50:10.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:50:10.546+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:10.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:50:10.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:50:10.568+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:10.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:50:10.577+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:10.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:50:10.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-10T20:50:40.993+0000] {processor.py:157} INFO - Started process (PID=19119) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:50:40.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:50:40.999+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:40.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:50:41.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:50:41.036+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:41.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:50:41.047+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:50:41.047+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:50:41.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-10T20:51:11.497+0000] {processor.py:157} INFO - Started process (PID=19139) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:51:11.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:51:11.499+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:11.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:51:11.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:51:11.523+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:11.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:51:11.533+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:11.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:51:11.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T20:51:41.958+0000] {processor.py:157} INFO - Started process (PID=19159) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:51:41.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:51:41.960+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:41.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:51:41.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:51:41.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:41.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:51:41.994+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:51:41.994+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:51:42.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T20:52:12.460+0000] {processor.py:157} INFO - Started process (PID=19179) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:52:12.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:52:12.464+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:12.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:52:12.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:52:12.488+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:12.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:52:12.498+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:12.498+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:52:12.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T20:52:42.993+0000] {processor.py:157} INFO - Started process (PID=19199) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:52:42.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:52:42.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:42.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:52:43.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:52:43.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:43.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:52:43.030+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:52:43.030+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:52:43.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T20:53:13.458+0000] {processor.py:157} INFO - Started process (PID=19219) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:53:13.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:53:13.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:13.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:53:13.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:53:13.485+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:13.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:53:13.495+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:13.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:53:13.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T20:53:43.937+0000] {processor.py:157} INFO - Started process (PID=19239) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:53:43.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:53:43.940+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:43.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:53:43.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:53:43.964+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:43.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:53:43.973+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:53:43.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:53:43.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T20:54:14.432+0000] {processor.py:157} INFO - Started process (PID=19259) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:54:14.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:54:14.434+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:14.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:54:14.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:54:14.459+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:14.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:54:14.469+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:14.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:54:14.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T20:54:44.956+0000] {processor.py:157} INFO - Started process (PID=19279) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:54:44.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T20:54:44.959+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:44.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:54:44.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T20:54:44.985+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:44.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T20:54:44.996+0000] {logging_mixin.py:151} INFO - [2024-07-10T20:54:44.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T20:54:45.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T21:12:10.570+0000] {processor.py:157} INFO - Started process (PID=19301) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:12:10.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T21:12:10.575+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:12:10.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:12:10.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:12:10.630+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:12:10.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:12:10.645+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:12:10.645+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:12:10.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-10T21:28:33.416+0000] {processor.py:157} INFO - Started process (PID=19321) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:28:33.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T21:28:33.419+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:28:33.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:28:33.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:28:33.446+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:28:33.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:28:33.456+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:28:33.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:28:33.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-10T21:29:03.921+0000] {processor.py:157} INFO - Started process (PID=19341) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:29:03.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T21:29:03.925+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:03.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:29:03.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:29:03.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:03.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:29:03.967+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:03.967+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:29:03.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-10T21:29:34.398+0000] {processor.py:157} INFO - Started process (PID=19361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:29:34.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T21:29:34.402+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:34.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:29:34.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:29:34.430+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:34.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:29:34.440+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:29:34.440+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:29:34.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-10T21:45:07.634+0000] {processor.py:157} INFO - Started process (PID=19383) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:45:07.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T21:45:07.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:45:07.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:45:07.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T21:45:07.694+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:45:07.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T21:45:07.725+0000] {logging_mixin.py:151} INFO - [2024-07-10T21:45:07.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T21:45:07.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-10T22:01:51.189+0000] {processor.py:157} INFO - Started process (PID=19403) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:01:51.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:01:51.195+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:01:51.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:01:51.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:01:51.271+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:01:51.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:01:51.302+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:01:51.302+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:01:51.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.135 seconds
[2024-07-10T22:02:21.787+0000] {processor.py:157} INFO - Started process (PID=19423) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:02:21.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:02:21.792+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:21.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:02:21.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:02:21.821+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:21.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:02:21.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:21.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:02:21.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T22:02:52.204+0000] {processor.py:157} INFO - Started process (PID=19443) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:02:52.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:02:52.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:52.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:02:52.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:02:52.232+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:52.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:02:52.241+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:02:52.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:02:52.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T22:03:22.590+0000] {processor.py:157} INFO - Started process (PID=19463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:03:22.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:03:22.592+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:22.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:03:22.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:03:22.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:22.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:03:22.627+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:22.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:03:22.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T22:03:53.016+0000] {processor.py:157} INFO - Started process (PID=19483) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:03:53.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:03:53.021+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:53.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:03:53.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:03:53.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:53.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:03:53.062+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:03:53.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:03:53.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T22:20:43.451+0000] {processor.py:157} INFO - Started process (PID=19503) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:20:43.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:20:43.457+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:20:43.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:20:43.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:20:43.520+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:20:43.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:20:43.542+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:20:43.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:20:43.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-10T22:21:14.022+0000] {processor.py:157} INFO - Started process (PID=19523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:21:14.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:21:14.027+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:14.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:21:14.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:21:14.067+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:14.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:21:14.080+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:14.080+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:21:14.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-10T22:21:44.433+0000] {processor.py:157} INFO - Started process (PID=19543) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:21:44.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:21:44.437+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:44.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:21:44.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:21:44.468+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:44.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:21:44.479+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:21:44.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:21:44.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T22:22:14.900+0000] {processor.py:157} INFO - Started process (PID=19563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:22:14.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:22:14.902+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:14.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:22:14.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:22:14.927+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:14.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:22:14.936+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:14.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:22:14.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T22:22:45.413+0000] {processor.py:157} INFO - Started process (PID=19583) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:22:45.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:22:45.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:45.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:22:45.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:22:45.453+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:45.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:22:45.465+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:22:45.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:22:45.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-10T22:23:15.871+0000] {processor.py:157} INFO - Started process (PID=19603) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:23:15.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:23:15.873+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:15.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:23:15.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:23:15.892+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:15.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:23:15.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:15.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:23:15.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T22:23:46.247+0000] {processor.py:157} INFO - Started process (PID=19623) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:23:46.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:23:46.251+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:46.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:23:46.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:23:46.275+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:46.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:23:46.285+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:23:46.285+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:23:46.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T22:24:16.732+0000] {processor.py:157} INFO - Started process (PID=19643) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:24:16.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:24:16.735+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:24:16.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:24:16.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:24:16.760+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:24:16.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:24:16.770+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:24:16.770+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:24:16.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T22:28:59.988+0000] {processor.py:157} INFO - Started process (PID=19665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:28:59.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:28:59.991+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:28:59.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:29:00.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:29:00.017+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:00.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:29:00.026+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:00.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:29:00.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T22:29:30.490+0000] {processor.py:157} INFO - Started process (PID=19685) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:29:30.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:29:30.494+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:30.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:29:30.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:29:30.525+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:30.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:29:30.536+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:29:30.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:29:30.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T22:46:44.872+0000] {processor.py:157} INFO - Started process (PID=19705) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:46:44.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:46:44.881+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:46:44.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:46:44.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:46:44.953+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:46:44.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:46:44.969+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:46:44.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:46:44.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-10T22:47:15.460+0000] {processor.py:157} INFO - Started process (PID=19725) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:47:15.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:47:15.463+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:15.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:47:15.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:47:15.492+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:15.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:47:15.503+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:15.503+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:47:15.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-10T22:47:45.927+0000] {processor.py:157} INFO - Started process (PID=19745) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:47:45.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:47:45.930+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:45.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:47:45.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:47:45.956+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:45.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:47:45.966+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:47:45.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:47:45.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T22:48:16.397+0000] {processor.py:157} INFO - Started process (PID=19765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:48:16.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:48:16.400+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:16.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:48:16.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:48:16.428+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:16.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:48:16.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:16.438+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:48:16.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-10T22:48:46.832+0000] {processor.py:157} INFO - Started process (PID=19785) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:48:46.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T22:48:46.837+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:46.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:48:46.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T22:48:46.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:46.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T22:48:46.879+0000] {logging_mixin.py:151} INFO - [2024-07-10T22:48:46.879+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T22:48:46.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-10T23:03:22.524+0000] {processor.py:157} INFO - Started process (PID=19805) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:03:22.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:03:22.530+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:03:22.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:03:22.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:03:22.576+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:03:22.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:03:22.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:03:22.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:03:22.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-10T23:16:57.000+0000] {processor.py:157} INFO - Started process (PID=19825) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:16:57.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:16:57.006+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:16:57.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:16:57.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:16:57.039+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:16:57.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:16:57.051+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:16:57.051+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:16:57.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T23:17:27.500+0000] {processor.py:157} INFO - Started process (PID=19845) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:17:27.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:17:27.506+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:27.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:17:27.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:17:27.538+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:27.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:17:27.548+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:27.548+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:17:27.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-10T23:17:58.055+0000] {processor.py:157} INFO - Started process (PID=19865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:17:58.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:17:58.059+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:58.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:17:58.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:17:58.090+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:58.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:17:58.101+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:17:58.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:17:58.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T23:18:28.614+0000] {processor.py:157} INFO - Started process (PID=19885) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:18:28.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:18:28.618+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:28.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:18:28.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:18:28.649+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:28.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:18:28.660+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:28.660+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:18:28.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T23:18:59.146+0000] {processor.py:157} INFO - Started process (PID=19905) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:18:59.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:18:59.149+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:59.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:18:59.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:18:59.176+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:59.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:18:59.186+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:18:59.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:18:59.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T23:19:29.691+0000] {processor.py:157} INFO - Started process (PID=19925) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:19:29.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:19:29.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:19:29.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:19:29.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:19:29.718+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:19:29.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:19:29.727+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:19:29.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:19:29.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:20:00.203+0000] {processor.py:157} INFO - Started process (PID=19945) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:20:00.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:20:00.206+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:00.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:20:00.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:20:00.238+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:00.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:20:00.249+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:00.249+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:20:00.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-10T23:20:30.701+0000] {processor.py:157} INFO - Started process (PID=19965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:20:30.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:20:30.703+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:30.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:20:30.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:20:30.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:30.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:20:30.738+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:20:30.738+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:20:30.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:21:01.152+0000] {processor.py:157} INFO - Started process (PID=19985) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:21:01.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:21:01.156+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:01.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:21:01.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:21:01.182+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:01.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:21:01.192+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:01.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:21:01.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T23:21:31.595+0000] {processor.py:157} INFO - Started process (PID=20005) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:21:31.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:21:31.598+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:31.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:21:31.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:21:31.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:31.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:21:31.633+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:21:31.632+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:21:31.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:22:02.130+0000] {processor.py:157} INFO - Started process (PID=20025) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:22:02.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:22:02.132+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:02.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:22:02.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:22:02.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:02.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:22:02.163+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:02.163+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:22:02.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T23:22:32.637+0000] {processor.py:157} INFO - Started process (PID=20045) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:22:32.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:22:32.640+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:32.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:22:32.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:22:32.665+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:32.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:22:32.675+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:22:32.675+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:22:32.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:23:03.185+0000] {processor.py:157} INFO - Started process (PID=20065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:23:03.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:23:03.187+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:03.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:23:03.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:23:03.213+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:03.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:23:03.225+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:03.225+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:23:03.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T23:23:33.678+0000] {processor.py:157} INFO - Started process (PID=20085) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:23:33.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:23:33.682+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:33.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:23:33.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:23:33.716+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:33.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:23:33.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:23:33.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:23:33.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-10T23:24:04.214+0000] {processor.py:157} INFO - Started process (PID=20105) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:24:04.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:24:04.217+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:04.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:24:04.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:24:04.242+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:04.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:24:04.252+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:04.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:24:04.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:24:34.691+0000] {processor.py:157} INFO - Started process (PID=20125) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:24:34.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:24:34.694+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:34.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:24:34.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:24:34.719+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:34.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:24:34.728+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:24:34.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:24:34.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:25:05.143+0000] {processor.py:157} INFO - Started process (PID=20145) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:25:05.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:25:05.145+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:05.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:25:05.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:25:05.168+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:05.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:25:05.178+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:05.178+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:25:05.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:25:35.612+0000] {processor.py:157} INFO - Started process (PID=20165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:25:35.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:25:35.615+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:35.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:25:35.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:25:35.638+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:35.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:25:35.647+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:25:35.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:25:35.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:26:06.108+0000] {processor.py:157} INFO - Started process (PID=20185) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:26:06.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:26:06.111+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:06.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:26:06.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:26:06.136+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:06.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:26:06.144+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:06.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:26:06.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:26:36.598+0000] {processor.py:157} INFO - Started process (PID=20205) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:26:36.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:26:36.602+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:36.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:26:36.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:26:36.627+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:36.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:26:36.637+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:26:36.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:26:36.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T23:27:07.129+0000] {processor.py:157} INFO - Started process (PID=20225) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:27:07.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:27:07.131+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:07.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:27:07.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:27:07.154+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:07.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:27:07.165+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:07.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:27:07.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T23:27:37.628+0000] {processor.py:157} INFO - Started process (PID=20245) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:27:37.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:27:37.631+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:37.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:27:37.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:27:37.655+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:37.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:27:37.664+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:27:37.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:27:37.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T23:28:08.131+0000] {processor.py:157} INFO - Started process (PID=20265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:28:08.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:28:08.134+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:08.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:28:08.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:28:08.159+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:08.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:28:08.169+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:08.169+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:28:08.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:28:38.652+0000] {processor.py:157} INFO - Started process (PID=20285) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:28:38.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:28:38.654+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:38.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:28:38.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:28:38.676+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:38.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:28:38.685+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:28:38.685+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:28:38.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T23:29:09.194+0000] {processor.py:157} INFO - Started process (PID=20305) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:29:09.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:29:09.196+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:09.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:29:09.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:29:09.219+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:09.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:29:09.228+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:09.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:29:09.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T23:29:39.720+0000] {processor.py:157} INFO - Started process (PID=20325) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:29:39.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:29:39.722+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:39.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:29:39.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:29:39.747+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:39.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:29:39.757+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:29:39.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:29:39.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:30:10.275+0000] {processor.py:157} INFO - Started process (PID=20345) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:30:10.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:30:10.283+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:10.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:30:10.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:30:10.345+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:10.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:30:10.361+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:10.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:30:10.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-10T23:30:40.783+0000] {processor.py:157} INFO - Started process (PID=20365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:30:40.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:30:40.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:40.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:30:40.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:30:40.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:40.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:30:40.822+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:30:40.822+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:30:40.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:31:11.299+0000] {processor.py:157} INFO - Started process (PID=20385) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:31:11.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:31:11.302+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:11.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:31:11.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:31:11.327+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:11.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:31:11.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:11.336+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:31:11.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:31:41.797+0000] {processor.py:157} INFO - Started process (PID=20405) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:31:41.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:31:41.800+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:41.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:31:41.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:31:41.823+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:41.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:31:41.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:31:41.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:31:41.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T23:32:12.349+0000] {processor.py:157} INFO - Started process (PID=20425) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:32:12.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:32:12.352+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:12.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:32:12.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:32:12.378+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:12.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:32:12.388+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:12.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:32:12.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T23:32:42.829+0000] {processor.py:157} INFO - Started process (PID=20445) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:32:42.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:32:42.832+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:42.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:32:42.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:32:42.857+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:42.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:32:42.867+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:32:42.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:32:42.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:33:13.381+0000] {processor.py:157} INFO - Started process (PID=20465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:33:13.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:33:13.384+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:13.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:33:13.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:33:13.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:13.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:33:13.418+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:13.418+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:33:13.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:33:43.919+0000] {processor.py:157} INFO - Started process (PID=20485) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:33:43.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:33:43.922+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:43.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:33:43.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:33:43.947+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:43.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:33:43.957+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:33:43.957+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:33:43.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:34:14.384+0000] {processor.py:157} INFO - Started process (PID=20505) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:34:14.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:34:14.387+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:14.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:34:14.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:34:14.413+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:14.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:34:14.422+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:14.422+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:34:14.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:34:44.828+0000] {processor.py:157} INFO - Started process (PID=20525) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:34:44.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:34:44.831+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:44.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:34:44.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:34:44.856+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:44.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:34:44.865+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:34:44.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:34:44.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:35:15.312+0000] {processor.py:157} INFO - Started process (PID=20545) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:35:15.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:35:15.316+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:15.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:35:15.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:35:15.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:15.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:35:15.351+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:15.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:35:15.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:35:45.775+0000] {processor.py:157} INFO - Started process (PID=20565) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:35:45.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:35:45.777+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:45.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:35:45.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:35:45.801+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:45.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:35:45.811+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:35:45.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:35:45.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T23:36:16.295+0000] {processor.py:157} INFO - Started process (PID=20585) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:36:16.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:36:16.298+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:16.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:36:16.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:36:16.322+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:16.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:36:16.332+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:16.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:36:16.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T23:36:46.797+0000] {processor.py:157} INFO - Started process (PID=20605) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:36:46.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:36:46.801+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:46.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:36:46.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:36:46.825+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:46.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:36:46.834+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:36:46.834+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:36:46.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:37:17.333+0000] {processor.py:157} INFO - Started process (PID=20625) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:37:17.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:37:17.336+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:17.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:37:17.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:37:17.360+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:17.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:37:17.370+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:17.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:37:17.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:37:47.867+0000] {processor.py:157} INFO - Started process (PID=20645) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:37:47.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:37:47.870+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:47.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:37:47.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:37:47.894+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:47.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:37:47.904+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:37:47.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:37:47.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:38:18.328+0000] {processor.py:157} INFO - Started process (PID=20665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:38:18.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:38:18.330+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:18.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:38:18.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:38:18.353+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:18.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:38:18.364+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:18.364+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:38:18.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T23:38:48.798+0000] {processor.py:157} INFO - Started process (PID=20685) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:38:48.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:38:48.801+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:48.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:38:48.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:38:48.826+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:48.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:38:48.836+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:38:48.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:38:48.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:39:19.265+0000] {processor.py:157} INFO - Started process (PID=20705) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:39:19.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:39:19.269+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:19.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:39:19.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:39:19.293+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:19.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:39:19.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:19.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:39:19.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:39:49.773+0000] {processor.py:157} INFO - Started process (PID=20725) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:39:49.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:39:49.776+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:49.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:39:49.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:39:49.799+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:49.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:39:49.808+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:39:49.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:39:49.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:40:20.250+0000] {processor.py:157} INFO - Started process (PID=20745) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:40:20.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:40:20.254+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:20.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:40:20.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:40:20.278+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:20.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:40:20.288+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:20.288+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:40:20.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:40:50.791+0000] {processor.py:157} INFO - Started process (PID=20765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:40:50.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:40:50.794+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:50.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:40:50.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:40:50.818+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:50.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:40:50.828+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:40:50.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:40:50.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:41:21.261+0000] {processor.py:157} INFO - Started process (PID=20785) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:41:21.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:41:21.266+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:21.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:41:21.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:41:21.299+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:21.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:41:21.310+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:21.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:41:21.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-10T23:41:51.824+0000] {processor.py:157} INFO - Started process (PID=20805) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:41:51.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:41:51.827+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:51.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:41:51.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:41:51.850+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:51.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:41:51.859+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:41:51.859+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:41:51.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:42:22.326+0000] {processor.py:157} INFO - Started process (PID=20825) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:42:22.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:42:22.328+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:22.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:42:22.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:42:22.354+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:22.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:42:22.365+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:22.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:42:22.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-10T23:42:52.861+0000] {processor.py:157} INFO - Started process (PID=20845) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:42:52.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:42:52.864+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:52.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:42:52.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:42:52.888+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:52.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:42:52.898+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:42:52.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:42:52.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:43:23.344+0000] {processor.py:157} INFO - Started process (PID=20865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:43:23.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:43:23.346+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:23.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:43:23.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:43:23.371+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:23.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:43:23.381+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:23.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:43:23.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:43:53.868+0000] {processor.py:157} INFO - Started process (PID=20885) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:43:53.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:43:53.871+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:53.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:43:53.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:43:53.896+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:53.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:43:53.906+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:43:53.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:43:53.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:44:24.376+0000] {processor.py:157} INFO - Started process (PID=20905) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:44:24.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:44:24.378+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:24.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:44:24.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:44:24.399+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:24.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:44:24.408+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:24.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:44:24.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-10T23:44:54.876+0000] {processor.py:157} INFO - Started process (PID=20925) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:44:54.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:44:54.878+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:54.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:44:54.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:44:54.896+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:54.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:44:54.905+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:44:54.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:44:54.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.038 seconds
[2024-07-10T23:45:25.337+0000] {processor.py:157} INFO - Started process (PID=20945) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:45:25.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:45:25.340+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:25.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:45:25.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:45:25.361+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:25.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:45:25.370+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:25.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:45:25.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-10T23:45:55.844+0000] {processor.py:157} INFO - Started process (PID=20965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:45:55.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:45:55.847+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:55.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:45:55.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:45:55.871+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:55.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:45:55.880+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:45:55.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:45:55.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:46:26.440+0000] {processor.py:157} INFO - Started process (PID=20985) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:46:26.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:46:26.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:26.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:46:26.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:46:26.467+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:26.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:46:26.476+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:26.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:46:26.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:46:56.944+0000] {processor.py:157} INFO - Started process (PID=21005) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:46:56.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:46:56.948+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:56.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:46:56.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:46:56.972+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:56.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:46:56.982+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:46:56.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:46:56.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:47:27.435+0000] {processor.py:157} INFO - Started process (PID=21025) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:47:27.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:47:27.438+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:27.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:47:27.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:47:27.462+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:27.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:47:27.472+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:27.472+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:47:27.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:47:57.785+0000] {processor.py:157} INFO - Started process (PID=21045) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:47:57.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:47:57.787+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:57.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:47:57.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:47:57.810+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:57.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:47:57.819+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:47:57.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:47:57.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T23:48:28.316+0000] {processor.py:157} INFO - Started process (PID=21065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:48:28.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:48:28.319+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:28.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:48:28.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:48:28.344+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:28.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:48:28.354+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:28.353+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:48:28.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:48:58.793+0000] {processor.py:157} INFO - Started process (PID=21085) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:48:58.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:48:58.796+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:58.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:48:58.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:48:58.820+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:58.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:48:58.830+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:48:58.830+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:48:58.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:49:29.219+0000] {processor.py:157} INFO - Started process (PID=21105) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:49:29.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:49:29.221+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:29.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:49:29.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:49:29.246+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:29.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:49:29.256+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:29.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:49:29.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:49:59.653+0000] {processor.py:157} INFO - Started process (PID=21125) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:49:59.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:49:59.657+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:59.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:49:59.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:49:59.681+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:59.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:49:59.691+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:49:59.691+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:49:59.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:50:30.075+0000] {processor.py:157} INFO - Started process (PID=21145) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:50:30.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:50:30.078+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:50:30.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:50:30.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:50:30.104+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:50:30.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:50:30.113+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:50:30.113+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:50:30.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:51:00.514+0000] {processor.py:157} INFO - Started process (PID=21165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:51:00.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:51:00.517+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:00.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:51:00.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:51:00.540+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:00.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:51:00.550+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:00.550+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:51:00.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:51:30.925+0000] {processor.py:157} INFO - Started process (PID=21185) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:51:30.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:51:30.928+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:30.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:51:30.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:51:30.952+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:30.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:51:30.962+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:51:30.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:51:30.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-10T23:52:01.451+0000] {processor.py:157} INFO - Started process (PID=21205) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:52:01.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:52:01.454+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:01.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:52:01.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:52:01.477+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:01.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:52:01.487+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:01.487+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:52:01.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:52:31.946+0000] {processor.py:157} INFO - Started process (PID=21225) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:52:31.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:52:31.949+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:31.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:52:31.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:52:31.974+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:31.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:52:31.984+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:52:31.984+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:52:31.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:53:02.408+0000] {processor.py:157} INFO - Started process (PID=21245) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:53:02.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:53:02.411+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:02.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:53:02.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:53:02.433+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:02.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:53:02.443+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:02.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:53:02.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:53:32.866+0000] {processor.py:157} INFO - Started process (PID=21265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:53:32.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:53:32.869+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:32.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:53:32.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:53:32.893+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:32.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:53:32.903+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:53:32.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:53:32.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T23:54:03.267+0000] {processor.py:157} INFO - Started process (PID=21285) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:54:03.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:54:03.269+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:03.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:54:03.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:54:03.293+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:03.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:54:03.303+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:03.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:54:03.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-10T23:54:33.715+0000] {processor.py:157} INFO - Started process (PID=21305) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:54:33.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:54:33.718+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:33.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:54:33.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:54:33.743+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:33.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:54:33.752+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:54:33.752+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:54:33.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:55:04.167+0000] {processor.py:157} INFO - Started process (PID=21325) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:55:04.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:55:04.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:04.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:55:04.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:55:04.193+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:04.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:55:04.203+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:04.203+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:55:04.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T23:55:34.703+0000] {processor.py:157} INFO - Started process (PID=21345) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:55:34.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:55:34.706+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:34.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:55:34.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:55:34.731+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:34.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:55:34.741+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:55:34.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:55:34.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:56:05.149+0000] {processor.py:157} INFO - Started process (PID=21365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:56:05.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:56:05.153+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:05.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:56:05.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:56:05.178+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:05.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:56:05.189+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:05.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:56:05.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-10T23:56:35.662+0000] {processor.py:157} INFO - Started process (PID=21385) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:56:35.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:56:35.665+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:35.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:56:35.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:56:35.689+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:35.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:56:35.699+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:56:35.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:56:35.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-10T23:57:06.089+0000] {processor.py:157} INFO - Started process (PID=21405) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:57:06.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:57:06.091+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:06.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:57:06.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:57:06.116+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:06.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:57:06.125+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:06.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:57:06.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-10T23:57:36.588+0000] {processor.py:157} INFO - Started process (PID=21425) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:57:36.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:57:36.590+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:36.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:57:36.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:57:36.614+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:36.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:57:36.623+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:57:36.623+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:57:36.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-10T23:58:07.084+0000] {processor.py:157} INFO - Started process (PID=21445) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:58:07.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:58:07.086+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:07.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:58:07.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:58:07.105+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:07.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:58:07.114+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:07.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:58:07.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.039 seconds
[2024-07-10T23:58:37.614+0000] {processor.py:157} INFO - Started process (PID=21465) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:58:37.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:58:37.617+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:37.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:58:37.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:58:37.641+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:37.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:58:37.651+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:58:37.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:58:37.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:59:08.133+0000] {processor.py:157} INFO - Started process (PID=21485) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:59:08.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:59:08.135+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:08.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:59:08.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:59:08.160+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:08.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:59:08.170+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:08.170+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:59:08.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-10T23:59:38.666+0000] {processor.py:157} INFO - Started process (PID=21505) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:59:38.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-10T23:59:38.669+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:38.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:59:38.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-10T23:59:38.693+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:38.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-10T23:59:38.703+0000] {logging_mixin.py:151} INFO - [2024-07-10T23:59:38.703+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-09T00:30:00+00:00, run_after=2024-07-10T00:30:00+00:00
[2024-07-10T23:59:38.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
