[2024-07-12T11:07:40.287+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:07:40.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:07:40.290+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:07:40.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:07:40.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:07:40.339+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:07:40.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:07:40.362+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:07:40.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:07:40.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-12T11:08:10.797+0000] {processor.py:157} INFO - Started process (PID=206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:08:10.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:08:10.808+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:08:10.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:08:10.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:08:10.876+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:08:10.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:08:10.898+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:08:10.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:08:10.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-12T11:08:41.268+0000] {processor.py:157} INFO - Started process (PID=231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:08:41.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:08:41.274+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:08:41.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:08:41.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:08:41.319+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:08:41.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:08:41.333+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:08:41.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:08:41.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-12T11:09:11.697+0000] {processor.py:157} INFO - Started process (PID=256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:09:11.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:09:11.702+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:09:11.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:09:11.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:09:11.737+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:09:11.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:09:11.749+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:09:11.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:09:11.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-12T11:09:42.142+0000] {processor.py:157} INFO - Started process (PID=281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:09:42.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:09:42.147+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:09:42.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:09:42.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:09:42.187+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:09:42.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:09:42.206+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:09:42.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:09:42.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-12T11:10:12.549+0000] {processor.py:157} INFO - Started process (PID=306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:10:12.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:10:12.553+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:10:12.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:10:12.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:10:12.590+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:10:12.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:10:12.607+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:10:12.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:10:12.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-12T11:10:43.001+0000] {processor.py:157} INFO - Started process (PID=331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:10:43.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:10:43.008+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:10:43.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:10:43.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:10:43.046+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:10:43.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:10:43.071+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:10:43.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:10:43.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-12T11:11:13.546+0000] {processor.py:157} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:11:13.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:11:13.549+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:11:13.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:11:13.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:11:13.578+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:11:13.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:11:13.591+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:11:13.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:11:13.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T11:11:43.914+0000] {processor.py:157} INFO - Started process (PID=381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:11:43.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:11:43.918+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:11:43.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:11:43.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:11:43.963+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:11:43.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:11:43.977+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:11:43.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:11:43.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-12T11:12:14.403+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:12:14.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:12:14.408+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:12:14.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:12:14.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:12:14.436+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:12:14.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:12:14.447+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:12:14.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:12:14.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T11:12:44.833+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:12:44.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:12:44.838+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:12:44.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:12:44.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:12:44.883+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:12:44.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:12:44.898+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:12:44.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:12:44.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-12T11:13:15.307+0000] {processor.py:157} INFO - Started process (PID=456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:13:15.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:13:15.311+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:13:15.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:13:15.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:13:15.342+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:13:15.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:13:15.355+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:13:15.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:13:15.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-12T11:13:45.689+0000] {processor.py:157} INFO - Started process (PID=481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:13:45.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:13:45.695+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:13:45.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:13:45.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:13:45.741+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:13:45.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:13:45.756+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:13:45.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:13:45.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-12T11:14:16.103+0000] {processor.py:157} INFO - Started process (PID=506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:14:16.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:14:16.106+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:14:16.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:14:16.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:14:16.141+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:14:16.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:14:16.155+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:14:16.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:14:16.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-12T11:14:46.593+0000] {processor.py:157} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:14:46.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:14:46.598+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:14:46.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:14:46.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:14:46.661+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:14:46.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:14:46.677+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:14:46.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:14:46.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-12T11:15:17.051+0000] {processor.py:157} INFO - Started process (PID=556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:15:17.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:15:17.057+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:15:17.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:15:17.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:15:17.090+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:15:17.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:15:17.104+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:15:17.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:15:17.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-12T11:15:47.451+0000] {processor.py:157} INFO - Started process (PID=581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:15:47.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:15:47.456+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:15:47.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:15:47.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:15:47.489+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:15:47.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:15:47.503+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:15:47.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:15:47.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-12T11:16:17.909+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:16:17.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:16:17.913+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:16:17.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:16:17.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:16:17.952+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:16:17.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:16:17.964+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:16:17.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:16:17.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-12T11:16:48.350+0000] {processor.py:157} INFO - Started process (PID=631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:16:48.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:16:48.354+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:16:48.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:16:48.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:16:48.385+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:16:48.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:16:48.400+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:16:48.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:16:48.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-12T11:17:18.786+0000] {processor.py:157} INFO - Started process (PID=656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:17:18.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:17:18.792+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:17:18.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:17:18.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:17:18.828+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:17:18.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:17:18.845+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:17:18.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:17:18.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-12T11:17:49.197+0000] {processor.py:157} INFO - Started process (PID=681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:17:49.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:17:49.200+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:17:49.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:17:49.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:17:49.238+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:17:49.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:17:49.254+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:17:49.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:17:49.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-12T11:18:19.637+0000] {processor.py:157} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:18:19.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:18:19.642+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:18:19.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:18:19.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:18:19.695+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:18:19.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:18:19.714+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:18:19.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:18:19.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-12T11:18:50.069+0000] {processor.py:157} INFO - Started process (PID=731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:18:50.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:18:50.073+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:18:50.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:18:50.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:18:50.112+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:18:50.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:18:50.123+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:18:50.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:18:50.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-12T11:19:20.543+0000] {processor.py:157} INFO - Started process (PID=756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:19:20.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:19:20.549+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:19:20.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:19:20.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:19:20.580+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:19:20.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:19:20.596+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:19:20.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:19:20.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-12T11:19:50.943+0000] {processor.py:157} INFO - Started process (PID=781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:19:50.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:19:50.947+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:19:50.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:19:50.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:19:50.981+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:19:50.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:19:50.993+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:19:50.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:19:51.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-12T11:20:21.441+0000] {processor.py:157} INFO - Started process (PID=806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:20:21.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:20:21.446+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:20:21.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:20:21.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:20:21.517+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:20:21.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:20:21.536+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:20:21.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:20:21.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-12T11:20:51.982+0000] {processor.py:157} INFO - Started process (PID=831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:20:51.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:20:51.986+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:20:51.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:20:51.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:20:52.017+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:20:52.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:20:52.029+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:20:52.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:20:52.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-12T11:21:22.379+0000] {processor.py:157} INFO - Started process (PID=856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:21:22.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:21:22.382+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:21:22.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:21:22.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:21:22.416+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:21:22.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:21:22.429+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:21:22.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:21:22.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-12T11:21:52.830+0000] {processor.py:157} INFO - Started process (PID=881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:21:52.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:21:52.836+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:21:52.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:21:52.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:21:52.895+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:21:52.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:21:52.910+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:21:52.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:21:52.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-12T11:22:23.278+0000] {processor.py:157} INFO - Started process (PID=906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:22:23.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:22:23.286+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:22:23.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:22:23.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:22:23.361+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:22:23.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:22:23.385+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:22:23.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:22:23.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-12T11:22:53.823+0000] {processor.py:157} INFO - Started process (PID=931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:22:53.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:22:53.828+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:22:53.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:22:53.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:22:53.873+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:22:53.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:22:53.889+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:22:53.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:22:53.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-12T11:23:24.227+0000] {processor.py:157} INFO - Started process (PID=956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:23:24.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:23:24.231+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:23:24.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:23:24.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:23:24.279+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:23:24.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:23:24.297+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:23:24.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:23:24.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-12T11:23:54.659+0000] {processor.py:157} INFO - Started process (PID=981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:23:54.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:23:54.662+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:23:54.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:23:54.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:23:54.699+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:23:54.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:23:54.712+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:23:54.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:23:54.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-12T11:24:25.130+0000] {processor.py:157} INFO - Started process (PID=1006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:24:25.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:24:25.134+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:24:25.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:24:25.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:24:25.174+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:24:25.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:24:25.191+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:24:25.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-11T01:00:00+00:00, run_after=2024-07-12T01:00:00+00:00
[2024-07-12T11:24:25.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-12T11:24:55.688+0000] {processor.py:157} INFO - Started process (PID=1034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:24:55.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:24:55.704+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:24:55.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:24:55.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:24:55.766+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:24:55.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:24:55.810+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:24:55.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:24:55.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-12T11:25:26.203+0000] {processor.py:157} INFO - Started process (PID=1059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:25:26.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:25:26.214+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:25:26.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:25:26.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:25:26.297+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:25:26.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:25:26.314+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:25:26.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:25:26.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-12T11:25:56.657+0000] {processor.py:157} INFO - Started process (PID=1084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:25:56.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:25:56.661+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:25:56.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:25:56.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:25:56.699+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:25:56.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:25:56.717+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:25:56.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:25:56.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-12T11:26:27.155+0000] {processor.py:157} INFO - Started process (PID=1109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:26:27.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:26:27.160+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:26:27.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:26:27.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:26:27.210+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:26:27.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:26:27.224+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:26:27.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:26:27.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-12T11:26:57.562+0000] {processor.py:157} INFO - Started process (PID=1137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:26:57.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:26:57.568+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:26:57.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:26:57.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:26:57.619+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:26:57.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:26:57.634+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:26:57.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:26:57.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-12T11:27:28.098+0000] {processor.py:157} INFO - Started process (PID=1162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:27:28.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:27:28.102+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:27:28.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:27:28.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:27:28.141+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:27:28.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:27:28.158+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:27:28.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:27:28.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-12T11:27:58.543+0000] {processor.py:157} INFO - Started process (PID=1187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:27:58.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:27:58.548+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:27:58.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:27:58.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:27:58.608+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:27:58.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:27:58.626+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:27:58.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:27:58.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-12T11:28:00.746+0000] {processor.py:157} INFO - Started process (PID=1212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:28:00.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:28:00.749+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:28:00.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:28:00.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:28:00.827+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:28:00.827+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:spark_data_processing_pipeline' as access control is unset.
[2024-07-12T11:28:00.827+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:28:00.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:28:00.837+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:28:00.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:28:00.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-12T11:28:31.235+0000] {processor.py:157} INFO - Started process (PID=1240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:28:31.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:28:31.239+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:28:31.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:28:31.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:28:31.271+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:28:31.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:28:31.284+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:28:31.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:28:31.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-12T11:29:01.749+0000] {processor.py:157} INFO - Started process (PID=1265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:29:01.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:29:01.752+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:29:01.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:29:01.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:29:01.783+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:29:01.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:29:01.795+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:29:01.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:29:01.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T11:29:32.226+0000] {processor.py:157} INFO - Started process (PID=1290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:29:32.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:29:32.229+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:29:32.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:29:32.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:29:32.262+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:29:32.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:29:32.275+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:29:32.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:29:32.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T11:30:02.707+0000] {processor.py:157} INFO - Started process (PID=1315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:30:02.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:30:02.709+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:30:02.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:30:02.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:30:02.807+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:30:02.807+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:spark_data_processing_pipeline' as access control is unset.
[2024-07-12T11:30:02.808+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:30:02.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:30:02.818+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:30:02.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:30:02.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-12T11:30:33.221+0000] {processor.py:157} INFO - Started process (PID=1389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:30:33.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:30:33.225+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:30:33.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:30:33.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:30:33.262+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:30:33.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:30:33.275+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:30:33.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:30:33.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-12T11:31:03.728+0000] {processor.py:157} INFO - Started process (PID=1414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:31:03.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:31:03.732+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:31:03.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:31:03.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:31:03.766+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:31:03.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:31:03.781+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:31:03.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:31:03.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-12T11:31:34.128+0000] {processor.py:157} INFO - Started process (PID=1439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:31:34.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:31:34.132+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:31:34.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:31:34.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:31:34.166+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:31:34.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:31:34.180+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:31:34.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:31:34.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-12T11:32:04.641+0000] {processor.py:157} INFO - Started process (PID=1464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:04.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:32:04.644+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:04.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:04.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:04.683+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:04.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:32:04.701+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:04.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:32:04.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-12T11:32:35.122+0000] {processor.py:157} INFO - Started process (PID=1538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:35.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:32:35.126+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:35.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:35.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:35.158+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:35.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:32:35.170+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:35.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:32:35.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T11:32:56.359+0000] {processor.py:157} INFO - Started process (PID=1543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:56.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:32:56.363+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:56.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:56.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:32:56.444+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:56.444+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:spark_data_processing_pipeline' as access control is unset.
[2024-07-12T11:32:56.444+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:56.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:32:56.456+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:32:56.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:32:56.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-12T11:33:26.830+0000] {processor.py:157} INFO - Started process (PID=1628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:33:26.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:33:26.834+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:33:26.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:33:26.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:33:26.895+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:33:26.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:33:26.912+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:33:26.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:33:26.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-12T11:33:57.281+0000] {processor.py:157} INFO - Started process (PID=1653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:33:57.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:33:57.287+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:33:57.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:33:57.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:33:57.337+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:33:57.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:33:57.354+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:33:57.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:33:57.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-12T11:34:24.634+0000] {processor.py:157} INFO - Started process (PID=1678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:34:24.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:34:24.636+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:34:24.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:34:24.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:34:24.716+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:34:24.715+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:spark_data_processing_pipeline' as access control is unset.
[2024-07-12T11:34:24.716+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:34:24.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:34:24.728+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:34:24.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:34:24.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-12T11:34:55.103+0000] {processor.py:157} INFO - Started process (PID=1773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:34:55.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:34:55.110+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:34:55.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:34:55.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:34:55.167+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:34:55.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:34:55.182+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:34:55.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:34:55.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-12T11:35:25.521+0000] {processor.py:157} INFO - Started process (PID=1798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:35:25.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:35:25.524+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:35:25.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:35:25.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:35:25.555+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:35:25.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:35:25.570+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:35:25.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:35:25.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-12T11:35:56.008+0000] {processor.py:157} INFO - Started process (PID=1823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:35:56.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:35:56.012+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:35:56.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:35:56.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:35:56.053+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:35:56.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:35:56.068+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:35:56.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:35:56.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-12T11:36:26.502+0000] {processor.py:157} INFO - Started process (PID=1982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:36:26.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:36:26.508+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:36:26.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:36:26.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:36:26.555+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:36:26.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:36:26.572+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:36:26.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:36:26.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-12T11:36:56.906+0000] {processor.py:157} INFO - Started process (PID=2007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:36:56.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:36:56.917+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:36:56.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:36:56.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:36:56.966+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:36:56.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:36:56.984+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:36:56.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:36:56.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-12T11:37:27.342+0000] {processor.py:157} INFO - Started process (PID=2032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:37:27.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:37:27.353+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:37:27.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:37:27.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:37:27.430+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:37:27.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:37:27.449+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:37:27.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:37:27.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-12T11:37:57.734+0000] {processor.py:157} INFO - Started process (PID=2456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:37:57.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:37:57.740+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:37:57.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:37:57.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:37:57.786+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:37:57.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:37:57.800+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:37:57.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:37:57.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-12T11:38:28.166+0000] {processor.py:157} INFO - Started process (PID=2481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:38:28.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:38:28.171+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:38:28.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:38:28.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:38:28.214+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:38:28.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:38:28.235+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:38:28.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:38:28.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-12T11:38:58.645+0000] {processor.py:157} INFO - Started process (PID=2506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:38:58.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:38:58.649+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:38:58.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:38:58.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:38:58.697+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:38:58.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:38:58.718+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:38:58.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:38:58.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-12T11:39:29.044+0000] {processor.py:157} INFO - Started process (PID=2531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:39:29.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:39:29.049+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:39:29.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:39:29.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:39:29.091+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:39:29.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:39:29.105+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:39:29.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:39:29.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-12T11:39:59.548+0000] {processor.py:157} INFO - Started process (PID=2556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:39:59.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:39:59.555+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:39:59.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:39:59.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:39:59.626+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:39:59.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:39:59.641+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:39:59.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:39:59.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-12T11:40:29.963+0000] {processor.py:157} INFO - Started process (PID=2581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:40:29.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:40:29.968+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:40:29.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:40:29.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:40:30.014+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:40:30.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:40:30.028+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:40:30.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:40:30.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-12T11:41:00.390+0000] {processor.py:157} INFO - Started process (PID=2606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:41:00.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:41:00.394+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:41:00.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:41:00.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:41:00.425+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:41:00.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:41:00.439+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:41:00.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:41:00.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-12T11:41:30.801+0000] {processor.py:157} INFO - Started process (PID=2631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:41:30.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:41:30.808+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:41:30.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:41:30.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:41:30.869+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:41:30.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:41:30.885+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:41:30.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:41:30.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-12T11:42:01.194+0000] {processor.py:157} INFO - Started process (PID=2656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:42:01.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:42:01.197+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:42:01.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:42:01.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:42:01.222+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:42:01.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:42:01.234+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:42:01.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:42:01.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T11:42:31.608+0000] {processor.py:157} INFO - Started process (PID=2681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:42:31.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:42:31.611+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:42:31.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:42:31.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:42:31.639+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:42:31.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:42:31.653+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:42:31.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:42:31.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T11:43:02.047+0000] {processor.py:157} INFO - Started process (PID=2706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:43:02.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:43:02.051+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:43:02.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:43:02.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:43:02.106+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:43:02.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:43:02.122+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:43:02.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:43:02.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-12T11:43:32.465+0000] {processor.py:157} INFO - Started process (PID=2731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:43:32.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:43:32.468+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:43:32.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:43:32.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:43:32.498+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:43:32.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:43:32.510+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:43:32.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:43:32.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T11:44:02.834+0000] {processor.py:157} INFO - Started process (PID=2756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:44:02.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:44:02.836+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:44:02.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:44:02.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:44:02.864+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:44:02.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:44:02.874+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:44:02.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:44:02.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T11:44:33.296+0000] {processor.py:157} INFO - Started process (PID=2781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:44:33.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:44:33.300+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:44:33.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:44:33.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:44:33.334+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:44:33.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:44:33.345+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:44:33.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:44:33.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T11:45:03.709+0000] {processor.py:157} INFO - Started process (PID=2806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:45:03.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:45:03.714+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:45:03.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:45:03.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:45:03.756+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:45:03.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:45:03.771+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:45:03.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:45:03.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-12T11:45:34.103+0000] {processor.py:157} INFO - Started process (PID=2831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:45:34.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:45:34.107+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:45:34.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:45:34.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:45:34.139+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:45:34.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:45:34.150+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:45:34.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:45:34.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T11:46:04.592+0000] {processor.py:157} INFO - Started process (PID=2856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:46:04.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:46:04.597+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:46:04.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:46:04.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:46:04.644+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:46:04.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:46:04.673+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:46:04.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:46:04.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-12T11:46:35.056+0000] {processor.py:157} INFO - Started process (PID=2881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:46:35.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:46:35.059+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:46:35.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:46:35.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:46:35.093+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:46:35.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:46:35.107+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:46:35.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:46:35.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-12T11:47:05.441+0000] {processor.py:157} INFO - Started process (PID=2906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:47:05.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:47:05.444+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:47:05.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:47:05.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:47:05.484+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:47:05.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:47:05.497+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:47:05.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:47:05.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-12T11:47:35.886+0000] {processor.py:157} INFO - Started process (PID=2931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:47:35.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:47:35.908+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:47:35.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:47:35.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:47:35.965+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:47:35.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:47:35.983+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:47:35.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:47:35.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-12T11:48:06.319+0000] {processor.py:157} INFO - Started process (PID=2956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:48:06.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:48:06.323+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:48:06.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:48:06.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:48:06.356+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:48:06.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:48:06.367+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:48:06.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:48:06.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T11:48:36.784+0000] {processor.py:157} INFO - Started process (PID=2981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:48:36.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:48:36.791+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:48:36.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:48:36.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:48:36.848+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:48:36.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:48:36.866+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:48:36.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:48:36.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-12T11:49:07.204+0000] {processor.py:157} INFO - Started process (PID=3006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:49:07.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:49:07.207+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:49:07.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:49:07.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:49:07.238+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:49:07.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:49:07.251+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:49:07.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:49:07.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T11:49:37.587+0000] {processor.py:157} INFO - Started process (PID=3031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:49:37.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:49:37.591+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:49:37.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:49:37.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:49:37.623+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:49:37.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:49:37.636+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:49:37.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:49:37.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T11:50:07.954+0000] {processor.py:157} INFO - Started process (PID=3056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:50:07.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:50:07.958+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:50:07.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:50:07.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:50:07.992+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:50:07.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:50:08.004+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:50:08.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:50:08.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-12T11:50:38.355+0000] {processor.py:157} INFO - Started process (PID=3081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:50:38.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:50:38.357+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:50:38.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:50:38.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:50:38.389+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:50:38.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:50:38.401+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:50:38.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:50:38.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-12T11:51:08.773+0000] {processor.py:157} INFO - Started process (PID=3106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:51:08.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:51:08.776+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:51:08.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:51:08.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:51:08.802+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:51:08.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:51:08.815+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:51:08.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:51:08.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T11:51:39.171+0000] {processor.py:157} INFO - Started process (PID=3131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:51:39.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:51:39.175+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:51:39.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:51:39.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:51:39.214+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:51:39.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:51:39.229+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:51:39.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:51:39.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-12T11:52:09.575+0000] {processor.py:157} INFO - Started process (PID=3156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:52:09.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:52:09.581+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:52:09.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:52:09.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:52:09.629+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:52:09.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:52:09.640+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:52:09.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:52:09.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-12T11:52:40.011+0000] {processor.py:157} INFO - Started process (PID=3181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:52:40.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:52:40.014+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:52:40.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:52:40.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:52:40.053+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:52:40.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:52:40.065+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:52:40.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:52:40.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-12T11:53:10.443+0000] {processor.py:157} INFO - Started process (PID=3206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:53:10.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:53:10.450+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:53:10.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:53:10.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:53:10.485+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:53:10.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:53:10.496+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:53:10.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:53:10.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-12T11:53:40.965+0000] {processor.py:157} INFO - Started process (PID=3231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:53:40.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:53:40.968+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:53:40.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:53:40.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:53:41.006+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:53:41.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:53:41.019+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:53:41.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:53:41.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-12T11:54:11.367+0000] {processor.py:157} INFO - Started process (PID=3256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:54:11.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:54:11.371+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:54:11.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:54:11.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:54:11.411+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:54:11.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:54:11.422+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:54:11.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:54:11.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-12T11:54:41.820+0000] {processor.py:157} INFO - Started process (PID=3281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:54:41.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:54:41.825+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:54:41.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:54:41.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:54:41.863+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:54:41.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:54:41.875+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:54:41.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:54:41.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-12T11:55:12.254+0000] {processor.py:157} INFO - Started process (PID=3306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:55:12.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:55:12.257+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:55:12.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:55:12.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:55:12.296+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:55:12.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:55:12.314+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:55:12.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:55:12.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-12T11:55:42.673+0000] {processor.py:157} INFO - Started process (PID=3331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:55:42.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:55:42.678+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:55:42.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:55:42.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:55:42.716+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:55:42.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:55:42.730+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:55:42.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:55:42.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-12T11:56:13.115+0000] {processor.py:157} INFO - Started process (PID=3356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:56:13.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:56:13.118+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:56:13.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:56:13.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:56:13.150+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:56:13.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:56:13.162+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:56:13.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:56:13.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T11:56:43.518+0000] {processor.py:157} INFO - Started process (PID=3381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:56:43.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:56:43.521+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:56:43.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:56:43.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:56:43.554+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:56:43.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:56:43.568+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:56:43.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:56:43.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-12T11:57:13.954+0000] {processor.py:157} INFO - Started process (PID=3406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:57:13.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:57:13.962+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:57:13.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:57:13.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:57:14.025+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:57:14.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:57:14.048+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:57:14.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:57:14.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-12T11:57:44.363+0000] {processor.py:157} INFO - Started process (PID=3431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:57:44.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T11:57:44.367+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:57:44.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:57:44.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T11:57:44.416+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:57:44.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T11:57:44.431+0000] {logging_mixin.py:151} INFO - [2024-07-12T11:57:44.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T11:57:44.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-12T12:32:56.006+0000] {processor.py:157} INFO - Started process (PID=3458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:32:56.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:32:56.010+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:32:56.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:32:56.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:32:56.050+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:32:56.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:32:56.072+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:32:56.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:32:56.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-12T12:33:26.615+0000] {processor.py:157} INFO - Started process (PID=3483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:33:26.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:33:26.618+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:33:26.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:33:26.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:33:26.653+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:33:26.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:33:26.663+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:33:26.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:33:26.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T12:49:15.913+0000] {processor.py:157} INFO - Started process (PID=3508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:49:15.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:49:15.921+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:49:15.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:49:15.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:49:15.990+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:49:15.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:49:16.018+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:49:16.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:49:16.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-12T12:49:46.428+0000] {processor.py:157} INFO - Started process (PID=3533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:49:46.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:49:46.432+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:49:46.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:49:46.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:49:46.460+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:49:46.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:49:46.474+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:49:46.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:49:46.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T12:50:16.826+0000] {processor.py:157} INFO - Started process (PID=3558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:50:16.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:50:16.830+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:50:16.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:50:16.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:50:16.857+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:50:16.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:50:16.869+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:50:16.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:50:16.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T12:50:47.308+0000] {processor.py:157} INFO - Started process (PID=3583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:50:47.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:50:47.312+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:50:47.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:50:47.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:50:47.340+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:50:47.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:50:47.355+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:50:47.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:50:47.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-12T12:51:17.738+0000] {processor.py:157} INFO - Started process (PID=3608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:51:17.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:51:17.740+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:51:17.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:51:17.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:51:17.770+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:51:17.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:51:17.781+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:51:17.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:51:17.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T12:51:48.178+0000] {processor.py:157} INFO - Started process (PID=3633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:51:48.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:51:48.183+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:51:48.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:51:48.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:51:48.209+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:51:48.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:51:48.219+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:51:48.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:51:48.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T12:52:18.611+0000] {processor.py:157} INFO - Started process (PID=3658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:52:18.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:52:18.613+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:52:18.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:52:18.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:52:18.640+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:52:18.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:52:18.652+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:52:18.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:52:18.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T12:52:49.053+0000] {processor.py:157} INFO - Started process (PID=3683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:52:49.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:52:49.056+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:52:49.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:52:49.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:52:49.097+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:52:49.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:52:49.110+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:52:49.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:52:49.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-12T12:53:19.452+0000] {processor.py:157} INFO - Started process (PID=3708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:53:19.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:53:19.456+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:53:19.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:53:19.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:53:19.487+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:53:19.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:53:19.497+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:53:19.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:53:19.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T12:53:49.819+0000] {processor.py:157} INFO - Started process (PID=3733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:53:49.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:53:49.822+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:53:49.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:53:49.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:53:49.852+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:53:49.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:53:49.862+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:53:49.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:53:49.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T12:54:20.195+0000] {processor.py:157} INFO - Started process (PID=3758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:54:20.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:54:20.198+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:54:20.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:54:20.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:54:20.223+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:54:20.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:54:20.233+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:54:20.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:54:20.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T12:54:50.655+0000] {processor.py:157} INFO - Started process (PID=3783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:54:50.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:54:50.658+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:54:50.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:54:50.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:54:50.688+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:54:50.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:54:50.699+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:54:50.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:54:50.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T12:55:21.099+0000] {processor.py:157} INFO - Started process (PID=3808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:55:21.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:55:21.101+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:55:21.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:55:21.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:55:21.133+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:55:21.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:55:21.144+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:55:21.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:55:21.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T12:55:51.580+0000] {processor.py:157} INFO - Started process (PID=3833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:55:51.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:55:51.584+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:55:51.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:55:51.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:55:51.615+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:55:51.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:55:51.625+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:55:51.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:55:51.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T12:56:22.115+0000] {processor.py:157} INFO - Started process (PID=3858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:56:22.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:56:22.118+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:56:22.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:56:22.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:56:22.141+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:56:22.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:56:22.151+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:56:22.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:56:22.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T12:56:52.572+0000] {processor.py:157} INFO - Started process (PID=3883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:56:52.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:56:52.575+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:56:52.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:56:52.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:56:52.604+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:56:52.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:56:52.615+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:56:52.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:56:52.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T12:57:23.003+0000] {processor.py:157} INFO - Started process (PID=3908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:57:23.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:57:23.006+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:57:23.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:57:23.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:57:23.030+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:57:23.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:57:23.040+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:57:23.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:57:23.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T12:57:53.435+0000] {processor.py:157} INFO - Started process (PID=3933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:57:53.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:57:53.438+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:57:53.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:57:53.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:57:53.464+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:57:53.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:57:53.476+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:57:53.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:57:53.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T12:58:23.862+0000] {processor.py:157} INFO - Started process (PID=3958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:58:23.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:58:23.864+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:58:23.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:58:23.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:58:23.889+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:58:23.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:58:23.906+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:58:23.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:58:23.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T12:58:54.316+0000] {processor.py:157} INFO - Started process (PID=3983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:58:54.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:58:54.318+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:58:54.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:58:54.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:58:54.343+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:58:54.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:58:54.359+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:58:54.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:58:54.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T12:59:24.821+0000] {processor.py:157} INFO - Started process (PID=4008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:59:24.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:59:24.823+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:59:24.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:59:24.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:59:24.849+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:59:24.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:59:24.864+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:59:24.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:59:24.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T12:59:55.254+0000] {processor.py:157} INFO - Started process (PID=4033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:59:55.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T12:59:55.257+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:59:55.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:59:55.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T12:59:55.284+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:59:55.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T12:59:55.294+0000] {logging_mixin.py:151} INFO - [2024-07-12T12:59:55.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T12:59:55.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:00:25.700+0000] {processor.py:157} INFO - Started process (PID=4058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:00:25.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:00:25.703+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:00:25.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:00:25.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:00:25.728+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:00:25.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:00:25.738+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:00:25.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:00:25.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:00:56.072+0000] {processor.py:157} INFO - Started process (PID=4083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:00:56.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:00:56.075+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:00:56.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:00:56.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:00:56.110+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:00:56.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:00:56.122+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:00:56.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:00:56.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-12T13:01:26.505+0000] {processor.py:157} INFO - Started process (PID=4108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:01:26.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:01:26.507+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:01:26.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:01:26.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:01:26.534+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:01:26.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:01:26.547+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:01:26.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:01:26.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T13:01:56.874+0000] {processor.py:157} INFO - Started process (PID=4133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:01:56.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:01:56.876+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:01:56.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:01:56.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:01:56.901+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:01:56.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:01:56.912+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:01:56.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:01:56.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:02:27.270+0000] {processor.py:157} INFO - Started process (PID=4158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:02:27.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:02:27.273+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:02:27.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:02:27.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:02:27.304+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:02:27.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:02:27.315+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:02:27.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:02:27.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T13:02:57.654+0000] {processor.py:157} INFO - Started process (PID=4183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:02:57.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:02:57.657+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:02:57.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:02:57.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:02:57.688+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:02:57.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:02:57.699+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:02:57.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:02:57.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T13:03:28.077+0000] {processor.py:157} INFO - Started process (PID=4208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:03:28.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:03:28.079+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:03:28.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:03:28.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:03:28.108+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:03:28.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:03:28.118+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:03:28.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:03:28.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T13:03:58.521+0000] {processor.py:157} INFO - Started process (PID=4233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:03:58.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:03:58.524+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:03:58.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:03:58.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:03:58.553+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:03:58.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:03:58.566+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:03:58.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:03:58.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T13:04:28.914+0000] {processor.py:157} INFO - Started process (PID=4258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:04:28.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:04:28.917+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:04:28.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:04:28.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:04:28.943+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:04:28.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:04:28.952+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:04:28.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:04:28.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:04:59.305+0000] {processor.py:157} INFO - Started process (PID=4283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:04:59.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:04:59.307+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:04:59.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:04:59.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:04:59.333+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:04:59.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:04:59.345+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:04:59.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:04:59.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:05:29.724+0000] {processor.py:157} INFO - Started process (PID=4308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:05:29.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:05:29.727+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:05:29.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:05:29.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:05:29.755+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:05:29.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:05:29.768+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:05:29.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:05:29.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T13:06:00.117+0000] {processor.py:157} INFO - Started process (PID=4333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:06:00.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:06:00.121+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:06:00.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:06:00.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:06:00.146+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:06:00.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:06:00.156+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:06:00.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:06:00.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T13:06:30.553+0000] {processor.py:157} INFO - Started process (PID=4358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:06:30.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:06:30.555+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:06:30.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:06:30.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:06:30.581+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:06:30.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:06:30.595+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:06:30.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:06:30.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:07:00.987+0000] {processor.py:157} INFO - Started process (PID=4383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:07:00.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:07:00.990+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:07:00.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:07:00.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:07:01.013+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:07:01.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:07:01.029+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:07:01.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:07:01.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T13:07:31.413+0000] {processor.py:157} INFO - Started process (PID=4408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:07:31.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:07:31.415+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:07:31.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:07:31.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:07:31.447+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:07:31.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:07:31.457+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:07:31.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:07:31.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T13:08:01.839+0000] {processor.py:157} INFO - Started process (PID=4433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:08:01.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:08:01.841+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:08:01.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:08:01.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:08:01.868+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:08:01.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:08:01.879+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:08:01.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:08:01.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:08:32.342+0000] {processor.py:157} INFO - Started process (PID=4458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:08:32.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:08:32.347+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:08:32.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:08:32.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:08:32.372+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:08:32.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:08:32.384+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:08:32.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:08:32.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T13:09:02.701+0000] {processor.py:157} INFO - Started process (PID=4483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:09:02.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:09:02.703+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:09:02.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:09:02.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:09:02.726+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:09:02.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:09:02.737+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:09:02.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:09:02.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-12T13:09:33.109+0000] {processor.py:157} INFO - Started process (PID=4508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:09:33.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:09:33.111+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:09:33.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:09:33.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:09:33.136+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:09:33.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:09:33.153+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:09:33.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:09:33.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T13:10:03.576+0000] {processor.py:157} INFO - Started process (PID=4533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:10:03.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:10:03.578+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:10:03.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:10:03.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:10:03.608+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:10:03.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:10:03.618+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:10:03.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:10:03.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:10:34.047+0000] {processor.py:157} INFO - Started process (PID=4558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:10:34.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:10:34.049+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:10:34.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:10:34.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:10:34.076+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:10:34.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:10:34.090+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:10:34.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:10:34.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T13:11:04.515+0000] {processor.py:157} INFO - Started process (PID=4583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:11:04.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:11:04.517+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:11:04.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:11:04.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:11:04.545+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:11:04.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:11:04.555+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:11:04.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:11:04.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-12T13:11:34.857+0000] {processor.py:157} INFO - Started process (PID=4608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:11:34.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:11:34.859+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:11:34.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:11:34.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:11:34.891+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:11:34.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:11:34.901+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:11:34.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:11:34.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T13:12:05.324+0000] {processor.py:157} INFO - Started process (PID=4633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:12:05.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:12:05.328+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:12:05.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:12:05.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:12:05.357+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:12:05.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:12:05.368+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:12:05.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:12:05.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T13:12:35.725+0000] {processor.py:157} INFO - Started process (PID=4658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:12:35.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:12:35.729+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:12:35.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:12:35.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:12:35.759+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:12:35.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:12:35.771+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:12:35.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:12:35.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T13:13:06.106+0000] {processor.py:157} INFO - Started process (PID=4683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:13:06.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:13:06.109+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:13:06.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:13:06.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:13:06.134+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:13:06.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:13:06.144+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:13:06.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:13:06.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:13:36.558+0000] {processor.py:157} INFO - Started process (PID=4708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:13:36.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:13:36.560+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:13:36.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:13:36.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:13:36.592+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:13:36.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:13:36.603+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:13:36.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:13:36.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T13:14:06.933+0000] {processor.py:157} INFO - Started process (PID=4733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:14:06.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:14:06.936+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:14:06.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:14:06.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:14:06.964+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:14:06.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:14:06.979+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:14:06.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:14:06.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T13:14:37.386+0000] {processor.py:157} INFO - Started process (PID=4758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:14:37.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:14:37.389+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:14:37.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:14:37.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:14:37.413+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:14:37.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:14:37.424+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:14:37.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:14:37.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:15:07.789+0000] {processor.py:157} INFO - Started process (PID=4783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:15:07.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:15:07.792+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:15:07.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:15:07.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:15:07.817+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:15:07.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:15:07.831+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:15:07.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:15:07.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T13:15:38.242+0000] {processor.py:157} INFO - Started process (PID=4808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:15:38.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:15:38.248+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:15:38.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:15:38.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:15:38.279+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:15:38.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:15:38.290+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:15:38.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:15:38.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T13:16:08.693+0000] {processor.py:157} INFO - Started process (PID=4833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:16:08.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:16:08.697+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:16:08.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:16:08.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:16:08.722+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:16:08.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:16:08.734+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:16:08.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:16:08.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T13:16:39.058+0000] {processor.py:157} INFO - Started process (PID=4858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:16:39.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:16:39.062+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:16:39.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:16:39.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:16:39.091+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:16:39.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:16:39.102+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:16:39.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:16:39.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T13:17:09.479+0000] {processor.py:157} INFO - Started process (PID=4883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:17:09.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:17:09.481+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:17:09.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:17:09.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:17:09.508+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:17:09.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:17:09.522+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:17:09.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:17:09.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T13:17:39.971+0000] {processor.py:157} INFO - Started process (PID=4908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:17:39.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:17:39.974+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:17:39.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:17:39.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:17:40.009+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:17:40.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:17:40.021+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:17:40.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:17:40.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-12T13:18:10.417+0000] {processor.py:157} INFO - Started process (PID=4933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:18:10.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:18:10.420+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:18:10.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:18:10.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:18:10.453+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:18:10.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:18:10.468+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:18:10.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:18:10.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T13:18:40.863+0000] {processor.py:157} INFO - Started process (PID=4958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:18:40.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:18:40.865+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:18:40.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:18:40.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:18:40.893+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:18:40.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:18:40.904+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:18:40.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:18:40.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:19:11.274+0000] {processor.py:157} INFO - Started process (PID=4983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:19:11.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:19:11.279+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:19:11.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:19:11.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:19:11.314+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:19:11.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:19:11.326+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:19:11.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:19:11.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-12T13:19:41.715+0000] {processor.py:157} INFO - Started process (PID=5008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:19:41.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:19:41.717+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:19:41.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:19:41.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:19:41.740+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:19:41.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:19:41.750+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:19:41.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:19:41.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-12T13:20:12.148+0000] {processor.py:157} INFO - Started process (PID=5033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:20:12.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:20:12.151+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:20:12.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:20:12.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:20:12.176+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:20:12.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:20:12.187+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:20:12.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:20:12.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T13:20:42.695+0000] {processor.py:157} INFO - Started process (PID=5058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:20:42.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:20:42.702+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:20:42.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:20:42.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:20:42.731+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:20:42.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:20:42.741+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:20:42.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:20:42.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T13:21:13.199+0000] {processor.py:157} INFO - Started process (PID=5083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:21:13.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:21:13.202+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:21:13.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:21:13.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:21:13.228+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:21:13.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:21:13.238+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:21:13.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:21:13.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:21:43.639+0000] {processor.py:157} INFO - Started process (PID=5108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:21:43.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:21:43.642+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:21:43.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:21:43.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:21:43.670+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:21:43.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:21:43.679+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:21:43.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:21:43.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:22:14.106+0000] {processor.py:157} INFO - Started process (PID=5133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:22:14.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:22:14.108+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:22:14.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:22:14.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:22:14.134+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:22:14.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:22:14.145+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:22:14.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:22:14.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:22:44.488+0000] {processor.py:157} INFO - Started process (PID=5158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:22:44.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:22:44.490+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:22:44.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:22:44.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:22:44.519+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:22:44.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:22:44.530+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:22:44.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:22:44.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T13:23:14.977+0000] {processor.py:157} INFO - Started process (PID=5183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:23:14.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:23:14.980+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:23:14.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:23:14.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:23:15.009+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:23:15.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:23:15.021+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:23:15.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:23:15.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T13:23:45.417+0000] {processor.py:157} INFO - Started process (PID=5208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:23:45.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:23:45.419+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:23:45.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:23:45.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:23:45.442+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:23:45.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:23:45.455+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:23:45.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:23:45.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T13:24:15.768+0000] {processor.py:157} INFO - Started process (PID=5233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:24:15.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:24:15.771+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:24:15.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:24:15.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:24:15.800+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:24:15.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:24:15.811+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:24:15.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:24:15.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:24:46.131+0000] {processor.py:157} INFO - Started process (PID=5258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:24:46.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:24:46.133+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:24:46.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:24:46.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:24:46.163+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:24:46.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:24:46.173+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:24:46.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:24:46.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T13:25:16.539+0000] {processor.py:157} INFO - Started process (PID=5283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:25:16.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:25:16.541+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:25:16.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:25:16.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:25:16.570+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:25:16.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:25:16.581+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:25:16.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:25:16.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:25:46.903+0000] {processor.py:157} INFO - Started process (PID=5308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:25:46.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:25:46.905+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:25:46.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:25:46.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:25:46.930+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:25:46.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:25:46.940+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:25:46.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:25:46.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:26:17.408+0000] {processor.py:157} INFO - Started process (PID=5333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:26:17.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:26:17.412+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:26:17.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:26:17.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:26:17.437+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:26:17.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:26:17.448+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:26:17.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:26:17.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T13:26:47.785+0000] {processor.py:157} INFO - Started process (PID=5358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:26:47.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:26:47.789+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:26:47.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:26:47.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:26:47.815+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:26:47.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:26:47.825+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:26:47.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:26:47.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T13:27:18.204+0000] {processor.py:157} INFO - Started process (PID=5383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:27:18.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:27:18.207+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:27:18.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:27:18.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:27:18.230+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:27:18.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:27:18.244+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:27:18.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:27:18.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T13:27:48.643+0000] {processor.py:157} INFO - Started process (PID=5408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:27:48.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:27:48.645+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:27:48.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:27:48.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:27:48.674+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:27:48.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:27:48.685+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:27:48.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:27:48.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T13:28:19.069+0000] {processor.py:157} INFO - Started process (PID=5433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:28:19.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:28:19.071+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:28:19.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:28:19.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:28:19.095+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:28:19.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:28:19.106+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:28:19.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:28:19.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-12T13:28:49.576+0000] {processor.py:157} INFO - Started process (PID=5458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:28:49.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:28:49.578+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:28:49.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:28:49.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:28:49.602+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:28:49.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:28:49.617+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:28:49.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:28:49.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T13:29:19.968+0000] {processor.py:157} INFO - Started process (PID=5483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:29:19.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:29:19.969+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:29:19.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:29:19.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:29:19.997+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:29:19.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:29:20.008+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:29:20.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:29:20.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T13:29:50.392+0000] {processor.py:157} INFO - Started process (PID=5508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:29:50.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:29:50.395+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:29:50.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:29:50.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:29:50.423+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:29:50.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:29:50.433+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:29:50.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:29:50.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T13:30:20.797+0000] {processor.py:157} INFO - Started process (PID=5533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:30:20.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:30:20.800+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:30:20.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:30:20.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:30:20.828+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:30:20.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:30:20.838+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:30:20.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:30:20.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T13:30:51.234+0000] {processor.py:157} INFO - Started process (PID=5558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:30:51.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:30:51.237+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:30:51.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:30:51.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:30:51.263+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:30:51.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:30:51.274+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:30:51.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:30:51.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T13:31:21.606+0000] {processor.py:157} INFO - Started process (PID=5583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:31:21.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:31:21.610+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:31:21.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:31:21.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:31:21.634+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:31:21.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:31:21.649+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:31:21.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:31:21.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T13:31:52.069+0000] {processor.py:157} INFO - Started process (PID=5608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:31:52.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:31:52.072+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:31:52.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:31:52.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:31:52.098+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:31:52.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:31:52.115+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:31:52.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:31:52.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-12T13:32:22.497+0000] {processor.py:157} INFO - Started process (PID=5633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:32:22.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:32:22.499+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:32:22.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:32:22.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:32:22.528+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:32:22.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:32:22.539+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:32:22.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:32:22.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T13:32:52.929+0000] {processor.py:157} INFO - Started process (PID=5658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:32:52.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:32:52.931+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:32:52.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:32:52.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:32:52.963+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:32:52.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:32:52.977+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:32:52.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:32:52.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T13:49:27.828+0000] {processor.py:157} INFO - Started process (PID=5683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:49:27.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T13:49:27.833+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:49:27.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:49:27.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T13:49:27.876+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:49:27.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T13:49:27.893+0000] {logging_mixin.py:151} INFO - [2024-07-12T13:49:27.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T13:49:27.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-12T14:05:35.836+0000] {processor.py:157} INFO - Started process (PID=5712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:05:35.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:05:35.838+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:05:35.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:05:35.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:05:35.874+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:05:35.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:05:35.885+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:05:35.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:05:35.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-12T14:06:06.244+0000] {processor.py:157} INFO - Started process (PID=5737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:06:06.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:06:06.247+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:06:06.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:06:06.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:06:06.274+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:06:06.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:06:06.284+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:06:06.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:06:06.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:23:12.743+0000] {processor.py:157} INFO - Started process (PID=5762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:23:12.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:23:12.747+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:23:12.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:23:12.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:23:12.771+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:23:12.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:23:12.787+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:23:12.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:23:12.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-12T14:23:43.158+0000] {processor.py:157} INFO - Started process (PID=5787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:23:43.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:23:43.161+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:23:43.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:23:43.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:23:43.189+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:23:43.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:23:43.199+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:23:43.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:23:43.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:24:13.526+0000] {processor.py:157} INFO - Started process (PID=5812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:24:13.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:24:13.528+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:24:13.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:24:13.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:24:13.562+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:24:13.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:24:13.574+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:24:13.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:24:13.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-12T14:24:43.908+0000] {processor.py:157} INFO - Started process (PID=5837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:24:43.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:24:43.910+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:24:43.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:24:43.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:24:43.939+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:24:43.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:24:43.950+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:24:43.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:24:43.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:25:14.258+0000] {processor.py:157} INFO - Started process (PID=5862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:25:14.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:25:14.261+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:25:14.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:25:14.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:25:14.293+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:25:14.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:25:14.307+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:25:14.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:25:14.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-12T14:25:44.644+0000] {processor.py:157} INFO - Started process (PID=5887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:25:44.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:25:44.647+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:25:44.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:25:44.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:25:44.676+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:25:44.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:25:44.690+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:25:44.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:25:44.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T14:26:15.030+0000] {processor.py:157} INFO - Started process (PID=5912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:26:15.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:26:15.032+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:26:15.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:26:15.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:26:15.061+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:26:15.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:26:15.072+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:26:15.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:26:15.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T14:26:45.468+0000] {processor.py:157} INFO - Started process (PID=5937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:26:45.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:26:45.470+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:26:45.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:26:45.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:26:45.501+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:26:45.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:26:45.511+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:26:45.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:26:45.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T14:27:15.866+0000] {processor.py:157} INFO - Started process (PID=5962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:27:15.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:27:15.869+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:27:15.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:27:15.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:27:15.897+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:27:15.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:27:15.912+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:27:15.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:27:15.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T14:27:46.282+0000] {processor.py:157} INFO - Started process (PID=5987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:27:46.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:27:46.285+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:27:46.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:27:46.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:27:46.310+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:27:46.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:27:46.321+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:27:46.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:27:46.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:28:16.683+0000] {processor.py:157} INFO - Started process (PID=6012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:28:16.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:28:16.684+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:28:16.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:28:16.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:28:16.710+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:28:16.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:28:16.723+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:28:16.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:28:16.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T14:28:47.106+0000] {processor.py:157} INFO - Started process (PID=6037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:28:47.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:28:47.109+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:28:47.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:28:47.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:28:47.133+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:28:47.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:28:47.146+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:28:47.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:28:47.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:29:17.462+0000] {processor.py:157} INFO - Started process (PID=6062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:29:17.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:29:17.465+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:29:17.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:29:17.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:29:17.492+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:29:17.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:29:17.503+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:29:17.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:29:17.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:29:47.883+0000] {processor.py:157} INFO - Started process (PID=6087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:29:47.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:29:47.886+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:29:47.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:29:47.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:29:47.914+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:29:47.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:29:47.925+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:29:47.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:29:47.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:30:18.246+0000] {processor.py:157} INFO - Started process (PID=6112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:30:18.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:30:18.250+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:30:18.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:30:18.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:30:18.276+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:30:18.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:30:18.287+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:30:18.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:30:18.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:30:48.600+0000] {processor.py:157} INFO - Started process (PID=6137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:30:48.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:30:48.604+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:30:48.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:30:48.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:30:48.630+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:30:48.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:30:48.640+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:30:48.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:30:48.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T14:31:19.036+0000] {processor.py:157} INFO - Started process (PID=6162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:31:19.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:31:19.039+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:31:19.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:31:19.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:31:19.063+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:31:19.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:31:19.074+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:31:19.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:31:19.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T14:31:49.468+0000] {processor.py:157} INFO - Started process (PID=6187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:31:49.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:31:49.470+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:31:49.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:31:49.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:31:49.493+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:31:49.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:31:49.506+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:31:49.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:31:49.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:32:19.846+0000] {processor.py:157} INFO - Started process (PID=6212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:32:19.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:32:19.849+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:32:19.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:32:19.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:32:19.878+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:32:19.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:32:19.888+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:32:19.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:32:19.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T14:32:50.271+0000] {processor.py:157} INFO - Started process (PID=6237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:32:50.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:32:50.272+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:32:50.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:32:50.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:32:50.296+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:32:50.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:32:50.307+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:32:50.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:32:50.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-12T14:33:20.667+0000] {processor.py:157} INFO - Started process (PID=6262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:33:20.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:33:20.670+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:33:20.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:33:20.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:33:20.700+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:33:20.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:33:20.711+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:33:20.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:33:20.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T14:33:51.008+0000] {processor.py:157} INFO - Started process (PID=6287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:33:51.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:33:51.012+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:33:51.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:33:51.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:33:51.041+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:33:51.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:33:51.051+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:33:51.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:33:51.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T14:34:21.368+0000] {processor.py:157} INFO - Started process (PID=6312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:34:21.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:34:21.374+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:34:21.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:34:21.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:34:21.398+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:34:21.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:34:21.409+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:34:21.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:34:21.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T14:34:51.733+0000] {processor.py:157} INFO - Started process (PID=6337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:34:51.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:34:51.734+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:34:51.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:34:51.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:34:51.760+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:34:51.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:34:51.770+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:34:51.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:34:51.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T14:35:22.149+0000] {processor.py:157} INFO - Started process (PID=6362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:35:22.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:35:22.152+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:35:22.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:35:22.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:35:22.177+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:35:22.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:35:22.191+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:35:22.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:35:22.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:35:52.570+0000] {processor.py:157} INFO - Started process (PID=6387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:35:52.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:35:52.573+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:35:52.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:35:52.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:35:52.598+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:35:52.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:35:52.608+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:35:52.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:35:52.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T14:36:22.951+0000] {processor.py:157} INFO - Started process (PID=6412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:36:22.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:36:22.955+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:36:22.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:36:22.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:36:22.980+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:36:22.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:36:22.993+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:36:22.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:36:23.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:36:53.300+0000] {processor.py:157} INFO - Started process (PID=6437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:36:53.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:36:53.303+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:36:53.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:36:53.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:36:53.328+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:36:53.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:36:53.337+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:36:53.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:36:53.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-12T14:37:23.667+0000] {processor.py:157} INFO - Started process (PID=6462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:37:23.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:37:23.670+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:37:23.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:37:23.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:37:23.697+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:37:23.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:37:23.708+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:37:23.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:37:23.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:37:54.003+0000] {processor.py:157} INFO - Started process (PID=6487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:37:54.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:37:54.006+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:37:54.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:37:54.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:37:54.030+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:37:54.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:37:54.041+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:37:54.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:37:54.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T14:38:24.402+0000] {processor.py:157} INFO - Started process (PID=6512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:38:24.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:38:24.403+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:38:24.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:38:24.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:38:24.431+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:38:24.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:38:24.441+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:38:24.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:38:24.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T14:38:54.790+0000] {processor.py:157} INFO - Started process (PID=6537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:38:54.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:38:54.795+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:38:54.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:38:54.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:38:54.821+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:38:54.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:38:54.831+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:38:54.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:38:54.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:39:25.155+0000] {processor.py:157} INFO - Started process (PID=6562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:39:25.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:39:25.160+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:39:25.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:39:25.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:39:25.191+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:39:25.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:39:25.201+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:39:25.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:39:25.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T14:39:55.559+0000] {processor.py:157} INFO - Started process (PID=6587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:39:55.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:39:55.561+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:39:55.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:39:55.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:39:55.584+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:39:55.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:39:55.595+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:39:55.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:39:55.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-12T14:40:25.921+0000] {processor.py:157} INFO - Started process (PID=6612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:40:25.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:40:25.924+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:40:25.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:40:25.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:40:25.952+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:40:25.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:40:25.963+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:40:25.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:40:25.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:40:56.293+0000] {processor.py:157} INFO - Started process (PID=6637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:40:56.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:40:56.295+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:40:56.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:40:56.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:40:56.323+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:40:56.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:40:56.335+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:40:56.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:40:56.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T14:41:26.698+0000] {processor.py:157} INFO - Started process (PID=6662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:41:26.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:41:26.700+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:41:26.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:41:26.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:41:26.726+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:41:26.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:41:26.736+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:41:26.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:41:26.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:41:57.031+0000] {processor.py:157} INFO - Started process (PID=6687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:41:57.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:41:57.033+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:41:57.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:41:57.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:41:57.057+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:41:57.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:41:57.066+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:41:57.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:41:57.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-12T14:42:27.416+0000] {processor.py:157} INFO - Started process (PID=6712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:42:27.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:42:27.419+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:42:27.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:42:27.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:42:27.456+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:42:27.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:42:27.468+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:42:27.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:42:27.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-12T14:42:57.831+0000] {processor.py:157} INFO - Started process (PID=6737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:42:57.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:42:57.833+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:42:57.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:42:57.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:42:57.854+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:42:57.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:42:57.865+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:42:57.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:42:57.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-12T14:43:28.200+0000] {processor.py:157} INFO - Started process (PID=6762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:43:28.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:43:28.205+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:43:28.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:43:28.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:43:28.235+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:43:28.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:43:28.247+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:43:28.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:43:28.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T14:43:58.623+0000] {processor.py:157} INFO - Started process (PID=6787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:43:58.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:43:58.625+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:43:58.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:43:58.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:43:58.654+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:43:58.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:43:58.664+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:43:58.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:43:58.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:44:28.997+0000] {processor.py:157} INFO - Started process (PID=6812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:44:28.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:44:28.999+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:44:28.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:44:29.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:44:29.025+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:44:29.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:44:29.038+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:44:29.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:44:29.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:44:59.396+0000] {processor.py:157} INFO - Started process (PID=6837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:44:59.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:44:59.399+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:44:59.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:44:59.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:44:59.425+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:44:59.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:44:59.436+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:44:59.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:44:59.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:45:29.804+0000] {processor.py:157} INFO - Started process (PID=6862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:45:29.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:45:29.807+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:45:29.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:45:29.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:45:29.833+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:45:29.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:45:29.844+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:45:29.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:45:29.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T14:46:00.152+0000] {processor.py:157} INFO - Started process (PID=6887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:46:00.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:46:00.155+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:46:00.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:46:00.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:46:00.187+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:46:00.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:46:00.197+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:46:00.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:46:00.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T14:46:30.516+0000] {processor.py:157} INFO - Started process (PID=6912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:46:30.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:46:30.518+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:46:30.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:46:30.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:46:30.548+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:46:30.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:46:30.559+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:46:30.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:46:30.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T14:47:00.949+0000] {processor.py:157} INFO - Started process (PID=6937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:47:00.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:47:00.953+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:47:00.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:47:00.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:47:00.979+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:47:00.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:47:00.989+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:47:00.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:47:01.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:47:31.359+0000] {processor.py:157} INFO - Started process (PID=6962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:47:31.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:47:31.362+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:47:31.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:47:31.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:47:31.387+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:47:31.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:47:31.396+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:47:31.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:47:31.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-12T14:48:01.737+0000] {processor.py:157} INFO - Started process (PID=6987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:48:01.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:48:01.739+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:48:01.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:48:01.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:48:01.763+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:48:01.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:48:01.778+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:48:01.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:48:01.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T14:48:32.152+0000] {processor.py:157} INFO - Started process (PID=7012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:48:32.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:48:32.154+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:48:32.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:48:32.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:48:32.180+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:48:32.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:48:32.193+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:48:32.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:48:32.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:49:02.593+0000] {processor.py:157} INFO - Started process (PID=7037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:49:02.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:49:02.595+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:49:02.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:49:02.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:49:02.621+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:49:02.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:49:02.636+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:49:02.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:49:02.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:49:33.014+0000] {processor.py:157} INFO - Started process (PID=7062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:49:33.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:49:33.016+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:49:33.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:49:33.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:49:33.045+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:49:33.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:49:33.058+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:49:33.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:49:33.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:50:03.377+0000] {processor.py:157} INFO - Started process (PID=7087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:50:03.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:50:03.378+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:50:03.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:50:03.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:50:03.409+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:50:03.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:50:03.420+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:50:03.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:50:03.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:50:33.810+0000] {processor.py:157} INFO - Started process (PID=7112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:50:33.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:50:33.812+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:50:33.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:50:33.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:50:33.840+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:50:33.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:50:33.855+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:50:33.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:50:33.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T14:51:04.207+0000] {processor.py:157} INFO - Started process (PID=7137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:51:04.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:51:04.209+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:51:04.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:51:04.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:51:04.234+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:51:04.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:51:04.244+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:51:04.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:51:04.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T14:51:34.640+0000] {processor.py:157} INFO - Started process (PID=7162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:51:34.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:51:34.643+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:51:34.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:51:34.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:51:34.672+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:51:34.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:51:34.683+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:51:34.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:51:34.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:52:05.050+0000] {processor.py:157} INFO - Started process (PID=7187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:52:05.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:52:05.053+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:52:05.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:52:05.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:52:05.076+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:52:05.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:52:05.086+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:52:05.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:52:05.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-12T14:52:35.455+0000] {processor.py:157} INFO - Started process (PID=7212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:52:35.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:52:35.458+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:52:35.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:52:35.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:52:35.481+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:52:35.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:52:35.492+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:52:35.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:52:35.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-12T14:53:05.847+0000] {processor.py:157} INFO - Started process (PID=7237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:53:05.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:53:05.849+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:53:05.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:53:05.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:53:05.873+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:53:05.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:53:05.883+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:53:05.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:53:05.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-12T14:53:36.223+0000] {processor.py:157} INFO - Started process (PID=7262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:53:36.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:53:36.227+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:53:36.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:53:36.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:53:36.253+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:53:36.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:53:36.266+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:53:36.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:53:36.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:54:06.641+0000] {processor.py:157} INFO - Started process (PID=7287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:54:06.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:54:06.643+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:54:06.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:54:06.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:54:06.668+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:54:06.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:54:06.680+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:54:06.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:54:06.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T14:54:37.037+0000] {processor.py:157} INFO - Started process (PID=7312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:54:37.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:54:37.040+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:54:37.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:54:37.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:54:37.063+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:54:37.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:54:37.074+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:54:37.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:54:37.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T14:55:07.394+0000] {processor.py:157} INFO - Started process (PID=7337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:55:07.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:55:07.397+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:55:07.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:55:07.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:55:07.422+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:55:07.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:55:07.433+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:55:07.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:55:07.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T14:55:37.795+0000] {processor.py:157} INFO - Started process (PID=7362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:55:37.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:55:37.799+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:55:37.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:55:37.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:55:37.826+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:55:37.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:55:37.836+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:55:37.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:55:37.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:56:08.202+0000] {processor.py:157} INFO - Started process (PID=7387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:56:08.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:56:08.204+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:56:08.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:56:08.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:56:08.229+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:56:08.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:56:08.240+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:56:08.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:56:08.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T14:56:38.630+0000] {processor.py:157} INFO - Started process (PID=7412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:56:38.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:56:38.632+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:56:38.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:56:38.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:56:38.656+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:56:38.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:56:38.667+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:56:38.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:56:38.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T14:57:08.989+0000] {processor.py:157} INFO - Started process (PID=7437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:57:08.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:57:08.991+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:57:08.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:57:09.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:57:09.024+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:57:09.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:57:09.035+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:57:09.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:57:09.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T14:57:39.393+0000] {processor.py:157} INFO - Started process (PID=7462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:57:39.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:57:39.396+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:57:39.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:57:39.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:57:39.423+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:57:39.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:57:39.434+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:57:39.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:57:39.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:58:09.768+0000] {processor.py:157} INFO - Started process (PID=7487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:58:09.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:58:09.770+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:58:09.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:58:09.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:58:09.797+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:58:09.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:58:09.807+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:58:09.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:58:09.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T14:58:40.184+0000] {processor.py:157} INFO - Started process (PID=7512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:58:40.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:58:40.188+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:58:40.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:58:40.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:58:40.214+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:58:40.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:58:40.227+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:58:40.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:58:40.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T14:59:10.598+0000] {processor.py:157} INFO - Started process (PID=7537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:59:10.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:59:10.601+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:59:10.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:59:10.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:59:10.625+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:59:10.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:59:10.637+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:59:10.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:59:10.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T14:59:41.029+0000] {processor.py:157} INFO - Started process (PID=7562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:59:41.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T14:59:41.031+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:59:41.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:59:41.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T14:59:41.058+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:59:41.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T14:59:41.069+0000] {logging_mixin.py:151} INFO - [2024-07-12T14:59:41.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T14:59:41.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T15:00:11.457+0000] {processor.py:157} INFO - Started process (PID=7587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:00:11.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:00:11.462+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:00:11.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:00:11.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:00:11.497+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:00:11.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:00:11.513+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:00:11.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:00:11.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-12T15:00:41.864+0000] {processor.py:157} INFO - Started process (PID=7612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:00:41.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:00:41.867+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:00:41.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:00:41.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:00:41.892+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:00:41.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:00:41.902+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:00:41.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:00:41.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-12T15:01:12.289+0000] {processor.py:157} INFO - Started process (PID=7637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:01:12.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:01:12.291+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:01:12.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:01:12.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:01:12.321+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:01:12.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:01:12.331+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:01:12.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:01:12.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T15:01:42.662+0000] {processor.py:157} INFO - Started process (PID=7662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:01:42.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:01:42.667+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:01:42.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:01:42.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:01:42.694+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:01:42.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:01:42.704+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:01:42.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:01:42.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T15:02:13.065+0000] {processor.py:157} INFO - Started process (PID=7687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:02:13.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:02:13.068+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:02:13.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:02:13.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:02:13.094+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:02:13.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:02:13.104+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:02:13.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:02:13.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-12T15:02:43.509+0000] {processor.py:157} INFO - Started process (PID=7712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:02:43.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:02:43.512+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:02:43.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:02:43.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:02:43.541+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:02:43.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:02:43.553+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:02:43.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:02:43.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-12T15:03:13.927+0000] {processor.py:157} INFO - Started process (PID=7737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:03:13.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:03:13.931+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:03:13.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:03:13.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:03:13.960+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:03:13.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:03:13.971+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:03:13.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:03:13.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T15:03:44.382+0000] {processor.py:157} INFO - Started process (PID=7762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:03:44.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:03:44.385+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:03:44.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:03:44.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:03:44.412+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:03:44.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:03:44.424+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:03:44.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:03:44.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-12T15:04:14.816+0000] {processor.py:157} INFO - Started process (PID=7787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:04:14.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:04:14.819+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:04:14.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:04:14.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:04:14.844+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:04:14.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:04:14.860+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:04:14.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:04:14.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T15:04:45.228+0000] {processor.py:157} INFO - Started process (PID=7812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:04:45.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:04:45.230+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:04:45.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:04:45.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:04:45.255+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:04:45.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:04:45.267+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:04:45.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:04:45.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T15:05:15.654+0000] {processor.py:157} INFO - Started process (PID=7837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:05:15.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:05:15.656+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:05:15.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:05:15.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:05:15.685+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:05:15.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:05:15.695+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:05:15.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:05:15.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-12T15:05:46.037+0000] {processor.py:157} INFO - Started process (PID=7862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:05:46.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:05:46.040+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:05:46.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:05:46.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:05:46.069+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:05:46.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:05:46.081+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:05:46.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:05:46.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-12T15:06:16.470+0000] {processor.py:157} INFO - Started process (PID=7887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:06:16.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:06:16.472+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:06:16.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:06:16.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:06:16.496+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:06:16.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:06:16.510+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:06:16.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:06:16.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-12T15:06:46.880+0000] {processor.py:157} INFO - Started process (PID=7912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:06:46.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:06:46.887+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:06:46.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:06:46.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:06:46.915+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:06:46.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:06:46.927+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:06:46.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:06:46.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T15:07:17.268+0000] {processor.py:157} INFO - Started process (PID=7937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:07:17.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:07:17.272+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:07:17.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:07:17.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:07:17.297+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:07:17.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:07:17.307+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:07:17.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:07:17.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T15:07:47.696+0000] {processor.py:157} INFO - Started process (PID=7962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:07:47.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:07:47.698+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:07:47.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:07:47.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:07:47.727+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:07:47.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:07:47.737+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:07:47.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:07:47.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T15:08:18.107+0000] {processor.py:157} INFO - Started process (PID=7987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:08:18.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:08:18.110+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:08:18.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:08:18.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:08:18.136+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:08:18.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:08:18.149+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:08:18.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:08:18.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T15:08:48.497+0000] {processor.py:157} INFO - Started process (PID=8012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:08:48.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:08:48.500+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:08:48.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:08:48.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:08:48.523+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:08:48.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:08:48.534+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:08:48.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:08:48.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-12T15:09:18.895+0000] {processor.py:157} INFO - Started process (PID=8037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:09:18.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:09:18.897+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:09:18.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:09:18.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:09:18.926+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:09:18.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:09:18.936+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:09:18.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:09:18.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T15:09:49.308+0000] {processor.py:157} INFO - Started process (PID=8062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:09:49.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:09:49.310+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:09:49.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:09:49.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:09:49.338+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:09:49.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:09:49.348+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:09:49.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:09:49.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-12T15:10:19.727+0000] {processor.py:157} INFO - Started process (PID=8087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:10:19.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:10:19.731+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:10:19.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:10:19.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:10:19.761+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:10:19.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:10:19.772+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:10:19.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:10:19.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-12T15:10:50.094+0000] {processor.py:157} INFO - Started process (PID=8112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:10:50.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:10:50.097+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:10:50.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:10:50.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:10:50.126+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:10:50.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:10:50.137+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:10:50.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:10:50.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-12T15:11:20.470+0000] {processor.py:157} INFO - Started process (PID=8137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:11:20.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:11:20.473+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:11:20.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:11:20.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:11:20.510+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:11:20.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:11:20.523+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:11:20.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:11:20.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-12T15:34:10.464+0000] {processor.py:157} INFO - Started process (PID=8162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:34:10.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T15:34:10.467+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:34:10.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:34:10.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T15:34:10.520+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:34:10.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T15:34:10.545+0000] {logging_mixin.py:151} INFO - [2024-07-12T15:34:10.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T15:34:10.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-12T16:08:00.892+0000] {processor.py:157} INFO - Started process (PID=8191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:08:00.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T16:08:00.895+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:08:00.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:08:00.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:08:00.938+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:08:00.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T16:08:00.957+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:08:00.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T16:08:00.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-12T16:35:07.244+0000] {processor.py:157} INFO - Started process (PID=8216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:35:07.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T16:35:07.251+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:35:07.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:35:07.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:35:07.302+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:35:07.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T16:35:07.327+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:35:07.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T16:35:07.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-12T16:52:54.787+0000] {processor.py:157} INFO - Started process (PID=8241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:52:54.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T16:52:54.790+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:52:54.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:52:54.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T16:52:54.834+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:52:54.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T16:52:54.848+0000] {logging_mixin.py:151} INFO - [2024-07-12T16:52:54.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T16:52:54.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-12T18:33:50.217+0000] {processor.py:157} INFO - Started process (PID=8266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T18:33:50.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T18:33:50.220+0000] {logging_mixin.py:151} INFO - [2024-07-12T18:33:50.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T18:33:50.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T18:33:50.259+0000] {logging_mixin.py:151} INFO - [2024-07-12T18:33:50.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T18:33:50.272+0000] {logging_mixin.py:151} INFO - [2024-07-12T18:33:50.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T18:33:50.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-12T20:14:38.299+0000] {processor.py:157} INFO - Started process (PID=8291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T20:14:38.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T20:14:38.302+0000] {logging_mixin.py:151} INFO - [2024-07-12T20:14:38.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T20:14:38.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T20:14:38.337+0000] {logging_mixin.py:151} INFO - [2024-07-12T20:14:38.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T20:14:38.350+0000] {logging_mixin.py:151} INFO - [2024-07-12T20:14:38.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T20:14:38.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-12T20:30:04.552+0000] {processor.py:157} INFO - Started process (PID=8316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T20:30:04.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T20:30:04.555+0000] {logging_mixin.py:151} INFO - [2024-07-12T20:30:04.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T20:30:04.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T20:30:04.589+0000] {logging_mixin.py:151} INFO - [2024-07-12T20:30:04.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T20:30:04.603+0000] {logging_mixin.py:151} INFO - [2024-07-12T20:30:04.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T20:30:04.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-12T21:05:16.942+0000] {processor.py:157} INFO - Started process (PID=8343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T21:05:16.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T21:05:16.945+0000] {logging_mixin.py:151} INFO - [2024-07-12T21:05:16.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T21:05:16.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T21:05:16.968+0000] {logging_mixin.py:151} INFO - [2024-07-12T21:05:16.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T21:05:16.981+0000] {logging_mixin.py:151} INFO - [2024-07-12T21:05:16.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T21:05:16.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-12T21:46:10.665+0000] {processor.py:157} INFO - Started process (PID=8368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T21:46:10.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T21:46:10.669+0000] {logging_mixin.py:151} INFO - [2024-07-12T21:46:10.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T21:46:10.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T21:46:10.715+0000] {logging_mixin.py:151} INFO - [2024-07-12T21:46:10.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T21:46:10.732+0000] {logging_mixin.py:151} INFO - [2024-07-12T21:46:10.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T21:46:10.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-12T22:02:21.258+0000] {processor.py:157} INFO - Started process (PID=8393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T22:02:21.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T22:02:21.261+0000] {logging_mixin.py:151} INFO - [2024-07-12T22:02:21.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T22:02:21.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T22:02:21.296+0000] {logging_mixin.py:151} INFO - [2024-07-12T22:02:21.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T22:02:21.311+0000] {logging_mixin.py:151} INFO - [2024-07-12T22:02:21.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T22:02:21.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-12T22:30:26.419+0000] {processor.py:157} INFO - Started process (PID=8418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T22:30:26.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T22:30:26.423+0000] {logging_mixin.py:151} INFO - [2024-07-12T22:30:26.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T22:30:26.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T22:30:26.462+0000] {logging_mixin.py:151} INFO - [2024-07-12T22:30:26.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T22:30:26.479+0000] {logging_mixin.py:151} INFO - [2024-07-12T22:30:26.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T22:30:26.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-12T23:17:06.821+0000] {processor.py:157} INFO - Started process (PID=8443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T23:17:06.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T23:17:06.824+0000] {logging_mixin.py:151} INFO - [2024-07-12T23:17:06.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T23:17:06.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T23:17:06.848+0000] {logging_mixin.py:151} INFO - [2024-07-12T23:17:06.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T23:17:06.859+0000] {logging_mixin.py:151} INFO - [2024-07-12T23:17:06.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T23:17:06.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-12T23:31:30.031+0000] {processor.py:157} INFO - Started process (PID=8470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-12T23:31:30.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-12T23:31:30.033+0000] {logging_mixin.py:151} INFO - [2024-07-12T23:31:30.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T23:31:30.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-12T23:31:30.055+0000] {logging_mixin.py:151} INFO - [2024-07-12T23:31:30.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-12T23:31:30.070+0000] {logging_mixin.py:151} INFO - [2024-07-12T23:31:30.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-12T23:31:30.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
